[
{
	"uri": "https://vatlab.github.io/vat-docs/administration/allrecent/",
	"title": "All recent changes",
	"tags": [],
	"description": "",
	"content": " Annotation.New? \u0026hellip; March 06, 2018, at 09:45 PM by ?: VtoolsReport.InbreedingCoefficient? \u0026hellip; March 06, 2018, at 09:31 PM by ?: Main.Concepts? \u0026hellip; March 06, 2018, at 06:10 PM by ?: Main.Installation? \u0026hellip; March 06, 2018, at 03:31 AM by ?: Main.HomePage \u0026hellip; March 04, 2018, at 04:52 AM by ?: Vtools.Show? \u0026hellip; September 20, 2017, at 09:16 PM by ?: Annotation.DbSNP? \u0026hellip; September 05, 2017, at 07:19 PM by Man Chong Leong?: Add more new lines Site.SideBar \u0026hellip; August 23, 2017, at 03:34 AM by ?: VtoolsReport.Sequence? \u0026hellip; February 07, 2017, at 05:42 PM by ?: Main.GetInvolved? \u0026hellip; January 06, 2017, at 04:29 PM by ?: Pipeline.HomePage? \u0026hellip; March 21, 2016, at 05:52 PM by ?: Tutorial.Case44Ctrl200? \u0026hellip; March 10, 2016, at 07:40 PM by ?: Pipeline.New? \u0026hellip; Februxary 12, 2016, at 04:44 AM by ?: Main.ChangeLog? \u0026hellip; January 21, 2016, at 02:52 AM by ?: Vtools.MutSequence? \u0026hellip; January 06, 2016, at 07:13 PM by ?: Vtools.SideBar? \u0026hellip; January 06, 2016, at 05:58 PM by ?: Vtools.OtherFunc? \u0026hellip; November 05, 2015, at 03:57 PM by ?: VMT.VMT? \u0026hellip; September 01, 2015, at 07:05 PM by ?: Tutorial.ACM-BCB2014? \u0026hellip; August 19, 2015, at 09:02 PM by ?: Pipeline.SideBar? \u0026hellip; July 02, 2015, at 02:53 AM by ?: Pipeline.Format10? \u0026hellip; June 29, 2015, at 07:19 PM by ?: Pipeline.BwaGatk33Hg19? \u0026hellip; February 26, 2015, at 05:32 PM by ?: Association.ExactTest? \u0026hellip; February 19, 2015, at 08:40 PM by ?: Vtools.Admin? \u0026hellip; February 04, 2015, at 10:34 PM by ?: Tutorial.MouseGenome? \u0026hellip; February 04, 2015, at 10:14 PM by ?: Main.Documentation? \u0026hellip; January 16, 2015, at 09:03 PM by ?: Simulation.New? \u0026hellip; January 07, 2015, at 09:05 PM by ?: Pipeline.BwaGatk28Hg19? \u0026hellip; December 18, 2014, at 09:27 PM by ?: Pipeline.HowTo? \u0026hellip; December 15, 2014, at 06:40 PM by ?: Association.ExploreAndQC? \u0026hellip; December 06, 2014, at 12:29 AM by ?: Pipeline.KING? \u0026hellip; December 05, 2014, at 07:12 PM by ?: Pipeline.BwaGatk33B37? \u0026hellip; November 07, 2014, at 10:09 PM by ?: Pipeline.AlignBwaGatk33Hg19? \u0026hellip; November 07, 2014, at 10:04 PM by ?: Pipeline.AlignBwaGatk33B37? \u0026hellip; November 07, 2014, at 10:00 PM by ?: Pipeline.AlignBwaGatk? \u0026hellip; November 07, 2014, at 08:21 PM by ?: Pipeline.BwaGatkHg19? \u0026hellip; November 07, 2014, at 06:16 PM by ?: Pipeline.BwaGatk28B37? \u0026hellip; November 07, 2014, at 06:06 PM by ?: Vtools.InTable? \u0026hellip; November 05, 2014, at 12:43 AM by ?: Association.QCPipeline? \u0026hellip; October 15, 2014, at 02:36 PM by ?: Association.SideBar? \u0026hellip; October 15, 2014, at 02:21 PM by ?: Association.HomePage? \u0026hellip; October 15, 2014, at 02:20 PM by ?: Private.Registration? \u0026hellip; October 09, 2014, at 03:54 PM by ?: Simulation.Peng2014Ex1? \u0026hellip; October 08, 2014, at 02:37 PM by ?: Simulation.Peng2014Ex2? \u0026hellip; October 08, 2014, at 02:34 PM by ?: Simulation.HomePage? \u0026hellip; September 30, 2014, at 03:45 PM by ?: Simulation.SideBar? \u0026hellip; September 20, 2014, at 05:28 PM by ?: Tutorial.ACM-BCB2014-VT? \u0026hellip; September 19, 2014, at 05:17 PM by ?: Calling.New? \u0026hellip; August 01, 2014, at 04:19 PM by ?: Annotation.LCR? \u0026hellip; July 24, 2014, at 07:14 PM by ?: Annotation.SideBar? \u0026hellip; July 24, 2014, at 07:13 PM by ?: Calling.SideBar? \u0026hellip; July 15, 2014, at 02:29 PM by ?: Simulation.Peng2011Srv? \u0026hellip; June 28, 2014, at 03:28 PM by ?: Pipeline.SnpEff? \u0026hellip; June 26, 2014, at 04:50 PM by ?: Association.Collapsing? \u0026hellip; May 08, 2014, at 02:05 PM by ?: Annotation.HomePage? \u0026hellip; May 02, 2014, at 05:11 PM by ?: Calling.BwaGatk28Hg19? \u0026hellip; April 09, 2014, at 09:07 PM by ?: Calling.BwaGatkHg19? \u0026hellip; April 03, 2014, at 07:15 PM by ?: Annotation.DbNSFP? \u0026hellip; March 21, 2014, at 04:29 PM by ?: Vtools.Phenotype? \u0026hellip; March 14, 2014, at 03:54 PM by ?: Vtools.Execute? \u0026hellip; February 26, 2014, at 03:29 AM by ?: VtoolsReport.Transmission? \u0026hellip; February 24, 2014, at 05:57 PM by ?: Pipeline.Transmission? \u0026hellip; February 24, 2014, at 05:34 PM by ?: Vtools.Init? \u0026hellip; February 23, 2014, at 06:48 AM by ?: Pipeline.Filtering? \u0026hellip; February 21, 2014, at 08:37 PM by ?: Format.SideBar? \u0026hellip; February 21, 2014, at 05:48 PM by ?: Calling.BwaGatk28B37? \u0026hellip; February 21, 2014, at 05:02 PM by ?: Vtools.Select? \u0026hellip; February 20, 2014, at 10:38 PM by ?: Vtools.Use? \u0026hellip; February 20, 2014, at 10:37 PM by ?: Vtools.Import? \u0026hellip; February 20, 2014, at 10:36 PM by ?: Vtools.Compare? \u0026hellip; February 20, 2014, at 02:03 PM by ?: Annotation.ThousandGenome? \u0026hellip; February 19, 2014, at 03:17 AM by ?: Pipeline.AnnoUtils? \u0026hellip; February 18, 2014, at 11:23 PM by ?: Utility.ReportProgress? \u0026hellip; January 29, 2014, at 07:11 PM by ?: Site.StyleSheet? \u0026hellip; January 22, 2014, at 03:34 PM by ?: Annotation.GwasCatalog? \u0026hellip; January 16, 2014, at 09:23 PM by ?: Annotation.DGV? \u0026hellip; January 16, 2014, at 09:00 PM by ?: Vtools.RefSequence? \u0026hellip; January 16, 2014, at 03:49 PM by ?: Vtools.Track? \u0026hellip; January 14, 2014, at 09:22 PM by ?: Annotation.COSMIC? \u0026hellip; January 14, 2014, at 09:10 PM by ?: Annotation.HapMap? \u0026hellip; January 14, 2014, at 03:57 PM by ?: Vtools.Samples? \u0026hellip; January 14, 2014, at 02:10 PM by ?: Vtools.Genotype? \u0026hellip; January 14, 2014, at 02:09 PM by ?: Vtools.Commands? \u0026hellip; January 14, 2014, at 01:58 PM by ?: Vtools.Export? \u0026hellip; January 11, 2014, at 03:46 AM by ?: Pipeline.ImportVcf? \u0026hellip; January 07, 2014, at 04:41 AM by ?: Format.Rsname? \u0026hellip; January 05, 2014, at 05:41 AM by ?: Format.HomePage? \u0026hellip; January 05, 2014, at 12:33 AM by ?: Association.WSS? \u0026hellip; December 20, 2013, at 06:26 PM by ?: Annotation.RutgersMap? \u0026hellip; December 17, 2013, at 04:24 AM by ?: VtoolsReport.PlotGenoFields? \u0026hellip; December 05, 2013, at 09:35 PM by ?: VtoolsReport.PlotPhenoFields? \u0026hellip; December 05, 2013, at 09:22 PM by ?: VtoolsReport.PlotFields? \u0026hellip; December 05, 2013, at 08:08 PM by ?: SiteAdmin.AutoLink? \u0026hellip; December 05, 2013, at 08:07 PM by ?: Vtools.Update? \u0026hellip; December 02, 2013, at 07:18 PM by ?: Annotation.Illumina? \u0026hellip; November 22, 2013, at 10:24 PM by ?: Calling.HomePage? \u0026hellip; November 18, 2013, at 05:16 PM by ?: Pipeline.Annovar? \u0026hellip; November 08, 2013, at 03:58 PM by ?: Annotation.HGNC? \u0026hellip; October 29, 2013, at 08:41 PM by ?: Annotation.EntrezGene? \u0026hellip; October 29, 2013, at 03:59 PM by ?: Format.Functor? \u0026hellip; October 29, 2013, at 02:57 PM by ?: Pipeline.Illumina? \u0026hellip; October 17, 2013, at 11:12 PM by ?: Association.AssociationTesting? \u0026hellip; October 17, 2013, at 06:48 PM by ?: Format.Basic? \u0026hellip; October 11, 2013, at 08:17 PM by ?: Annotation.EVS? \u0026hellip; October 09, 2013, at 08:33 PM by ?: Tutorial.QuickStart? \u0026hellip; October 08, 2013, at 12:07 AM by ?: Vtools.Output? \u0026hellip; October 04, 2013, at 04:00 AM by ?: Annotation.CancerGenomeCensus? \u0026hellip; September 19, 2013, at 06:17 PM by ?: Annotation.Tutorial? \u0026hellip; September 18, 2013, at 02:12 PM by ?: Annotation.KnownGene? \u0026hellip; September 04, 2013, at 06:07 PM by ?: Annotation.RefGene? \u0026hellip; September 04, 2013, at 05:54 PM by ?: Annotation.CcdsGene? \u0026hellip; September 04, 2013, at 05:42 PM by ?: Vtools.Associate? \u0026hellip; September 01, 2013, at 01:19 PM by ?: VtoolsReport.DiscordanceRate? \u0026hellip; September 01, 2013, at 05:34 AM by ?: Vtools.Exclude? \u0026hellip; September 01, 2013, at 05:17 AM by ?: Vtools.Remove? \u0026hellip; September 01, 2013, at 05:16 AM by ?: Utility.Md5sumd? \u0026hellip; August 25, 2013, at 05:17 AM by ?: VtoolsReport.PlotAssociation? \u0026hellip; August 25, 2013, at 05:16 AM by ?: VtoolsReport.MetaAnalysis? \u0026hellip; August 25, 2013, at 05:14 AM by ?: VtoolsReport.VariantStat? \u0026hellip; August 25, 2013, at 05:14 AM by ?: VtoolsReport.TransRatio? \u0026hellip; August 25, 2013, at 05:13 AM by ?: VtoolsReport.AvgDepth? \u0026hellip; August 25, 2013, at 05:12 AM by ?: Vtools.Liftover? \u0026hellip; August 25, 2013, at 04:50 AM by ?: Details.Variants? \u0026hellip; August 23, 2013, at 08:36 PM by ?: VtoolsReport.SamInfo? \u0026hellip; August 22, 2013, at 05:52 PM by ?: Annotation.ENCODE? \u0026hellip; August 20, 2013, at 05:52 AM by ?: Main.FAQ? \u0026hellip; July 26, 2013, at 05:05 PM by ?: Tutorial.1000Genomes? \u0026hellip; July 24, 2013, at 04:58 PM by ?: Annotation.KeggPathway? \u0026hellip; July 14, 2013, at 09:55 PM by ?: Format.New? \u0026hellip; July 11, 2013, at 08:55 PM by ?: Tutorial.Subprojects? \u0026hellip; July 11, 2013, at 04:46 AM by ?: Format.Csv? \u0026hellip; July 10, 2013, at 07:45 PM by ?: Calling.Hg19Gatk23? \u0026hellip; July 09, 2013, at 05:52 AM by ?: Annotation.PhastCons? \u0026hellip; July 07, 2013, at 04:17 PM by ?: Annotation.GenomicSuperDups? \u0026hellip; June 28, 2013, at 03:11 AM by ?: Calling.BwaGatkHg19Align? \u0026hellip; June 27, 2013, at 07:44 PM by ?: Vtools.Align? \u0026hellip; June 23, 2013, at 12:24 AM by ?: Tutorial.IlluminaFive? \u0026hellip; June 18, 2013, at 09:25 PM by ?: Utility.CallVariants? \u0026hellip; June 07, 2013, at 07:10 PM by ?: Association.RMetaSKAT? \u0026hellip; May 06, 2013, at 04:36 PM by ?: Tutorial.SelectingVariants? \u0026hellip; April 20, 2013, at 09:06 PM by ?: Details.ExportVCF? \u0026hellip; April 20, 2013, at 04:22 PM by ?: Association.RTest? \u0026hellip; April 19, 2013, at 05:31 AM by ?: Associate.RMetaSKAT? \u0026hellip; April 19, 2013, at 05:20 AM by ?: Vtools.RTest? \u0026hellip; April 19, 2013, at 04:55 AM by ?: Private.TODO? \u0026hellip; April 16, 2013, at 04:23 PM by ?: Utility.SideBar? \u0026hellip; April 03, 2013, at 04:23 AM by ?: Utility.Mmd5? \u0026hellip; April 03, 2013, at 03:44 AM by ?: VtoolsReport.SideBar? \u0026hellip; March 25, 2013, at 08:07 PM by ?: Association.SKAT? \u0026hellip; February 19, 2013, at 02:18 PM by ?: Association.SingleGene? \u0026hellip; February 13, 2013, at 12:55 AM by ?: Association.Multivariate? \u0026hellip; February 13, 2013, at 12:54 AM by ?: Association.Basic? \u0026hellip; February 11, 2013, at 10:35 PM by ?: Association.Weighted? \u0026hellip; February 06, 2013, at 12:09 AM by ?: Association.Aggregation? \u0026hellip; February 06, 2013, at 12:07 AM by ?: Association.ASUM? \u0026hellip; February 05, 2013, at 11:48 PM by ?: Association.CMC? \u0026hellip; February 05, 2013, at 11:36 PM by ?: Association.RareCover? \u0026hellip; February 05, 2013, at 11:20 PM by ?: Association.MultivariateVt? \u0026hellip; February 01, 2013, at 06:00 PM by ?: Association.VariableThresholds? \u0026hellip; February 01, 2013, at 05:57 PM by ?: Association.RBT? \u0026hellip; January 31, 2013, at 09:30 PM by ?: Association.KBAC? \u0026hellip; January 31, 2013, at 09:22 PM by ?: Association.CALPHA? \u0026hellip; January 31, 2013, at 09:20 PM by ?: Association.EREC? \u0026hellip; January 28, 2013, at 09:27 PM by ?: Tutorial.QCforAssociation? \u0026hellip; January 21, 2013, at 08:00 PM by ?: Association.PostAssociation? \u0026hellip; January 21, 2013, at 07:55 PM by ?: Vtools.CMC? \u0026hellip; January 04, 2013, at 09:45 PM by ?: Format.Tped? \u0026hellip; December 20, 2012, at 08:57 PM by ?: Format.Plink? \u0026hellip; December 19, 2012, at 05:33 PM by ?: Site.Search \u0026hellip; December 05, 2012, at 06:12 PM by ?: Hidden.Registration? \u0026hellip; December 05, 2012, at 06:08 PM by ?: Hide.Registration? \u0026hellip; December 05, 2012, at 06:08 PM by ?: Site.Redirect? \u0026hellip; December 05, 2012, at 06:46 AM by ?: Main.Registration? \u0026hellip; December 05, 2012, at 04:37 AM by ?: Private.Private? \u0026hellip; December 05, 2012, at 04:16 AM by ?: SiteAdmin.Registration? \u0026hellip; December 05, 2012, at 04:11 AM by ?: Main.ToDo? \u0026hellip; December 04, 2012, at 08:47 PM by ?: Main.GoToDownload? \u0026hellip; December 04, 2012, at 08:03 PM by ?: Mailform4.FormTemplate? \u0026hellip; December 04, 2012, at 03:49 PM by ?: Association.Test? \u0026hellip; December 04, 2012, at 01:51 AM by ?: Vtools.Concepts? \u0026hellip; November 29, 2012, at 09:13 PM by ?: Vtools.Help? \u0026hellip; November 29, 2012, at 04:28 PM by ?: Vtools.GroupFooter? \u0026hellip; November 28, 2012, at 04:34 PM by ?: Association.AssociationOverview? \u0026hellip; November 20, 2012, at 05:51 PM by ?: Main.Discovery? \u0026hellip; November 19, 2012, at 03:35 PM by ?: Main.Selection? \u0026hellip; November 17, 2012, at 02:39 AM by ?: Main.Reporting? \u0026hellip; November 16, 2012, at 08:41 PM by ?: Main.QuickStart? \u0026hellip; November 16, 2012, at 05:36 PM by ?: Association.Framework? \u0026hellip; November 16, 2012, at 05:08 PM by ?: Details.AssociationFramework? \u0026hellip; November 16, 2012, at 05:07 PM by ?: Main.Commands? \u0026hellip; November 15, 2012, at 10:13 PM by ?: Main.Vtools? \u0026hellip; November 15, 2012, at 09:14 PM by ?: VtoolsReport.Help? \u0026hellip; November 15, 2012, at 09:01 PM by ?: Simulation.Documentation? \u0026hellip; November 15, 2012, at 07:25 PM by ?: Annotation.ThousandGenomesEBI? \u0026hellip; November 15, 2012, at 07:10 PM by ?: Annotation.CytoBand? \u0026hellip; November 15, 2012, at 07:08 PM by ?: Examples.Annotation? \u0026hellip; November 15, 2012, at 07:04 PM by ?: SideBar.Annotation? \u0026hellip; November 15, 2012, at 06:53 PM by ?: VAT.VAT? \u0026hellip; November 15, 2012, at 04:15 AM by ?: VAT.SideBar? \u0026hellip; November 14, 2012, at 05:24 PM by ?: Details.Association? \u0026hellip; November 12, 2012, at 06:22 PM by ?: Tutorial.Samples? \u0026hellip; May 15, 2012, at 09:47 PM by ?: Format.ANNOVARVariantFunction? \u0026hellip; March 29, 2012, at 09:23 PM by ?: Format.ANNOVAR? \u0026hellip; March 26, 2012, at 05:32 PM by ?: Tutorial.ImportVariantsFromList? \u0026hellip; February 09, 2012, at 04:15 PM by ?: Vtools.Vtools? \u0026hellip; February 09, 2012 by ?: Tutorial.CompareVariants? \u0026hellip; February 08, 2012, at 09:21 PM by ?: Format.Map? \u0026hellip; January 25, 2012, at 03:08 AM by ?: Annotation.CancerGeneCensus? \u0026hellip; December 16, 2011, at 05:34 PM by ?: Tutorial.OneVariant? \u0026hellip; December 01, 2011, at 04:16 AM by ?: Vtools.SampleStat? \u0026hellip; November 05, 2011, at 03:45 PM by ?: Format.CGA? \u0026hellip; October 31, 2011, at 08:00 PM by ?: Vtools.Merge? \u0026hellip; October 11, 2011, at 12:51 PM by ?:  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/",
	"title": "Annotation",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/variants/cosmic/",
	"title": "COSMIC",
	"tags": [],
	"description": "",
	"content": " Catalogue of Somatic Mutations in Cancer COSMIC (Catalogue of Somatic Mutations in Cancer) is a data resource that is designed to store and display somatic mutation information and related details and contains information relating to human cancers. Data in COSMIC is curated from known Cancer Genes Literature and Systematic Screens. COSMIC data is freely downloadable in many formats on the project\u0026rsquo;s FTP site: ftp://ftp.sanger.ac.uk/pub/CGP/cosmic.\nIf you use COSMIC annotations, please credit the project with the following acknowledgement:\nThe mutation data was obtained from the Sanger Institute Catalogue Of Somatic Mutations In Cancer web site, http://www.sanger.ac.uk/cosmic. Bamford et al (2004). The COSMIC (Catalogue of Somatic Mutations in Cancer) database and website. Br J Cancer, 91,355-358.\nThere are 3 data sources that you can use to annotate vtools project variants with those from the COSMIC project. There are 2 higher-level databases that annotate variants with information such as how many cancer samples have been documented to contain the variant. These databases include a database that annotates coding mutations (CosmicCodingMuts) and a database that annotates noncoding variants (CosmicNonCodingVariants).\nThere is also a more detailed database (CosmicMutantExport) that can be linked to these higher-level databases (e.g., vtools use CosmicMutantExport --linkedby CosmicCodingMuts.COSMIC_ID or vtools use CosmicMutantExport --linked_by CosmicNonCodingVariants.COSMIC_ID) to extract detailed information about the COSMIC variant (such as variant details and details of the samples the variant was detected in). See below for the available annotation fields from these databases.\n% vtools use CosmicCodingMuts % vtools show annotation CosmicCodingMuts -v2 Annotation database CosmicCodingMuts (version v61_260912) Description: Cosmic coding mutation database. This data contains mutations affecting 10 or less nucleotides in REF. The mutation data was obtained from the Sanger Institute Catalogue Of Somatic Mutations In Cancer web site, http://www.sanger.ac.uk/cosmic. Bamford et al (2004). The COSMIC (Catalogue of Somatic Mutations in Cancer) database and website. Br J Cancer, 91,355-358. Database type: variant Number of records: 216,900 Number of distinct variants: 198,331 Reference genome hg19: ['chr', 'pos', 'ref', 'alt'] Field: chr Type: string Comment: Chromosome Missing entries: 0 Unique Entries: 25 Field: pos Type: integer Comment: 1-based position Missing entries: 0 Unique Entries: 193,076 Range: 8115 - 249212084 Field: COSMIC_ID Type: string Comment: cosmic id of mutation Missing entries: 0 Unique Entries: 216,900 Field: ref Type: string Comment: Reference allele, '-' for insertion. Missing entries: 0 Unique Entries: 1,241 Field: alt Type: string Comment: Alternative allele, '-' for deletion. Missing entries: 0 Unique Entries: 1,138 Field: gene Type: string Comment: genename Missing entries: 0 Unique Entries: 20,405 Field: strand Type: string Comment: strand Missing entries: 0 Unique Entries: 2 Field: CDS Type: string Comment: CDS annotation Missing entries: 0 Unique Entries: 65,794 Field: AA Type: string Comment: Peptide annotation Missing entries: 0 Unique Entries: 111,311 Field: CNT Type: integer Comment: Number of samples with this mutation Missing entries: 0 Unique Entries: 157 Range: 1 - 29906 % vtools use CosmicNonCodingVariants % vtools show annotation CosmicNonCodingVariants -v2 Annotation database CosmicNonCodingVariants (version v61_260912) Description: Cosmic non-coding mutation database. This data contains mutations affecting 10 or less nucleotides in REF. The mutation data was obtained from the Sanger Institute Catalogue Of Somatic Mutations In Cancer web site, http://www.sanger.ac.uk/cosmic. Bamford et al (2004). The COSMIC (Catalogue of Somatic Mutations in Cancer) database and website. Br J Cancer, 91,355-358. Database type: variant Number of records: 108,713 Number of distinct variants: 104,410 Reference genome hg19: ['chr', 'pos', 'ref', 'alt'] Field: chr Type: string Comment: Chromosome Missing entries: 0 Unique Entries: 24 Field: pos Type: integer Comment: 1-based position Missing entries: 0 Unique Entries: 104,370 Range: 13663 - 249204167 Field: COSMIC_ID Type: string Comment: cosmic id of mutation Missing entries: 0 Unique Entries: 108,713 Field: ref Type: string Comment: Reference allele, '-' for insertion. Missing entries: 0 Unique Entries: 1,251 Field: alt Type: string Comment: Alternative allele, '-' for deletion. Missing entries: 0 Unique Entries: 152 Field: gene Type: string Comment: genename Missing entries: 88,900 (81.8% of 108,713 records) Unique Entries: 7,501 Field: strand Type: string Comment: strand Missing entries: 88,900 (81.8% of 108,713 records) Unique Entries: 2 % vtools use CosmicMutantExport --linked_by CosmicCodingMuts.COSMIC_ID % vtools show annotation CosmicMutantExport -v2 Annotation database CosmicMutantExport (version v61_260912) Description: Cosmic mutant export. This data contains all coding point mutations. The mutation data was obtained from the Sanger Institute Catalogue Of Somatic Mutations In Cancer web site, http://www.sanger.ac.uk/cosmic. Bamford et al (2004). The COSMIC (Catalogue of Somatic Mutations in Cancer) database and website. Br J Cancer, 91,355-358. Database type: field Number of records: 404,865 Number of distinct entries: 224,650 Reference genome *: ['COSMIC_ID'] Field: COSMIC_ID Type: string Missing entries: 0 Unique Entries: 224,650 Field: Gene_name Type: string Missing entries: 0 Unique Entries: 20,451 Field: Accession_Number Type: string Missing entries: 0 Unique Entries: 20,403 Field: Gene_CDS_length Type: string Missing entries: 0 Unique Entries: 2,220 Field: HGNC_ID Type: string Missing entries: 0 Unique Entries: 16,990 Field: Sample_name Type: string Missing entries: 0 Unique Entries: 179,301 Field: ID_sample Type: string Missing entries: 0 Unique Entries: 183,630 Field: ID_tumour Type: string Missing entries: 0 Unique Entries: 181,851 Field: Primary_site Type: string Missing entries: 0 Unique Entries: 44 Field: Site_subtype Type: string Missing entries: 0 Unique Entries: 185 Field: Primary_histology Type: string Missing entries: 0 Unique Entries: 91 Field: Histology_subtype Type: string Missing entries: 0 Unique Entries: 417 Field: Genomewide_screen Type: string Missing entries: 0 Unique Entries: 3 Field: Mutation_ID Type: string Missing entries: 0 Unique Entries: 224,650 Field: Mutation_CDS Type: string Missing entries: 0 Unique Entries: 69,434 Field: Mutation_AA Type: string Missing entries: 0 Unique Entries: 115,530 Field: Mutation_Description Type: string Missing entries: 0 Unique Entries: 17 Field: Mutation_zygosity Type: string Missing entries: 0 Unique Entries: 4 Field: Mutation_NCBI36_genome_position Type: string Missing entries: 0 Unique Entries: 35,240 Field: Mutation_NCBI36_strand Type: string Missing entries: 0 Unique Entries: 4 Field: Mutation_GRCh37_genome_position Type: string Missing entries: 0 Unique Entries: 198,031 Field: Mutation_GRCh37_strand Type: string Missing entries: 0 Unique Entries: 4 Field: Mutation_somatic_status Type: string Missing entries: 0 Unique Entries: 7 Field: Pubmed_PMID Type: string Missing entries: 0 Unique Entries: 7,690 Field: Sample_source Type: string Missing entries: 0 Unique Entries: 30 Field: Tumour_origin Type: string Missing entries: 0 Unique Entries: 9 Field: Comments Type: string Missing entries: 0 Unique Entries: 3,202  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/development/changelog/",
	"title": "ChangeLog",
	"tags": [],
	"description": "",
	"content": " Change Log of variant tools Version 2.7.0 (Released on Jan 20, 2016) MAJOR NEW FEATURES:\n Normalize variants using reference sequence information before importing variants. New file format for spec file of variant pipeline tools. Support arbitrary reference genome.  BUG FIXES:\n Fix importing wildtype genotypes in some cases.  Version 2.6.1 (Released on Jan 15, 2015)  Fix a few small bugs introduced in 2.6.0. Fix compatibility issues with Python 3.  Version 2.6.0 (Released on Dec 15, 2014) NEW FEATURES:\n Major cleanup of the pipeline code (vtools execute and vtools simulate), especially for the pipeline action interface. Add command vtools show actions and vtools show action ACTION. Select annotation databases automatically (the latest version for project annotation database) for command vtools use annoDB when no version information is given.  Version 2.5.1 (Released on Nov 10, 2014) BUG FIX:\n Nov 1st: Fix the handling of runtime option temp_dir  NEW FEATURES:\n Nov 3rd: Add function in_table.  Version 2.5.0 (Release on Oct 15, 2014) MAJOR NEW FEATURE:\n Oct 2nd: Implement a mirrored file distribution system so that users can download resources from multiple servers. Oct 5th: Add site_options.py to allow system administrator to set up site-wide resource directory for variant tools users.  NEW FEATURES:\n Oct 5th: Add md5 signature of database files to .ann files and re-decompress .DB.gz files if the decompressed .DB files are corrupted.  Version 2.4.1 ((Released on August 20, 2014)) BUG FIX:\n Fix a python2/3 compatibility bug that prevents vtools from working properly under python2.  Version 2.4.0 (Released on August 15, 2014) MAJOR NEW FEATURE:\n June 10: Variant Simulation Tools is introduced to simulate genetic samples with common and rare variants.  NEW FEATURE:\n Mar 13: Allow the specification of a header using option --header for command vtools phenotype --from_file. May 15: Progress bar for saving and loading snapshots. May 15: Use faster compression for local compressed snapshots. May 20: Add option --translate to command to output protein sequence of genes in specified region. Jun 5: Allow the execution of many information-based commands such as vtools show annotations without a project. Jun 26: New features in pipeline allows definitions of multiple steps using one section. July 5th: Add option --build to command vtools init  BUGS:\n June 5: Allow the use of function genotype() when one or more samples do not have genotype.  Version 2.3.0 (Released on Feb 27, 2014) BUGS:\n Jan 26: Fix a bug with pipeline functor DecompressFiles when the input tar file contains directories. Feb 22: Fix a bug with wildcard match with table names having special characters such as ( or ).  NEW FEATURE:\n Feb 19: Add option --expression to command vtools compare. Feb 20: Add pipelines filtering to identify recessive and de novo mutations in families with unaffected parents and an affected offspring. Feb 20: Allow the use of snapshot files (or name of online snapshot name) as --child or --parent in command vtools init. Feb 22: Keep a copy of original variant tables when merging projects.  Version 2.2.0 (Released on Jan 16, 2014) MAJOR NEW FEATURES:\n Jan 12, 2014: Add parameters type, show_seq, delimiter, limit and strand to track() function for bam tracks. Dec 4nd: Add command vtools admin --validate_sex to check sample sex using genotypes on sex chromosomes. Dec 3nd: Add command vtools_report inbreeding_coefficient to compute individual level inbreeding coefficient, the F-statistic. Nov 15: Add sub-commands plot_fields, plot_geno_fields and plot_pheno_fields to vtools_report. These commands generate summary plots for specified variant/genotype/sample information. Dec 2nd: Add special function maf() to command vtools update --from_stat to calculate minor allele frequency.  NEW FEATURES:\n Jan 16, 2014: Update gwas catalogue annotation database. Jan 16, 2014: Add annotation databases for Database of Genomic Variation (DGV). Jan 10, 2014: Add population-specific hapmap frequency annotations. Jan 6th, 2014: Add pipeline import_vcf to import all variant and genotype info from vcf file. Jan 6th, 2014: Add pipeline anno_utils.annFileFromVcf to make it easier to create an annotation database from vcf files. Nov 22: Add an annotation database for expanded exome regions of the Illumina Nextera Rapid Capture Expanded Exome Enrichment Kits. Nov 29: Add KING pipeline to perform global ancestry and kinship analysis.  BUG FIXES:\n Jan 8: Do not abort vtools remove genotypes if genotypes from one of the samples fail to remove. Jan 4: Fix a multi-processing bug with functor FieldFromDb. Dec 2: Fix a regression bug for online vcf track. Nov 14: Fix the use of annotation field if the annotation database has the same name of a variant table. Nov 18: Fix import PLINK format to allow for arbitrary coding for unknown \u0026ldquo;sex\u0026rdquo; status in fam file. Nov 20: Properly handle meta analysis input with trailing white space in column names. Nov 27: Properly handle missing data in external weight for $vtools associate command.  Version 2.1.0 (Released on Nov. 6th) MAJOR NEW FEATURES:\n Nov 4: Add option --as to command vtools use, which allows the use of multiple versions of the same annotation databases. Oct 25: Add SQL function samples() to output samples that contain the variants. Oct 21: Add SQL function genotype() to output genotypes that contains the variants.  NEW FEATURES:\n Nov 6: Add option all=1 to parameter field of track() function and deprecate the third option. Oct 30: Add pipelines ANNOVAR and snpEff to facilitate the use of ANNOVAR and snpEff to get variant effect estimate. Oct 25: Allow the use of wildcast characters in the first (filename) parameter of the track function. Oct 22: Add descriptions to fields added to the project using command vtools update --from_stat and vtools update --set. Oct 22: Add option --delimiter to command vtools associate. Oct 17: Handle missing phenotypes more cleverly. Oct 10: Allow the output read tags and use of tags for read filtering in the track function of BAM tracks.  BUGS:\n Oct 24: Fix a bug that caused misalignment of reads in the output of BAM track when the reads are clipped in CIGAR string. Oct 11: Fix a bug related to exporting a large number of samples (\u0026gt; 60) in vcf format.  Version 2.0.1 (Released on Oct 7th, 2013) NEW FEATURES:\n Oct 5: Update dbNSFP to version 2.1. Oct 3: align columns of output of command vtools output and vtools show genotypes using variable spaces. Sep 23: Save ${local_resource} in annoDB to increase portability of projects. Sep 2: Expand command vtool compare to compare location and genotypes as well.  BUGS:\n Oct 5: Fix the vcf exporter for multiple variants at the same location. Oct 4: Fix indel track mismatch for vcf track files because position adjustment for indels. Oct 2: Fix a deadlock bug for flag info when using vcf track. Sep 18: Fix a bug in vtools admin --merge_samples. Sep 23: Fix a crash caused by unrecognized chromosome name or out of range positions in function ref_sequence. Sep 25: Fix a bug related to the use of arbitrary table name in command vtools update.  Version 2.0.0 (Released on Aug. 27, 2013) MAJOR NEW FEATURE:\n Aug. 15: Add function track to annotate variants using vcf, bigWig and bigBed tracks. Jun. 28: Add command vtools execute pipeline to execute variant tools pipelines. July 13: Add option --all to vtools output, vtools select --output and vtools export to remove duplicated lines without sorting output.  NEW FEATURE:\n Aug. 14: Add item fmt to field definitions used to output fields. Aug. 14: Add functors InfoFormatter and FlagFormatter to output fields in vcf format. Aug. 13: Add SQL functions ref_sequence. Aug. 12: Add runtime option check_update. Jul. 11: Allow .ann files to use preprocessor to process files before importing. Jul. 11: Add a preprocessor Dos2Unix to convert files with \\r as newline character to unix format. Jul. 10: Change the output of vtools show table TABLE to make it more informative. Jul. 5: Allow exporting genotypes in format csv. Jun. 29: Add a feature that allows vtools admin --rename_samples COND NAME1 NAME2 to rename samples by replacing the first incidence of NAME1 in selected samples to NAME2. Jun. 29: Add annotation database genomicSuperDups? and phast cons elements? May 24: Check duplicate genotypes after samples are imported. Jun. 25: Allow importing csv files for command vtools phenotype --from_file. Jun. 25: Add command vtools show phenotypes P1 P2. Jun. 25: Allow command vtools show samples to show a selected list of samples.  Version 1.0.6 (Released on May 16th, 2013) NEW FEATURE:\n May 16: Allow the merge of projects with different phenotypes. May 14: Adding a few fields to vcf.fmt for Illumina data. May 6: Extend vtools update --from_file to update genotype info from non-original input file, and without genotype. Apr. 15: Allow the use of wildcard characters in command vtools compare Apr. 22: Allow the merge of project with different variant tables and fields  BUG FIXES:\n May 16: Allow the use of non-ascii table name in commands vtools export and output/ May 15: Remove statistics missing from vtools phenotype because it is not meaningful. May 10: Fix runtime variable local_resource May 10: Fix importing data in binary plink format.  Version 1.0.5 (Released on Mar. 20, 2013) NEW FEATURES:\n March, 2013: Allow the use of arbitrary characters in name of variant tables. March, 2013: Add command vtools admin \u0026ndash;update_resource to download all relevant resources. March 18, 2013: Add command vtools_report sequence to output nucleotide sequence at specified chromosome region.  BUG FIXES:\n Feb 26, Fix a bug with command vtools select --samples when there are more than 50 specified samples.  Version 1.0.4 (Released on Feb 22, 2013) NEW FEATURES:\n Oct 20, 2012: Allow users to list and download online snapshots, which are used for training and documentation purposes. Oct 20, 2012: Use colors to differentiate debug, info, warning and error message. Nov 2, 2012: Define runtime option local_resource and use resources from this directory first. Nov 3, 2012: Add command vtools admin --validate_build.  Version 1.0.3 (Released on Sep 21, 2012) NEW FEATURES:\n Jul 11, 2012: Add command vtools admin --reset_runtime_option and vtools show runtime_options. Jul 4, 2012: Reorganize the association test to improve the efficiency of vtools associate. Jun 16, 2012: Reorganize the import process to substantially improve the efficiency of vtools import when it is used to import files with a large number of samples. Jun 15, 2012: Add command vtools admin --rename_table and vtools admin --describe_table to change the name and meta information of variant tables. Jun 12, 2012: Allow a comment string when a variant table is created from command vtools select, vtools exclude, and vtools compare. May 21, 2012: Add Exact Tests of Hardy-Weinberg Equilibrium? and Fisher\u0026rsquo;s exact test for case/ctrl associations to vtools update May 12, 2012: Add command vtools admin. Jan 27, 2012: Analyze project database automatically (if needed) to improve the performance of queries. Feb 29, 2012: Completion of the interface of command vtools associate Mar 1, 2012: add output formatting options --header, --na, --delimiter and --limit to vtools phenotype Mar 5, 2012: add parameter --genotypes to command vtools init --parent. (This option was defined but not implemented).  BUGS:\n Jan 27, 2012: Correctly handle missing data when exporting genotype in TPEF format Feb 9, 2012: Allow the use of single field name (e.g. ccdsid instead of dbNSFP.ccdsid) for parameter --linked_by of command vtools use Feb 17, 2012: Fix a bug with exporting deletion in vcf format, for python2 version of variant tools.  Version 1.0.2 (released on Jan 24, 2012) NEW FEATURES:\n Jan 4, 2012: add parameter --style to format tped to allow output of genotype in numeric style Jan 4, 2012: allow command vtools phenotype --from_stat to use conditions that involve variant tables in the project. Jan 23, 2012: Add a new import format map. A new functor is created to retrieve reference and alternative alleles from dbSNP.  BUGS:\n Jan 11, 2012: Fix a bug that prevents the removal of genotype in command vtools remove variant if the genotype tables are not indexed. Jan 11-13, 2012: Fix the use of vtools_report under python 3. Jan 17, 2012: Fix the use of annotation database when exporting in TPED format. Jan 23, 2012: Remove the use of COLLATE in a query to avoid potential compatibility problems. Jan 23, 2012: Fix a bug that causes duplicate output in commands vtools output and vtools export. Jan 23, 2012: Fix a bug for the detection of the existence of indexes.  Version 1.0.1 (released on Jan 2nd, 2012) NEW FEATURES:\n Nov 20, 2011: associate command can now be executed under python 3 Nov 27, 2011: Add entry encoding to .ann and .fmt in order to import files with non-ascii characters Dec 06, 2011: Give a warning when duplicated records are outputted Dec 13, 2011: Stop altering user-provided headers for command vtools output. Dec 13, 2011: Add a parameter --order_by to order output from commands select, exclude and output. Dec 13, 2011: Add a new format csv.fmt in order to output fields in csv format (with properly quoted fields) Dec 14, 2011: Add a keyword sort_output_by to file format specification in order to sort variants by specified fields. Dec 14, 2011: Allow command vtools output to read a header from standard input using option --header -. Dec 15, 2011: Add parameters anno_type and linked_fields to command vtools use in order to allow the flexibility of how an annotation database it linked. Dec 15, 2011: Beautify output of vtools show when there are multiple variant tables and annotation databases. Dec 15, 2011: Adding a new interface for command vtools compare and allow the comparison of more than two tables, using new parameters --intersection, --difference, and --union. The old interface still exits and functional, but has been marked as deprecated. Dec 28, 2011: Allow the use of wildcard characters ? and * in table names in command vtools remove tables.  DEPRECATED:\n Dec 14, 2011: Parameter filename for command vtools export is deprecated. Using a pipe to save output to a file is recommended. Dec 15, 2011: Parameter --A_and_B, --A_or_B, --A_diff_B, and --B_diff_A are deprecated. Parameters --intersection, --difference, and --union should be used instead. Dec 29, 2011: Use of name \u0026lsquo;field annotation database\u0026rsquo; instead of \u0026lsquo;attribute annotation database\u0026rsquo; for consistency considerations. Both names are however allowed in .ann file for backward compatibility considerations.  BUGS:\n Dec 15, 2011: Fix a bug when number of genotype is counted when one or more samples do not have genotype field GT. Dec 15, 2011: Fix a bug where vtools update table --set FIELD=NULL fails because variant tools cannot determine the type of the RHS value. This should be allowed when the LHS is an existing field. Jan 1, 2012: Fix vtools export --format vcf for the output of genotype when there are two different alternative alleles.  REGRESSIONS:\n Dec 14, 2011: parameter --header of command vtools export is redesigned to work similarly to parameter --header of the vtools output command.  INTERNAL IMPROVEMENTS:\n Nov 17, 2011: Improve efficiency of commands vtools compare by using direct SQL query in the case of --verbosity 0 Nov 17, 2011: Improve efficiency of vtools remove variants by creating indexes for genotype tables before removing variants. Nov 25, 2011: Improve efficiency of vtools select by creating indexes of relevant fields of the annotation database. Dec 28, 2011: Improve efficiency of commands vtools select for ranged based queries by creating auxiliary binning tables.  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/single_variant/fisher-exact-test/",
	"title": "Fisher exact test",
	"tags": [],
	"description": "",
	"content": " Fisher\u0026rsquo;s Exact Test for Single Variant Analysis Introduction Genetic association studies of common variants in case control samples usually compare directly the differences in frequencies of an allele or genotype between case and control populations, with the assumption that a significant difference in frequencies is indication to association between the locus and increase risk of disease. Many statistical tests for binomial or multinomial proportions can be used for such analysis, including Fisher\u0026rsquo;s exact test, {$\\chi^2$} test and Cochran-Armitage Trend Test. For rare variants association tests, single variant analysis will be underpowered (see Sahai H. 1996[^H. Sahai and A. Khurshid (1996) Formulas and tables for the determination of sample sizes and power in clinical trials for testing differences in proportions for the matched pair design: a review. Fundamental \u0026amp; Clinical Pharmacology doi:10.1111/j.1472-8206.1996.tb00614.x. http://doi.wiley.com/10.1111/j.1472-8206.1996.tb00614.x^] for power and sample size estimation for tests for proportions). Still single variant tests can be useful when only summary statistics is avaiable for controls (e.g., only MAF is available from public database), or one wants to compare the differences in frequency between populations for other purposes. For single variants analysis we offer the Fisher\u0026rsquo;s exact test routine which is abit conservative but guarantees type I error control for small sample sizes. Fisher\u0026rsquo;s test method in VAT is implemented as a special function for vtools update command, which is very efficient.\nFor Single variant tests adjusting for covariates, or tests for quantitative phenotypes, please refer to the multivariate methods? in VAT.\nUsage The function Fisher_exact(num_var_alleles_case, num_var_alleles_ctrl, 2*num_gt_case, 2*num_gt_ctrl) tests for association of an alternate allele with a phenotype (i.e., case or control) status. Given a variant site to be tested, the function takes in the following 4 parameters, that are obtainable through vtools functions:\n num_var_alleles_case: number of alternative alleles for the case samples num_var_alleles_ctrl: number of alternative alleles for the control samples num_gt_case: total number of genotypes for the case samples num_gt_ctrl: total number of genotypes for the control samples   Examples: Fisher\u0026rsquo;s exact test for case/ctrl association First, we compute statistics separately in cases and ctrls:\nvtools update variant --from_stat 'num_gt_case=#(GT)' 'num_var_alleles_case=#(alt)' --samples \u0026quot;filename in ('V1.vcf', 'V2.vcf')\u0026quot; Counting variants: 100% [================================] 2 69.2/s in 00:00:00 INFO: Adding field num_var_alleles_case INFO: Adding field num_gt_case Updating variant: 100% [==============================] 1,341 41.9K/s in 00:00:00 INFO: 1340 records are updated vtools update variant --from_stat \u0026quot;num_gt_ctrl=#(GT)\u0026quot; \u0026quot;num_var_alleles_ctrl=#(alt)\u0026quot; --samples \u0026quot;filename = 'V3.vcf'\u0026quot; Counting variants: 100% [===============================] 1 220.3/s in 00:00:00 INFO: Adding field num_var_alleles_ctrl INFO: Adding field num_gt_ctrl Updating variant: 100% [=============================] 988 42.7K/s in 00:00:00 INFO: 987 records are updated  And calcualte p-value for the Fisher\u0026rsquo;s exact test:\nvtools update variant --set \u0026quot;prop_pval=Fisher_exact(num_var_alleles_case, num_var_alleles_ctrl, 2*num_gt_case, 2*num_gt_ctrl)\u0026quot; INFO: Adding field prop_pva  [^#^]\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/basic_data_statistics/group_stat_write/",
	"title": "GroupStat&amp;Write",
	"tags": [],
	"description": "",
	"content": " Basic Statistics for Association Testing Units Introduction GroupStat and GroupWrite are \u0026ldquo;ancillary\u0026rdquo; features for the collection of VAT association tests. Instead of carrying out association analysis, GroupStat reports summary statistics of an association test unit such as total allele counts, total variant counts, number of samples, etc., while GroupWrite output genotype and phenotype information (into zipped bundles) in the format compatible with the SCORE-Seq software such that the data can be closely examined or manipulated using other software tools.\nAlthough the vtools export function may also write variant/genotype data into VCF and other formats with variants annotated and genotype calls cleaned after quality control, it will not be able to output result from fine-scale QC for each test unit (see the usage of? --discard_samples and --discard_variants). The GroupWrite will output the exact dataset that goes into association testing methods\nIt is recommended to run GroupStat and GroupWrite simultaneously with other association methods, as documented here?.\nDetails Command interface vtools show test GroupStat vtools show test GroupWrite Name: GroupWrite Description: Write data to disk for each testing group usage: vtools associate --method GroupWrite [-h] [--name NAME] directory Group data writer. It will create 3 files for each group: a phenotype file with rows representing samples , the 1st column is sample name, the 2nd column is the quantitative or binary phenotype and remaining columns are covariates if there are any; a genotype file with rows representing variants and the columns represent sample genotypes (order of the rows matches the genotype file). Coding of genotypes are minor allele counts (0/1/2). Missing values are denoted as NA; a mapping file that matches the group ID and variant ID in pairs. positional arguments: directory Output data will be written to the directory specified. optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields.  Application  Example using snapshot vt_ExomeAssociation\nvtools associate rare status -m \u0026quot;GroupStat ... \u0026quot; \u0026quot;GroupWrite /path/to/outputdir\u0026quot; --group_by\\ name2 --to_db gstat -j8 \u0026gt; gstat.txt  (:exampleend\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/misc/illumina/",
	"title": "Illumina",
	"tags": [],
	"description": "",
	"content": " Expanded exome regions of Nextera Rapid Capture Exome and Expanded Exome Enrichment Kits from Illumina.\nUsage % vtools show annotation Illumina_NRCE Annotation database Illumina_NRCE (version 20130307) Description: This annotation database contains expanded exome targeted regions covered by the Nextera Rapid Capture Expanded platform from illumina. Database type: range Reference genome hg19: Chromosome, Start, End Name Name of region Chromosome Start Transcription start position End Transcription end position  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/installation/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": " Download and installation 1.Installing variant tools Variant Tools / Variant Association Tools is available on Mac OSX, and posix systems such as Linux, Unix and Solaris. It is distributed under a GNU Public License (V3), which means that you are free to use, change, and share this software. Due to the nature of next-gen sequencing data, a reasonably powerful machine is needed to use this tool for real-world applications.\n1.1 Compile from source if you have a standard Python installation If you have a standard Python installation (Python 2.7.1 or Python 3.3 or higher), you can install variant tools using command pip\n% pip install variant_tools  If you already have variant tools installed and would like to update to the newest version, run\n% pip install variant_tools --upgrade  to download and compile variant tools from source.\n1.2 Direct installation for Anaconda Python If you are using anaconda python, you can install Variant Tools using command\n% conda install -c https://conda.binstar.org/bpeng variant_tools  If you already have variant tools installed, running\n% conda update -c https://conda.binstar.org/bpeng variant_tools  would update variant tools to the newest version.\n1.3 Download and compile from source code (for advanced users) If no binary distribution is available for your platform or if you would like to perform a site-wide installation (see next section), you can build variant tools from source.\nPrerequisites:  Python  Variant Tools requires Python 2.7.1 or higher, or Python 3.2 or higher. Please make sure you have the right version of python before you install Variant Tools.\nMac OSX\nMac OSX Lion (10.7) comes with Python 2.7.1, which is compatible with Variant Tools. You can also download and install Python 3 from the Python website.\nLinux\nThe latest version of Ubuntu has recent versions of Python 2 and Python 3. Redhat Linux comes with Python 2.6. You will have to upgrade it to Python 2.7, or install Python 3. Because header files are sometimes provided as separate packages, you will need to install packages such as python-dev or python3-dev (Ubuntu) if you see error messages related to missing header files. For example, Ubuntu and other debian-derived systems need to install packages python-dev, swig (if using development version), build-essential, and libbz2-dev.\n simuPOP (version 1.1.4 or higher) for the use of Variant Simulation Tools  You will need to install a recent version (1.1.4 or higher) of simuPOP if you plan to use Variant Simulation Tools to simulate data (command vtools simulate).\n A C/C++ compiler  Linux (gcc)\nGcc is generally available for all Linux systems\nMaxOS X (gcc or clang)\nFor MacOSX Lion (10.7), please install the latest version of Xcode, and Command Line Tools for Xcode if you are using Xcode 4.3.2 or later. If you wish to create Installer packages with PackageMaker, you will also need to install PackageMaker, which is in the “Auxiliary Tools for Xcode” package as of Xcode 4.3. The download page for this package can be opened via the Xcode -\u0026gt; Open Developer Tool -\u0026gt; More Developer Tools\u0026hellip; menu item. After downloading and mounting the disk image, drag the PackageMaker application to your /Applications directory.\nInstalling variant tools After downloading the variant tools package, please run\n% tar -xvzf variant_tools-VERSION.tar.gz % cd variant_tools-VERSION % (optionally, adjust site-wide options in source/site_options.py, see next section) % sudo python setup.py install  or\nsudo python3 setup.py install  if you would like to use Python 3.\nIf you get error messages for missing header files, please check if you have zlib and bzip2 library and header files installed. You might need to install packages such as bzip2-devel and zlib-devel under linux.\n Commands vtools and vtools_report in the source code directory will not work. Please move out of the installation directory and execute globally installed commands.\n 1.4 Installing variant tools locally variant tools consists of commands vtools and vtools_report, which are usually installed to /usr/local/bin. If you would like to install variant tools to a local directory, please use commands such as\n% python setup.py install --install-platlib=~/python_lib \\ --install-scripts=~/bin  In this way, the variant tools library will be installed to ~/python_lib, and the vtools and vtools_report commands will be installed to ~/bin. You will need to add ~/bin to $PATH, and set environment variables PYTHONPATH to refer to ~/python_lib so that python can find the library. If you are using bash, you can set these paths by adding the following two lines at the end of your .bashrc file:\n% export PATH=~/bin:$PATH % export PYTHONPATH=~/python_lib  1.5 Building the development version of variant tools If you would like to try the absolute newest version of variant tools, you can check out variant tools from its sourceforge git repository. Under linux, you can simply run\n% git clone git://git.code.sf.net/p/varianttools/git varianttools % cd varianttools % python setup.py install # or python3 setup.py install  If you have changed the C/C++ code, you will need to re-generate the Python wrapper using SWIG. If you are using the latest version of Ubuntu, you can get it from package swig2.0. The package SWIG under Redhat or CentOS at version 1.34 is also usable (but only for python 2).\nDue to a bug in type handling, some versions of swig (2.0.6 and 2.0.7 are confirmed) can not be used to build variant tools. Please use version 2.0.4 if you experience any swig related problem.\n 1.6 Troubleshooting 1. Error message ImportError: No module named variant_tools.\nIf you used a customized local installation by setting --install-platlib, you will have to set PYTHONPATH to the specified directory (which should contain directory variant_tools). This can be done in the .bashrc file, or in a module file if a module management system is used.\n2. Error message Failed to import module (No module named _vt_sqlite3)\nWe have noticed this problem under some special circumstances. The problem is caused by lacking read permission of .so files under /path/to/site_package/variant_tools. Using chmod o+x /path/to/site_package/variant_tools/*.so can fix the problem.\n3. Use of clang compiler under MacOSX\nIf you are using a version of Python downloaded from the Python official website, you might need to create a symbolic link of gcc as gcc-4.2 using command\n% ln -s /usr/bin/gcc /usr/bin/gcc-4.2  because these distributions are built using command \u0026ldquo;gcc-4.2\u0026rdquo;. If you do not have gcc installed, clang could be used for variant tools version 1.0.3d or later.\n4. MaxOS X MDK mismatch with non-system Python\nThe downloaded version of Python might not use the same version of Xcode and OS SDK that is available on your system. For example, the official package for Python 3.2.3 assumes a SDK path of /Developer/SDKs/MacOSX10.6.sdk, and will not work for Xcode 4.3.3 on OSX 10.7 with a SDK path of /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.7.sdk. To correct this problem, you will need to set CFLAGS explicitly, namely running\nexport CFLAGS=-sysroot,/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.7.sdk export LDFLAGS=-L/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.7.sdk/usr/lib  before you call python3 setup.py install to compile variant tools. Also, in this particular configuration, the vtools and vtools_report executables will be put under /Library/Frameworks/Python.framework/Versions/3.2/bin instead of /usr/local/bin. You will either need to add /Library/Frameworks/Python.framework/Versions/3.2/bin to $PATH, or create symbolic links of those executables to /usr/local/bin.\n2. Resource management for individual or site-wide installation 2.1 Batch download of resources The variant tools website hosts a large number of annotation databases and other resources. These files are downloaded automatically to a local resource directory (~/.variant_tools) when they are needed, and need not to be downloaded again. However, if you plan to use many of the variant tools resources and have enough disk space, you can download all variant tools resources into your local resource directory using commands\n% vtools admin --update_resource  This command by default download all current resources (e.g. most recent versions of annotation databases for latest version of reference genome). You can however using option hg18 to download resources for hg18\n% vtools admin --update resource hg18  Multiple users could share the same local resource directory if you put these files under a directory that is writable by multiple users, and set runtime option local_resource to this directory using command \u0026ldquo;vtools admin --set_runtime_option local_resource=XXX\u0026rdquo;. For example, you could download all resources to directory /Data/vtools_resource using commands\n% vtools init temp % vtools admin --set_runtime_option local_resource=/Data/vtools_resource % vtools admin --update_resource all % vtools remove project  Note that the all option will download all versions of resources for all reference genomes and can take a lot of disk spaces (about 60G as of March 2013).\nYou can set shared_resource during the variant tools installation so that you do not have to set $local_resource for each project.\n 2.2 Runtime options for site-wide installation from source code If you are a system administrator, you can change the default values of runtime options such as shared_resource, temp_dir, and search_path before installing variant tools. These options are defined in source/site_options.py. You can change them before running python setup.py install, or modify them afterwards (under a directory named similar to /usr/lib/python/lib/python2.7/site-packages/variant_tools).\n temp_dir. Users will by default use /tmp for temporary files. However, due to the size of next-gen sequencing data, /tmp might not have enough space for these files. You can set this option to a directory with more disk space if /tmp is small.\n shared_resource. A directory for shared resource files. It can be configured as\n No shared resource (default). All users maintain their own resource directory ($local_resource, which is usually ~/.variant_tools).\n A read-only directory with a mirror of the variant tools repository, with .DB.gz files decompressed in the annoDB directory. This is important because otherwise each user will have to decompress the files in their local resource directory. The system admin can choose to remove outdated databases to reduce the use of disk space. This option requires regular update of the resources.\n A directory that is writable by all users. The resources will be downloaded to this directory by users, and shared by all users. This option is easier to implement and requires less maintenance. A system administrator can choose to mirror the variant tools repository and let the users to keep it up to date.\n  search_path. This option is a ;-separated list of URL that host the variant tools repository. It should only be changed if you have created a local mirror of the variant tools repository. Adding the URL before the default URL might provide better downloading performance for your users. Removing the default URL is possible but not recommended.\n  2.3 Mirroring the variant tools repository You can mirror the variant tools repository and provide it either to local users or all users of variant tools. For example, you can run\n% vtools admin --mirror_repository /path/to/mirror  to create a local copy of the repository, and either\n add /path/to/mirror or a URL to the mirror to search_path in source/site_options.py. Users will be able to download from this mirror with better performance, or set /path/to/mirror as shared_resource so that users can use them directly. You can set this directory as read-only so that users cannot change the content of this directory.  We always look for public mirrors for our repository. Your help would be highly appreciated if you could send us the URL so that we can make it a public mirror for all variant tools users.\nThe vtools admin --mirror_repository command should be run regularly to keep the mirror updated. It is recommended that you set it up as a daily cron job.\n The variant tools repository is split into a main repository and an archive repository. You generally need only to mirror the main repository. The archive repository contains earlier versions of annotation databases that are kept for reproducibility reasons.\n "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": " Variant annotation using variant tools Annotation Functions of Variant tools Variant, info fields, and annotation fields Variants in a variant tools project are stored in a master variant table after they are imported? from external data files. Multiple variant info fields could be added to this table to describe these variant. These fields could be imported from a file? when variants are imported, or updated? from files after variants are imported, calculated from samples as sample statistics, or derived from other variant info or annotation fields. Variant info fields are part of a project and are usually project-specific.\nAnnotation fields are provided in annotation databases and are available to a project after they are linked to the project?. Conceptually, annotation databases add columns to the master variant table so that you can select variants? based on these fields, or output? variants with these annotation fields. A key difference between an variant info field and an annotation field is that variant info is unique for each variant whereas there can be multiple annotation values for a single variant. Note that annotation databases vary greatly in number of fields and coverage of variants and usually do not provide annotation for all variants.\nVariant tools commands use?, output?, and export? The annotation features of variant tools involve mostly commands vtools use, vtools output, and vtools export.\n Command vtools use creates, downloads, and links annotation databases to a project. It accepts the name of an annotation database and try to locate it locally (current directory, ~/.variant_tools), online (usually \u0026lt;a class='urllink' href='http://vtools.houstonbioinformatics.org/annoDB' rel='nofollow'\u0026gt;http://vtools.houstonbioinformatics.org/annoDB\u0026lt;/a\u0026gt;), and build an annotation database from source files if no existing database could be found. When a database is linked to a project, all its annotation fields becomes available to the project.  Command vtools show fields lists all variant info and annotation fields of a project.\n Command vtools output outputs variants in a variant table along with their info fields and annotation fields. Conceptually speaking, the master variant table and all the variant info and annotation fields form a huge table with variants as rows and fields as columns. This command outputs subsets of variants and fields to the standard output. (As an advanced feature, this command can also outputs summary statistics of variants and fields).\n Command vtools export export variant in specific formats. This command is similar to vtools output but it exports variants and related fields in user-specified formats?.\n  We will demonstrate the use of these commands in the Tutorial?.\nAnnotation databases Variant tools supports four different types of annotation databases where each type of databases links to variants using a different method. An annotation database can support one or more reference genomes and it must match either the primary or the alternative reference genome of a project to be linked to the project, unless it is a field database that annotate another field such as gene name.\nVariant-based databases Variant-based annotation databases annotate specific variants. They contain annotation information for variants (chr, pos, ref, alt). For example, the dbNSFP? database lists, among about 20 annotation fields, reference and mutated amino acid, nonsynonymous-to-synonymous-rate ratio, SIFT, PolyPhen2, MutationTaster and other scores, allele frequencies in dbSNP and the 1000 genomes project. Variant tools currently provides the following variant-based annotation databases:\n Exome Variant Server (EVS)?: NHLBI GO Exome Sequencing Project (ESP) variants with population-specific allele frequencies and various functional annotations (currently has two versions: evs was created from EVS on November 7, 2011 with approximately 2500 exomes; evs_5400 was created from EVS on December 15, 2011 with approximately 5400 exomes). dbNSFP?: non-synonymous variants of CCDS genes. dbSNP?: NCBI\u0026rsquo;s variant database. 1000 Genomes?: 1000 Genomes variants deposited in dbSNP. 1000 Genomes (provided through the European Bioinformatics Institute)?: This represents version 3 of an integrated variant call set based on both low coverage and exome whole genome sequence data from the 1000 Genomes project. Coding and NonCoding variants from the COSMIC (Catalogue Of Somatic Mutations In Cancer) Project?  Position-based databases Position-based databases annotate chromosomal locations. Such databases provide annotation for all variants at a locus, mostly because there is no variant-specific information available. For example, the gwasCatalog? database contains chromosomal locations of susceptibility loci of all published genome wide association studies.\n gwasCatalog?: this annotation source can be used to annotate your variants with published GWA hits. The database is probably more useful as a range-based database however (see example of how to use this database as a range-based database here?).  Range-based databases Range-based databases annotate regions of chromosomes. These databases are used to annotate regions of chromosomes, such as genes, exon regions of genes, and highly-conserved regions. Variant tools provides the following range-based annotation databases:\n refGene?: specifies known human protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq). knownGene?: defines gene predictions based on data from RefSeq, Genbank, CCDS and UniProt. ccdsGene?: contains high-confidence gene annotations from the Consensus Coding Sequence (CCDS) project phastCons?: defines phastCons scores (e.g., conservation scores) for blocks of the human genome. cytoBand?: gives the approximate location of cytogenic bands as seen on Giemsa-stained chromosomes. gwasCatalog?: this annotation source can be used to find published GWA hits that are \u0026ldquo;near\u0026rdquo; your variants. To use the annotation source as a range-based database, you must specify a coordinate range that describes how close your variant needs to be to the GWA hit (see example?).  Field databases Field-based annotation databases annotate variants indirectly through other variant info or annotation fields. For example, the keggPathway? database lists all the pathways genes belong so it technically annotate gene IDs, not variants. To use this database, you will need to first link the project to a database that provides IDs of genes each variant belongs, and then link the keggPathway database to the project through gene ID. Therefore, a \u0026ndash;linked_by field is required to use a field-based database. Variant tools provides the following field-based annotation databases:\n keggPathway?: allows annotation of variants to KEGG pathways indirectly by using CCDS gene IDs. As a pre-requisite, first variants need to be annotated to CCDS gene IDs - if you use dbNSFP this is already done for you because dbNSFP annotates variants to CCDS gene IDs. CancerGeneCensus?: genes for which mutations have been causally implicated in cancer, maintained by Cancer Genome Project gwasCatalog?: in addition to being used as a position- or range-based annotation source, gwasCatalog can be used as a field-based annotation source to find published GWA hits that are in the same cytoband as your project variants. To use gwasCatalog as a field-based database, you can link your variants to the cytoBand? annotation source and then annotate your variant cytoBands to published GWA hits (see example?). Detailed annotation for each COSMIC (Catalogue Of Somatic Mutations In Cancer) Mutant?  Create your own annotation databases If you would like to use an annotation database that is not provided by variant tools, you could write a customized .ann file to? create your own annotation database. This file tells variant tools the type of annotation database, reference genome, URL to source files, version, and more importantly, the type of each annotation field and how to extract them from source files. A large number of functors? are provided in case that you need to post-processing texts from input file to extract values of annotation fields.\nCitation for Variant Annotation Tools Please cite\nF. Anthony San Lucas, Gao Wang, Paul Scheet, and Bo Peng (2012) Integrated annotation and analysis of genetic variants from next-generation sequencing studies with variant tools, Bioinformatics 28 (3): 421-422.\nif you find Variant Annotation Tools helpful and use it in your publication. Thank you.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": " Variant Association Tools About Variant Association Tools (VAT), designed and developed by Gao Wang (Baylor College of Medicine), Dr. Bo Peng (the University of Texas, MD Anderson Cancer Center) and Dr. Suzanne Leal (Baylor College of Medicine), is a new developmental branch of variant tools expanding its scope from analyzing individual genomic variants to analyzing large sequence data (whole genome sequencing, whole exome sequencing) or exome genotyping arrays (exome chips) from population based genotype-phenotype association studies. It features a large collection of utilities devoted to data exploration, quality control and association analysis of rare/common single nucleotide variants and indels.\nVariant Association Tools inherits the intuitive command-line interface of variant tools with re-design and implementation of its infrastructure to accommodate the scale of dataset generated from nowadays sequencing efforts on large populations. Features of Variant Association Tools are implemented into vtools subcommand system\n vtools update, vtools phenotype and vtools_report implements data management, exploration and quality control for association studies. Various summary statistics on variants, genotypes or samples can be obtained to learn characteristics of data, to create data cleaning filters, or to provide answers to scientific hypothesis. vtools associate implements a number of rare variant association tests for rare variants association analysis. We developed a VAT ensemble method that generalizes a number of burden tests for rare variants into a unified framework.  VAT association pipeline\nAttach:association_pipeline.png\nRegistration and download variant association tools is packaged into the variant tools system, and shares its mailing list. Please refer to the installation guide? for download and installation instructions.\nCitation Please cite\nGao Wang, Bo Peng and Suzanne M. Leal (2014) Variant Association Tools for Quality Control and Analysis of Large-Scale Sequence and Genotyping Array Data, The American Journal of Human Genetics 94 (5): 770–83.\nif you find Variant Association Tools helpful and use it in your publication. Thank you.\nData Exploration and Quality Control We demonstrate data exploration and QC in a few tutorials? available from this website. You may start with the intro tutorial and move on to advanced in preparation for your real world project. Please contact us if you think additional data exploration and QC steps should be included in the VAT QC pipeline.\nAssociation Tests Statistical tests for association are implemented under vtools associate, and can be categorized as\n Single gene rare variant tests, including CMC, BRV, KBAC, WSS, RBT, VT, aSum, RareCover, c-alpha, etc; Rare variants analysis conditional on arbitrary phenotype covariates for both disease and quantitative traits, including CollapsedTest, BurdenTest, VariableThresholdsTest, WeightedBurdenTest-WSS, WeightedBurdenTest-KBAC, WeightedBurdenTest-RBT; Two flexible regression methods allowing for combination of several internal weighting themes and any arbitrary external weights (e.g., functional information) as well as the variable thresholds framework; Association testing interface to external software, including the R package SKAT and the SCORE-Seq program; Ancillary routines reporting basic statistics for association test units (GroupStat) or exporting the association data from project database (GroupWrite).  The flexible regression framework naturally supports single SNV analysis (for common variants). It also provides analysis of imputed genotype data although some weighting themes may not apply. For data with missing genotypes (either due to genotype calling failure or QC cleaning) remedies are available for several burden tests based on Auer et al 2013[^personal communication with Paul L. Auer at Fred Hutchinson Cancer Research Center^]. For implementation details of each method, please refer to this [documentation] on rare variants association methods.\nFine-scale Data Cleaning for Association Test Units Associate tests for rare variants are often carried out by units of groups, which is usually genes in the context of exome analysis. The distribution of missing genotype data in each group might be different, and as has been discussed in previous section it is recommended to perform fine-scale cleaning of missing data while running association analysis. This is implemented as options --discard_samples '%(NA)\u0026gt;p' and --discard_variants '%(NA)\u0026gt;p'. The first option will dynamically remove samples having more than a proportion of {$p$} missing genotypes within each association group; the second option will remove variant sites based on specified missingness criteria after the first option is applied.\nFor genes having too few variant sites after data cleaning, we can analyze them first yet keep a record of the actual number of variant sites that contributed to each association test unit (using GroupStat) and clean out the results for groups failing to satisfy some minimum variant sites cut-off.\nStoring and Representing Association Results Results from association analysis are available as commandline standard output which can be redirected to a file. It is also possible (and is strongly recommended) to record the results into an annotation database via --to_db option. Using a database to store the results will not only facilitate post-analysis variant selection/output conditioning on variant properties annotated by association analysis, but also make it possible to interrupt an association scan at any time and resume the analysis without having to start all over. Association results ({$p$} values) can be graphically viewed using AssociationViewer, a utility software that produces high quality QQ and Manhattan plots of {$p$} values.\n[^#^]\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/single_gene/introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": " Single gene Association Tests for Single Gene and Case Control Phenotypes The application of next-generation sequencing methods to the discovery of disease causal genes has been successful in finding rare genetic mutations responsible for a number of Mendalian disorders. There is growing evidence that rare variants contribute to the etiology of complex traits and whole genome (or exome) squencing in large populations provides valuable resource for identifying such variants. Although it is believed that effect size of rare variants to complex diseases is usually higher compare to common variants, due to the low frequency of rare variants large sample size is required to detect the effect. To improve power a number of methods have been proposed which analyze groups of variants together as a single unit. These methods are generally viewed as first moment methods (collapsing methods such as CMC, RareCover; aggregation methods such as WSS, KBAC, RBT, etc.) and second moment methods (such as {$C(\\alpha)$} and SKAT).\nMost statistical methods for rare variants were originally proposed for association analysis between single gene and case control phenotype, although many can be readily generalized into testing for association adjusting for phenotype covariates. Implementation of single gene analysis in VAT include:\n CMC method? C{$(\\alpha)$} method? KBAC method? RBT method? RareCover method? VT method? WSS method? aSum method?  These single gene analysis methods are implemented in the form as they were originally published with minimal modifications or optimizations. They are good for analyzing gene and case control phenotype associations without adjusting for covariates. Please use multivariate methods? if you want to perform conditional association analysis (--covariates option). The multivariate methods generalizes the scope of rare variant association tests to being able to handle both quantitative and case control data with flexible weighting and grouping approaches.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/simulation/introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": " Variant Simulation Tools   A presentation about variant simulation tools (Sep. 2014)  Variant Simulation Tools is still under development. Development (subversion) versions of Variant Tools and simuPOP are needed to use VST. Also, because of a lack of mature simulation models (only two examples in the submitted paper are available), users are strongly advised to contact me for the creation of any simulation model. \n1. What is Variant Simulation Tools Variant Simulation Tools (VST) is a simulation tool for post-GWAS genetic epidemiological studies using whole-genome or whole-exome next-gen sequencing data, with an emphasis on user-friendliness and reproducibility. Because simulating high-quality datasets for genetic epidemiological studies requires careful selection and validation of appropriate simulation method for particular applications, VST aims to provide validated application-specific simulation methods and simulated datasets. It distinguishes itself from other simulators in that\n VST provides multiple simulation engines for different simulation methods  Because different simulation methods have their own pros and cons and application areas, VST does not limit itself to a particular simulation method. Instead, it provides simulation engines for theoretical, forward-time, coalescent, and resampling-based simulations.\n VST separates simulation models from their implementations  VST uses a two-tier design. The core of VST is a set of functions to perform different tasks and is distributed with Variant Tools. Simulations are defined in simulation specification files that are stored in the variant tools repository. New simulations become available to all VST users as soon as they are uploaded to the repository.\n VST encourages reproducible simulations  Each VST simulation encapsulates simulation methods and parameters that have been used for a particular application. It allows no or only a few parameters to make it easy to reproduce a simulation. In addition to simulation models, VST also distribute simulated datasets for some simulation models, making it easier for casual users to explore the properties of selected simulation models.\nWhereas it is easy to reproduce an existing VST simulation, creating a new simulation in VST requires some in-depth knowledge of simuPOP and variant tools.It is strongly recommended that you discuss your simulation study with other users of VST in the varianttools-user mailing list before you write your own simulations.  You could also write to me directly if you would like to discuss your project in private.\nSchematic illustration of the role of the variant tools repository in the distribution of simulation models and simulated datasets. The repository provides simulation models and simulated datasets that can be downloaded using VST. Casual users can download simulated datasets and use them without running VST. Users who need to use a model without existing simulated datasets or need more replicates of an existing simulation can simulate data using VST. Advanced users who write their own simulation methods can choose to share their models with others by uploading their models to the repository.\n2. Key features  VST simulates real nucleotide sequences of the human genome  VST simulates human nucleotide sequences with common or rare mutations. Simulated variants (mutations) locate at specific locations of the genome (chr and pos) with reference (ref) and alternative alleles (alt). VST maps mutations to the human genome if the underlying simulation engine simulates SNP markers on hypothetical regions.\n The forward-time simulation engine knows the regions it simulate  In comparison to previous forward-time simulations that simulate hypothetical genomic regions with random fitness effect, VST * identifies all genes (isoforms) that locate within or overlap with the user-provided regions, locates exons, coding regions, and codons on the forward and reverse strands. * recombine parental chromosomes using a fine-scale genetic map with recombination rates and hotspots provided by the HapMap project * use a nucleotide mutation model to introduce new mutants to the population * determine the fitness of individuals from amino-acid changes of the translated protein sequences\n VST supports a large number of penetrance and quantitative trait models and sampling methods  The flexible design of VST allows the application of very complex penetrance and quantitative trait models to the simulated population and draw random, case control, extreme trait, and pedigree-based samples.\n Datasets simulated by VST could be exported in VCF format, or analyzed directly using Variant Association Tools  Simulated datasets could be exported and analyzed by other programs, or imported into a variant tools project and analyzed directly using Variant Association Tools.\n3. Basic usages of VST 3.1 Step 1: check available simulation models After installing variant tools, run\n% vtools show simulations Peng2011_srv Re-implementation of some of the simulations performed by SRV (Peng \u0026amp; Liu, Simulating Sequences of the Human Genome with Rare Variants, 2011). Peng2014_ex1 Simulations of DNA sequences in specified regions using different simulation methods, for the first example in paper \u0026quot;Reproducible Simulations of realistic samples for next-gen sequencing studies using Variant Simulation Tools\u0026quot;. The simulated populations are analyzed and discarded to save diskspace. ... ...  to get a list of available simulation models.\nIf you cannot find a simulation model that fits your need, please write to the [varianttools-user mailing list][7] and check if others have performed similar simulations using VST. You could also [write to me][4] directly for potential collaboration on simulation part of your study.\n 3.2 Step 2: Learn the details of a simulation model A simulation specification file can define multiple simulation models. Command vtools show simulation SPECFILE lists all simulation models defined in SPECFILE and their descriptions, include parameters they accept.\n% vtools show simulation Peng2014_ex1 Simulations of DNA sequences in specified regions using different simulation methods, for the first example in paper \u0026quot;Reproducible Simulations of realistic samples for next-gen sequencing studies using Variant Simulation Tools\u0026quot;. The simulated populations are analyzed and discarded to save diskspace. Available simulation models: ms, neutral, resample, with_selection Model \u0026quot;ms\u0026quot;: This simulator calls ms to execute coalescent-based simulations, create a population with simulated dataset and run through the same statistical analysis as other pipeline. ms_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. ms_5: Check the existence of command ms ms_10: Create a new project if there is no existing project under the current directory. ms_20: Execute ms. NOTE that these parameters only matches the parameters used in example 1 of Peng 2014. ms_30: Create an empty simuPOP population for specified regions and import ms-simulated genotypes. The segregating sites are distributed within the specified region according to the positions (float numbers from 0 to 1) assigned by ms. Mutants are assumed to be from A-\u0026gt;C, C-\u0026gt;G, G-\u0026gt;T and T-\u0026gt;A for bases A, C, G and T respectively. ms_50: Get allele frequency spectrum in a sample of 700 individuals. ms_999: Remove intermediate populations to save diskspace. Model \u0026quot;neutral\u0026quot;: A neutral simulation using a Juke-Cantor (1969) DNA nucleotide mutation model, a mutation rate of 1.8x10^-8, a fine-scale recombination map, a demographic model that mimicks the European population, and no natural selelction. neutral_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. neutral_10: Create a new project if there is no existing project under the current directory. neutral_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. neutral_30: Create an empty simuPOP population for specified regions. neutral_40: Evolve and expand the population using a JC69 mutation model and a demographic model that evolves a population of size 8100 for 81000 generations before it is expanded to size 900000 in 370 generations. neutral_50: Get allele frequency spectrum in a sample of 700 individuals. neutral_999: Remove intermediate populations to save diskspace. Model \u0026quot;resample\u0026quot;: A simulation model that extracts genotypes within the sepecified regions from the 1000 genomes project, and expands it very rapidly to mimick a resampling-based simulation. resample_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. resample_10: Create a new project if there is no existing project under the current directory. resample_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. resample_25: Extract genotypes of specified regions from 1000 genomes project. No dependency check will be performed so the extracted file can be used by other projects if you put is to a place accessible by other projects. Location of the extracted file can be specified by option --extracted_file. resample_30: Create an empty simuPOP population for specified regions. resample_40: Expand the population exponentially to reach a large population in 10 generations. Mutations and recombinations are allowed and a selection model that only select against stopgain mutations are used. resample_50: Get allele frequency spectrum in a sample of 700 individuals. resample_999: Remove intermediate populations to save diskspace. Model \u0026quot;with_selection\u0026quot;: A simulation that uses identical models as the neutral model but use a protein selection model with selection pressure 0.005, 0.02 and 0.1 for missense, stoploss and stopgain mutations. with_selection_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. with_selection_10: Create a new project if there is no existing project under the current directory. with_selection_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. with_selection_30: Create an empty simuPOP population for specified regions. with_selection_40: Evolve and expand the population using a JC69 mutation model and a demographic model that evolves a population of size 8100 for 81000 generations before it is expanded to size 900000 in 370 generations. with_selection_50: Get allele frequency spectrum in a sample of 700 individuals. with_selection_999: Remove intermediate populations to save diskspace. Model parameters: regions One or more chromosome regions (separated by ',') in the format of chr:start-end (e.g. chr21:33031597-33041570), or Field:Value from a region-based annotation database (e.g. refGene.name2:TRIM2 or refGene_exon.name:NM_000947). Please visit http://varianttools.sourceforge.net/Simulation for detailed description of this parameter. (default: chr17:41200001-41263000) scale Scaling factor to speed up the simulation by scaling down the simulation while boosting mutation, selection and recombination rates. (default: 10) extracted_vcf Filename (with dir) to save genotypes (.vcf file extracted by tabix command) for the resample model. This file will be automatically created and reused if it already exists. You will need to remove this file if you run the same pipeline using another region. (default: extracted.vcf)  3.3 Step 3: Perform simulations % vtools simulate -h usage: vtools simulate [-h] [--seed SEED] [--replicates REPLICATES] [-j JOBS] [-v {0,1,2}] SPECFILE [MODELS [MODELS ...]] Simulate case control or family-based samples using specified simulation models. positional arguments: SPECFILE Name of a model specification file, which can be the name of an online specification file, or path to a local .pipeline file. Please use command \u0026quot;vtools show simulations\u0026quot; to get a list all available simulation models. MODELS Name of one or more simulation models defined in SPECFILE, which can be ignored if the SPECFILE only defines one simulation model. Please use command \u0026quot;vtools show simulation SPECFILE\u0026quot; for details of available models in SPECFILE, including model-specific parameters that could be used to change the default behavior of these models. optional arguments: -h, --help show this help message and exit --seed SEED Random seed for the simulation. A random seed will be used by default but a specific seed could be used to reproduce a previously executed simulation. --replicates REPLICATES Number of consecutive replications to simulate -j JOBS, --jobs JOBS Maximum number of concurrent jobs to execute, for steps of a pipeline that allows multi-processing. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1).  Each simulation specification file can contain more than one simulation models. You can use commands such as\n% vtools simulate Peng2014_ex1 neutral  to perform one of them. Some models accept parameters. For example, the following command performs the simulation on gene BRCA1 with locations defined in the refGene database.\n% vtools simulate Peng2014_ex1 neutral --regions refGene.name2:BRCA1 INFO: Starting simulation cache/Peng2014_ex1_neutral_273426005.cfg INFO: Executing Peng2014_ex1.neutral_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. INFO: Executing Peng2014_ex1.neutral_10: Create a new project if there is no existing project under the current directory. INFO: Executing Peng2014_ex1.neutral_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. INFO: Running vtools use refGene INFO: Downloading annotation database from annoDB/refGene.ann INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/refGene-hg19_20130904.DB.gz INFO: Using annotation DB refGene as refGene in project Peng2014_ex1. INFO: Known human protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq). INFO: Command \u0026quot;vtools use refGene\u0026quot; completed successfully in 00:00:01 INFO: Executing Peng2014_ex1.neutral_30: Create an empty simuPOP population for specified regions. INFO: Regions to be simulated (81189 bp): 17:41196312-41277500 INFO: Saving created population to cache/ex1_neutral_init_273426005.pop INFO: Executing Peng2014_ex1.neutral_40: Evolve and expand the population using a JC69 mutation model and a demographic model that evolves a population of size 8100 for 81000 generations before it is expanded to size 900000 in 370 generations. INFO: Regions to be simulated (81189 bp): 17:41196312-41277500 INFO: Simulated regions with 81,189 basepair have 23,556 A, 17,899 C, 16,955 G, 22,779 T, and 0 N on reference genome. INFO: Regions to be simulated (81189 bp): 17:41196312-41277500 INFO: Map distance of 71 markers within region 17:41196312-41277500 are found INFO: Total map distance from 17:41196312-41277500 (81189 bp) is 4.0144e-03 cM (r=4.9446e-08/bp) INFO: Start evolving... Statistics outputted are 1. Generation number, 2. population size (a list), 3. number of segregation sites, 4. average number of mutants per individual 5. average allele frequency * 100 6. average fitness value 7. minimal fitness value of the parental population INFO: 1690 [810] 285 60.677778 10.645224 0.000000 0.000000 INFO: 3030 [810] 307 73.462963 11.964652 0.000000 0.000000 INFO: 4275 [810] 305 82.586420 13.538757 0.000000 0.000000 INFO: 5393 [810] 371 108.137037 14.573725 0.000000 0.000000 INFO: 6433 [810] 324 102.554321 15.826284 0.000000 0.000000 INFO: 7620 [810] 325 92.483951 14.228300 0.000000 0.000000 INFO: 8040 [810] 358 95.301235 13.310228 0.000000 0.000000 INFO: 8137 [90000] 5614 99.777544 0.888649 0.000000 0.000000 INFO: Simulated population has 90000 individuals, 5614 segregation sites. There are on average 99.0 mutants per individual. Mean allele frequency is 0.8886%. INFO: Population simulation takes 219.77 seconds INFO: Executing Peng2014_ex1.neutral_50: Get allele frequency spectrum in a sample of 700 individuals. INFO: Loading population from ex1_neutral_evolved_273426005.pop INFO: Executing Peng2014_ex1.neutral_999: Remove intermediate populations to save diskspace. INFO: Replace ex1_neutral_evolved_273426005.pop with ex1_neutral_evolved_273426005.pop.file_info INFO: Replace cache/ex1_neutral_init_273426005.pop with cache/ex1_neutral_init_273426005.pop.file_info  4. Some technical details 4.1 Option --seed and --replicates A random seed will be used by default for each simulation. For each simulation, a file cache/MODEL_SEED.cfg will be created as the input file for the execution of the simulation pipeline. You can, however, use the --seed option to specify the seed of the simulation to reproduce a previous simulation.\nFor reproducibility reasons, all simulated datasets provided my VST will be simulated with seeds 1, 2, 3, \u0026hellip;.\n The vtools simulate command by default only simulates one replicate of the simulation. It will repeat itself a number of times if option --replicates is specified. SEED, SEED+1, SEED+2 etc will be used as seed for subsequent simulations.\nIf you need to run multiple instances of VST at the same time, please use separate directories for different instances of the vtools simulate command.\n 4.2 Specification of regions (option --regions) Because VST simulates true genomic regions of the human genome, a key parameter of many simulation models is --regions. You can, for example, pass a region in chr:start-end format as\n--regions chr17:540000-570000  or multiple regions as\n--regions chr17:540000-570000,20000-210000,chr20:123450-134500  Here multiple regions are separated by \u0026ldquo;,\u0026rdquo;, and chromosome name can be ignored if it is the same as the previous region.\nMore interestingly, you can use value of a field-based annotation database to specify regions. For example,\n--regions refGene.name2:BRCA1  locates all genes (isoforms) in the refGene database with common name name2 equals to BRCA1. You can specify regions for multiple genes using\n--regions refGene.name2:BRCA1,BRCA2,P53  You can use a different annotation database for this purpose. For example\n% vtools simulate MODELFILE MODEL --regions refGene_exon.name2:BRCA1,BRCA2  simulates exon regions of BRCA1 and BRCA2. Command vtools use refGene_exon will be automatically called if refGene_exon is not linked to the current project.\nThe --regions option allows the use of set operations (|, \u0026amp;, -, and ^ for union, intersection, difference, and symmetric difference, respectively) to modify specified regions. For example, if you need to specify intron regions of a gene, you can use\n--regions 'refGene.name2:BRCA1 - refGene_exon.name2:BRCA1'  Another example would be to limit, for example, a penetrance model to certain chromosome regions:\n--regions 'refGene.name2:BRCA1 \u0026amp; chr17:41196312-41200000'  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/simulation/introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": " Variant Simulation Tools A presentation about variant simulation tools (Sep. 2014)\nVariant Simulation Tools is still under development. Development (subversion) versions of Variant Tools and simuPOP are needed to use VST. Also, because of a lack of mature simulation models (only two examples in the submitted paper are available), users are strongly advised to contact me for the creation of any simulation model.\nWhat is Variant Simulation Tools Variant Simulation Tools (VST) is a simulation tool for post-GWAS genetic epidemiological studies using whole-genome or whole-exome next-gen sequencing data, with an emphasis on user-friendliness and reproducibility. Because simulating high-quality datasets for genetic epidemiological studies requires careful selection and validation of appropriate simulation method for particular applications, VST aims to provide validated application-specific simulation methods and simulated datasets. It distinguishes itself from other simulators in that\n VST provides multiple simulation engines for different simulation methods  Because different simulation methods have their own pros and cons and application areas, VST does not limit itself to a particular simulation method. Instead, it provides simulation engines for theoretical, forward-time, coalescent, and resampling-based simulations.\n VST separates simulation models from their implementations  VST uses a two-tier design. The core of VST is a set of functions to perform different tasks and is distributed with Variant Tools. Simulations are defined in simulation specification files that are stored in the variant tools repository. New simulations become available to all VST users as soon as they are uploaded to the repository.\n VST encourages reproducible simulations  Each VST simulation encapsulates simulation methods and parameters that have been used for a particular application. It allows no or only a few parameters to make it easy to reproduce a simulation. In addition to simulation models, VST also distribute simulated datasets for some simulation models, making it easier for casual users to explore the properties of selected simulation models.\nWhereas it is easy to reproduce an existing VST simulation, creating a new simulation? in VST requires some in-depth knowledge of simuPOP and variant tools. It is strongly recommended that you discuss your simulation study with other users of VST in the varianttools-user mailing list before you write your own simulations. You could also write to me directly if you would like to discuss your project in private.\nAttach:repository.jpg\nSchematic illustration of the role of the variant tools repository in the distribution of simulation models and simulated datasets. The repository provides simulation models and simulated datasets that can be downloaded using VST. Casual users can download simulated datasets and use them without running VST. Users who need to use a model without existing simulated datasets or need more replicates of an existing simulation can simulate data using VST. Advanced users who write their own simulation methods can choose to share their models with others by uploading their models to the repository.\nKey features  VST simulates real nucleotide sequences of the human genome  VST simulates human nucleotide sequences with common or rare mutations. Simulated variants (mutations) locate at specific locations of the genome (chr and pos) with reference (ref) and alternative alleles (alt). VST maps mutations to the human genome if the underlying simulation engine simulates SNP markers on hypothetical regions.\n The forward-time simulation engine knows the regions it simulate  In comparison to previous forward-time simulations that simulate hypothetical genomic regions with random fitness effect, VST * identifies all genes (isoforms) that locate within or overlap with the user-provided regions, locates exons, coding regions, and codons on the forward and reverse strands. * recombine parental chromosomes using a fine-scale genetic map with recombination rates and hotspots provided by the HapMap project * use a nucleotide mutation model to introduce new mutants to the population * determine the fitness of individuals from amino-acid changes of the translated protein sequences\n VST supports a large number of penetrance and quantitative trait models and sampling methods  The flexible design of VST allows the application of very complex penetrance and quantitative trait models to the simulated population and draw random, case control, extreme trait, and pedigree-based samples.\n Datasets simulated by VST could be exported in VCF format, or analyzed directly using Variant Association Tools  Simulated datasets could be exported and analyzed by other programs, or imported into a variant tools project and analyzed directly using Variant Association Tools?.\nBasic usages of VST Step 1: check available simulation models After installing variant tools?, run\n% vtools show simulations Peng2011_srv Re-implementation of some of the simulations performed by SRV (Peng \u0026amp; Liu, Simulating Sequences of the Human Genome with Rare Variants, 2011). Peng2014_ex1 Simulations of DNA sequences in specified regions using different simulation methods, for the first example in paper \u0026quot;Reproducible Simulations of realistic samples for next-gen sequencing studies using Variant Simulation Tools\u0026quot;. The simulated populations are analyzed and discarded to save diskspace. ... ...  to get a list of available simulation models.\nIf you cannot find a simulation model that fits your need, please write to the varianttools-user mailing list and check if others have performed similar simulations using VST. You could also write to me directly for potential collaboration on simulation part of your study.\nStep 2: Learn the details of a simulation model A simulation specification file can define multiple simulation models. Command vtools show simulation SPECFILE lists all simulation models defined in SPECFILE and their descriptions, include parameters they accept.\n% vtools show simulation Peng2014_ex1 Simulations of DNA sequences in specified regions using different simulation methods, for the first example in paper \u0026quot;Reproducible Simulations of realistic samples for next-gen sequencing studies using Variant Simulation Tools\u0026quot;. The simulated populations are analyzed and discarded to save diskspace. Available simulation models: ms, neutral, resample, with_selection Model \u0026quot;ms\u0026quot;: This simulator calls ms to execute coalescent-based simulations, create a population with simulated dataset and run through the same statistical analysis as other pipeline. ms_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. ms_5: Check the existence of command ms ms_10: Create a new project if there is no existing project under the current directory. ms_20: Execute ms. NOTE that these parameters only matches the parameters used in example 1 of Peng 2014. ms_30: Create an empty simuPOP population for specified regions and import ms-simulated genotypes. The segregating sites are distributed within the specified region according to the positions (float numbers from 0 to 1) assigned by ms. Mutants are assumed to be from A-\u0026gt;C, C-\u0026gt;G, G-\u0026gt;T and T-\u0026gt;A for bases A, C, G and T respectively. ms_50: Get allele frequency spectrum in a sample of 700 individuals. ms_999: Remove intermediate populations to save diskspace. Model \u0026quot;neutral\u0026quot;: A neutral simulation using a Juke-Cantor (1969) DNA nucleotide mutation model, a mutation rate of 1.8x10^-8, a fine-scale recombination map, a demographic model that mimicks the European population, and no natural selelction. neutral_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. neutral_10: Create a new project if there is no existing project under the current directory. neutral_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. neutral_30: Create an empty simuPOP population for specified regions. neutral_40: Evolve and expand the population using a JC69 mutation model and a demographic model that evolves a population of size 8100 for 81000 generations before it is expanded to size 900000 in 370 generations. neutral_50: Get allele frequency spectrum in a sample of 700 individuals. neutral_999: Remove intermediate populations to save diskspace. Model \u0026quot;resample\u0026quot;: A simulation model that extracts genotypes within the sepecified regions from the 1000 genomes project, and expands it very rapidly to mimick a resampling-based simulation. resample_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. resample_10: Create a new project if there is no existing project under the current directory. resample_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. resample_25: Extract genotypes of specified regions from 1000 genomes project. No dependency check will be performed so the extracted file can be used by other projects if you put is to a place accessible by other projects. Location of the extracted file can be specified by option --extracted_file. resample_30: Create an empty simuPOP population for specified regions. resample_40: Expand the population exponentially to reach a large population in 10 generations. Mutations and recombinations are allowed and a selection model that only select against stopgain mutations are used. resample_50: Get allele frequency spectrum in a sample of 700 individuals. resample_999: Remove intermediate populations to save diskspace. Model \u0026quot;with_selection\u0026quot;: A simulation that uses identical models as the neutral model but use a protein selection model with selection pressure 0.005, 0.02 and 0.1 for missense, stoploss and stopgain mutations. with_selection_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. with_selection_10: Create a new project if there is no existing project under the current directory. with_selection_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. with_selection_30: Create an empty simuPOP population for specified regions. with_selection_40: Evolve and expand the population using a JC69 mutation model and a demographic model that evolves a population of size 8100 for 81000 generations before it is expanded to size 900000 in 370 generations. with_selection_50: Get allele frequency spectrum in a sample of 700 individuals. with_selection_999: Remove intermediate populations to save diskspace. Model parameters: regions One or more chromosome regions (separated by ',') in the format of chr:start-end (e.g. chr21:33031597-33041570), or Field:Value from a region-based annotation database (e.g. refGene.name2:TRIM2 or refGene_exon.name:NM_000947). Please visit http://varianttools.sourceforge.net/Simulation for detailed description of this parameter. (default: chr17:41200001-41263000) scale Scaling factor to speed up the simulation by scaling down the simulation while boosting mutation, selection and recombination rates. (default: 10) extracted_vcf Filename (with dir) to save genotypes (.vcf file extracted by tabix command) for the resample model. This file will be automatically created and reused if it already exists. You will need to remove this file if you run the same pipeline using another region. (default: extracted.vcf)  Step 3: Perform simulations % vtools simulate -h usage: vtools simulate [-h] [--seed SEED] [--replicates REPLICATES] [-j JOBS] [-v {0,1,2}] SPECFILE [MODELS [MODELS ...]] Simulate case control or family-based samples using specified simulation models. positional arguments: SPECFILE Name of a model specification file, which can be the name of an online specification file, or path to a local .pipeline file. Please use command \u0026quot;vtools show simulations\u0026quot; to get a list all available simulation models. MODELS Name of one or more simulation models defined in SPECFILE, which can be ignored if the SPECFILE only defines one simulation model. Please use command \u0026quot;vtools show simulation SPECFILE\u0026quot; for details of available models in SPECFILE, including model-specific parameters that could be used to change the default behavior of these models. optional arguments: -h, --help show this help message and exit --seed SEED Random seed for the simulation. A random seed will be used by default but a specific seed could be used to reproduce a previously executed simulation. --replicates REPLICATES Number of consecutive replications to simulate -j JOBS, --jobs JOBS Maximum number of concurrent jobs to execute, for steps of a pipeline that allows multi-processing. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1).  Each simulation specification file can contain more than one simulation models. You can use commands such as\n% vtools simulate Peng2014_ex1 neutral  to perform one of them. Some models accept parameters. For example, the following command performs the simulation on gene BRCA1 with locations defined in the refGene database.\n% vtools simulate Peng2014_ex1 neutral --regions refGene.name2:BRCA1 INFO: Starting simulation cache/Peng2014_ex1_neutral_273426005.cfg INFO: Executing Peng2014_ex1.neutral_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. INFO: Executing Peng2014_ex1.neutral_10: Create a new project if there is no existing project under the current directory. INFO: Executing Peng2014_ex1.neutral_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. INFO: Running vtools use refGene INFO: Downloading annotation database from annoDB/refGene.ann INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/refGene-hg19_20130904.DB.gz INFO: Using annotation DB refGene as refGene in project Peng2014_ex1. INFO: Known human protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq). INFO: Command \u0026quot;vtools use refGene\u0026quot; completed successfully in 00:00:01 INFO: Executing Peng2014_ex1.neutral_30: Create an empty simuPOP population for specified regions. INFO: Regions to be simulated (81189 bp): 17:41196312-41277500 INFO: Saving created population to cache/ex1_neutral_init_273426005.pop INFO: Executing Peng2014_ex1.neutral_40: Evolve and expand the population using a JC69 mutation model and a demographic model that evolves a population of size 8100 for 81000 generations before it is expanded to size 900000 in 370 generations. INFO: Regions to be simulated (81189 bp): 17:41196312-41277500 INFO: Simulated regions with 81,189 basepair have 23,556 A, 17,899 C, 16,955 G, 22,779 T, and 0 N on reference genome. INFO: Regions to be simulated (81189 bp): 17:41196312-41277500 INFO: Map distance of 71 markers within region 17:41196312-41277500 are found INFO: Total map distance from 17:41196312-41277500 (81189 bp) is 4.0144e-03 cM (r=4.9446e-08/bp) INFO: Start evolving... Statistics outputted are 1. Generation number, 2. population size (a list), 3. number of segregation sites, 4. average number of mutants per individual 5. average allele frequency * 100 6. average fitness value 7. minimal fitness value of the parental population INFO: 1690 [810] 285 60.677778 10.645224 0.000000 0.000000 INFO: 3030 [810] 307 73.462963 11.964652 0.000000 0.000000 INFO: 4275 [810] 305 82.586420 13.538757 0.000000 0.000000 INFO: 5393 [810] 371 108.137037 14.573725 0.000000 0.000000 INFO: 6433 [810] 324 102.554321 15.826284 0.000000 0.000000 INFO: 7620 [810] 325 92.483951 14.228300 0.000000 0.000000 INFO: 8040 [810] 358 95.301235 13.310228 0.000000 0.000000 INFO: 8137 [90000] 5614 99.777544 0.888649 0.000000 0.000000 INFO: Simulated population has 90000 individuals, 5614 segregation sites. There are on average 99.0 mutants per individual. Mean allele frequency is 0.8886%. INFO: Population simulation takes 219.77 seconds INFO: Executing Peng2014_ex1.neutral_50: Get allele frequency spectrum in a sample of 700 individuals. INFO: Loading population from ex1_neutral_evolved_273426005.pop INFO: Executing Peng2014_ex1.neutral_999: Remove intermediate populations to save diskspace. INFO: Replace ex1_neutral_evolved_273426005.pop with ex1_neutral_evolved_273426005.pop.file_info INFO: Replace cache/ex1_neutral_init_273426005.pop with cache/ex1_neutral_init_273426005.pop.file_info  Some technical details Option --seed and --replicates A random seed will be used by default for each simulation. For each simulation, a file cache/MODEL_SEED.cfg will be created as the input file for the execution of the simulation pipeline. You can, however, use the --seed option to specify the seed of the simulation to reproduce a previous simulation.\nFor reproducibility reasons, all simulated datasets provided my VST will be simulated with seeds 1, 2, 3, \u0026hellip;.\nThe vtools simulate command by default only simulates one replicate of the simulation. It will repeat itself a number of times if option --replicates is specified. SEED, SEED+1, SEED+2 etc will be used as seed for subsequent simulations.\nIf you need to run multiple instances of VST at the same time, please use separate directories for different instances of the vtools simulate command.\nSpecification of regions (option --regions) Because VST simulates true genomic regions of the human genome, a key parameter of many simulation models is --regions. You can, for example, pass a region in chr:start-end format as\n--regions chr17:540000-570000  or multiple regions as\n--regions chr17:540000-570000,20000-210000,chr20:123450-134500  Here multiple regions are separated by \u0026ldquo;,\u0026rdquo;, and chromosome name can be ignored if it is the same as the previous region.\nMore interestingly, you can use value of a field-based annotation database to specify regions. For example,\n--regions refGene.name2:BRCA1  locates all genes (isoforms) in the refGene database with common name name2 equals to BRCA1. You can specify regions for multiple genes using\n--regions refGene.name2:BRCA1,BRCA2,P53  You can use a different annotation database for this purpose. For example\n% vtools simulate MODELFILE MODEL --regions refGene_exon.name2:BRCA1,BRCA2  simulates exon regions of BRCA1 and BRCA2. Command vtools use refGene_exon will be automatically called if refGene_exon is not linked to the current project.\nThe --regions option allows the use of set operations (|, \u0026amp;, -, and ^ for union, intersection, difference, and symmetric difference, respectively) to modify specified regions. For example, if you need to specify intron regions of a gene, you can use\n--regions 'refGene.name2:BRCA1 - refGene_exon.name2:BRCA1'  Another example would be to limit, for example, a penetrance model to certain chromosome regions:\n--regions 'refGene.name2:BRCA1 \u0026amp; chr17:41196312-41200000'  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": " Calling variants using BWA and GATK best practice pipeline Usage This pipeline is deprecated because version 2.3 of the GATK resource bundle is no longer available.\n% vtools show pipeline bwa_gatk_hg19 A pipeline to align raw reads from fastq or BAW/SAM files using BWA and GATK best practice. It uses hg19 of human reference genome and assumes paired-end reads in plain text and compressed formats. Available pipelines: align, call Pipeline \u0026quot;align\u0026quot;: Align raw reads from input files using bwa, gatk, and picard. This pipeline accepts raw input files in plain text format, SAM/BAM format, and their compressed versions (.zip, .tar.gz, .tgz, .bz2, .tbz2 etc). All input files are assumed to be raw reads from the same sample. This pipeline generates a calibrated bam file (--output), and its reduced version if an additional output file is specified. align_0: Check the version of variant tools (version 2.1.1 and above is required to execute this pipeline) align_1: Download required resources to resource directory align_10: Check existence of commands bwa, samtools and java align_11: Check the version of bwa. Version is 0.7.4 is recommended align_12: Check the version of picard. Version is 1.82 is recommended. align_13: Check the version of GATK. Version 2.4 is recommended. align_20: Check existence of class files for Picard and GATK align_30: Build bwa index for build hg19 of reference genome align_40: Build samtools index for build hg19 of reference genome align_100: Convert bam files to paired fastq files if the input is in bam/sam format. Other input files are returned untouched. align_101: Decompress all input files (.tgz2, .tar, .tar.gz, .gz, .tgz, .zip etc) to a cache directory. Uncompressed files are hard-linked to the cache directory. align_200: Check the format of the input fastq file and write an option file with option -I if the sequences are in Illumina 1.3+ format. align_201: Call bwa aln to produce .sai files align_300: Determine (guess) a read group tag and write to a .RG file. align_301: Running bwa sampe for paired end reads, using read group tag saved in a .RG file align_302: Check the proportion of aligned reads and exit if there are less than 80% of aligned reads. align_400: Merge per-lane sam files into a single bam file. This step is skipped if there is only one input file. align_500: Sort merged bam file using picard SortSam align_501: If in production mode, remove decompressed fastq and individual bam files after a single bam file has been produced. align_600: Mark duplicates using picard MarkDuplicates command align_601: Remove _sorted.bam file after deduplication is completed. align_610: Index dedupped bam file using samtools align_700: Realign indels create indel realigner target align_710: Apply indel realigner target to bam file align_800: Create base recalibrator target align_810: Apply base recalibrator target align_811: If in production mode, remove bam files before realignment steps align_900: Generated bam file with reduced reads if more than one output file is specified Pipeline \u0026quot;call\u0026quot;: Call and validate variants (SNPs and Indels) from one or more input bam files. This pipeline accepts one or more bam files as input and a vcf file as output. If multiple input files are specified, multi-sample variant calling will be performed. call_1: call_10: Check existence of commands bwa, samtools and java call_13: Check the version of GATK call_20: Check existence of class files for GATK call_100: Use unified genotyper to get raw variants call_200: Recalibrate SNPs call_210: Recalibrate INDELs call_300: Apply SNP recalibration call_310: Apply INDEL recalibration Pipeline parameters: name Name of the job to be executed. All intermediate files generated from this pipeline will be saved to $CACHE_DIR/$NAME where $CACHE_DIR is the cache directory of the project. (default: bwa_gatk_hg19) strict_prog_version Whether or not use other version of programs if the exact version does not exist. Setting it to False allows variant tools to use other versions of the programs. (default: False) production If set to True or 1, all intermediate files will be removed. The whole pipeline would need to be rerun if a different parameter or different version of external program is used. (default: False) bwa path to bwa. Default to 'bwa' (use $PATH to determine actual path) (default: bwa) samtools path to samtools. Default to 'samtools' (use $PATH to determine actual path) (default: samtools) java path to java. Default to 'java' (use $PATH to determine actual path) (default: java) picard_path Path to picard jar files gatk_path Path to GATK jar file GenomeAnalysisTK.jar opt_java Option to java program. -Djava.io.tmpdir is frequently used to set java temporary directory if system temporary partition is not big enough. (default: -Xmx4g -XX:-UseGCOverheadLimit) opt_bwa_index Option to command 'bwa index' opt_bwa_aln Option to command 'bwa aln' opt_bwa_sampe Option to command 'bwa sampe' opt_samtools_faidx Option to command 'samtools faidx' opt_samtools_index Option to command 'samtools index' opt_picard_sortsam Option to picard SortSam.jar (default: VALIDATION_STRINGENCY=LENIENT) opt_picard_mergesamfiles Option to picard MergeSamFiles.jar (default: MAX_RECORDS_IN_RAM=5000000) opt_picard_samtofastq Option to picard SamToFastq.jar (default: VALIDATION_STRINGENCY=LENIENT NON_PF=true) opt_picard_markduplicates Option to picard MarkDuplicates.jar opt_gatk_realignertargetcreator Option to command gatk RealignerTargetCreator opt_gatk_indelrealigner Option to command gatk IndelRealigner (default: --filter_mismatching_base_and_quals) opt_gatk_baserecalibrator Option to command gatk BaseRecalibrator (default: -rf BadCigar) opt_gatk_printreads Option to command gatk PrintReads opt_gatk_reducereads Option to command gatk ReduceReads opt_gatk_unifiedgenotyper Option to command gatk UnifiedGenotyper (default: -rf BadCigar -stand_call_conf 50.0 -stand_emit_conf 10.0 -dcov 200 -A AlleleBalance -A QualByDepth -A HaplotypeScore -A MappingQualityRankSumTest -A ReadPosRankSumTest -A FisherStrand -A RMSMappingQuality -A InbreedingCoeff -A Coverage) opt_gatk_variantrecalibrator Option to command gatk VarintRecalibrator opt_gatk_variantrecalibrator_snp Option to command gatk VarintRecalibrator -mode SNP (default: -percentBad 0.01 -minNumBad 1000 -an QD -an MQRankSum -an ReadPosRankSum -an FS -an DP) opt_gatk_variantrecalibrator_indel Option to command gatk VarintRecalibrator -mode INDEL (default: --maxGaussians 4 -percentBad 0.01 -minNumBad 1000 -an DP -an FS -an ReadPosRankSum -an MQRankSum) opt_gatk_applyrecalibration Option to command gatk ApplyRecalibrator (default: --ts_filter_level 99.9) opt_gatk_applyrecalibration_snp Option to command gatk ApplyRecalibrator -mode SNP opt_gatk_applyrecalibration_indel Option to command gatk ApplyRecalibrator -mode INDEL  Details Set up environment This pipeline uses the following external commands:\n bwa samtools Picard GATK (Optional) pysam if you will be dealing with non paired-end data.  You can add path to bwa and samtools to $PATH or pass full path name to options bwa=/path/to/bwa and samtools=/path/to/samtools. Paths to Picard and GATK should be passed using options gatk_path and picard_path.\nTest the environment After you installed the programs, you should running the following commands to test if everything works ok:\n% vtools init test --parent vt_illuminaTestData % vtools execute bwa_gatk_hg19 align --input illumina_test_seq.tar.gz --output test.bam \\ --gatk_path /path/to/gatk --picard_path /path/to/picard --strict_prog_version False  Executing the pipeline in production mode The pipeline will by default keep all intermediate files. If you restart the pipeline with different parameter or a different version of an external file, only the affected steps will be repeated. Intermediate files will be reused if available. This allows you to examine and fine-tune the pipeline to make sure it works as expected.\nBecause intermediate files can be large, an option --production true is provided to execute the pipeline in production mode. In this mode, most intermediate files will be removed after the completion of the steps that make use of them. The pipeline can resume from the right step if it is interrupted, but has to be re-executed from the beginning if a result file is removed.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/keyconcepts/",
	"title": "Key concepts",
	"tags": [],
	"description": "",
	"content": " Key concepts 1. Project Variant Tools is project based. All data need to be imported to the project to be analyzed. A variant tools project $name consists of a project file $name.proj, a genotype database $name_genotype.DB, and a log file $name.log. After a project is created, subsequent vtools calls will automatically load the project in the current directory. Working from outside of a project directory is not allowed.\n  Examples \nLet us create a sample project and import two datasets from the pilot phase of the 1000 genomes project:\n% vtools init concept % vtools import CEU_hg38_all.vcf --build hg38 --sample_name CEU --var_info AA AC AN DP % vtools import JPT_hg38_all.vcf --sample_name JPT --var_info AA AC AN DP  The project properties can be displayed as follows\n% vtools show project Project name: concept Primary reference genome: hg38 Secondary reference genome: Storage method: hdf5 Variant tables: variant Annotation databases:  \nVariant Tools can import and manage large projects with thousands of samples and millions of variants. Although it can be slow to import data from large whole genome sequencing projects (e.g. it takes around 3 days to import all genotype data from the 1000 genomes project, with raw data exceeding 1T in size), data analysis is relatively fast because imported data are properly organized (indexed) and readily accessible.\n 2. Variant \u0026amp; variant table Variants refer to DNA sequence variations at a particular locus. Each variant consists of a chromosome name (1, 2, \u0026hellip;, X etc, without leading chr), a position (1-based), a reference allele, and an alternative allele, denoted by fields chr, pos, ref, and alt. variant tools currently supports SNV, small indels, and MNP (Multiple-nucleotide polymorphism). All variants are assumed to be on the forward (+) strand.\nUnlike some other tools that can analyze variants in external files directly, variants must be imported into a project before they are annotated or analyzed. All variant tools project has a master variant table that consists of all variants in this project. These variants are usually imported from external files. A project can have many variant tables that consist of subsets of variants from the master variant table. They are usually created using command vtools select according to sample properties and annotation of variants. Information about variant tables can be listed by command vtools show tables. Names of variant tables can contain special characters such as \u0026lsquo;@\u0026rsquo;.\n  Examples \nThis project has a single master variant table with 4,858 variants:\n% vtools show tables table #variants date message variant 4,839 May30 Master variant table  Each variant has chr, position, reference and alternative alleles,\n% vtools output variant chr pos ref alt --limit 5 1 1180123 T C 1 1180168 G A 1 1182895 C T 1 1184997 T A 1 1185051 G A  We can select all variants with reference allele T and save the results to a variant table named refT,\n% vtools select variant 'ref=\u0026quot;T\u0026quot;' --to_table refT 'variants with reference allele T' Running: 3 1.5K/s in 00:00:00 INFO: 780 variants selected.  Now there are two variant tables variant and refT in this project\n% vtools show tables table #variants date message refT 780 May30 variants with reference allele T variant 4,839 May30 Master variant table  As you can see, all variants in table refT have reference allele T:\n% vtools output refT chr pos ref alt --limit 5 1 1180123 T C 1 1184997 T A 1 3631572 T C 1 6464441 T C 1 6464628 T C  \n3. Variant info \u0026amp; variant info field Variant info refers to information that describes a variant, such as the INFO fields of a vcf file. It usually consists of annotation information such as membership in dbSNP, or sample statistics such as sample frequency of each variant. The names of these info are called variant info fields and can be displayed using command vtools show fields.\nExamples: The project has 4 variant info fields AA, AC, AN, and DP, as shown by the following command\n% vtools show fields variant.chr (char) Chromosome name (VARCHAR) variant.pos (int) Position (INT, 1-based) variant.ref (char) Reference allele (VARCHAR, - for missing allele of an insertion) variant.alt (char) Alternative allele (VARCHAR, - for missing allele of an deletion) variant.AA (char) variant.AC (int) variant.AN (int) variant.DP (int) refT.chr (char) Chromosome name (VARCHAR)  These fields are imported from the INFO fields of the vcf file, and are the ancestral allele, total number of alternate alleles in called genotypes, total number of alleles in called genotypes, and Read Depth from MOSAIK BAM, respectively, for each variant. These fields could be outputted for each variant,\n% vtools output refT chr pos ref alt AA AC AN DP --limit 5 1 1180123 T C T 4 114 3251 1 1184997 T A T 1 178 7275 1 3631572 T C C 156 156 1753 1 6464441 T C T 12 172 4691 1 6464628 T C T 9 176 6871  More variant info fields could be added to the project using command vtools update.\n% vtools update variant --from_file CEU_hg38_all.vcf --var_info id INFO: Using primary reference genome hg38 of the project. Getting existing variants: 100% [=======================] 4,839 372.4K/s in 00:00:00 INFO: Updating variants from CEU_hg38_all.vcf (1/1) CEU_hg38_all.vcf: 100% [==================================] 3,512 7.4K/s in 00:00:00 Getting existing variants: 100% [=======================] 4,839 368.5K/s in 00:00:00 $ vtools output refT chr pos ref alt id AA AC AN DP -l 5 1 1180123 T C . T 4 114 3251 1 1184997 T A . T 1 178 7275 1 3631572 T C rs2760321 C 156 156 1753 1 6464441 T C rs11800462 T 12 172 4691 1 6464628 T C rs3170675 T 9 176 6871  \n4. Annotation databases \u0026amp; annotation fields Annotation databases are databases that provide annotation information for variants. They are not part of a project but they provide additional annotation fields to a project when they are linked to a project. Conceptually speaking, attaching annotation databases to a project adds info fields to variants of the project, although annotation databases usually annotate only part of the variants, leaving a lot of NULL values for these fields.\nExamples: Let us download and use an annotation database dbSNP version 135 for reference genome hg19\n% vtools use dbSNP INFO: Choosing version dbSNP-hg38_143 from 10 available databases. INFO: Downloading annotation database annoDB/dbSNP-hg38_143.ann INFO: Using annotation DB dbSNP as dbSNP in project concept. INFO: dbSNP version 143, created using vcf file downloaded from NCBI  This database provides the following annotation fields\n% vtools show annotation dbSNP Annotation database dbSNP (version hg38_143) Description: dbSNP version 143, created using vcf file downloaded from NCBI Database type: variant Reference genome hg38: chr, pos, ref, alt chr (char) pos (int) name (char) DB SNP ID (rsname) ref (char) Reference allele (as on the + strand) alt (char) Alternative allele (as on the + strand) FILTER (char) Inconsistent Genotype Submission For At Least One Sample RS (int) dbSNP ID (i.e. rs number) RSPOS (int) Chr position reported in dbSNP RV (int) RS orientation is reversed VP (char) Variation Property. Documentation is at ftp://ftp.ncbi.nlm.nih.gov/snp/specs/dbSNP_BitField_latest.pdf GENEINFO (char) Pairs each of gene symbol:gene id. The gene symbol and id are delimited by a colon (:) and each pair is delimited by a vertical bar (|) dbSNPBuildID (int) First dbSNP Build for RS SAO (int) Variant Allele Origin: 0 - unspecified, 1 - Germline, 2 - Somatic, 3 - Both SSR (int) Variant Suspect Reason Codes (may be more than one value added together) 0 - unspecified, 1 - Paralog, 2 - byEST, 4 - oldAlign, 8 - Para_EST, 16 - 1kg_failed, 1024 - other WGT (int) Weight, 00 - unmapped, 1 - weight 1, 2 - weight 2, 3 - weight 3 or more VC (char) Variation Class PM_flag (int) Variant is Precious(Clinical,Pubmed Cited) TPA_flag (int) Provisional Third Party Annotation(TPA) (currently rs from PHARMGKB who will give phenotype data) PMC_flag (int) Links exist to PubMed Central article S3D_flag (int) Has 3D structure - SNP3D table SLO_flag (int) Has SubmitterLinkOut - From SNP-\u0026gt;SubSNP-\u0026gt;Batch.link_out NSF_flag (int) Has non-synonymous frameshift A coding region variation where one allele in the set changes all downstream amino acids. FxnClass = 44 NSM_flag (int) Has non-synonymous missense A coding region variation where one allele in the set changes protein peptide. FxnClass = 42 NSN_flag (int) Has non-synonymous nonsense A coding region variation where one allele in the set changes to STOP codon (TER). FxnClass = 41 REF_flag_flag (int) Has reference A coding region variation where one allele in the set is identical to the reference sequence. FxnCode = 8 SYN_flag (int) Has synonymous A coding region variation where one allele in the set does not change the encoded amino acid. FxnCode = 3 U3_flag (int) In 3' UTR Location is in an untranslated region (UTR). FxnCode = 53 U5_flag (int) In 5' UTR Location is in an untranslated region (UTR). FxnCode = 55 ASS_flag (int) In acceptor splice site FxnCode = 73 DSS_flag (int) In donor splice-site FxnCode = 75 INT_flag (int) In Intron FxnCode = 6 R3_flag (int) In 3' gene region FxnCode = 13 R5_flag (int) In 5' gene region FxnCode = 15 OTH_flag (int) Has other variant with exactly the same set of mapped positions on NCBI refernce assembly. CFL_flag (int) Has Assembly conflict. This is for weight 1 and 2 variant that maps to different chromosomes on different assemblies. ASP_flag (int) Is Assembly specific. This is set if the variant only maps to one assembly MUT_flag (int) Is mutation (journal citation, explicit fact): a low frequency variation that is cited in journal and other reputable sources VLD_flag (int) Is Validated. This bit is set if the variant has 2+ minor allele count based on frequency or genotype data. G5A_flag (int) \u0026gt;5% minor allele frequency in each and all populations G5_flag (int) \u0026gt;5% minor allele frequency in 1+ populations HD_flag (int) Marker is on high density genotyping kit (50K density or greater). The variant may have phenotype associations present in dbGaP. GNO_flag (int) Genotypes available. The variant has individual genotype (in SubInd table). KGValidated_flag (int) 1000 Genome validated KGPhase1_flag (int) 1000 Genome phase 1 (incl. June Interim phase 1) KGPilot123_flag (int) 1000 Genome discovery all pilots 2010(1,2,3) KGPROD_flag (int) Has 1000 Genome submission OTHERKG_flag (int) non-1000 Genome submission PH3_flag (int) HAP_MAP Phase 3 genotyped: filtered, non-redundant CDA_flag (int) Variation is interrogated in a clinical diagnostic assay LSD_flag (int) Submitted from a locus-specific database MTP_flag (int) Microattribution/third-party annotation(TPA:GWAS,PAGE) OM_flag (int) Has OMIM/OMIA NOC_flag (int) Contig allele not present in variant allele list. The reference sequence allele at the mapped position is not present in the variant allele list, adjusted for orientation. WTD_flag (int) Is Withdrawn by submitter If one member ss is withdrawn by submitter, then this bit is set. If all member ss' are withdrawn, then the rs is deleted to SNPHistory NOV_flag (int) Rs cluster has non-overlapping allele sets. True when rs set has more than 2 alleles from different submissions and these sets share no alleles in common. CAF (char) An ordered, comma delimited list of allele frequencies based on 1000Genomes, starting with the reference allele followed by alternate alleles as ordered in the ALT column. Where a 1000Genomes alternate allele is not in the dbSNPs alternate allele set, the allele is added to the ALT column. The minor allele is the second largest value in the list, and was previuosly reported in VCF as the GMAF. This is the GMAF reported on the RefSNP and EntrezSNP pages and VariationReporter COMMON (int) RS is a common SNP. A common SNP is one that has at least one 1000Genomes population with a minor allele of frequency \u0026gt;= 1% and for which 2 or more founders contribute to that minor allele frequency.  The fields are now available in the project,\n% vtools show fields variant.chr (char) Chromosome name (VARCHAR) variant.pos (int) Position (INT, 1-based) variant.ref (char) Reference allele (VARCHAR, - for missing allele of an insertion) variant.alt (char) Alternative allele (VARCHAR, - for missing allele of an deletion) variant.AA (char) variant.AC (int) variant.AN (int) variant.DP (int) variant.id (char) refT.chr (char) Chromosome name (VARCHAR) dbSNP.chr (char) dbSNP.pos (int) dbSNP.name (char) DB SNP ID (rsname) dbSNP.ref (char) Reference allele (as on the + strand) dbSNP.alt (char) Alternative allele (as on the + strand) dbSNP.FILTER (char) Inconsistent Genotype Submission For At Least One Sample dbSNP.RS (int) dbSNP ID (i.e. rs number) dbSNP.RSPOS (int) Chr position reported in dbSNP dbSNP.RV (int) RS orientation is reversed dbSNP.VP (char) Variation Property. Documentation is at ftp://ftp.ncbi.nlm.nih.gov/snp/specs/dbSNP_BitField_latest.pdf dbSNP.GENEINFO (char) Pairs each of gene symbol:gene id. The gene symbol and id are delimited by a colon (:) and each pair is delimited by a vertical bar (|) dbSNP.dbSNPBuildID (int) First dbSNP Build for RS dbSNP.SAO (int) Variant Allele Origin: 0 - unspecified, 1 - Germline, 2 - Somatic, 3 - Both dbSNP.SSR (int) Variant Suspect Reason Codes (may be more than one value added together) 0 - unspecified, 1 - Paralog, 2 - byEST, 4 - oldAlign, 8 - Para_EST, 16 - 1kg_failed, 1024 - other dbSNP.WGT (int) Weight, 00 - unmapped, 1 - weight 1, 2 - weight 2, 3 - weight 3 or more dbSNP.VC (char) Variation Class dbSNP.PM_flag (int) Variant is Precious(Clinical,Pubmed Cited) dbSNP.TPA_flag (int) Provisional Third Party Annotation(TPA) (currently rs from PHARMGKB who will give phenotype data) dbSNP.PMC_flag (int) Links exist to PubMed Central article dbSNP.S3D_flag (int) Has 3D structure - SNP3D table dbSNP.SLO_flag (int) Has SubmitterLinkOut - From SNP-\u0026gt;SubSNP-\u0026gt;Batch.link_out dbSNP.NSF_flag (int) Has non-synonymous frameshift A coding region variation where one allele in the set changes all downstream amino acids. FxnClass = 44 dbSNP.NSM_flag (int) Has non-synonymous missense A coding region variation where one allele in the set changes protein peptide. FxnClass = 42 dbSNP.NSN_flag (int) Has non-synonymous nonsense A coding region variation where one allele in the set changes to STOP codon (TER). FxnClass = 41 dbSNP.REF_flag_flag (int) Has reference A coding region variation where one allele in the set is identical to the reference sequence. FxnCode = 8 dbSNP.SYN_flag (int) Has synonymous A coding region variation where one allele in the set does not change the encoded amino acid. FxnCode = 3 dbSNP.U3_flag (int) In 3' UTR Location is in an untranslated region (UTR). FxnCode = 53 dbSNP.U5_flag (int) In 5' UTR Location is in an untranslated region (UTR). FxnCode = 55 dbSNP.ASS_flag (int) In acceptor splice site FxnCode = 73 dbSNP.DSS_flag (int) In donor splice-site FxnCode = 75 dbSNP.INT_flag (int) In Intron FxnCode = 6 dbSNP.R3_flag (int) In 3' gene region FxnCode = 13 dbSNP.R5_flag (int) In 5' gene region FxnCode = 15 dbSNP.OTH_flag (int) Has other variant with exactly the same set of mapped positions on NCBI refernce assembly. dbSNP.CFL_flag (int) Has Assembly conflict. This is for weight 1 and 2 variant that maps to different chromosomes on different assemblies. dbSNP.ASP_flag (int) Is Assembly specific. This is set if the variant only maps to one assembly dbSNP.MUT_flag (int) Is mutation (journal citation, explicit fact): a low frequency variation that is cited in journal and other reputable sources dbSNP.VLD_flag (int) Is Validated. This bit is set if the variant has 2+ minor allele count based on frequency or genotype data. dbSNP.G5A_flag (int) \u0026gt;5% minor allele frequency in each and all populations dbSNP.G5_flag (int) \u0026gt;5% minor allele frequency in 1+ populations dbSNP.HD_flag (int) Marker is on high density genotyping kit (50K density or greater). The variant may have phenotype associations present in dbGaP. dbSNP.GNO_flag (int) Genotypes available. The variant has individual genotype (in SubInd table). dbSNP.KGValidated_flag (int) 1000 Genome validated dbSNP.KGPhase1_flag (int) 1000 Genome phase 1 (incl. June Interim phase 1) dbSNP.KGPilot123_flag (int) 1000 Genome discovery all pilots 2010(1,2,3) dbSNP.KGPROD_flag (int) Has 1000 Genome submission dbSNP.OTHERKG_flag (int) non-1000 Genome submission dbSNP.PH3_flag (int) HAP_MAP Phase 3 genotyped: filtered, non-redundant dbSNP.CDA_flag (int) Variation is interrogated in a clinical diagnostic assay dbSNP.LSD_flag (int) Submitted from a locus-specific database dbSNP.MTP_flag (int) Microattribution/third-party annotation(TPA:GWAS,PAGE) dbSNP.OM_flag (int) Has OMIM/OMIA dbSNP.NOC_flag (int) Contig allele not present in variant allele list. The reference sequence allele at the mapped position is not present in the variant allele list, adjusted for orientation. dbSNP.WTD_flag (int) Is Withdrawn by submitter If one member ss is withdrawn by submitter, then this bit is set. If all member ss' are withdrawn, then the rs is deleted to SNPHistory dbSNP.NOV_flag (int) Rs cluster has non-overlapping allele sets. True when rs set has more than 2 alleles from different submissions and these sets share no alleles in common. dbSNP.CAF (char) An ordered, comma delimited list of allele frequencies based on 1000Genomes, starting with the reference allele followed by alternate alleles as ordered in the ALT column. Where a 1000Genomes alternate allele is not in the dbSNPs alternate allele set, the allele is added to the ALT column. The minor allele is the second largest value in the list, and was previuosly reported in VCF as the GMAF. This is the GMAF reported on the RefSNP and EntrezSNP pages and VariationReporter dbSNP.COMMON (int) RS is a common SNP. A common SNP is one that has at least one 1000Genomes population with a minor allele of frequency \u0026gt;= 1% and for which 2 or more founders contribute to that minor allele frequency.  These fields can be used just like variant info fields,\n% vtools output refT chr pos ref alt dbSNP.name --limit 5 1 1180123 T C rs111751804 1 1184997 T A rs116321663 1 3631572 T C rs2760321 1 6464441 T C rs11800462 1 6464628 T C rs3170675  As you can see, not all variants are in dbSNP. If we select variants that are in dbSNP, about half of variants are in dbSNP,\n% vtools select variant 'dbSNP.chr is not NULL' -t inDBSNP 'variants in dbSNP version 143' Running: 18 8.3/s in 00:00:02 INFO: 4833 variants selected.  We can check the details of variants in dbSNP using\n% vtools output inDBSNP chr pos ref alt name GENEINFO --limit 5  1 1180123 T C rs111751804 TTLL10:254173|TTLL10-AS1:100506376 1 1180168 G A rs114390380 TTLL10:254173|TTLL10-AS1:100506376 1 1182895 C T rs61733845 TTLL10:254173 1 1184997 T A rs116321663 TTLL10:254173 1 1185051 G A rs1320571 TTLL10:254173\n\n5. Track A track file is a file that contains annotation information for variants and regions that can be displayed on the UCSC genome browser. It provides another source of annotation to variant tools through function track(filename, field). variant tools currently support track files in tabix-indexed vcf, indexed BAM, bigBed, and bigWig formats.\nExamples: If we download a bigWig annotation file from the UCSC ENCODE website, you can use it to annotate and select variants,\n% vtools output variant chr pos ref alt 'track(\u0026quot;wgEncodeGisRnaSeqH1hescCellPapPlusRawRep1.bigWig\u0026quot;)' -l 10  \n6. Sample, genotype \u0026amp; genotype info A sample in variant tools refers to a collection of variants with optional associated genotypes, and genotype info fields. Here genotype refers to type of variants (homozygote, heterozygote or others) of a particular sample at a particular locus. If there is only one variant at a locus, a genotype can be 0 (all wildtype alleles), 1 (heterozygote), or 2 (homozygous alternative alleles). If there are more then one variants at a locus, a genotype can be -1, referring to two different alternative alleles. variant tools currently does not consider phase of genotypes.\nEach genotype can have any number of genotype info fields, which are information that describes a genotype, usually quality scores of each called variant.\nSample names are important but not unique identifiers of samples. For example, genotypes belonging to the same physical sample might be imported from several files (e.g. chromosome by chromosome), resulting in several variant tools samples that share the same name. (In this case, you can use commands \u0026ldquo;vtools admin --merge_samples\u0026rdquo; to merge them into one sample). Samples are usually identified by an SQL query so you could use sample name, filenames from which samples are imported, and arbitrary phenotypes (e.g. affection status) to specify samples.\nNot all samples have genotypes because variant tools can treat a list of variants as a sample.\n Examples: This project has two samples with names CEU and JPT:\n% vtools show samples sample_name filename CEU CEU_hg38_all.vcf JPT JPT_hg38_all.vcf  However, for this particular project, the samples are just lists of variants so there is no genotype and genotype fields.\n% vtools show genotypes sample_name filename num_genotypes sample_genotype_fields CEU CEU_hg38_all.vcf 3470 GT JPT JPT_hg38_all.vcf 2878 GT  \n7. Phenotype Phenotypes in variant tools are generally any properties of samples, such as blood pressure, weight, height, ethnicity, affection status, ID, and ID of parents. It could be imported from a text file, calculated from samples (e.g. average quality score of all variants of a sample could be a phenotype of the sample), or from other phenotypes. Phenotypes are frequently used to identify groups of samples (e.g. by affection status using parameter --samples 'aff=1'), and in genotype-phenotype association analysis.\nExamples: This project does not have any genotype and existing phenotype, we can add a phenotype num as the number of variants in each sample:\n% vtools phenotype --from_stat 'num=#(GT)' Calculating phenotype: 100% [==========================================] 2 2.0/s in 00:00:01 INFO: 2 values of 1 phenotypes (1 new, 0 existing) of 2 samples are updated.  The samples are now have a phenotype called num,\n% vtools show samples sample_name filename num CEU CEU_hg38_all.vcf 3470 JPT JPT_hg38_all.vcf 2878  \n8. Primary \u0026amp; alternative reference genome Variant Tools supports build hg18, hg19 and hg38 of the human genome natively. For reference genome of other species, you will need to provide fasta sequences of the reference genome and use command vtools admin --fasta2crr to convert it to a binary format that can be used by variant tools.\nBecause the same variants might have different coordinates on different reference genomes, it is very important to know the build of the reference genome of your data, which can be hg18, hg19 or hg38 for the human genome. The build information is important because it tells variant tools what annotation databases should be used. If you are uncertain about the reference genome used for your data, you could use a recent build and command vtools admin --validate_build to check if you have specified the correct build.\nA sequencing analysis project might sometimes need to handle data using different reference genomes. For example, you might need to use a new batch of sample with variants called using a more recent reference genome, or some public control data that use an older reference genome. Variant tools allows you to important data in an alternative reference genome in addition to a primary reference genome that the project uses. Variant tools will automatically convert between different coordinates so you do not have to worry about matching variants across datasets.\nPlease use name hg19 if your data uses b37, because the name hg19 is used for all annotation databases. Note that variant tools uses 1, 2 etc (for b37) instead of chr1, chr2 etc (for hg19) internally but it can handle data sources with chr1 etc.\n Whereas projects with a single reference genome will have unique coordinates for variants (chr, pos), projects with two reference genomes might have missing or duplicate coordinates for each reference genome. This is because not all genomic locations could be mapped from one reference genome to another and two locations might be mapped to the same location on another reference genome.\n Examples: Our project uses reference genome hg38 so we used dbSNP version 143 . If you would like to use another version of dbSNP for this project, you can first add an alternative reference genome to the project by lifting over existing variants:\n% vtools liftover hg19 INFO: Downloading liftOver chain file from UCSC INFO: Exporting variants in BED format Exporting variants: 100% [===========================] 4,839 250.8K/s in 00:00:00 INFO: Running UCSC liftOver tool Updating table variant: 100% [========================] 4,839 735.4/s in 00:00:06  The project now has two reference genomes\n% vtools show project Project name: concept Primary reference genome: hg38 Secondary reference genome: hg19 Storage method: hdf5 Variant tables: inDBSNP refT variant Annotation databases: dbSNP (~/.variant_tools/annoDB/dbSNP, hg38_143)  Now if we remove and re-link to dbSNP, we can use version 141 of the database\n% vtools remove annotations dbSNP % vtools use dbSNP-hg19_141 INFO: Downloading annotation database annoDB/dbSNP-hg19_141.ann INFO: Using annotation DB dbSNP as dbSNP in project concept. INFO: dbSNP version 141 % vtools select variant 'dbSNP.chr is not NULL' -t inDBSNP 'variants in dbSNP version 141' Running: 18 484.7/s in 00:00:00 INFO: 4833 variants selected.  \n9. Pipeline Pipelines are sequences of commands defined in pipeline configuration files, and are executed by command vtools execute. Pipelines are used, among many possibilities, to use external commands such as bwa and gatk to align raw reads and call genetic variants from aligned reads.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/simulation/models/peng1/",
	"title": "Peng2014_ex1",
	"tags": [],
	"description": "",
	"content": " Simulations for the first example of Peng (2014) Genetic Epidemiology Usage $ vtools show simulation Peng2014_ex1 Simulations of DNA sequences in specified regions using different simulation methods, for the first example in paper \u0026quot;Reproducible Simulations of realistic samples for next-gen sequencing studies using Variant Simulation Tools\u0026quot;. The simulated populations are analyzed and discarded to save diskspace. Available simulation models: ms, neutral, resample, with_selection Model \u0026quot;ms\u0026quot;: This simulator calls ms to execute coalescent-based simulations, create a population with simulated dataset and run through the same statistical analysis as other pipeline. ms_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. ms_1: Import required modules. ms_5: Check the existence of command ms ms_10: Create a new project if there is no existing project under the current directory. ms_20: Execute ms. NOTE that these parameters only matches the parameters used in example 1 of Peng 2014. ms_30: Create an empty simuPOP population for specified regions and import ms- simulated genotypes. The segregating sites are distributed within the specified region according to the positions (float numbers from 0 to 1) assigned by ms. Mutants are assumed to be from A-\u0026gt;C, C-\u0026gt;G, G-\u0026gt;T and T-\u0026gt;A for bases A, C, G and T respectively. ms_50: Get allele frequency spectrum in a sample of 700 individuals. ms_999: Remove intermediate populations to save diskspace. Model \u0026quot;neutral\u0026quot;: A neutral simulation using a Juke-Cantor (1969) DNA nucleotide mutation model, a mutation rate of 1.8x10^-8, a fine-scale recombination map, a demographic model that mimicks the European population, and no natural selelction. neutral_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. neutral_1: Import required modules. neutral_10: Create a new project if there is no existing project under the current directory. neutral_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. neutral_30: Create an empty simuPOP population for specified regions. neutral_40: Evolve and expand the population using a JC69 mutation model and a demographic model that evolves a population of size 8100 for 81000 generations before it is expanded to size 900000 in 370 generations. neutral_50: Get allele frequency spectrum in a sample of 700 individuals. neutral_999: Remove intermediate populations to save diskspace. Model \u0026quot;resample\u0026quot;: A simulation model that extracts genotypes within the sepecified regions from the 1000 genomes project, and expands it very rapidly to mimick a resampling-based simulation. resample_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. resample_1: Import required modules. resample_10: Create a new project if there is no existing project under the current directory. resample_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. resample_25: Extract genotypes of specified regions from 1000 genomes project. No dependency check will be performed so the extracted file can be used by other projects if you put is to a place accessible by other projects. Location of the extracted file can be specified by option --extracted_file. resample_30: Create an empty simuPOP population for specified regions. resample_40: Expand the population exponentially to reach a large population in 10 generations. Mutations and recombinations are allowed and a selection model that only select against stopgain mutations are used. resample_50: Get allele frequency spectrum in a sample of 700 individuals. resample_999: Remove intermediate populations to save diskspace. Model \u0026quot;with_selection\u0026quot;: A simulation that uses identical models as the neutral model but use a protein selection model with selection pressure 0.005, 0.02 and 0.1 for missense, stoploss and stopgain mutations. with_selection_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. with_selection_1: Import required modules. with_selection_10: Create a new project if there is no existing project under the current directory. with_selection_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. with_selection_30: Create an empty simuPOP population for specified regions. with_selection_40: Evolve and expand the population using a JC69 mutation model and a demographic model that evolves a population of size 8100 for 81000 generations before it is expanded to size 900000 in 370 generations. with_selection_50: Get allele frequency spectrum in a sample of 700 individuals. with_selection_999: Remove intermediate populations to save diskspace. Model parameters: regions One or more chromosome regions (separated by ',') in the format of chr :start-end (e.g. chr21:33031597-33041570), or Field:Value from a region- based annotation database (e.g. refGene.name2:TRIM2 or refGene_exon.name:NM_000947). Please visit http://varianttools.sourceforge.net/Simulation for detailed description of this parameter. (default: chr17:41200001-41263000) scale Scaling factor to speed up the simulation by scaling down the simulation while boosting mutation, selection and recombination rates. (default: 10) extracted_vcf Filename (with dir) to save genotypes (.vcf file extracted by tabix command) for the resample model. This file will be automatically created and reused if it already exists. You will need to remove this file if you run the same pipeline using another region. (default: extracted.vcf)  Model As a demonstration of the simulation engines of VST, we simulated the evolution of a sequence of 63,000 base pairs on chromosome 17 (chr17:41,200,001-41,263,000) using four simulation methods: a neutral coalescent simulation using ms [Hudson 2002] (wrapped by VST), a neutral forward-time simulation, a simulation with natural selection, and a resampling-based simulation. This region overlaps with five isoforms (NM_007294, NM_007297, NM_007298, NM_007299, NM_007300) of BRCA1, with 5337 nucleotides (8.47%) within the coding regions of one of the isoforms. All coalescent and forward-time simulations assumed a demographic model that mimics the evolution of the European population. This model evolves an initial population of 8,100 individuals for 81,000 generations and expands it to 900,000 individuals in 370 generations after a short bottleneck of 7,900 individuals [Kryukov, et al. 2007]. A mutation rate of 1.8 × 10–8 was used for ms. A Jukes-Cantor DNA evolution model with mutation rate 2.4 × 10–8 was used for the forward-time simulations because the Jukes-Cantor model with mutation rate μ mutates a nucleotide to any of the four nucleotides at equal probability and has an effective mutation rate of 0.75 μ. For VST simulations with natural selection, we used constant fitness values 0.005, 0.02, and 0.1 for missense, stoploss, and stopgain mutations, respectively. A multiplicative model was used to combine fitness values if an individual carried more than one non-synonymous mutation. This model applies strong purifying selection to stopgain mutations and practically disallows the existence of such mutations in the population. The resampling-based simulation extracts genotypes at this region from the 1000 Genomes Project and expands the population to 10,000 individuals in 10 generations, subject to the same mutation, recombination, and selection forces as the forward-time simulation.\nWith 10,000 replicates for each simulation method, we drew a sample of 700 individuals from the simulated population. We counted the number of mutants at each locus and then the number of loci in each mutation frequency class. The results from two neutral models obtained from ms and VST differed in that the VST simulations yielded less singleton variants. This difference may be partly due to the different mutation models used by the two programs. Whereas ms uses an infinite-sites model in which new mutations always lead to a new segregating site, VST uses a finite-sites mutation model where mutations can happen at existing segregating sites (Figure 1a). The allele frequency spectra of neutral and selection simulations differ only slightly because only 8.47% of the simulated region is under the influence of natural selection. We can observe a more significant difference between allele frequency spectra if we limit the loci to coding regions (Figure 1b).\nResult Attach:fig1.png\nExcept for resampling-based simulations, the allele frequency spectra of the simulated datasets are, however, different from what we observed from 700 random samples of the 1000 Genomes Project [Abecasis, et al. 2012] (Figure 1, blue bars). The observed allele frequency spectrum has more singletons than most simulated datasets, especially for coding regions of the VST simulations with natural selection. The reasons for this phenomenon can be multi-fold but we suspect that most rare variants were introduced during the rapid expansion of the European population which had a much stronger effect than natural selection in coding regions.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/simulation/models/peng1/",
	"title": "Peng2014_ex1",
	"tags": [],
	"description": "",
	"content": " Simulations for the first example of Peng (2014) Genetic Epidemiology 1. Usage $ vtools show simulation Peng2014_ex1 Simulations of DNA sequences in specified regions using different simulation methods, for the first example in paper \u0026quot;Reproducible Simulations of realistic samples for next-gen sequencing studies using Variant Simulation Tools\u0026quot;. The simulated populations are analyzed and discarded to save diskspace. Available simulation models: ms, neutral, resample, with_selection Model \u0026quot;ms\u0026quot;: This simulator calls ms to execute coalescent-based simulations, create a population with simulated dataset and run through the same statistical analysis as other pipeline. ms_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. ms_1: Import required modules. ms_5: Check the existence of command ms ms_10: Create a new project if there is no existing project under the current directory. ms_20: Execute ms. NOTE that these parameters only matches the parameters used in example 1 of Peng 2014. ms_30: Create an empty simuPOP population for specified regions and import ms- simulated genotypes. The segregating sites are distributed within the specified region according to the positions (float numbers from 0 to 1) assigned by ms. Mutants are assumed to be from A-\u0026gt;C, C-\u0026gt;G, G-\u0026gt;T and T-\u0026gt;A for bases A, C, G and T respectively. ms_50: Get allele frequency spectrum in a sample of 700 individuals. ms_999: Remove intermediate populations to save diskspace. Model \u0026quot;neutral\u0026quot;: A neutral simulation using a Juke-Cantor (1969) DNA nucleotide mutation model, a mutation rate of 1.8x10^-8, a fine-scale recombination map, a demographic model that mimicks the European population, and no natural selelction. neutral_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. neutral_1: Import required modules. neutral_10: Create a new project if there is no existing project under the current directory. neutral_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. neutral_30: Create an empty simuPOP population for specified regions. neutral_40: Evolve and expand the population using a JC69 mutation model and a demographic model that evolves a population of size 8100 for 81000 generations before it is expanded to size 900000 in 370 generations. neutral_50: Get allele frequency spectrum in a sample of 700 individuals. neutral_999: Remove intermediate populations to save diskspace. Model \u0026quot;resample\u0026quot;: A simulation model that extracts genotypes within the sepecified regions from the 1000 genomes project, and expands it very rapidly to mimick a resampling-based simulation. resample_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. resample_1: Import required modules. resample_10: Create a new project if there is no existing project under the current directory. resample_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. resample_25: Extract genotypes of specified regions from 1000 genomes project. No dependency check will be performed so the extracted file can be used by other projects if you put is to a place accessible by other projects. Location of the extracted file can be specified by option --extracted_file. resample_30: Create an empty simuPOP population for specified regions. resample_40: Expand the population exponentially to reach a large population in 10 generations. Mutations and recombinations are allowed and a selection model that only select against stopgain mutations are used. resample_50: Get allele frequency spectrum in a sample of 700 individuals. resample_999: Remove intermediate populations to save diskspace. Model \u0026quot;with_selection\u0026quot;: A simulation that uses identical models as the neutral model but use a protein selection model with selection pressure 0.005, 0.02 and 0.1 for missense, stoploss and stopgain mutations. with_selection_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. with_selection_1: Import required modules. with_selection_10: Create a new project if there is no existing project under the current directory. with_selection_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. with_selection_30: Create an empty simuPOP population for specified regions. with_selection_40: Evolve and expand the population using a JC69 mutation model and a demographic model that evolves a population of size 8100 for 81000 generations before it is expanded to size 900000 in 370 generations. with_selection_50: Get allele frequency spectrum in a sample of 700 individuals. with_selection_999: Remove intermediate populations to save diskspace. Model parameters: regions One or more chromosome regions (separated by ',') in the format of chr :start-end (e.g. chr21:33031597-33041570), or Field:Value from a region- based annotation database (e.g. refGene.name2:TRIM2 or refGene_exon.name:NM_000947). Please visit http://varianttools.sourceforge.net/Simulation for detailed description of this parameter. (default: chr17:41200001-41263000) scale Scaling factor to speed up the simulation by scaling down the simulation while boosting mutation, selection and recombination rates. (default: 10) extracted_vcf Filename (with dir) to save genotypes (.vcf file extracted by tabix command) for the resample model. This file will be automatically created and reused if it already exists. You will need to remove this file if you run the same pipeline using another region. (default: extracted.vcf)  2. Model As a demonstration of the simulation engines of VST, we simulated the evolution of a sequence of 63,000 base pairs on chromosome 17 (chr17:41,200,001-41,263,000) using four simulation methods: a neutral coalescent simulation using ms [Hudson 2002] (wrapped by VST), a neutral forward-time simulation, a simulation with natural selection, and a resampling-based simulation. This region overlaps with five isoforms (NM_007294, NM_007297, NM_007298, NM_007299, NM_007300) of BRCA1, with 5337 nucleotides (8.47%) within the coding regions of one of the isoforms. All coalescent and forward-time simulations assumed a demographic model that mimics the evolution of the European population. This model evolves an initial population of 8,100 individuals for 81,000 generations and expands it to 900,000 individuals in 370 generations after a short bottleneck of 7,900 individuals [Kryukov, et al. 2007]. A mutation rate of 1.8 × 10–8 was used for ms. A Jukes-Cantor DNA evolution model with mutation rate 2.4 × 10–8 was used for the forward-time simulations because the Jukes-Cantor model with mutation rate μ mutates a nucleotide to any of the four nucleotides at equal probability and has an effective mutation rate of 0.75 μ. For VST simulations with natural selection, we used constant fitness values 0.005, 0.02, and 0.1 for missense, stoploss, and stopgain mutations, respectively. A multiplicative model was used to combine fitness values if an individual carried more than one non-synonymous mutation. This model applies strong purifying selection to stopgain mutations and practically disallows the existence of such mutations in the population. The resampling-based simulation extracts genotypes at this region from the 1000 Genomes Project and expands the population to 10,000 individuals in 10 generations, subject to the same mutation, recombination, and selection forces as the forward-time simulation.\nWith 10,000 replicates for each simulation method, we drew a sample of 700 individuals from the simulated population. We counted the number of mutants at each locus and then the number of loci in each mutation frequency class. The results from two neutral models obtained from ms and VST differed in that the VST simulations yielded less singleton variants. This difference may be partly due to the different mutation models used by the two programs. Whereas ms uses an infinite-sites model in which new mutations always lead to a new segregating site, VST uses a finite-sites mutation model where mutations can happen at existing segregating sites (Figure 1a). The allele frequency spectra of neutral and selection simulations differ only slightly because only 8.47% of the simulated region is under the influence of natural selection. We can observe a more significant difference between allele frequency spectra if we limit the loci to coding regions (Figure 1b).\n3. Result Except for resampling-based simulations, the allele frequency spectra of the simulated datasets are, however, different from what we observed from 700 random samples of the 1000 Genomes Project [Abecasis, et al. 2012] (Figure 1, blue bars). The observed allele frequency spectrum has more singletons than most simulated datasets, especially for coding regions of the VST simulations with natural selection. The reasons for this phenomenon can be multi-fold but we suspect that most rare variants were introduced during the rapid expansion of the European population which had a much stronger effect than natural selection in coding regions.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/view_association_result/qq-plot-and-manhattan-plot/",
	"title": "QQ plot and Manhattan plot",
	"tags": [],
	"description": "",
	"content": " Graphic Summary of Association Analysis Introduction vtools_report plot_association generates QQ plot and Manhattan plot of p-values from output of vtools associate command. The graphics are powered by the R package ggplot2. Fonts, color, page layout etc can be specified from the command interface, generating high quality and customized graphs.\nInput data format vtools associate command typically generates two types of output: output of gene based association tests and single variant analysis.\nGene-based test input #refGene_name2 sample_size_SBurdenTest statistic_SBurdenTest pvalue_SBurdenTest AAGAB 1246 14 0.709392 ABHD2 1246 1 0.423756 ACAN 1246 107 0.0235792 ACSBG1 1246 23 0.887873 ACTC1 1246 0 1 ADAL 1246 2 1 ADAMTS17 1246 19 0.875558 ADAM10 1246 0 0.0766778 AGBL1 1246 120 0.119562 ...  Single variant test input #chr pos sample_size_SNV beta_x_SNV pvalue_SNV 1 802398 120 0.164128 0.205794 1 861292 316 -0.0339594 0.556444 1 865580 252 0.448666 0.271728 1 866422 316 -0.106212 0.734266 1 865584 268 0.0681559 0.267732 1 865625 303 -0.54794 0.837163 1 866517 311 0.154219 0.17982 1 865662 303 -0.571153 0.881119 1 871129 315 0.0691795 0.476523  Note that\n The program will read the header and only handle the columns prefixed by pvalue_ and suffixed by some non-empty character string which will be used as legend names Multiple columns of p-values are allowed (see examples below)  Sample output graphs QQ Plot samples Attach:qqplots.zip\nManhattan Plot samples Attach:manhattanplots.zip\nDetails Command interface % vtools_report plot_association -h usage: vtools_report plot_association [-h] [-v {0,1,2}] {qq,manhattan,manhattan_plain} ... positional arguments: {qq,manhattan,manhattan_plain} qq QQ plot via ggplot2 manhattan Manhattan plot via ggplot2 manhattan_plain Manhattan plot implementation not using ggplot2 optional arguments: -h, --help show this help message and exit -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information of vtools and vtools_report. Debug information are always recorded in project and vtools_report log files. % vtools_report plot_association qq -h usage: vtools_report plot_association qq [-h] [--shape INTEGER] [--fixed_shape] [--no_slope] [-t TITLE] [--color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd}] [--width_height INCHES INCHES] [-s] [-o FILE] [-b] [-l POSITION [POSITION ...]] [--label_top INTEGER] [--label_these NAME [NAME ...]] [-f SIZE] optional arguments: -h, --help show this help message and exit --shape INTEGER Choose a shape theme (integer 1 to 16) for dots on QQ plot. Default set to 1. --fixed_shape Use the same dot-shape theme for all plots --no_slope Do not plot the diagonal line graph properties: -t TITLE, --title TITLE Title of plot. --color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd} Choose a color theme from the list above to apply to the plot. (via the 'RColorBrewer' package: cran.r-project.org/web/packages/RColorBrewer) --width_height INCHES INCHES The width and height of the graphics region in inches -s, --same_page Plot multiple groups of p-values on the same graph -o FILE, --output FILE Specify output graph filename. Output is in pdf format. It can be converted to jpg format via the 'convert' command in Linux (e.g., convert -density 180 p.pdf p.jpg) variants/genes highlighting: -b, --bonferroni Plot the horizontal line at 0.05/N on Y-axis (significance level after Bonferroni correction) -l POSITION [POSITION ...], --hlines POSITION [POSITION ...] Additional horizontal line(s) to be drawn on the Y-axis. --label_top INTEGER Specify how many top hits (smallest p-values by rank) you want to highlight with their identifiers in text. --label_these NAME [NAME ...] Specify the names of variants (chr:pos, e.g., 1:87463) or genes (genename, e.g., IKBKB) you want to highlight with their identifiers in text. -f SIZE, --font_size SIZE Font size of text labels. Default set to '2.5'. % vtools_report plot_association manhattan -h usage: vtools_report plot_association manhattan [-h] [--chrom CHROMOSOME [CHROMOSOME ...]] [--chrom_prefix PREFIX] [--gene_map FILE] [-t TITLE] [--color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd}] [--width_height INCHES INCHES] [-s] [-o FILE] [-b] [-l POSITION [POSITION ...]] [--label_top INTEGER] [--label_these NAME [NAME ...]] [-f SIZE] optional arguments: -h, --help show this help message and exit --chrom CHROMOSOME [CHROMOSOME ...] Specify the particular chromosome(s) to display. Can be one or multiple in this list: \u0026quot;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y Un ?:?\u0026quot;. Slicing syntax \u0026quot;?:?\u0026quot; is supported. For example \u0026quot;1:22\u0026quot; is equivalent to displaying all autosomes; \u0026quot;1:Y\u0026quot; is equivalent to displaying all mapped chromosomes. Default set to all including unmapped chromosomes. --chrom_prefix PREFIX Prefix chromosome ID with a string. Default is set to \u0026quot;chr\u0026quot; (X-axis will be displayed as \u0026quot;chr1\u0026quot;, \u0026quot;chr2\u0026quot;, etc). Use \u0026quot;None\u0026quot; for no prefix. --gene_map FILE If the plot units are genes and the program fails to map certain genes to chromosomes, you can fix it by providing a text file of genomic coordinate information of these genes. Each gene in the file is a line of 3 columns specifying \u0026quot;GENENAME CHROM MIDPOINT_POSITION\u0026quot;, e.g., \u0026quot;IKBKB 8 42128820\u0026quot;. graph properties: -t TITLE, --title TITLE Title of plot. --color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd} Choose a color theme from the list above to apply to the plot. (via the 'RColorBrewer' package: cran.r-project.org/web/packages/RColorBrewer) --width_height INCHES INCHES The width and height of the graphics region in inches -s, --same_page Plot multiple groups of p-values on the same graph -o FILE, --output FILE Specify output graph filename. Output is in pdf format. It can be converted to jpg format via the 'convert' command in Linux (e.g., convert -density 180 p.pdf p.jpg) variants/genes highlighting: -b, --bonferroni Plot the horizontal line at 0.05/N on Y-axis (significance level after Bonferroni correction) -l POSITION [POSITION ...], --hlines POSITION [POSITION ...] Additional horizontal line(s) to be drawn on the Y-axis. --label_top INTEGER Specify how many top hits (smallest p-values by rank) you want to highlight with their identifiers in text. --label_these NAME [NAME ...] Specify the names of variants (chr:pos, e.g., 1:87463) or genes (genename, e.g., IKBKB) you want to highlight with their identifiers in text. -f SIZE, --font_size SIZE Font size of text labels. Default set to '2.5'. % vtools_report plot_association manhattan_plain -h usage: vtools_report plot_association manhattan_plain [-h] [--chrom CHROMOSOME [CHROMOSOME ...]] [--chrom_prefix PREFIX] [--gene_map FILE] [-t TITLE] [--color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd}] [--width_height INCHES INCHES] [-s] [-o FILE] [-b] [-l POSITION [POSITION ...]] [--label_top INTEGER] [--label_these NAME [NAME ...]] [-f SIZE] optional arguments: -h, --help show this help message and exit --chrom CHROMOSOME [CHROMOSOME ...] Specify the particular chromosome(s) to display. Can be one or multiple in this list: \u0026quot;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y Un ?:?\u0026quot;. Slicing syntax \u0026quot;?:?\u0026quot; is supported. For example \u0026quot;1:22\u0026quot; is equivalent to displaying all autosomes; \u0026quot;1:Y\u0026quot; is equivalent to displaying all mapped chromosomes. Default set to all including unmapped chromosomes. --chrom_prefix PREFIX Prefix chromosome ID with a string. Default is set to \u0026quot;chr\u0026quot; (X-axis will be displayed as \u0026quot;chr1\u0026quot;, \u0026quot;chr2\u0026quot;, etc). Use \u0026quot;None\u0026quot; for no prefix. --gene_map FILE If the plot units are genes and the program fails to map certain genes to chromosomes, you can fix it by providing a text file of genomic coordinate information of these genes. Each gene in the file is a line of 3 columns specifying \u0026quot;GENENAME CHROM MIDPOINT_POSITION\u0026quot;, e.g., \u0026quot;IKBKB 8 42128820\u0026quot;. graph properties: -t TITLE, --title TITLE Title of plot. --color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd} Choose a color theme from the list above to apply to the plot. (via the 'RColorBrewer' package: cran.r-project.org/web/packages/RColorBrewer) --width_height INCHES INCHES The width and height of the graphics region in inches -s, --same_page Plot multiple groups of p-values on the same graph -o FILE, --output FILE Specify output graph filename. Output is in pdf format. It can be converted to jpg format via the 'convert' command in Linux (e.g., convert -density 180 p.pdf p.jpg) variants/genes highlighting: -b, --bonferroni Plot the horizontal line at 0.05/N on Y-axis (significance level after Bonferroni correction) -l POSITION [POSITION ...], --hlines POSITION [POSITION ...] Additional horizontal line(s) to be drawn on the Y-axis. --label_top INTEGER Specify how many top hits (smallest p-values by rank) you want to highlight with their identifiers in text. --label_these NAME [NAME ...] Specify the names of variants (chr:pos, e.g., 1:87463) or genes (genename, e.g., IKBKB) you want to highlight with their identifiers in text. -f SIZE, --font_size SIZE Font size of text labels. Default set to '2.5'.  QQ Plot Examples Gene base tests zcat genetest.result.gz | vtools_report plot_association qq -o genes_qq1 zcat genetest.result.gz | vtools_report plot_association qq -s --color Dark2 -b -o genes_qq\\ 2 zcat genetest.result.gz | vtools_report plot_association qq -t \u0026quot;Demo QQ plot\u0026quot; -b -o genes_q\\ q3 zcat genetest.result.gz | vtools_report plot_association qq -t \u0026quot;Demo otherwise shaped QQ pl\\ ot\u0026quot; -s -b --shape 12 -o genes_qq4  Single variant tests zcat varianttest.result.gz | vtools_report plot_association qq -o variants_qq1 zcat varianttest.result.gz | vtools_report plot_association qq -s --color Dark2 -b -o varia\\ nts_qq2 zcat varianttest.result.gz | vtools_report plot_association qq -t \u0026quot;Demo QQ plot\u0026quot; -b -o vari\\ ants_qq3 zcat varianttest.result.gz | vtools_report plot_association qq -t \u0026quot;Demo otherwise shaped QQ\\ plot\u0026quot; -s -b --shape 12 -o variants_qq4  Manhattan Plot Examples Gene base tests zcat genetest.result.gz | vtools_report plot_association manhattan -t \u0026quot;Demo Manhattan plot\u0026quot;\\ --color Dark2 --s -b -o genes_man1 zcat genetest.result.gz | vtools_report plot_association manhattan -t \u0026quot;Demo Manhattan plot\u0026quot;\\ --chrom 1:22 --chrom_prefix None --same_page -o genes_man2 zcat genetest.result.gz | vtools_report plot_association manhattan_plain -t \u0026quot;Demo Manhattan\\ plain plot\u0026quot; --color Dark2 --s -b -o genes_man3 zcat genetest.result.gz | vtools_report plot_association manhattan_plain -t \u0026quot;Demo Manhattan\\ plain plot\u0026quot; --chrom 1:22 --chrom_prefix None --same_page -o genes_man4  Single variant tests zcat varianttest.result.gz | vtools_report plot_association manhattan -t \u0026quot;Demo Manhattan pl\\ ot\u0026quot; --color Dark2 --s -b -o variants_man1 zcat varianttest.result.gz | vtools_report plot_association manhattan -t \u0026quot;Demo Manhattan pl\\ ot\u0026quot; --chrom 1:22 --chrom_prefix None --same_page -o variants_man2 zcat varianttest.result.gz | vtools_report plot_association manhattan_plain -t \u0026quot;Demo Manhat\\ tan plain plot\u0026quot; --color Dark2 --s -b -o variants_man3 zcat varianttest.result.gz | vtools_report plot_association manhattan_plain -t \u0026quot;Demo Manhat\\ tan plain plot\u0026quot; --chrom 1:22 --chrom_prefix None --same_page -o variants_man4  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/quickstartguide/",
	"title": "Quick start",
	"tags": [],
	"description": "",
	"content": " Quick Start Guide variant tools is a software toolset that facilitates the import, annotation and analysis of your variants. This 10-minute quick start guide steps you through a minimal real-world data set so that you can get a feel for the software and assess its helpfulness. For demonstrations on more real-world data analysis, please refer to the software tutorials\n1. Installation Required software:\n Python 2.7.2 or higher or Python 3.2 or higher  Download the current release of vtools, extract the archive and install the software.\n% tar -xvzf variant_tools-VERSION.tar.gz % cd variant_tools-VERSION % sudo python setup.py install  If you want to install on a windows system or use Python 3 see the detailed installation instructions here.\n2. Create a project Create a directory to put all your project files in - lets call it tutorial. And then create a vtools project called quickstart.\n% mkdir tutorial % cd tutorial % vtools init quickstart INFO: variant tools 1.0.3 : Copyright (c) 2011 - 2012 Bo Peng INFO: San Lucas FA, Wang G, Scheet P, Peng B (2012) Bioinformatics 28(3):421-422 INFO: Please visit http://varianttools.sourceforge.net for more information. INFO: Creating a new project quickstart  3. Import an example data set Download these example VCF files, put them in your tutorial directory and unzip them.\nftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/pilot_data/release/2010_07/exon/snps/CEU.exon.2010_03.sites.vcf.gz ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/pilot_data/release/2010_07/exon/snps/JPT.exon.2010_03.sites.vcf.gz  You can then import this data into your quickstart project. These example VCFs contain variants for the CEU and JPT populations from the 1000 Genomes project.\n% vtools import CEU.exon.2010_03.sites.vcf.gz --build hg19 --sample_name CEU INFO: Importing variants from CEU.exon.2010_03.sites.vcf.gz (1/1) CEU.exon.2010_03.sites.vcf.gz: 100% [=======================] 3,500 10.3K/s in 00:00:00 INFO: 3,489 new variants (3,489 SNVs) from 3,500 lines are imported. WARNING: No genotype column could be found from the input file. Assuming no genotype. Importing genotypes: 100% [==================================] 3,500 1.7K/s in 00:00:02 Copying genotype: 100% [=========================================] 1 3.8K/s in 00:00:00 % vtools import JPT.exon.2010_03.sites.vcf.gz --sample_name JPT INFO: Using primary reference genome hg19 of the project. Getting existing variants: 100% [==========================] 3,489 207.8K/s in 00:00:00 INFO: Importing variants from JPT.exon.2010_03.sites.vcf.gz (1/1) JPT.exon.2010_03.sites.vcf.gz: 100% [=======================] 2,911 12.9K/s in 00:00:00 INFO: 1,369 new variants (1,369 SNVs) from 2,910 lines are imported. WARNING: No genotype column could be found from the input file. Assuming no genotype. Importing genotypes: 100% [==================================] 2,910 1.5K/s in 00:00:02 Copying genotype: 100% [=========================================] 1 2.4K/s in 00:00:00  These two files do not have any sample names associated with them. We however give each file a sample name so that we can track the source of variants (CEU vs JPT). If you do not need to track variant membership, you can import the two files using a single command vtools import *.vcf.gz --build hg19.\n If for some reason you cannot download the source files from NCBI, you could download this sample project as a snapshot using command\n% vtools admin --load_snapshot vt_quickStartGuide Downloading snapshot vt_quickStartGuide.tar.gz from online vt_quickStartGuide.tar.gz: 100% [============================] 112,837 81.8K/s in 00:00:01 INFO: Snapshot vt_quickStartGuide has been loaded  4. Annotate your variants To annotate variants, you first need to download annotation sources. For more details see the documentation? page. For this quick start, we will annotate variants to transcripts (CCDS IDs) and KEGG pathways. These first 2 vtools use commands downloads 2 annotation sources.\nThis command downloads the ccdsGene data source allowing variants to be annotated to transcripts.\n% vtools use ccdsGene INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/ccdsGene.ann INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/ccdsGene-hg19_20110909.DB.gz : Unsupported scheme. --18:47:23-- http://vtools.houstonbioinformatics.org/annoDB/ccdsGene-hg19_20110909.DB.gz =\u0026gt; `./ccdsGene-hg19_20110909.DB.gz' Resolving vtools.houstonbioinformatics.org... 70.39.145.13 Connecting to vtools.houstonbioinformatics.org[70.39.145.13]:80... connected. HTTP request sent, awaiting response... 200 OK Length: 744,834 [application/x-gzip] 100%[=============================================================================\u0026gt;] 744,834 370.44K/s 18:47:26 (369.03 KB/s) - `./ccdsGene-hg19_20110909.DB.gz' saved [744834/744834] FINISHED --18:47:26-- Downloaded: 744,834 bytes in 1 files INFO: Using annotation DB ccdsGene in project quickstart. INFO: CCDS Genes  This command downloads the keggPathway annotation source allowing variants to be annotated to KEGG pathways indirectly through transcript annotations (provided by the ccdsGene annotation source).\n% vtools use keggPathway --linked_by ccdsGene.name INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/keggPathway.ann INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/keggPathway-20110823.DB.gz : Unsupported scheme. --18:54:24-- http://vtools.houstonbioinformatics.org/annoDB/keggPathway-20110823.DB.gz =\u0026gt; `./keggPathway-20110823.DB.gz' Resolving vtools.houstonbioinformatics.org... 70.39.145.13 Connecting to vtools.houstonbioinformatics.org[70.39.145.13]:80... connected. HTTP request sent, awaiting response... 200 OK Length: 350,847 [application/x-gzip] 100%[=============================================================================\u0026gt;] 350,847 330.94K/s 18:54:26 (329.78 KB/s) - `./keggPathway-20110823.DB.gz' saved [350847/350847] FINISHED --18:54:26-- Downloaded: 350,847 bytes in 1 files INFO: Using annotation DB keggPathway in project quickstart. INFO: kegg pathway for CCDS genes  Now lets filter all of our variants to include only those involved in metabolic pathways. This command uses the pathway annotation source that we just downloaded to find all variants that are on transcripts of proteins known to be involved in metabolic pathways. These variants are then stored in a table called metabolic.\n% vtools select variant 'kgDesc=\u0026quot;Metabolic pathways\u0026quot;' -t metabolic Running: 2,788 2.1K/s in 00:00:01 INFO: 109 variants selected.  Now lets create a table of the metabolic pathway variants that are seen in the CEU population.\n% vtools select metabolic --samples \u0026quot;sample_name='CEU'\u0026quot; -t metabolic_CEU INFO: 1 samples are selected by condition: sample_name='CEU' Running: 3 488.8/s in 00:00:00 INFO: 71 variants selected.  Lets to the same for the JPT population\n% vtools select metabolic --samples \u0026quot;sample_name='JPT'\u0026quot; -t metabolic_JPT INFO: 1 samples are selected by condition: sample_name='JPT' Running: 2 330.8/s in 00:00:00 INFO: 67 variants selected.  5. Basic analysis of variants The vtools sample_stat command and vtools_reports provide analysis capabilities that use sample genotypes. In our current data set we don\u0026rsquo;t have genotypes but you can see examples of these types of analyses in our tutorials in the documentation?. Here we will show a simple compare command. This identifies which of the metabolic pathway variants are seen in the CEU population but are not seen in the JPT population.\n% vtools compare metabolic_CEU metabolic_JPT --difference unique_CEU_metabolic INFO: Reading 71 variants in metabolic_CEU... INFO: Reading 67 variants in metabolic_JPT... Writing to unique_CEU_metabolic: 100.0% [=======================================================\u0026gt;] 42 3.5K/s in 00:00:00  6. Export reports Report of metabolic pathway variants unique to the CEU population (when analyzed with the JPT population).\n% vtools output unique_CEU_metabolic chr pos ref alt ccdsGene.name kgDesc \u0026gt; unique_CEU_metabolic_variants.txt 1 76650391 C T CCDS672.1 Glycosphingolipid biosynthesis - ganglio series 1 76650391 C T CCDS672.1 Metabolic pathways 1 76866926 T C CCDS672.1 Glycosphingolipid biosynthesis - ganglio series 1 76866926 T C CCDS672.1 Metabolic pathways 2 154866325 A G CCDS2199.1 O-Glycan biosynthesis 2 154866325 A G CCDS2199.1 Metabolic pathways 2 154960831 C T CCDS2199.1 O-Glycan biosynthesis 2 154960831 C T CCDS2199.1 Metabolic pathways 2 158120947 T G CCDS2203.1 O-Glycan biosynthesis ...  Simple report to list all CEU and JPT variants involved in metabolic pathways.\n% vtools output metabolic chr pos ref alt ccdsGene.name kgDesc \u0026gt; metabolic_variants.txt 1 20916748 A G CCDS210.1 Pyrimidine metabolism 1 20916748 A G CCDS210.1 Drug metabolism - other enzymes 1 20916748 A G CCDS210.1 Metabolic pathways 1 76650391 C T CCDS672.1 Glycosphingolipid biosynthesis - ganglio series 1 76650391 C T CCDS672.1 Metabolic pathways 1 76865768 C A CCDS672.1 Glycosphingolipid biosynthesis - ganglio series 1 76865768 C A CCDS672.1 Metabolic pathways 1 76866926 T C CCDS672.1 Glycosphingolipid biosynthesis - ganglio series 1 76866926 T C CCDS672.1 Metabolic pathways ...  The example here was very simplistic using only 2 samples and the VCFs did not have genotype information within them. But hopefully this gives you a feel for how the software works. For more involved tutorials and details of vtools capabilities, please see our documentation.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/keyconcepts/supportedtypes/",
	"title": "Variants",
	"tags": [],
	"description": "",
	"content": " Supported types of variants How variants are imported and stored in variant tools Variant tools import different types of variants as follows:\n   Type Reference Alternative Imported Variant(s) Note     SNV A G A,G     TC TG C,G pos + 1   Deletion TC T C,- pos + 1    TCG TG C,- pos + 1    TCGC TC GC,- pos + 2, *    TC - or . TC,- Not VCF compatible   Insertion TCG TCAG -,A pos + 2    TC TCA -,A pos + 2    - or . A -,A not VCF compatible   MNP AA ATAAC A,TAAC pos + 1    TACT TCTA ACT,CTA pos + 1   Mixed A C,G A,C A,G Two single nucleotide variants    TC TCGG,T -,GG C,- A deletion and an insertion    Note that\n - or . are treated as missing allele and can be used to import indels. When reference and alternative variants have common leading alleles, variant positions are adjusted. For example, 10, ACG, A will be imported as variant CG,- at position 11. The Common ending alleles are also removed. We remove common leading alleles greedily to avoid ambiguity. For example, deletion TCGC-\u0026gt;GC (case * in the table) can be intepretted as a deletion of GC at pos + 2 and CG at pos + 1, variant tools uses the first interpretation. When there are multiple alternative variants, they are treated as multiple variants. If a sample with two alternative variants are imported, the sample will have other type for this variant, in contrast to homozygote (two identical alternative variant) and heterozygote (one reference and one alternative variant. Although indels could be imported, annotation database for these kinds of variants are, essentially, non-exist at this time. Using command vtools import --format ANNOVAR to import annotation for ANNOVAR might be a good choice.  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_report/avg_depth/",
	"title": "avg_depth",
	"tags": [],
	"description": "",
	"content": " Average depth of coverage Ratio About vtools_report avg_depth This command report average depth of all variants, or variants divided by sample allele count.\nUsage % vtools_report avg_depth -h usage: vtools_report avg_depth [-h] -n NUM_FIELD -d DEPTH_FIELD [--group_by [GROUP_BY [GROUP_BY ...]]] [-v {0,1,2}] table Command 'vtools update table --from_stat \u0026quot;meanDP=avg(DP_geno)\u0026quot;' calculates the average depth of variants across sample (e.g. average depth of three variants if the variant appears three times in the sample). This command report average depth of all variants, or variants divided by sample allele count (output count, number of variant, and average depth for count from 1 to 2*#sample). This command requires a field that stores the sample count for each variant and a field to store average depth of each variant, which should be prepared using command 'vtools update table --from_stat \u0026quot;num=#(alt)\u0026quot; \u0026quot;meanDP=avg(DP_geno)\u0026quot;'. positional arguments: table Variant table for which average depth are calculated. optional arguments: -h, --help show this help message and exit -n NUM_FIELD, --num_field NUM_FIELD Name of the field that holds sample variant count, which is the field name for command 'vtools update table --from_stat \u0026quot;num=#(alt)\u0026quot;'. -d DEPTH_FIELD, --depth_field DEPTH_FIELD Name of the field that holds average depth of each variant, which is the field name for command 'vtools update table --from_stat \u0026quot;meanDP=avg(DP_geno)\u0026quot;'. --group_by [GROUP_BY [GROUP_BY ...]] Output average depth for each group, for example, '-- group_by NUM_FIELD to output depth for each sample variant frequency (count). -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information of vtools and vtools_report. Debug information are always recorded in project and vtools_report log files.  Example % vtools_report avg_depth variant -n num -d depth num_of_variant average_depth 905 6.86372641088 % vtools_report avg_depth variant -n num -d depth --group_by num num num_of_variant average_depth 1 410 7.18662601626 2 163 32.3737218814 3 28 6.8375 4 72 35.1266203704 5 19 4.93245614035 6 14 4.93571428571 7 23 4.10942028986 ... ...  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/format/formats/txt/",
	"title": "basic",
	"tags": [],
	"description": "",
	"content": " Importing variants from tab-delimited files Format description % vtools show format basic A basic variant import/export format that import variants with four tab- delimited columns (chr, pos, ref, alt), and export variants, optional variant info fields and genotypes. Columns: 1 Output variant info fields as one column 2 variant position, set --pos_adj to -1 to export variants in 0-based positions. 3 reference allele 4 alternative allele 5 genotype in numeric style Formatters are provided for fields: gt variant: chr Chromosome pos 1-based position, set --pos_adj to 1 if input position is 0 based. ref Reference allele, '-' for insertion. alt Alternative allele, '-' for deletion. Format parameters: chr_col Column index for the chromosome field (default: 1) pos_col Column index for the position field (default: 2) ref_col Column index for the reference field (default: 3) alt_col Column index for the alternative field (default: 4) pos_adj Set to 1 to import variants with 0-based positions, or to -1 to export variants in 0-based positions. (default: 0) fields Fields to output, simple arithmetics are allowed (e.g. pos+1) but aggregation functions are not supported. (default: chr,pos,ref,alt)  Examples Import variants with columns chr, pos, ref, and alt  Examples: create a sample project Let us load a project with a few test datasets\n% vtools init basic % vtools admin --load_snapshot vt_testData Downloading snapshot vt_testData.tar.gz from online INFO: Snapshot vt_testData has been loaded  \nThis format can be used to import variants that are provided as four columns in the input file,\n Examples: Import variants using format basic File variants.txt has a list of variants as follows\n% head variants.txt 1 203148112 T - 1 203148168 G A 1 203148202 G C 1 203148224 G A 1 203148265 GG T 1 203148284 T C 1 203148294 G T 1 203148359 C A 1 203148360 G A 1 203148360 G C  You can import variants using format basic as follows:\n% vtools import variants.txt --format basic --build hg19 INFO: Importing variants from variants.txt (1/1) variants.txt: 100% [===============================================] 20 9.9K/s in 00:00:00 INFO: 20 new variants (17 SNVs, 1 insertions, 1 deletions, 1 complex variants) from 20 lines are imported. WARNING: Sample information is not recorded for a file without genotype and sample name. Importing genotypes: 0 0.0/s in 00:00:00 Copying genotype: 0 0.0/s in 00:00:00  The variants can be displayed using command vtools output,\n% vtools output variant chr pos ref alt -l 10 1 203148112 T - 1 203148168 G A 1 203148202 G C 1 203148224 G A 1 203148265 GG T 1 203148284 T C 1 203148294 G T 1 203148359 C A 1 203148360 G A 1 203148360 G C  \nIf the chr, pos, ref, alt columns are not columns 1 through 4 in the input file, you can use parameters chr_col, pos_col, ref_col, and alt_col to specify the columns of these fields. If the input data uses 0-based position, parameter pos_adj can be used to adjust input.\n Examples: Use parameters \u0026ndash;pos_adj to import data in 0-based coordinates If the position used in variants.txt is zero-based (like all data downloaded from UCSC), you can use format parameter --pos_adj 1 to add 1 to import positions:\n% vtools init import -f % vtools import variants.txt --format basic --pos_adj 1 --build hg19 vtools import variants.txt --format basic --pos_adj 1 --build hg19 INFO: Importing variants from variants.txt (1/1) variants.txt: 100% [========================================] 20 758.8/s in 00:00:00 INFO: 20 new variants (17 SNVs, 1 insertions, 1 deletions, 1 complex variants) from 20 lines are imported. WARNING: Sample information is not recorded for a file without genotype and sample name. Importing genotypes: 0 0.0/s in 00:00:00 Copying genotype: 0 0.0/s in 00:00:00 % vtools output variant chr pos ref alt -l 10 1 203148113 T - 1 203148169 G A 1 203148203 G C 1 203148225 G A 1 203148266 GG T 1 203148285 T C 1 203148295 G T 1 203148360 C A 1 203148361 G A 1 203148361 G C  \nExport variants, variants info and genotypes If we export data in basic format without any parameter, the output is similar to the output of command vtools output variant chr pos ref alt,\n Examples: export variants Let us get more variants,\n% vtools import CEU.vcf.gz --var_info DP INFO: Using primary reference genome hg18 of the project. Getting existing variants: 100% [=======================] 20 30.5K/s in 00:00:00 INFO: Importing variants from CEU.vcf.gz (1/1) CEU.vcf.gz: 100% [=====================================] 300 16.8K/s in 00:00:00 INFO: 288 new variants (288 SNVs) from 300 lines are imported. Importing genotypes: 100% [==========================] 18,000 9.0K/s in 00:00:02 Removing duplicates: 100% [===========================] 120 445.8K/s in 00:00:00 Copying samples: 100% [===============================] 120 558.0K/s in 00:00:00  Then export variants in basic format,\n% vtools export variant --format basic \u0026gt; bb Writing: 100% [========================================] 308 32.4K/s in 00:00:00 INFO: 308 lines are exported from variant table variant % head -5 bb 1 203148112 T - 1 203148168 G A 1 203148202 G C 1 203148224 G A 1 203148265 GG T  \nYou can specify more fields, even annotation fields, through parameter --fields\n Examples: export variant info fields\n% vtools use dbSNP-hg18_130 % vtools export variant --fields DP dbSNP.name --format ~/vtools/format/basic \u0026gt; bb Writing: 100% [========================================] 308 29.3K/s in 00:00:00 INFO: 308 lines are exported from variant table variant  You can see the output has six columns, with depth (field DP) and rsname (field dbSNP.name) as the last two columns. Note that missing entries are displayed as empty string.\n% head -30 bb 1 203148112 T - 1 203148168 G A 1 203148202 G C 1 203148224 G A 1 203148265 GG T 1 203148284 T C 1 203148294 G T 1 203148359 C A 1 203148360 G A 1 203148360 G C 1 203148510 G T 1 203148513 A T 1 203148633 A G 1 203148677 T C 1 203148727 C T 1 203148868 T C 1 203148989 - C 10 58118181 A C 10 58118185 C T 10 58120990 C T 1 533 G C 423 1 41342 T A 188 1 41791 G A 192 1 44449 T C 166 1 44539 C T 131 rs2462492 1 44571 G C 135 1 45162 C T 166 rs10399749 1 52066 T C 159 rs28402963 1 53534 G A 243 1 75891 T C 182  \nThe basic format can also be used to export genotypes,\n Examples: export genotypes  This example select 8 samples using condition 'sample_name like \u0026quot;NA128%\u0026quot;',\n% vtools select variant --samples 1 -t inSamples % vtools export inSamples --samples 'sample_name like \u0026quot;NA128%\u0026quot;' --format ~/vtools/format/basic \u0026gt; bb INFO: Genotypes of 8 samples are exported. Writing: 100% [========================================] 288 10.6K/s in 00:00:00 INFO: 288 lines are exported from variant table inSamples % head -5 bb 1 533 G C 0 0 0 1 0 1 1 1 41342 T A 0 0 1 1 0 0 0 1 41791 G A 0 0 0 0 0 0 0 1 44449 T C 1 0 0 0 0 0 0 1 44539 C T 1 0 0 0 0 0 0  \nThe --header option can be used to specify a header, with %(sample_names)s being replaced by names of samples,\n Examples: specify a header to exported file\n% vtools export inSamples --samples 'sample_name like \u0026quot;NA128%\u0026quot;' --format ~/vtools/format/basic --header chr pos ref alt \u0026quot;%(sample_names)s\u0026quot; \u0026gt; bb INFO: Genotypes of 8 samples are exported. Writing: 100% [========================================] 288 12.9K/s in 00:00:00 INFO: 288 lines are exported from variant table inSamples % head -5 bb chr pos ref alt NA12812 NA12813 NA12814 NA12815 NA12828 NA12872 NA12873 NA12874 1 533 G C 0 0 0 1 0 1 1 1 41342 T A 0 0 1 1 0 0 0 1 41791 G A 0 0 0 0 0 0 0 1 44449 T C 1 0 0 0 0 0 0  (:exampleend\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/variant_calling/bwa_gatk33_hg19/",
	"title": "bwa_gatk33_hg19",
	"tags": [],
	"description": "",
	"content": " Variant calling using BWA and GATK best practice pipeline Usage % vtools show pipeline bwa_gatk33_hg19 A pipeline to align raw reads from fastq or BAM/SAM files using BWA and GATK best practice. It uses hg19 of human reference genome and assumes paired-end reads in plain text and compressed formats. Available pipelines: align Pipeline \u0026quot;align\u0026quot;: Align raw reads from input files using bwa, gatk, and picard. This pipeline accepts raw input files in plain text format, SAM/BAM format, and their compressed versions (.zip, .tar.gz, .tgz, .bz2, .tbz2 etc). All input files are assumed to be raw reads from the same sample. This pipeline generates a calibrated bam file (--output), and its reduced version if an additional output file is specified. align_0: Check the version of variant tools (version 2.1.1 and above is required to execute this pipeline) align_1: Check if a name has been asigned to the job align_2: Check path to GATK jar file align_3: Check path to Picard jar file align_10: Check existence of commands bwa, samtools and java align_11: Check the version of bwa. Version is 0.7.4 is recommended align_12: Check the version of picard. Version is 1.82 is recommended. align_13: Check the version of GATK. Version 3.3 is recommended. align_20: Check existence of class files for Picard and GATK align_50: Download the GATK resource bundle to resource directory align_60: Build bwa index for build hg19 of reference genome align_100: Convert bam files to paired fastq files if the input is in bam/sam format. Other input files are returned untouched. align_101: Decompress all input files (.tgz2, .tar, .tar.gz, .gz, .tgz, .zip etc) to a cache directory. Uncompressed files are hard- linked to the cache directory. align_200: Check the format of the input fastq file and write an option file with option -I if the sequences are in Illumina 1.3+ format. align_201: Call bwa aln to produce .sai files align_300: Running bwa sampe for paired end reads, using read group tag saved in a .RG file align_302: Check the proportion of aligned reads and exit if there are less than 80% of aligned reads. align_303: If in production mode, remove fastq files dumped from bam files align_400: Merge per-lane sam files into a single bam file. This step is skipped if there is only one input file. align_500: Sort merged bam file using picard SortSam align_501: If in production mode, remove decompressed fastq and individual bam files after a single bam file has been produced. align_600: Mark duplicates using picard MarkDuplicates command align_601: Remove _sorted.bam file after deduplication is completed. align_610: Index dedupped bam file using samtools align_700: Realign indels create indel realigner target align_710: Apply indel realigner target to bam file align_711: If in production mode, remove bam files before realignment steps align_800: Create base recalibrator target align_810: Apply base recalibrator target align_811: If in production mode, remove bam files before realignment steps align_900: Generated bam file with reduced reads if more than one output file is specified align_1000: Send a warning message if default read group is used. align_1001: Send a warning message if default read group is used. Pipeline parameters: name Name of the job to be executed. All intermediate files generated from this pipeline will be saved to $CACHE_DIR/$NAME where $CACHE_DIR is the cache directory of the project. strict_prog_version Whether or not use other version of programs if the exact version does not exist. Setting it to False allows variant tools to use other versions of the programs. (default: False) production If set to True or 1, all intermediate files will be removed. The whole pipeline would need to be rerun if a different parameter or different version of external program is used. (default: False) picard_path Path to picard jar files gatk_path Path to GATK jar file GenomeAnalysisTK.jar rgid Read group ID (default: 1) rglb Read group Library. (default: LIB) rgpl Read group Platform (default: Illumina) rgsm Read group sample name. Value of parameter --name will be used if this parameter is left unspecified. rgpu Read group platform unit (e.g. flowcall-barcode.lane). (default: FC.1) opt_java Option to java program. -Djava.io.tmpdir is frequently used to set java temporary directory if system temporary partition is not big enough. (default: -Xmx4g -XX:-UseGCOverheadLimit -Djava.io.tmpdir=${TEMP_DIR}/tmp) opt_bwa_index Option to command 'bwa index' opt_bwa_aln Option to command 'bwa aln' opt_bwa_sampe Option to command 'bwa sampe' opt_samtools_faidx Option to command 'samtools faidx' opt_samtools_index Option to command 'samtools index' opt_picard_sortsam Option to picard SortSam.jar (default: VALIDATION_STRINGENCY=LENIENT) opt_picard_mergesamfiles Option to picard MergeSamFiles.jar (default: MAX_RECORDS_IN_RAM=5000000) opt_picard_samtofastq Option to picard SamToFastq.jar (default: VALIDATION_STRINGENCY=LENIENT NON_PF=true) opt_picard_markduplicates Option to picard MarkDuplicates.jar opt_gatk_realignertargetcreator Option to command gatk RealignerTargetCreator opt_gatk_indelrealigner Option to command gatk IndelRealigner (default: --filter_mismatching_base_and_quals) opt_gatk_baserecalibrator Option to command gatk BaseRecalibrator (default: -rf BadCigar) opt_gatk_printreads Option to command gatk PrintReads opt_gatk_reducereads Option to command gatk ReduceReads  Please specify correct readgroup information using parameters --RGID, --RGLB, --RGPL, --RGPU and --RGSM if you plan to analyze the generated bam file with other files (e.g. joint variant calling).\nDetails Set up environment This pipeline uses the following external commands:\n bwa samtools Picard GATK  You should add path to bwa and samtools to $PATH so that the pipeline can find these tools. The pipeline expects to use certain versions of the tools. You can pass \u0026ndash;strict_version no to use newer tools but the pipeline might not work as expected. Paths to Picard and GATK should be passed using options gatk_path and picard_path.\nTest the environment After you installed the programs, you should running the following commands to test if everything works ok:\n# create a new project and download test data (an online snapshot) % vtools init test --parent vt_illuminaTestData % vtools execute bwa_gatk33_hg19 align --input illumina_test_seq.tar.gz --output test.bam \\ --gatk_path /path/to/gatk --picard_path /path/to/picard --name test  This command will not only test the availability of tools, but also download all required resource files and build necessary indexes.\nExecuting the pipeline in production mode The pipeline will by default keep all intermediate files. If you restart the pipeline with different parameter or a different version of an external file, only the affected steps will be repeated. Intermediate files will be reused if available. This allows you to examine and fine-tune the pipeline to make sure it works as expected.\nBecause intermediate files can be large, an option --production true is provided to execute the pipeline in production mode. In this mode, most intermediate files will be removed after the completion of the steps that make use of them. The pipeline can resume from the right step if it is interrupted, but has to be re-executed from the beginning if a result file is removed.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/genes/ccdsgene/",
	"title": "ccdsGene",
	"tags": [],
	"description": "",
	"content": " This database contains high-confidence human gene annotations from the Consensus Coding Sequence (CCDS) project. It was constructed from the UCSC Genome Browser ccdsGene track. If you would like to annotate your variants to these genes, you can use the simpler ccdsGene database. If you would like to determine the exons that your variants are in, use the ccdsGene_exon database. See the available annotation fields for each database below.\nccdsGene % vtools show annotation ccdsGene -v2 Annotation database ccdsGene (version hg19_20130904) Description: High-confidence human gene annotations from the Consensus Coding Sequence (CCDS) project. Database type: range Number of records: 27,762 Distinct ranges: 23,393 Reference genome hg19: chr, cdsStart, cdsEnd Field: name Type: string Comment: Gene name (usually a CCDS transcript ID) Missing entries: 0 Unique Entries: 27,731 Field: chr Type: string Missing entries: 0 Unique Entries: 24 Field: strand Type: string Comment: which DNA strand contains the observed alleles Missing entries: 0 Unique Entries: 2 Field: cdsStart Type: integer Comment: Coding region start Missing entries: 0 Unique Entries: 20,946 Range: 41608 - 249211537 Field: cdsEnd Type: integer Comment: Coding region end Missing entries: 0 Unique Entries: 21,000 Range: 46385 - 249212562 Field: exonCount Type: integer Comment: Number of exons Missing entries: 0 Unique Entries: 107 Range: 1 - 362 Field: score Type: integer Comment: Score Missing entries: 0 Unique Entries: 1 Range: 0 - 0 Field: name2 Type: string Comment: Alternate name Missing entries: 0 Unique Entries: 1 Field: cdsStartStat Type: string Comment: cds start stat, can be 'non', 'unk', 'incompl', and 'cmp1' Missing entries: 0 Unique Entries: 1 Field: cdsEndStat Type: string Comment: cds end stat, can be 'non', 'unk', 'incompl', and 'cmp1' Missing entries: 0 Unique Entries: 1  ccdsGene_exon % vtools show annotation ccdsGene_exon -v2 Annotation database ccdsGene_exon (version hg19_20130904) Description: High-confidence human gene annotations from the Consensus Coding Sequence (CCDS) project. This database contains all exon regions of the CCDS genes. Database type: range Number of records: 291,746 Distinct ranges: 192,096 Reference genome hg19: chr, exon_start, exon_end Field: name Type: string Comment: CCDS gene name Missing entries: 0 Unique Entries: 27,731 Field: chr Type: string Missing entries: 0 Unique Entries: 24 Field: strand Type: string Comment: which DNA strand contains the observed alleles Missing entries: 0 Unique Entries: 2 Field: cdsStart Type: integer Comment: Coding region start Missing entries: 0 Unique Entries: 20,946 Range: 41608 - 249211537 Field: cdsEnd Type: integer Comment: Coding region end Missing entries: 0 Unique Entries: 21,000 Range: 46385 - 249212562 Field: exonCount Type: integer Comment: Number of exons Missing entries: 0 Unique Entries: 107 Range: 1 - 362 Field: exon_start Type: integer Comment: exon start position Missing entries: 0 Unique Entries: 189,635 Range: 41608 - 249211537 Field: exon_end Type: integer Comment: exon end position Missing entries: 0 Unique Entries: 189,690 Range: 41627 - 249212562 Field: score Type: integer Comment: Score Missing entries: 0 Unique Entries: 1 Range: 0 - 0 Field: name2 Type: string Comment: Alternative name Missing entries: 0 Unique Entries: 1 Field: cdsStartStat Type: string Comment: cds start stat, can be 'non', 'unk', 'incompl', and 'cmp1' Missing entries: 0 Unique Entries: 1 Field: cdsEndStat Type: string Comment: cds end stat, can be 'non', 'unk', 'incompl', and 'cmp1' Missing entries: 0 Unique Entries: 1  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/joint_conditional/collapsing-methods/",
	"title": "collapsing methods",
	"tags": [],
	"description": "",
	"content": " Collapsing Methods for Disease and Quantitative Traits Introduction This is implementation of the fixed threshold collapsing methods for both disease and quantitative traits. Collapsing method for rare variants treats a genetic region as a test unit; based on observed genotype it assigns a numeric coding to the region {$X$}:{$$X = I_(0,N)(\\sum_i^N X_i)$$} i.e., the observed genotype will be coded as {$1$} if there exists at least one mutation, and {$0$} otherwise. This coding theme has been used in Li and Leal 2008[^Bingshan Li and Suzanne M. Leal (2008) Methods for Detecting Associations with Rare Variants for Common Diseases: Application to Analysis of Sequence Data. The American Journal of Human Genetics doi:10.1016/j.ajhg.2008.06.024. http://linkinghub.elsevier.com/retrieve/pii/S0002929708004084^] and Bhatia et al 2010[^Gaurav Bhatia, Vikas Bansal, Olivier Harismendy, Nicholas J. Schork, Eric J. Topol, Kelly Frazer and Vineet Bafna (2010) A Covering Method for Detecting Genetic Associations between Rare Variants and Common Phenotypes. PLoS Computational Biology doi:10.1371/journal.pcbi.1000954. http://dx.plos.org/10.1371/journal.pcbi.1000954^].\nAdvantages in using collapsing methods instead of aggregation methods? is in its robustness to LD of multiple rare variants in the region under investigation, which would potentially inflate type I error. However under additive assumptions of genetic effects, collapsing methods may be less powerful than aggregation methods.\nOur program implements the collapsing coding in a logistic regression framework for disease traits analysis (case control data) as CollapseBt method, and a linear regression framework for quantitative traits analysis as CollapseQt method. {$p$} value for collapsing method is based on asymptotic normal distribution of the Wald statistic in generalized linear models. One could incorporate a number of phenotype covariates in collapsing tests and evaluate the significance of the genetics component.\nAdjust for missing genotypes If the pattern of missing genotypes is not random in sample (e.g., missing ratio in cases is different from in controls), then type I error can be inflated. For small proportion of missing data, this issue can be alleviated using methods proposed by Auer et al 2013[^personal communication with Paul L. Auer at Fred Hutchinson Cancer Research Center^], which is implemented as an option --NA_adjust.\nDetails Command interface % vtools show test CollapseBt Name: CollapseBt Description: Collapsing method for disease traits, Li \u0026amp; Leal 2008 usage: vtools associate --method CollapseBt [-h] [--name NAME] [--mafupper MAFUPPER] [--alternative TAILED] [--NA_adjust] [--moi {additive,dominant,recessive}] Fixed threshold collapsing method for disease traits (Li \u0026amp; Leal 2008). p-value is based on the significance level of the regression coefficient for genotypes. If --group_by option is specified, variants within a group will be collapsed into a single binary coding using an indicator function (coding will be \u0026quot;1\u0026quot; if ANY locus in the group has the alternative allele, \u0026quot;0\u0026quot; otherwise) optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 0.01 --alternative TAILED Alternative hypothesis is one-sided (\u0026quot;1\u0026quot;) or two-sided (\u0026quot;2\u0026quot;). Default set to 1 --NA_adjust This option, if evoked, will replace missing genotype values with a score relative to sample allele frequencies. The association test will be adjusted to incorporate the information. This is an effective approach to control for type I error due to differential degrees of missing genotypes among samples. --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive model. Default set to additive % vtools show test CollapseQt Name: CollapseQt Description: Collapsing method for quantitative traits, Li \u0026amp; Leal 2008 usage: vtools associate --method CollapseQt [-h] [--name NAME] [--mafupper MAFUPPER] [--alternative TAILED] [--NA_adjust] [--moi {additive,dominant,recessive}] Fixed threshold collapsing method for quantitative traits (Li \u0026amp; Leal 2008). p-value is based on the significance level of the regression coefficient for genotypes. If --group_by option is specified, variants within a group will be collapsed into a single binary coding using an indicator function (coding will be \u0026quot;1\u0026quot; if ANY locus in the group has the alternative allele, \u0026quot;0\u0026quot; otherwise) optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 0.01 --alternative TAILED Alternative hypothesis is one-sided (\u0026quot;1\u0026quot;) or two-sided (\u0026quot;2\u0026quot;). Default set to 1 --NA_adjust This option, if evoked, will replace missing genotype values with a score relative to sample allele frequencies. The association test will be adjusted to incorporate the information. This is an effective approach to control for type I error due to differential degrees of missing genotypes among samples. --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive model. Default set to additive  Application  Example using snapshot vt_ExomeAssociation\n# create a project and download sample project % vtools init asso --parent vt_ExomeAssociation % vtools associate rare status --covariates age gender bmi exposure -m \u0026quot;CollapseBt --name Col\\ lapseBt --alternative 2\u0026quot; --group_by name2 --to_db collapseBt -j8 \u0026gt; collapseBt.txt INFO: 3180 samples are found INFO: 2632 groups are found INFO: Starting 8 processes to load genotypes Loading genotypes: 100% [=============================] 3,180 32.8/s in 00:01:36 Testing for association: 100% [=====================] 2,632/147 5.7/s in 00:07:37 INFO: Association tests on 2632 groups have completed. 147 failed. INFO: Using annotation DB collapseBt in project test. INFO: Annotation database used to record results of association tests. Created on Wed, 30 Jan 2013 23:10:09 % vtools show fields | grep collapseBt collapseBt.name2 name2 collapseBt.sample_size_CollapseBt sample size collapseBt.num_variants_CollapseBt number of variants in each group (adjusted for specified MAF collapseBt.total_mac_CollapseBt total minor allele counts in a group (adjusted for MOI) collapseBt.beta_x_CollapseBt test statistic. In the context of regression this is estimate of collapseBt.pvalue_CollapseBt p-value collapseBt.wald_x_CollapseBt Wald statistic for x (beta_x/SE(beta_x)) collapseBt.beta_2_CollapseBt estimate of beta for covariate 2 collapseBt.beta_2_pvalue_CollapseBt p-value for covariate 2 collapseBt.wald_2_CollapseBt Wald statistic for covariate 2 collapseBt.beta_3_CollapseBt estimate of beta for covariate 3 collapseBt.beta_3_pvalue_CollapseBt p-value for covariate 3 collapseBt.wald_3_CollapseBt Wald statistic for covariate 3 collapseBt.beta_4_CollapseBt estimate of beta for covariate 4 collapseBt.beta_4_pvalue_CollapseBt p-value for covariate 4 collapseBt.wald_4_CollapseBt Wald statistic for covariate 4 collapseBt.beta_5_CollapseBt estimate of beta for covariate 5 collapseBt.beta_5_pvalue_CollapseBt p-value for covariate 5 collapseBt.wald_5_CollapseBt Wald statistic for covariate 5 % head collapseBt.txt name2 sample_size_CollapseBt num_variants_CollapseBt total_mac_CollapseBt beta_x_CollapseBt pvalue_CollapseBt wald_x_CollapseBt beta_2_CollapseBt beta_2_pvalue_CollapseBt wald_2_CollapseBt beta_3_CollapseBt beta_3_pvalue_CollapseBt wald_3_CollapseBt beta_4_CollapseBt beta_4_pvalue_CollapseBt wald_4_CollapseBt beta_5_CollapseBt beta_5_pvalue_CollapseBt wald_5_CollapseBt AADACL4 3180 5 138 -0.2941 0.368956 -0.89843 0.0312903 4.30942E-09 5.87186 -0.296598 0.0154271 -2.42219 0.129942 1.83369E-40 13.3174 0.437372 0.00133613 3.2081 AAMP 3180 3 35 0.00135633 0.997852 0.0026919 0.0312624 4.39097E-09 5.86875 -0.298944 0.0146254 -2.44152 0.130231 1.24946E-40 13.346 0.43547 0.00139464 3.19576 ABCB10 3180 6 122 0.333178 0.219379 1.22818 0.0312644 4.40563E-09 5.8682 -0.301597 0.013796 -2.46253 0.130493 9.8029E-41 13.3641 0.431826 0.00154525 3.16605 ABCG8 3180 12 152 -0.432823 0.171192 -1.36838 0.0314772 3.67916E-09 5.89801 -0.295762 0.0157794 -2.41398 0.130108 1.52929E-40 13.331 0.440976 0.001228 3.2323 ABCB6 3180 7 151 -0.0619203 0.825828 -0.220056 0.0312972 4.27575E-09 5.87316 -0.299244 0.0145216 -2.4441 0.130203 1.22141E-40 13.3477 0.435756 0.00138398 3.19797 ABHD1 3180 5 29 -0.129748 0.840786 -0.200889 0.0312418 4.49451E-09 5.86488 -0.298341 0.0148474 -2.43608 0.130264 1.16331E-40 13.3513 0.43624 0.00137271 3.20033 ABCG5 3180 6 87 0.35312 0.287604 1.06339 0.0312942 4.1554E-09 5.87789 -0.298364 0.0148076 -2.43705 0.130389 9.49319E-41 13.3665 0.440212 0.00124756 3.22778 ABCD3 3180 3 42 -0.255649 0.662305 -0.436732 0.0312799 4.33855E-09 5.87074 -0.301233 0.0139678 -2.45809 0.130221 1.02858E-40 13.3605 0.436902 0.00134823 3.20551 ABCA4 3180 43 492 -0.00909763 0.95585 -0.0553619 0.0312634 4.37388E-09 5.8694 -0.298919 0.0146254 -2.44153 0.130239 1.15466E-40 13.3519 0.435484 0.00139409 3.19587  QQ-plot Attach:collapseBt.jpg\n% vtools associate rare bmi --covariates age gender exposure -m \u0026quot;CollapseQt --name CollapseQt\\ --alternative 2\u0026quot; --group_by name2 --to_db collapseQt -j8 \u0026gt; collapseQt.txt INFO: 3180 samples are found INFO: 2632 groups are found INFO: Starting 8 processes to load genotypes Loading genotypes: 100% [=======================] 3,180 33.4/s in 00:01:35 Testing for association: 100% [====================] 2,632/147 26.2/s in 00:01:40 INFO: Association tests on 2632 groups have completed. 147 failed. INFO: Using annotation DB collapseQt in project test. INFO: Annotation database used to record results of association tests. Created on Thu, 31 Jan 2013 03:48:21 % vtools show fields | grep collapseQt collapseQt.name2 name2 collapseQt.sample_size_CollapseQt sample size collapseQt.num_variants_CollapseQt number of variants in each group (adjusted for specified MAF collapseQt.total_mac_CollapseQt total minor allele counts in a group (adjusted for MOI) collapseQt.beta_x_CollapseQt test statistic. In the context of regression this is estimate of collapseQt.pvalue_CollapseQt p-value collapseQt.wald_x_CollapseQt Wald statistic for x (beta_x/SE(beta_x)) collapseQt.beta_2_CollapseQt estimate of beta for covariate 2 collapseQt.beta_2_pvalue_CollapseQt p-value for covariate 2 collapseQt.wald_2_CollapseQt Wald statistic for covariate 2 collapseQt.beta_3_CollapseQt estimate of beta for covariate 3 collapseQt.beta_3_pvalue_CollapseQt p-value for covariate 3 collapseQt.wald_3_CollapseQt Wald statistic for covariate 3 collapseQt.beta_4_CollapseQt estimate of beta for covariate 4 collapseQt.beta_4_pvalue_CollapseQt p-value for covariate 4 collapseQt.wald_4_CollapseQt Wald statistic for covariate 4 % head collapseQt.txt name2 sample_size_CollapseQt num_variants_CollapseQt total_mac_CollapseQt beta_x_CollapseQt pvalue_CollapseQt wald_x_CollapseQt beta_2_CollapseQt beta_2_pvalue_CollapseQt wald_2_CollapseQt beta_3_CollapseQt beta_3_pvalue_CollapseQt wald_3_CollapseQt beta_4_CollapseQt beta_4_pvalue_CollapseQt wald_4_CollapseQt ABCD3 3180 3 42 -0.487474 0.571152 -0.566415 0.0149956 0.0588415 1.89006 -0.0808192 0.693535 -0.394098 -0.941867 2.64731E-05 -4.20804 ABCB6 3180 7 151 -0.532616 0.24625 -1.15972 0.0151515 0.056238 1.90989 -0.0810239 0.692719 -0.395204 -0.944219 2.5176E-05 -4.21945 ABHD1 3180 5 29 0.18344 0.859929 0.176479 0.0150381 0.0581416 1.89531 -0.0794273 0.698569 -0.387288 -0.94411 2.54398E-05 -4.21708 ABCA12 3180 28 312 -0.415972 0.211796 -1.24889 0.0151627 0.0560493 1.91135 -0.0789784 0.700073 -0.385257 -0.937093 2.90651E-05 -4.18676 ABCG8 3180 12 152 -0.56687 0.212912 -1.24585 0.0151496 0.0562578 1.90973 -0.0744998 0.716361 -0.363359 -0.939062 2.78992E-05 -4.1961 ABCA4 3180 43 492 0.0984281 0.721612 0.356337 0.0150102 0.0586022 1.89185 -0.0792212 0.699266 -0.386347 -0.942427 2.61944E-05 -4.21045 ABI2 3180 1 25 1.19633 0.276415 1.0886 0.0150043 0.0586562 1.89144 -0.081478 0.691101 -0.397397 -0.941765 2.64399E-05 -4.20833 ABL2 3180 4 41 -0.613866 0.475633 -0.713429 0.0150498 0.0579226 1.89697 -0.0781101 0.703263 -0.380954 -0.945432 2.46814E-05 -4.22394 ACADL 3180 5 65 1.33815 0.0528276 1.93705 0.0150444 0.0578831 1.89727 -0.082882 0.685934 -0.404416 -0.941384 2.64356E-05 -4.20836  QQ-plot Attach:collapseQt.jpg\n\n[^#^]\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/other_pipelines/import_vcf/",
	"title": "import_vcf",
	"tags": [],
	"description": "",
	"content": " Import all variant and genotype fields from vcf files Usage % vtools show pipeline import_vcf This pipeline creates a customized .fmt file to import all variant and genotype info fields of input vcf files. Available pipelines: import_vcf Pipeline \u0026quot;import_vcf\u0026quot;: This pipeline creates a customized .fmt file by scanning the header of input vcf files and imports all variant and genotype info fields of the input files in VCF format. If an output file is specified (--output), it will be used to save the customized .fmt file. import_vcf_0: Check the version of variant tools (version 2.1.1 and above is required to execute this pipeline) import_vcf_10: Create a feild description file from input text file. import_vcf_20: Import input files using customized .fmt file. Please check the .fmt file if the import process fails due to incorrect field information. Pipeline parameters: build Build of reference genome, which will be guessed from the input vcf file (if it contains a comment line with reference genome information).  Details variant tools provides a general vcf.fmt that contains the definition of many commonly used variant and genotype info fields, but the command vtools import by default does not import any of them. The reasons behind this include\n A vcf file can contain many info fields, including novel ones that are not defined in vcf.fmt Importing all info into a project is not always a good idea (increase the size of project etc). Even if you lave them out during the import stage, you can add them later using command vtools update --from_file, access them using the track function, or move them into an annotation database (see pipeline annFileFromVcf in anno_utils.pipeline. It is not always clear how to import certain variant or genotype fields. For example, a variant info field DP might better be imported as genotype field if the samples are called one by one and DP describes per-sample read depth.  Anyway, if you would like to import all information from an input vcf file, you can\n Create a customized .fmt file that contains all variant and genotype info fields from the input vcf file Import data using this customized .fmt file,  This pipeline assists this process by automating the creation of the .fmt file.\n This pipeline outputs a .fmt file if you specify a output file using command line option --output. You can modify this file and use command vtools import to import data if the pipeline fails to execute (e.g. when an invalid field name is used). Although you can specify multiple vcf files in the command line (parameter \u0026ndash;input), the format will be generated from the first vcf file. These vcf files therefore must have the same variant and genotype fields.   Import all fields from vcf files\n% vtools init test -f % vtools execute import_vcf --input V*.vcf INFO: Executing import_vcf.import_vcf_0: Check the version of variant tools (version 2.1.1 and above is required to execute this pipeline) INFO: Executing import_vcf.import_vcf_10: Create a feild description file from input text file. INFO: Executing import_vcf.import_vcf_20: Import input files using customized .fmt file. Please check the .fmt file if the import process fails due to incorrect field information. INFO: Running vtools import V1.vcf V2.vcf V3.vcf --build hg19 --format cache/V1.vcf.fmt INFO: Importing variants from V1.vcf (1/3) V1.vcf: 100% [================================================] 1,000 17.2K/s in 00:00:00 INFO: 985 new variants (985 SNVs, 2 unsupported) from 1,000 lines are imported. INFO: Importing variants from V2.vcf (2/3) V2.vcf: 100% [================================================] 1,000 15.1K/s in 00:00:00 INFO: 348 new variants (984 SNVs, 3 unsupported) from 1,000 lines are imported. INFO: Importing variants from V3.vcf (3/3) V3.vcf: 100% [================================================] 1,000 14.8K/s in 00:00:00 INFO: 270 new variants (986 SNVs, 1 unsupported) from 1,000 lines are imported. Importing genotypes: 100% [====================================] 4,818 2.4K/s in 00:00:02 Copying samples: 100% [===========================================] 6 48.0K/s in 00:00:00 INFO: 1,603 new variants (2,955 SNVs, 6 unsupported) from 3,000 lines (3 samples) are imported. INFO: Command \u0026quot;vtools import V1.vcf V2.vcf V3.vcf --build hg19 --format cache/V1.vcf.fmt\u0026quot; completed successfully in 00:00:12  (:exampleend\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_commands/init/",
	"title": "init",
	"tags": [],
	"description": "",
	"content": " Create a new project 1. Usage % vtools init -h usage: vtools init [-h] [-f] [--parent DIR_or_SNAPSHOT] [--variants [TABLE]] [--samples [COND [COND ...]]] [--genotypes [COND [COND ...]]] [--children DIR_OR_SNAPSHOT [DIR_OR_SNAPSHOT ...]] [-v {0,1,2}] project Create a new project in the current directory. This command will fail if another project already exists in this directory, unless option '--force' is used to remove the existing project. positional arguments: project Name of a new project. This will create a new .proj file under the current directory. Only one project is allowed in a directory. optional arguments: -h, --help show this help message and exit -f, --force Remove a project if it already exists. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1). Derive from a parent project: --parent DIR_or_SNAPSHOT Directory or snapshot file of a parent project (e.g. --parent ../main) from which all or part of variants (--variants), samples (--samples) and genotypes (--genotypes) will be copied to the newly created project. --variants [TABLE] A variant table of the parental project whose variants will be copied to the new project. Default to variant (all variants). --samples [COND [COND ...]] Copy only samples of the parental project that match specified conditions. --genotypes [COND [COND ...]] Copy only genotypes that match specified conditions. Merge from children projects: --children DIR_OR_SNAPSHOT [DIR_OR_SNAPSHOT ...] A list of a subprojects (directories or snapshot files of projects) that will be merged to create this new project. The subprojects must have the same primary and alternative reference genome. Variant tables with the same names from multiple samples will be merged. Samples from the children projects will be copied even if they were identical samples imported from the same source files.  2. Details Command vtools init creates a new project in the current directory. The project will be empty unless it is a child project from a parent project (with a subset of samples, variants etc), or a parent project of several children projects (with merged variants and samples).\nA directory can only have one project. After a project is created, subsequent vtools calls will automatically load the project in the current directory. Working from outside of a project directory is not allowed.\nA variant tools project $name consists of a project file $name.proj, a genotype database (HDF5 or SQLite), and a log file $name.log. In addition to the project databases under the project directory, variant tools will store\n annotation databases, format specification etc in a local resource directory, which is by default ~/.variant_tools. You can use command \u0026ldquo;vtools admin --set_runtime_option local_resource\u0026rdquo; to relocate this directory if your home directory does not have enough free space. temporary files stored in a system temporary directory, which is usually under /tmp. If your temp partition is not large enough, you can set runtime option temp_dir to another directory. This directory will be cleared automatically after a project is closed, so do not point it to a directory with existing files.  2.1 Create a new project Command `vtools init NAME creates a new project NAME under the current directory. It will fail if there is already a project in the current directory, unless option --force is used to remove any existing project.\n Examples: create a new project The following commands create a directory myproj and create a variant tools project in this directory:\n% mkdir myproj % cd myproj % vtools init myproj INFO: variant tools 3.0.0dev : Copyright (c) 2011 - 2016 Bo Peng INFO: Please visit http://varianttools.sourceforge.net for more information. INFO: Creating a new project myproj  If you attempt to create another project in the same directory, command `vtools init will fail with an error message:\n% vtools init myproj ERROR: A project can only be created in a directory without another project.  Using the --force option will remove the existing project and create a new one:\n% vtools init test --force INFO: variant tools 3.0.0dev : Copyright (c) 2011 - 2016 Bo Peng INFO: Please visit http://varianttools.sourceforge.net for more information. INFO: Creating a new project test  \nIf you are worried about losing your work by accidentally calling vtools init with option --force, you could save copies of your project using command `vtools admin --save_snapshot from time to time, and load a saved snapshot using command `vtools admin --load_snapshot when needed.\n 2.2 Create a project from a parent project A project could be created from a parent project with a subset of its variants and samples. For example, a child project with variants from a small chromosomal region could be created from a parent project to test a pipeline before it is applied to the whole project. This also allows differential analysis of subsets of variants (e.g. SNVs and indels) and samples.\n Examples: create a parent project Let us start from a snapshot project quickStartGuide:\n% vtools admin --load_snapshot vt_quickStartGuide_v3 Downloading snapshot vt_quickStartGuide_v3.tar.gz from online repository Extracting vt_quickStartGuide_v3: 100% [===================================] 148,585 20.1M/s in 00:00:00 INFO: Snapshot vt_quickStartGuide_v3 has been loaded  This project has variants from two samples and a single master variant table with 4,858 variants:\n% vtools show samples sample_name filename CEU CEU_hg38_all.vcf JPT JPT_hg38_all.vcf % vtools show tables table #variants date message variant 4,839 May30 Master variant table  Variants from the HG00096 and HG00479 samples could be selected to separate variant tables using commands\n% vtools select variant --samples \u0026quot;sample_name=='CEU'\u0026quot; -t CEU INFO: 3470 variants selected. % vtools select variant --samples \u0026quot;sample_name=='JPT'\u0026quot; -t JPT INFO: 2878 variants selected.  The project now has three variant tables\n% vtools show tables table #variants date message CEU 3,470 May30 JPT 2,878 May30 variant 4,839 May30 Master variant table  \n Examples (This function is only supported when STOREMODE is set to sqlite.): create subprojects from the parent project \nThe following filters could be applied to the parent project if the STOREMODE is set to SQLite.\n --variants Only variants from the specified variant table of the parent project will be copied. Genotypes of samples will be affected because only genotypes related to these variants will be copied. --samples Only samples matching specified conditions (e.g. sample names) will be copied. --genotypes Only genotypes matching specified conditions (e.g. with quality score above certain threshold) will be copied.  You can create a subproject with variants from the CEU:\n% mkdir myproj % cd myproj % vtools admin --load_snapshot vt_quickStartGuide % export STOREMODE=\u0026quot;sqlite\u0026quot; % vtools select variant --samples 'sample_name == \u0026quot;CEU\u0026quot;' -t CEU 'Variants from CEU population' % vtools select variant --samples 'sample_name == \u0026quot;JPT\u0026quot;' -t JPT 'Variants from JPT population' % mkdir ../CEU % cd ../CEU % vtools init CEU --parent ../myproj --variants CEU INFO: variant tools 3.0.0dev : Copyright (c) 2011 - 2016 Bo Peng INFO: Please visit http://varianttools.sourceforge.net for more information. INFO: Creating a new project CEU Copying variant tables ../myproj/test.proj: 100% [============================] 6 251.6/s in 00:00:00 Copying samples: 100% [=======================================================] 2 211.4/s in 00:00:00 INFO: 3489 variants and 2 samples are copied  The new project has a master variant table with 3,489 variants:\n% vtools show tables table #variants date message CEU 3,489 May14 Variants from CEU population JPT 1,531 May14 Variants from JPT population variant 3,489  and two samples (with subsets of variants):\n% vtools show genotypes sample_name filename num_genotypes sample_genotype_fields CEU CEU.exon.2010_03.sites.vcf.gz 3489 JPT JPT.exon.2010_03.sites.vcf.gz 1531  You can create another project with variants in the JPT population, and only the JPT sample:\n% mkdir ../JPT % cd ../JPT % vtools init JPT --parent ../myproj --variants JPT --samples 'sample_name == \u0026quot;JPT\u0026quot;' INFO: variant tools 3.0.0dev : Copyright (c) 2011 - 2016 Bo Peng INFO: Please visit http://varianttools.sourceforge.net for more information. INFO: Creating a new project JPT Copying variant tables ../myproj/test.proj: 100% [==================================] 6 214.4/s in 00:00:00 Copying samples: 100% [=============================================================] 1 111.3/s in 00:00:00 INFO: 4858 variants and 1 samples are copied  The new JPT project has a master variant table with 2,900 variants,\n% vtools show tables table #variants date message CEU 1,531 May14 Variants from CEU population JPT 2,900 May14 Variants from JPT population variant 2,900  and a single sample JPT:\n% vtools show samples sample_name filename JPT JPT.exon...3.sites.vcf.gz  if you use –-samples (or –-genotypes) options without –-variants option to create a subproject, all of the variant tables in the parent project will be copied into your subproject, and the specified samples or genotypes will be copied to your subproject.\n\nThe parent project does not have to be a directory. It can also be a local or online snapshot. For example, command\n% mkdir ../test % cd ..test % vtools init test --parent vt_simple INFO: variant tools 3.0.0dev : Copyright (c) 2011 - 2016 Bo Peng INFO: Please visit http://varianttools.sourceforge.net for more information. INFO: Creating a new project test INFO: Extracting snapshot vt_simple to . Downloading snapshot vt_simple.tar.gz from online repository Extracting vt_simple: 100% [====================================================] 41,325 5.4M/s in 00:00:00  will download snapshot vt_simple from online and become the present project. In addition, if you have a snapshot file, you can use command\n% vtools init test --parent my_snapshot.tar.gz  which is a shortcut to commands\n% vtools init test % vtools admin --load_snapshot my_snapshot.tar.gz  2.3 (This function is only supported when STOREMODE is set to sqlite.) Create a project from several subprojects A project could also be created from one or more children projects if the STOREMODE is set to sqlite. This allows flexible handling of batches of data (e.g. analyze data separately or jointly), and parallel processing of large datasets (e.g. split a project by chromosomes, analyze them separately, and combine the results).\nMerging two or more variant tools projects will merge variants and samples from these projects. More specifically,\n variant tables with the same names are merged with duplicate variants removed variant info fields are merged. Projects that do not have certain fields will have NULL values for these fields. samples from the children projects are copied to the merged project even if they are identical.  Because subprojects might have overlapping variants, variant tables, and samples, merging subproject might lead to unexpected results.\nVariant tables from children projects will be copied to $name (from $proj) before they are merged. This allows you to keep track of information from the original projects, or compare tables from children projects.\n  Examples: merge subprojects Continue from the previous example, if we just merge the CEU and JPT projects we created,\n% mkdir ../merged % cd ../merged % vtools init merged --children ../CEU ../JPT INFO: variant tools 3.0.0dev : Copyright (c) 2011 - 2016 Bo Peng INFO: Please visit http://varianttools.sourceforge.net for more information. INFO: Creating a new project merged Loading ../CEU/CEU (1/2): 0 0.0/s in 00:00:00 Loading ../JPT/JPT (2/2): 0 0.0/s in 00:00:00 Merging all projects: 100% [========================================================] 22 21.9/s in 00:00:01  we will see that variants from these two projects are corrected merged\n% vtools show tables table #variants date message CEU 3,489 May14 Variants from CEU population (merged) CEU (from CEU) 3,489 May14 Variants from CEU population (from CEU) CEU (from JPT) 1,531 May14 Variants from CEU population (from JPT) JPT 2,900 May14 Variants from JPT population (merged) JPT (from CEU) 1,531 May14 Variants from JPT population (from CEU) JPT (from JPT) 2,900 May14 Variants from JPT population (from JPT) variant 4,858 May14 (merged) variant (from CEU) 3,489 (from CEU) variant (from JPT) 1,369 (from JPT)  but we have three samples with different number of variants\n% vtools show genotypes sample_name filename num_genotypes sample_genotype_fields CEU CEU.exon...3.sites.vcf.gz 3489 JPT JPT.exon...3.sites.vcf.gz 1531 JPT JPT.exon...3.sites.vcf.gz 2900  Because the latter two samples have the same name, it is even difficult to remove one of them using command vtools remove samples. If you have to merge samples with the same names from different projects, it is recommended that you use command vtools admin --rename_samples to change names of samples before merging, and remove duplicated samples afterwards.\nIf you have a large number of samples from different sources, it is a good idea to create subprojects for groups of samples. Merging subprojects will be faster than reading from source files again. However, due to the overhead of re-mapping all variants, pre-processing each sample by creating its own project usually does not help much.\n\nThe children projects can also be snapshots, so if you have snapshots of a number of children projects, you can create a merged project using command\n% vtools init test --children max_gt_data.tar poly_data.tar  The snapshots can also be an online snapshot so you can use an online snapshot to start your new project:\n% vtools init test --children vt_simple  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/regions/low_complexity_regions/",
	"title": "low complexity regions",
	"tags": [],
	"description": "",
	"content": " Low Complexity and RepetitiveRegions Low Complexity Regions "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/functions/ref_sequence/",
	"title": "ref_sequence",
	"tags": [],
	"description": "",
	"content": " Reference sequence around variant site Usage Function ref_sequence(chr, start, end) returns the reference sequence between start and end on chromosome chr of the reference genome (primary reference genome unless parameter --build is used to specify an alternative reference genome). If end is unspecified, ref_sequence(chr, pos) returns the reference allele at the specified location. This function is very useful in output the context of variants or select variants based on the contexts (e.g. select variants in CpG islands).\nSimply put, function ref_sequence in\n% vtools output variant chr pos 'ref_sequence(chr, pos)'  returns the nucleotide at the variant site, and\n% vtools output variant chr pos 'ref_sequence(chr, pos, pos+5)'  returns the 5-base sequence at and after the variant sites, for all variants in the master variant table.\nDetails  Examples: output reference sequence around variants Let us get a test project\n% vtools admin --load_snapshot vt_simple Downloading snapshot vt_simple.tar.gz from online INFO: Snapshot vt_simple has been loaded  We can check if the imported reference alleles is consistent with the reference genome:\n% vtools output variant chr pos ref 'ref_sequence(chr, pos)' -l 10 1 4540 G G 1 5683 G G 1 5966 T T 1 6241 T T 1 9992 C C 1 9993 G G 1 10007 G G 1 10098 G G 1 14775 G G 1 16862 A A  This means that we used the correct build of reference genome to import the data (c.f. vtools admin --validate_build). If we are interested in the up and down stream sequence of variants, we can use function ref_sequence,\n% vtools output variant chr pos ref 'ref_sequence(chr, pos-5, pos+5)' -l 10 1 4540 G GGGGGGAAGGT 1 5683 G CTGCTGCTTCT 1 5966 T GTGTGTGGGGG 1 6241 T AGGAATGGGGA 1 9992 C GGCCGCGGTGA 1 9993 G GCCGCGGTGAG 1 10007 G CAGGGGCCAGC 1 10098 G ATCTCGAGTCA 1 14775 G GGAGCGTCAGA 1 16862 A CCAGGAAGGTG  Now, if you are interested in checking if the variants happen in a region with high concentration of reference alleles (e.g. a repeatitive region), you can use an expression to calculate the concentration of reference allele in the region. For example, the following expression first gets the reference sequence of length 11 around the variant ((ref_sequence(chr, pos-5, pos+5)), remove all occurance of reference allele (replace(SEQ, ref, \u0026quot;\u0026quot;), and count the number of remaining alleles:\n% vtools update variant --set 'nRef=11-length(replace(ref_sequence(chr, pos-5, pos+5), ref, \u0026quot;\u0026quot;))' INFO: Adding variant info field nRef  The resulting new column nRef records the number of reference alleles in the 11 basepair regions around the variants:\n% vtools output variant chr pos ref 'ref_sequence(chr, pos-5, pos+5)' nRef -l 10 1 4540 G GGGGGGAAGGT 8 1 5683 G CTGCTGCTTCT 2 1 5966 T GTGTGTGGGGG 3 1 6241 T AGGAATGGGGA 1 1 9992 C GGCCGCGGTGA 3 1 9993 G GCCGCGGTGAG 6 1 10007 G CAGGGGCCAGC 5 1 10098 G ATCTCGAGTCA 2 1 14775 G GGAGCGTCAGA 5 1 16862 A CCAGGAAGGTG 3  (:exampleend\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/utilities/report_progress/",
	"title": "report progress",
	"tags": [],
	"description": "",
	"content": " Report the progress of the execution of pipelines ChangeLog  Dec 30, 2013: Initial release  Download Download report_progress, use\n% python report_progress\nor execute\n% report_progress\ndirectly after chmod +x report_progress.\nNote: Python module matplotlib is required to execute this script.\nIntroduction variant tools records the progress of the execution of pipelines in log files. This script parses the log files, extract the starting end ending time of the execution of each step of the pipeline, and plots them in a resulting pdf file.\n% report_progress -h usage: report_progress [-h] [--output OUTPUT] logfiles [logfiles ...] This script reads one or more local or remote log files produces by variant tools, extract starting times of steps of pipelines, and generate graphical reports positional arguments: logfiles One or more log files. If address:path is specified, log files will be copied to a temporary directory using command scp. No password can be specified so public key authentication is needed if a password is needed. optional arguments: -h, --help show this help message and exit --output OUTPUT Name of the output file (in pdf format). progress.pdf will be used if no file is specified.  This command accept a list of log files, which can be local or remote. In the latter case, command scp will be used to copy the files to a local temporary directory.\n% python report_progress /path/to/*.log % python report_progress 'username@server:path/to/*bam.log'  Without specifying the --output parameter, the figures will be saved in a PDF file named progress.pdf, with figures similar to\nAttach:progress_Page_01.png\nNote that\n Green lines represent running times of successful steps. Red lines represent running times of failed steps. Purple lines represent on-going steps, which is the last started job in the log file. Because a job might be killed during the last step, the running time might not be accurate. Duration for the execution of successful steps are reported (for non-trivial steps that lasts more than 2 minutes).  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/create_your_test/running-r-programs/",
	"title": "running R programs",
	"tags": [],
	"description": "",
	"content": " A General Framework for Association Analysis Using R Programs Introduction A number of rare variant association methods as well as the flexible VAT ensemble algorithm makes it possible to conveniently evaluate variant associations via different statistical options. In addition to the existing association testing framework, variant association tools can talk to R via customized R programs prepared by users. Under this mechanism, users write up an R function that analyzes data of an association testing unit (e.g., gene) and specify the output statistic that passes into VAT to create formatted text file or annotation databases. Input association data comes directly from the project database, cleaned and annotated. Users can thus focus on customizing the association analysis without having to worry about file format conversions, quality control and annotations. Multiprocessing and auto results annotation features are also supported to guarantee efficient computation and neat output. This general R interface is not only suitable for evaluating novel statistical tests for method development projects, but also good for highly customized analysis of real world data with simple R scripts.\nThe mechanism is implemented as RTest method which is available from vtools associate command interface. Please read below for instructions on preparing and executing R programs via RTest.\nDetails Interface vtools show test RTest Name: RTest Description: A general framework for association analysis using R programs usage: vtools associate --method RTest [-h] [--name NAME] [--data_cache N] script R test positional arguments: script R program to be loaded. The R script format has to follow the convention documented at http://varianttools.sf.net/Association/RTest optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields. --data_cache N Name of R data sets to be written into cache folder, for debug purpose.  A trivial example of the R script looks like the following\n(:codestart r\n BEGINCONF [sample.size] [result] n=2 columns=2 name=beta0, beta1 column_name=estimate, p.value ENDCONF  regression = function (dat, phenotype.name, family = \u0026ldquo;gaussian\u0026rdquo;) {\ny = dat@Y[, phenotype.name] x = apply(dat@X, 1, function(i) sum(i, na.rm=T)) m = glm(y~x,family=family) return (list(sample.size=length(y), result=summary(m)$coef[,c(1,4)]))  } (:codeend\nTo use this program for data analysis,\nvtools associate variant stroke \\ -m 'RTest /path/to/regression.R --name demo --phenotype.name \u0026quot;stroke\u0026quot; --family \u0026quot;binomial\u0026quot;' \\ \\ -g refGene.name2 -j8 --to_db demo \u0026gt; demo.txt  Format You should have one main function in the R program named the same as the R script file name. This is the interface function that interacts with the RTest command, taking input parameters from command line and return output in specified format (see below for details) that can be recognized by RTest and be stored in databases. This main function can call any other R objects as long as they are available from R or implemented elsewhere in your R program.\nInput parameters The main function should be defined in the following format\n(:codestart r ScriptName \u0026lt;- function(dataname, args, **kwargs) { \u0026hellip; } (:codeend\nwhere the first argument has to be the data object variable name (e.g. dat in the regression.R example, or any other valid names you specify), followed by a few required positional arguments (e.g. phenotype.name in regression.R example which has to be passed from commandline every time the program is executed), and other keyword arguments that have default values (e.g. family in the regression.R example. If not specified from the command line it will use default value \u0026ldquo;gaussian\u0026rdquo;). The required and optional arguments can be assigned from the commandline (e.g., the --phenotype.name 'stroke' argument of vtools associate).\nOutput configuration The return object of the main R function should be a list with the properties of each element in the list been pre-specified as comment strings at the beginning of the scripts taking the following format\n# BEGINCONF # [attribute1] # name= # type= # comment= # [attribute2] # n=N # columns= # name= # column_name= # type= # comment= # ENDCONF  and the return R list object is\nlist(attribute1=..., attribute2=..., ...)   The configuration area are R comments, starts with BEGINCONF and ends with ENDCONF. Each section name corresponds to an attribute in the return R list of the main function. Values of these attributes can be R numeric, string, vector, matrix or data.frame. Other R data type are not allowed. For attributes that are single values, e.g., numeric or string, two properties can be specified: a name property (default to the same name as the R attribute\u0026rsquo;s name), atype property (default to \u0026ldquo;float\u0026rdquo;) and a comment property (default to empty string). You can set them to different values than default, or use the default value by leaving the attribute empty (e.g. the [sample.size] attribute in the regression.R example) For attributes that are R vectors or two dimensional (2D) data.frame or matrices, the property n, indicating the number of elements in the vector or number of rows in 2D objects, have to be specified. If n is not specified the attribute will be treated as a single numeric value, leading to truncated result output. Besides n, all other properties have default values same as with single value attributes which can be re-set by specifying them in the configuration. For vector objects the name property, if set, should be comma separated and have number of elements equals n. The type of all elements in a vector should be the same, so there is only one type value to be set (e.g. type=float for all the n elements). For 2D objects, an additional required property p has to be set to specify how many columns are there in the attribute. The type property now would have to have p elements separated by comma, specifying the type of each column (e.g., type=float, string for the 1st column being float and 2nd column being character string). The name property is now the name of the rows, and an additional optional column_name property can be specified for column names. The comment property, if set, should be a sentence that briefly describes the entire section, not specific to certain row or column.  It is important that the return R object matches the descriptions in the configuration area. If the configuration area is not found in the R script, no output will be written to result databases. This is allowed because there are usage cases that does not need any output, e.g., you write an R program to plot some graphical summary of the association testing unit rather than performing association analysis and calculate p-values.\nData structure Data from vtools associate are passed into the main R function taking a variable name defined by the first argument of the function. For example if the first argument name is dat then you should manipulate the R variable dat in your R program. The dat object contains 3 default attributes and two optional attributes.\nDefault attributes\n R variable dat@name is a single character string which is the association testing group name of the data set. For example if the command is vtools associate ... -m ' ... ' --group_by refGene.name2, then the group name will be refseq gene names. If no --group_by option is used the group name will be chromosome:position of a variant. R variable dat@X is a data.frame with rows being samples (row names are sample names) and columns being variants (column names are chromosome:position of variants). The samples match the vtools associate ... --samples specification, and the variants are the ones in the variant_table specified by the association command vtools associate variant_table ... R variable dat object, although you can also pass the names of these phenotype/covariates to the R function and refer to the columns by their names (e.g., the phenotype.name specification in the regression.R example)  Optional attributes\n R variable dat@V is a data.frame of variant information corresponding to --var_info option in vtools associate command. The rows are variants (row names are chromosome:position) and columns are variant information / annotation field names. R variable dat@G is a list of data.frame of genotype information corresponding to --geno_info option in vtools associate command. Each attribute in the list is a data.frame with rows being samples and columns being the genotype information of each genotype call in a sample, e.g., the genotype quality, imputation scores, etc.  Cautions This R interfacing mechanism is flexible, and fragile at the same time, because the RTest method of vtools associate will have no control over what are implemented inside the R program. It assumes the R program the users provide is flawless and can result in exactly the same output as specified in the configuration area. If any errors occurs in the program, RTest will not attempt to fix it. It instead will simply flag an association test as \u0026ldquo;failed\u0026rdquo;. If you run an genome-wide association scan with your R program via RTest method and noticed all tests failed, its most likely your R program is problematic.\nDebug suggestions  All error messages will be written to the project log file for you to look into. Take a look at the log file to figure out why failures occur and fix your R code. A more advance option is to write out one or two groups of data with the R code to test interactively in R to see what\u0026rsquo;s going wrong. The --data_cache N option will output N R scripts per thread with data-set coded in it, to cache folder. The file name will be [Association Group Name].dat.R. For debug purpose you can add --data_cache 1 to the association command and run the command on a small variant table, find the R data file in cache, load it in R and play with the data-set to make sure your R function works, then remove the --data_cache option to actually perform association scans.  Example We provide some R interface examples for RTest method as extensions to the standard routines vtools associate provides. These examples are meant to be demonstrations for RTest method and are not thoroughly tested for use in a production environment. You are welcome to engineer them to better shape and use for your projects. We and other uses would appreciate it if you are willing to share your R program to the developers mailinglist (varianttools-devel@lists.sourceforge.net) and allow us to publish on this website for others to use.\n MetaSKAT analysis?, contributed by Gao Wang (varianttools-devel) and Raphael Mourad (University of Chicago) The RAssociation package  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/acm-bcb/",
	"title": "ACM-BCB",
	"tags": [],
	"description": "",
	"content": " Tutorial for ACM-BCB 2014 1. Integrated Analysis of Next-Generation-Sequencing Data using Variant Tools This part of the talk gives an overview of variant tools, its concepts, components, and tutorials on how to import, annotate, and select variants.\n Tutorial Sample data Slides  2. Association Analysis of Whole Exome Sequence Data using Variant Association Tools This part of the talk gives a minimal demonstration on data quality control and association analysis of rare variants.\n Tutorial Data bundle  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/administration/autolink/",
	"title": "Autolink",
	"tags": [],
	"description": "",
	"content": "vtools -h|vtools/commands vtools init|vtools/init vtools import|vtools/import vtools export|vtools/export vtools update|vtools/update vtools phenotype|vtools/phenotype vtools liftover|vtools/liftover vtools show|vtools/show vtools subsample|vtools/subsample vtools remove|vtools/remove vtools merge|vtools/merge vtools use|vtools/use vtools output|vtools/output vtools select|vtools/select vtools admin|vtools/admin vtools exclude|vtools/exclude vtools execute|vtools/execute vtools compare|vtools/compare vtools associate|vtools/associate vtools_report -h|vtools/commands vtools_report trans_ratio|vtools_report/trans_ratio vtools_report avg_depth|vtools_report/avg_depth vtools_report variant_stat|vtools_report/variant_stat vtools_report discordance_rate|vtools_report/discordance_rate vtools_report inbreeding_coefficient|vtools_report/inbreeding_coefficient vtools_report sequence|vtools_report/sequence vtools_report plot_fields|vtools_report/plot_fields vtools_report plot_pheno_fields|vtools_report/plot_pheno_fields vtools_report plot_geno_fields|vtools_report/plot_geno_fields vtools_report plot_association|vtools_report/plot_association vtools_report meta_analysis|vtools_report/meta_analysis\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/single_gene/cmc-test/",
	"title": "CMC test",
	"tags": [],
	"description": "",
	"content": " Combined and Multivariate Collapsing Method for Rare Variants Introduction This is the Combined and Multivariate Collapsing (CMC, Li and Leal, 2008[^Bingshan Li and Suzanne M. Leal (2008) Methods for Detecting Associations with Rare Variants for Common Diseases: Application to Analysis of Sequence Data. The American Journal of Human Genetics doi:10.1016/j.ajhg.2008.06.024. http://linkinghub.elsevier.com/retrieve/pii/S0002929708004084^]) test for rare variants. CMC method considers all variants in a test unit (e.g., a gene). It \u0026ldquo;collapses\u0026rdquo; all rare variants in the gene region such that the region is coded \u0026ldquo;0\u0026rdquo; if all loci are wildtype, and \u0026ldquo;1\u0026rdquo; if any one locus has a minor allele. Then it \u0026ldquo;combines\u0026rdquo; this coding with the rest of common variants in the gene region into a multivariate problem that tests for the null hypothesis that the gene region is not associated with a disease or quantitative trait. The statistic for CMC method can be {$\\chi^2$} test for collapsed rare variants, Hotelling\u0026rsquo;s {$T^2$} or multivariate regression analysis for joint analysis of common and rare variants. This program implements CMC method for rare variants with Fisher\u0026rsquo;s exact test for evaluating association between rare variants and disease phenotypes (case/ctrl data). The use of Fisher\u0026rsquo;s test results in exact p-value, avoiding the computationally intensive permutation procedure.\nThis test only works for case control data without covariates. Please refer to CollapseBt and CollapseQt for case control and quantitative traits using the collapsing theme under regression framework that incorporates covariates.\nDetails Command interface vtools show test CFisher Name: CFisher Description: Fisher's exact test on collapsed variant loci, Li \u0026amp; Leal 2008 usage: vtools associate --method CFisher [-h] [--name NAME] [-q1 MAFUPPER] [-q2 MAFLOWER] [--alternative TAILED] [--midp] [--moi {additive,dominant,recessive}] Collapsing test for case-control data (CMC test, Li \u0026amp; Leal 2008). Different from the original publication which jointly test for common/rare variants using Hotelling's t^2 method, this version of CMC will binaries rare variants (default frequency set to 0.01) within a group defined by \u0026quot;--group_by\u0026quot; and calculate p-value via Fisher's exact test. A \u0026quot;mid-p\u0026quot; option is available for one-sided test to obtain a less conservative p-value estimate. optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. Default set to \u0026quot;CFisher\u0026quot; -q1 MAFUPPER, --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 0.01 -q2 MAFLOWER, --maflower MAFLOWER Minor allele frequency lower limit. All variants having sample MAF\u0026gt;m2 will be included in analysis. Default set to 0.0 --alternative TAILED Alternative hypothesis is one-sided (\u0026quot;1\u0026quot;) or two-sided (\u0026quot;2\u0026quot;). Default set to 1 --midp This option, if evoked, will use mid-p value correction for one-sided Fisher's exact test. --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive model. Default set to additive  Application  Example using snapshot vt_ExomeAssociation\nvtools associate rare status -m \u0026quot;CFisher --name Fisher --alternative 2\u0026quot; --group_by name2 --\\ to_db cfisher -j8 \u0026gt; cfisher.txt INFO: 3180 samples are found INFO: 2632 groups are found INFO: Starting 8 processes to load genotypes Loading genotypes: 100% [======================================] 3,180 32.9/s in 00:01:36 Testing for association: 100% [====================================] 2,632/147 26.5/s in 00:01:39 INFO: Association tests on 2632 groups have completed. 147 failed. INFO: Using annotation DB cfisher in project test. INFO: Annotation database used to record results of association tests. Created on Wed, 30 Jan 2013 22:06:07 vtools show fields | grep cfisher cfisher.name2 name2 cfisher.sample_size_Fisher sample size cfisher.num_variants_Fisher number of variants in each group (adjusted for specified MAF cfisher.total_mac_Fisher total minor allele counts in a group (adjusted for MOI) cfisher.statistic_Fisher test statistic. cfisher.pvalue_Fisher p-value head cfisher.txt name2 sample_size_Fisher num_variants_Fisher total_mac_Fisher statistic_Fisher pvalue_Fisher AAMP 3180 3 35 1.27335 0.593442 ABCD3 3180 3 42 0.821622 1 ABCB10 3180 6 122 1.33481 0.250852 ABCB6 3180 7 151 0.91265 0.895567 ABHD1 3180 5 29 0.913443 1 ABCG8 3180 12 152 0.641297 0.15483 ABCA12 3180 28 312 0.979172 1 ABI2 3180 1 25 3.00046 0.020062 ACADM 3180 4 103 0.477756 0.0807384  QQ-plot Attach:cfisher.jpg\n\nUsing Mid-P values for exact test This collapsing test for rare variant is based on an exact test which guarantees to control for type I error yet may be overly conservative. Mid-P values are a reasonable compromise between the conservativeness of the ordinary exact test and the uncertain adequacy of large-sample methods. --midp switch gives Mid-P values for one-sided exact test\n Example using snapshot vt_ExomeAssociation\nvtools associate rare status -m \u0026quot;CFisher --name FisherMidP --alternative 1 --midp\u0026quot; --group_\\ by name2 --to_db cfisher -j8 \u0026gt; cfisher-midp.txt INFO: 3180 samples are found INFO: 2632 groups are found Loading genotypes: 100% [==========================] 3,180 33.3/s in 00:01:35 Testing for association: 100% [================================] 2,632/147 25.9/s in 00:01:41 INFO: Association tests on 2632 groups have completed. 147 failed. INFO: Using annotation DB cfisher in project test. INFO: Annotation database used to record results of association tests. Created on Wed, 30 Jan 2013 22:14:57 vtools show fields | grep cfisher cfisher.name2 name2 cfisher.sample_size_FisherMidP sample size cfisher.num_variants_FisherMidP number of variants in each group (adjusted for specified MAF cfisher.total_mac_FisherMidP total minor allele counts in a group (adjusted for MOI) cfisher.statistic_FisherMidP test statistic. cfisher.pvalue_FisherMidP p-value head cfisher-midp.txt name2 sample_size_FisherMidP num_variants_FisherMidP total_mac_FisherMidP statistic_FisherMidP pvalue_FisherMidP AAMP 3180 3 35 1.27335 0.298742 ABCB6 3180 7 151 0.91265 0.620991 ABCG5 3180 6 87 1.26073 0.228907 ABHD1 3180 5 29 0.913443 0.529454 ABI2 3180 1 25 3.00046 0.0127947 ABL2 3180 4 41 1.05884 0.431808 ABCG8 3180 12 152 0.641297 0.932016 ABCA4 3180 43 492 1.01841 0.448273 ABCA12 3180 28 312 0.979172 0.535912  QQ-plot Attach:cfisher-midp.jpg \n[^#^]\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/simulation/customized_simu/",
	"title": "Customized",
	"tags": [],
	"description": "",
	"content": " Variant Simulation Tools A presentation about variant simulation tools (Sep. 2014)\nVariant Simulation Tools is still under development. Development (subversion) versions of Variant Tools and simuPOP are needed to use VST. Also, because of a lack of mature simulation models (only two examples in the submitted paper are available), users are strongly advised to contact me for the creation of any simulation model.\nWhat is Variant Simulation Tools Variant Simulation Tools (VST) is a simulation tool for post-GWAS genetic epidemiological studies using whole-genome or whole-exome next-gen sequencing data, with an emphasis on user-friendliness and reproducibility. Because simulating high-quality datasets for genetic epidemiological studies requires careful selection and validation of appropriate simulation method for particular applications, VST aims to provide validated application-specific simulation methods and simulated datasets. It distinguishes itself from other simulators in that\n VST provides multiple simulation engines for different simulation methods  Because different simulation methods have their own pros and cons and application areas, VST does not limit itself to a particular simulation method. Instead, it provides simulation engines for theoretical, forward-time, coalescent, and resampling-based simulations.\n VST separates simulation models from their implementations  VST uses a two-tier design. The core of VST is a set of functions to perform different tasks and is distributed with Variant Tools. Simulations are defined in simulation specification files that are stored in the variant tools repository. New simulations become available to all VST users as soon as they are uploaded to the repository.\n VST encourages reproducible simulations  Each VST simulation encapsulates simulation methods and parameters that have been used for a particular application. It allows no or only a few parameters to make it easy to reproduce a simulation. In addition to simulation models, VST also distribute simulated datasets for some simulation models, making it easier for casual users to explore the properties of selected simulation models.\nWhereas it is easy to reproduce an existing VST simulation, creating a new simulation? in VST requires some in-depth knowledge of simuPOP and variant tools. It is strongly recommended that you discuss your simulation study with other users of VST in the varianttools-user mailing list before you write your own simulations. You could also write to me directly if you would like to discuss your project in private.\nAttach:repository.jpg\nSchematic illustration of the role of the variant tools repository in the distribution of simulation models and simulated datasets. The repository provides simulation models and simulated datasets that can be downloaded using VST. Casual users can download simulated datasets and use them without running VST. Users who need to use a model without existing simulated datasets or need more replicates of an existing simulation can simulate data using VST. Advanced users who write their own simulation methods can choose to share their models with others by uploading their models to the repository.\nKey features  VST simulates real nucleotide sequences of the human genome  VST simulates human nucleotide sequences with common or rare mutations. Simulated variants (mutations) locate at specific locations of the genome (chr and pos) with reference (ref) and alternative alleles (alt). VST maps mutations to the human genome if the underlying simulation engine simulates SNP markers on hypothetical regions.\n The forward-time simulation engine knows the regions it simulate  In comparison to previous forward-time simulations that simulate hypothetical genomic regions with random fitness effect, VST * identifies all genes (isoforms) that locate within or overlap with the user-provided regions, locates exons, coding regions, and codons on the forward and reverse strands. * recombine parental chromosomes using a fine-scale genetic map with recombination rates and hotspots provided by the HapMap project * use a nucleotide mutation model to introduce new mutants to the population * determine the fitness of individuals from amino-acid changes of the translated protein sequences\n VST supports a large number of penetrance and quantitative trait models and sampling methods  The flexible design of VST allows the application of very complex penetrance and quantitative trait models to the simulated population and draw random, case control, extreme trait, and pedigree-based samples.\n Datasets simulated by VST could be exported in VCF format, or analyzed directly using Variant Association Tools  Simulated datasets could be exported and analyzed by other programs, or imported into a variant tools project and analyzed directly using Variant Association Tools?.\nBasic usages of VST Step 1: check available simulation models After installing variant tools?, run\n% vtools show simulations Peng2011_srv Re-implementation of some of the simulations performed by SRV (Peng \u0026amp; Liu, Simulating Sequences of the Human Genome with Rare Variants, 2011). Peng2014_ex1 Simulations of DNA sequences in specified regions using different simulation methods, for the first example in paper \u0026quot;Reproducible Simulations of realistic samples for next-gen sequencing studies using Variant Simulation Tools\u0026quot;. The simulated populations are analyzed and discarded to save diskspace. ... ...  to get a list of available simulation models.\nIf you cannot find a simulation model that fits your need, please write to the varianttools-user mailing list and check if others have performed similar simulations using VST. You could also write to me directly for potential collaboration on simulation part of your study.\nStep 2: Learn the details of a simulation model A simulation specification file can define multiple simulation models. Command vtools show simulation SPECFILE lists all simulation models defined in SPECFILE and their descriptions, include parameters they accept.\n% vtools show simulation Peng2014_ex1 Simulations of DNA sequences in specified regions using different simulation methods, for the first example in paper \u0026quot;Reproducible Simulations of realistic samples for next-gen sequencing studies using Variant Simulation Tools\u0026quot;. The simulated populations are analyzed and discarded to save diskspace. Available simulation models: ms, neutral, resample, with_selection Model \u0026quot;ms\u0026quot;: This simulator calls ms to execute coalescent-based simulations, create a population with simulated dataset and run through the same statistical analysis as other pipeline. ms_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. ms_5: Check the existence of command ms ms_10: Create a new project if there is no existing project under the current directory. ms_20: Execute ms. NOTE that these parameters only matches the parameters used in example 1 of Peng 2014. ms_30: Create an empty simuPOP population for specified regions and import ms-simulated genotypes. The segregating sites are distributed within the specified region according to the positions (float numbers from 0 to 1) assigned by ms. Mutants are assumed to be from A-\u0026gt;C, C-\u0026gt;G, G-\u0026gt;T and T-\u0026gt;A for bases A, C, G and T respectively. ms_50: Get allele frequency spectrum in a sample of 700 individuals. ms_999: Remove intermediate populations to save diskspace. Model \u0026quot;neutral\u0026quot;: A neutral simulation using a Juke-Cantor (1969) DNA nucleotide mutation model, a mutation rate of 1.8x10^-8, a fine-scale recombination map, a demographic model that mimicks the European population, and no natural selelction. neutral_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. neutral_10: Create a new project if there is no existing project under the current directory. neutral_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. neutral_30: Create an empty simuPOP population for specified regions. neutral_40: Evolve and expand the population using a JC69 mutation model and a demographic model that evolves a population of size 8100 for 81000 generations before it is expanded to size 900000 in 370 generations. neutral_50: Get allele frequency spectrum in a sample of 700 individuals. neutral_999: Remove intermediate populations to save diskspace. Model \u0026quot;resample\u0026quot;: A simulation model that extracts genotypes within the sepecified regions from the 1000 genomes project, and expands it very rapidly to mimick a resampling-based simulation. resample_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. resample_10: Create a new project if there is no existing project under the current directory. resample_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. resample_25: Extract genotypes of specified regions from 1000 genomes project. No dependency check will be performed so the extracted file can be used by other projects if you put is to a place accessible by other projects. Location of the extracted file can be specified by option --extracted_file. resample_30: Create an empty simuPOP population for specified regions. resample_40: Expand the population exponentially to reach a large population in 10 generations. Mutations and recombinations are allowed and a selection model that only select against stopgain mutations are used. resample_50: Get allele frequency spectrum in a sample of 700 individuals. resample_999: Remove intermediate populations to save diskspace. Model \u0026quot;with_selection\u0026quot;: A simulation that uses identical models as the neutral model but use a protein selection model with selection pressure 0.005, 0.02 and 0.1 for missense, stoploss and stopgain mutations. with_selection_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. with_selection_10: Create a new project if there is no existing project under the current directory. with_selection_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. with_selection_30: Create an empty simuPOP population for specified regions. with_selection_40: Evolve and expand the population using a JC69 mutation model and a demographic model that evolves a population of size 8100 for 81000 generations before it is expanded to size 900000 in 370 generations. with_selection_50: Get allele frequency spectrum in a sample of 700 individuals. with_selection_999: Remove intermediate populations to save diskspace. Model parameters: regions One or more chromosome regions (separated by ',') in the format of chr:start-end (e.g. chr21:33031597-33041570), or Field:Value from a region-based annotation database (e.g. refGene.name2:TRIM2 or refGene_exon.name:NM_000947). Please visit http://varianttools.sourceforge.net/Simulation for detailed description of this parameter. (default: chr17:41200001-41263000) scale Scaling factor to speed up the simulation by scaling down the simulation while boosting mutation, selection and recombination rates. (default: 10) extracted_vcf Filename (with dir) to save genotypes (.vcf file extracted by tabix command) for the resample model. This file will be automatically created and reused if it already exists. You will need to remove this file if you run the same pipeline using another region. (default: extracted.vcf)  Step 3: Perform simulations % vtools simulate -h usage: vtools simulate [-h] [--seed SEED] [--replicates REPLICATES] [-j JOBS] [-v {0,1,2}] SPECFILE [MODELS [MODELS ...]] Simulate case control or family-based samples using specified simulation models. positional arguments: SPECFILE Name of a model specification file, which can be the name of an online specification file, or path to a local .pipeline file. Please use command \u0026quot;vtools show simulations\u0026quot; to get a list all available simulation models. MODELS Name of one or more simulation models defined in SPECFILE, which can be ignored if the SPECFILE only defines one simulation model. Please use command \u0026quot;vtools show simulation SPECFILE\u0026quot; for details of available models in SPECFILE, including model-specific parameters that could be used to change the default behavior of these models. optional arguments: -h, --help show this help message and exit --seed SEED Random seed for the simulation. A random seed will be used by default but a specific seed could be used to reproduce a previously executed simulation. --replicates REPLICATES Number of consecutive replications to simulate -j JOBS, --jobs JOBS Maximum number of concurrent jobs to execute, for steps of a pipeline that allows multi-processing. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1).  Each simulation specification file can contain more than one simulation models. You can use commands such as\n% vtools simulate Peng2014_ex1 neutral  to perform one of them. Some models accept parameters. For example, the following command performs the simulation on gene BRCA1 with locations defined in the refGene database.\n% vtools simulate Peng2014_ex1 neutral --regions refGene.name2:BRCA1 INFO: Starting simulation cache/Peng2014_ex1_neutral_273426005.cfg INFO: Executing Peng2014_ex1.neutral_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. INFO: Executing Peng2014_ex1.neutral_10: Create a new project if there is no existing project under the current directory. INFO: Executing Peng2014_ex1.neutral_20: Link the refGene database to the project. This database is required to parse the regions for gene structure. INFO: Running vtools use refGene INFO: Downloading annotation database from annoDB/refGene.ann INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/refGene-hg19_20130904.DB.gz INFO: Using annotation DB refGene as refGene in project Peng2014_ex1. INFO: Known human protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq). INFO: Command \u0026quot;vtools use refGene\u0026quot; completed successfully in 00:00:01 INFO: Executing Peng2014_ex1.neutral_30: Create an empty simuPOP population for specified regions. INFO: Regions to be simulated (81189 bp): 17:41196312-41277500 INFO: Saving created population to cache/ex1_neutral_init_273426005.pop INFO: Executing Peng2014_ex1.neutral_40: Evolve and expand the population using a JC69 mutation model and a demographic model that evolves a population of size 8100 for 81000 generations before it is expanded to size 900000 in 370 generations. INFO: Regions to be simulated (81189 bp): 17:41196312-41277500 INFO: Simulated regions with 81,189 basepair have 23,556 A, 17,899 C, 16,955 G, 22,779 T, and 0 N on reference genome. INFO: Regions to be simulated (81189 bp): 17:41196312-41277500 INFO: Map distance of 71 markers within region 17:41196312-41277500 are found INFO: Total map distance from 17:41196312-41277500 (81189 bp) is 4.0144e-03 cM (r=4.9446e-08/bp) INFO: Start evolving... Statistics outputted are 1. Generation number, 2. population size (a list), 3. number of segregation sites, 4. average number of mutants per individual 5. average allele frequency * 100 6. average fitness value 7. minimal fitness value of the parental population INFO: 1690 [810] 285 60.677778 10.645224 0.000000 0.000000 INFO: 3030 [810] 307 73.462963 11.964652 0.000000 0.000000 INFO: 4275 [810] 305 82.586420 13.538757 0.000000 0.000000 INFO: 5393 [810] 371 108.137037 14.573725 0.000000 0.000000 INFO: 6433 [810] 324 102.554321 15.826284 0.000000 0.000000 INFO: 7620 [810] 325 92.483951 14.228300 0.000000 0.000000 INFO: 8040 [810] 358 95.301235 13.310228 0.000000 0.000000 INFO: 8137 [90000] 5614 99.777544 0.888649 0.000000 0.000000 INFO: Simulated population has 90000 individuals, 5614 segregation sites. There are on average 99.0 mutants per individual. Mean allele frequency is 0.8886%. INFO: Population simulation takes 219.77 seconds INFO: Executing Peng2014_ex1.neutral_50: Get allele frequency spectrum in a sample of 700 individuals. INFO: Loading population from ex1_neutral_evolved_273426005.pop INFO: Executing Peng2014_ex1.neutral_999: Remove intermediate populations to save diskspace. INFO: Replace ex1_neutral_evolved_273426005.pop with ex1_neutral_evolved_273426005.pop.file_info INFO: Replace cache/ex1_neutral_init_273426005.pop with cache/ex1_neutral_init_273426005.pop.file_info  Some technical details Option --seed and --replicates A random seed will be used by default for each simulation. For each simulation, a file cache/MODEL_SEED.cfg will be created as the input file for the execution of the simulation pipeline. You can, however, use the --seed option to specify the seed of the simulation to reproduce a previous simulation.\nFor reproducibility reasons, all simulated datasets provided my VST will be simulated with seeds 1, 2, 3, \u0026hellip;.\nThe vtools simulate command by default only simulates one replicate of the simulation. It will repeat itself a number of times if option --replicates is specified. SEED, SEED+1, SEED+2 etc will be used as seed for subsequent simulations.\nIf you need to run multiple instances of VST at the same time, please use separate directories for different instances of the vtools simulate command.\nSpecification of regions (option --regions) Because VST simulates true genomic regions of the human genome, a key parameter of many simulation models is --regions. You can, for example, pass a region in chr:start-end format as\n--regions chr17:540000-570000  or multiple regions as\n--regions chr17:540000-570000,20000-210000,chr20:123450-134500  Here multiple regions are separated by \u0026ldquo;,\u0026rdquo;, and chromosome name can be ignored if it is the same as the previous region.\nMore interestingly, you can use value of a field-based annotation database to specify regions. For example,\n--regions refGene.name2:BRCA1  locates all genes (isoforms) in the refGene database with common name name2 equals to BRCA1. You can specify regions for multiple genes using\n--regions refGene.name2:BRCA1,BRCA2,P53  You can use a different annotation database for this purpose. For example\n% vtools simulate MODELFILE MODEL --regions refGene_exon.name2:BRCA1,BRCA2  simulates exon regions of BRCA1 and BRCA2. Command vtools use refGene_exon will be automatically called if refGene_exon is not linked to the current project.\nThe --regions option allows the use of set operations (|, \u0026amp;, -, and ^ for union, intersection, difference, and symmetric difference, respectively) to modify specified regions. For example, if you need to specify intron regions of a gene, you can use\n--regions 'refGene.name2:BRCA1 - refGene_exon.name2:BRCA1'  Another example would be to limit, for example, a penetrance model to certain chromosome regions:\n--regions 'refGene.name2:BRCA1 \u0026amp; chr17:41196312-41200000'  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/customizedpipeline/",
	"title": "Customized",
	"tags": [],
	"description": "",
	"content": " Specification of a variant tools pipeline This page describes the new pipeline format (version 1.1 and later). Please refer to Format1_0? if you are editing a pipeline specification file for variant tools 2.7 and earlier..\nIntxroduction Variant Tools uses pipeline specification files to define pipelines. A pipeline specification file can define multiple pipelines. It can be stored locally or online in the variant tools repository (or a local repository maintained by your system adminstrator). You can use command\n% vtools show pipelines  to get a list of all publicly available pipelines, and\n% vtools show pipeline SPECFILE  to get the details of pipelines defined in SPECFILE. The output of this command consists of description of the SPECFILE, all pipelines in it, steps of each pipeline, and options of the pipelines.\nA pipeline can be executed by command\n% vtools execute SPECFILE PIPELINE [--input XXX] [--output XXX] [OPTIONS]  where SPECFILE can be a local .pipeline file, or name of an online pipeline specification file, PIPELINE is the name of the pipeline defined in SPECFILE. The command line can be simplified to\n% vtools execute SPECFILE [-i XXX] [-o XXX] [OPTIONS]  if the spec file only defines one pipeline.\nThe format of pipeline spec files is similar to the .ini files of the good old days. It is not as fashionable as XML based configuration files but it is easier to read and write. The most simple pipeline specification file is a collection of commands and scripts as follows\n###fileformat=PIPELINE1.1 # Copyright, change log etc # This is a description of all pipelines defined in this spec file [1] RunCommand(cmd='a shell command') [2] ExecuteRScript(script=''' library(mylib) a \u0026lt;- read.table(\u0026quot;${var2}.txt\u0026quot;) ''')  although a spec file that defines multiple pipelines, accepts multiple command line parameters and makes uses of pipeline variables looks as follows:\n  output\u0026lt;\n  ###fileformat=PIPELINE1.1 # Copyright, change log etc # This is a description of all pipelines defined in this spec file # p1_description: The p1 pipeline performs ... p2_description: The p1 pipeline performs ... # pipeline variables VAR=VALUE VAR1=VALUE1 [DEFAULT] arg1= This argument does this arg2=1.0 This argument has a default value 1.0 [*_10: passthrough] # Check the version of variant tools CheckVariantToolVersion('2.7') [p1_20] # Execute a single command input: ${cmd_input} RunCommand(cmd=''' a very long command \u0026gt; ${var1} ''', output='${var1}') [p1_200] # Execute a R script ExecuteRScript(script=''' library(mylib) a \u0026lt;- read.table(\u0026quot;${var2}.txt\u0026quot; ''', output='${var2[:-3]}.pdf') [p2_20] # Execute a R script for pipeline p2 ExecuteRScript(script=''' library(mylib) a \u0026lt;- read.table(\u0026quot;${var2}.txt\u0026quot; ''', output='${var2[:-3]}.pdf')  This small example demonstrates almost all the features of pipeline specification files. Before we go to the details of each section, here are some basic rules:\n A spec file should start with line\n##fileformat=PIPELINE1.1\n Lines starts with # are comments. Some comments are significant and will be displayed in the output of vtools show pipeline.\n A pipeline spec file consists of a starting description section with no header, an optional [DEFAULT] section, and multiple pipeline step sections.\n Values of an item can be expanded into multiple lines, e.g.\nname=this is a long text that continues to the second line or the third\n  Consequently, you can expand your comments or commands into several lines as long as you do not start from the first column. An exception to this rule is when a large piece of text is quoted in triple quotes such as\nExecuteRScript(''' data \u0026lt;- read.table(\u0026quot;${input}\u0026quot;) data \u0026lt;- data[1,] ''')  Note that ''' ... ''' literals are automatically translated to r''' ... ''' so escape characters are not translated. Use \u0026quot;\u0026quot;\u0026quot; ... \u0026quot;\u0026quot;\u0026quot; string literals if you would like to allow escape characters.\n You can use either KEY = VALUE or KEY : VALUE. The convention is to use KEY = VALUE for variable assignment and KEY : VALUE for all other.\n Pattern ${ } are specially handled as pipeline variables. ; and % are not special characters as in the original specification format.\n  Top Section A pipeline specification file should start with a description section (no header is needed). This section should have the following keys:\n description: Summary of pipelines defined in this SPECFILE, which should include format and type of input data (raw reads? bam file? paired end?), external commands that are used, a short description of steps involved, and reference to external documentation if available. If no description is provided, the second block of comments will be treated as overall pipeline description in the output of vtools show pipeline. For example,\n##fileformat=PIPELINE1.1\nCopyright line This is the overall pipeline description #\n PIPELINE_description: (Optional) Description of pipeline PIPELINE. PIPELINE has to be a valid pipeline defined in this file (with sections PIPELINE_XX).\n  If you have long descriptions (highly recommended!), you can break it into several paragraphs by adding HTML tags \u0026lt;p\u0026gt; or \u0026lt;br\u0026gt;. Tag \u0026lt;p\u0026gt; starts a new paragraph (two newlines) and tag \u0026lt;br\u0026gt; starts a new line (one newline). You can also use tags  and  to generate itemized lists. For example,\nThis pipeline uses \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;tophat 2.0.13 \u0026lt;li\u0026gt;bowtie 1.1.1 \u0026lt;li\u0026gt;samtools 0.1.19 \u0026lt;li\u0026gt;picard 1.82 \u0026lt;/ul\u0026gt;  will produce output\nThis pipeline uses * tophat 2.0.13 * bowtie 1.1.1 * samtools 0.1.19 * picard 1.82  when the description is outputted using command vtools show pipeline.\n NAME=VAL (optional): Pipeline variables. This is usually a good place to define constant values that will be used by pipeline steps. For example:\nRESOURCE_DIR=${local_resource}/pipeline_resource/name_of_pipeline   where ${local_resource} is another pipeline variable that has value of project runtime option $local_resource. We will talk about pipeline variables in details later.\nSection [DEFAULT] (command line options) The DEFAULT section defines parameters that can be changed using command line arguments. For example, in the following .pipeline file (partial)\n[DEFAULT] opt_java=-Xmx4g Parameter passed to the java command, default to -Xmx4g to use a maximum of 4g heap space. [align_5] RunCommand(cmd=\u0026quot;java ${opt_java} SortSam ...\u0026quot;)  The value of opt_java will be used to replace all instances of ${opt_java} in the pipeline configuration file (or its derivatives, more on this later). The parameter has a default value -Xmx4g and a help message, which will be displayed when you view the details of this parameter.\n% vtools show pipeline my_pipeline  you will see at the end of the output the following description:\nPipeline parameters: opt_java Parameter passed to the java command, default to -Xmx4g to use a maximum of 4g heap space. (default: -Xmx4g)  That is to say, you can pass an alternative value of opt_java to this format using command-line options such as --opt_java -Xmx32g to change the value of this option.\nIf you have a large number of parameters, you can save them to an external file, one item per line, and load them by prefixing filename with a \u0026quot;@\u0026quot; symbol. For example, if you have a file param.cfg with content\n--bwa /path/to/bwa --samtools /path/to/samtools  you can load parameters --bwa /path/to/bwa --samtools /path/to/samtools using \u0026quot;@param.cfg\u0026quot; from command line.\nYou do not have to define parameter --input and --output but it is a good practice to define them in this section to provide description of the input and output of the pipeline.\nPipeline variables Definition of pipeline variables Pipeline variables are variables associated with the execution of pipeline. They are added with the progression of the pipeline and provides runtime information for each step. All pipelines starts with the following variables:\n Command line options: All command line options will be passed as pipeline variables as a list of strings, with the exceptions for  ${cmd_input} for option --input ${cmd_output} for option --output Pipeline output , which will be ['data.bam'] for the above mentioned example. It does not have to a list of files. For example, it can be used to specify output directory or   For example, ${cmd_input} and ${cmd_output} will be ['data.tgz'] and ['data.bam'] respectively for command vtools execute bwa_gatk28_hg19 align --input data.tgz --output data.bam.\n A pipeline starts by default with ${cmd_input} as input files but it can start without any input, or from another variable. ${cmd_input} and ${cmd_output} will always be a list even if only one input or output file is passed. ${cmd_input} and @@${cmd_output} do not have to be a list of files. For example they can be used to specify input and output directories.\n Execution environment including\n ${vtools_version}: Version of variant tools (e.g. 2.0.2) used to execute the pipeline. ${spec_file}: Full path of the specfile in which the pipeline is defined. ${pipeline_name} and ${model_name}: Name of the pipeline. The name MODEL_NAME is preferred when the pipeline is used in variant simulation tools. ${pipeline_step}: Current step in the pipeline (as a string). ${ref_genome_build}: Primary build of the reference genome of the project (e.g. hg19). ${local_resource}: Project resource directory (runtime variable $local_resource). ${cache_dir}: Project cache directory, which is usually used to store all intermediate files of a pipeline. ${temp_dir}: Project temporary directory ($temp_dir), which can be used to store, for example, java temp directories. This directory can be set by runtime option $temp_dir. A system temp directory will be used if the pipeline is executed without a variant tools project. ${model_name} and SEED: Name of the simulation model (pipeline) and seed. Used by Variant Simulation Tools?. ${home}: user\u0026rsquo;s home directory. ${working_dir} Working directory, which is default to current directory.   User-defined variables defined in the top section and pipeline sections. The top section usually defines constant that will be used later. The pipeline sections usually define variables as a result of certain action.\n  You can override some execution environment variables by re-defining it in the top section. In particular, if you define ${working_dir} in the top section of the spec file, all jobs will be executed under this directory (although some actions can have their own working directories).\n Runtime variables including\n ${input} as input to actions because an action might be repeated for each input files.   Use of Pipline variables It is important to remember that\n Pipeline variables are case-insensitive, read only, and can be only string or list of strings. List of strings are joined by space when they are outputted. All file-list variables such as cmd_input, cmd_output, input, inputXXX, outputXXX (where XXX is step of pipeline) and their aliases are list of strings, even if there is only one file in the list. All command line arguments are list of strings. All other variables such as user-defined variables can hold string only.  For example, if the value of variable cmd_input is ['file1.txt', 'file2.txt'], they will appear as file1.txt file2.txt when ${cmd_input} is used in a command line (with proper quotation).\nIf you need to access one or more elements of the list of strings, use variables such as ${input[0]}, ${cmd_output[-1]}, ${input[2:]} and ${input[0][:-3]}.\nIf you need to output pipeline variables in any other format, you can use a function form of the variable ${var: lambda_func} using Python lambda function. For example,\n${cmd_output: os.path.basename(cmd_output[0])}  passes value of cmd_output to a Python lambda function lambda x: os.path.basename(x[0]), which will be \u0026quot;output.bam\u0026quot; if ${cmd_output} equals to \u0026quot;/path/to/output.bam\u0026quot;.\n${input: ','.join(sorted([x for x in input if '_R1_' in x]))}  takes a list of input files, select files with _R1_ in filename, sort them, and output them as comma-separated list.\nThis mechanism is very powerful in that the lambda function can take zero or more than one pipeline variables. For example\nhostname=${: subprocess.check_output(\u0026quot;hostname\u0026quot;)}  returns the output of the hostname command\n${input,cmd_output: OS.PATH.JOIN(cmd_output[0], input[0])}   Use of shell variables (e.g. use a for loop in action RunCommand) is possible but can be tricky because pipeline and shell variables can take the same form. Whereas simple form of shell variables ($VAR instead of ${var}) can be used without problem, the brace form ${var} will trigger a warning message if VAR is a not valid pipeline variable, and return unexpected results otherwise. Pipeline variables can use functions from common Python modules such as os, sys, glob, subprocess, and functions defined in modules imported using action ImportModule. If you need more modules, you can import them using inline script of action ImportModule.  Step sections Name of step sections [PIPELINE], [XX], [PIPELINE_XX], or [PIPELINE_XX,PIPELINE1_XX], or [*_XX] A pipeline is, roughly speaking, a pipe that connects the input (e.g. raw reads in fastq format) to the output (e.g. aligned reads in bam format), going through a few steps (actions) along the way. A pipeline specification file can define multiple pipelines with different PIPELINE. Steps in a pipeline are numbered and will be executed in such order. The indexes of actions do not have to be consecutive so align_10, align_20, and align_30 are acceptable. They do not even have to be defined in the order they are be executed.\nIf your pipeline contains only one step, you can just define a section as follows\n[test_env]  If your spec file defines only one pipeline or if you would like to define a default pipeline that will be executed without specifying a name, you can specify this pipeline without name, e.g.\n[100] [200]  Otherwise you can define multiple multi-step pipelines like\n[EU_10] [EU_20] [AF_10] [AF_20]  A section can define multiple pipeline steps if the same step can be used for multiple steps of a pipeline or for other pipelines in the same file. For example\n[EU_100,EU_200,EU_300] [100, EU_100,AF_100,GT_100]  can be used to perform the same action for steps 100, 200, and 300 of pipeline EU, or the same step 100 for pipelines default, EU, AF and GT. In the latter case, you can even use wildcard character\n[*_100]  to define a step that will be executed by all pipelines defined in this file.\nContent of pipeline step sections For each step of a pipeline, we need to know\n What are the input files How to process input files? One by one or altogether? What actions should be applied to the input files? What are the outputs?  Answers of these questions should be specified using the following keys:\n input (optional). List of input files for a step. The default value of the input is the output of the previous step (or the command input for the first step). One or more files could be specified explicitly (separated by space). For example,\noutput of step 400, not from previous step input: ${output400}\noutput from multiple steps input: ${output400} ${output500}\nall files in a directory input: ${:glob.glob(\u0026rsquo;*.gz\u0026rsquo;)}\n A pipeline will be terminated if there is no input file or if any of the specified input files does not exist.\n input options (optional). By default, all input files are passed together to the action (so ${input} equals to ${inputxxx} where XXX is number of pipeline step. You can change this behavior by setting one or more input options, which are specified by one or more comma-separated opt=val options in the format of\ninput: input_files : option1, option2, option3\n  For example, the following example select all fastq files from input files and send them to pipeline action in pairs:\ninput: ${cmd_input} : select='fastq', group='pair'  Variant Tools currently provides the following options:\n \u0026rdquo;\u0026rsquo;group_by='all' Eligible files are by default sent altogether (group_by='all') to action (group_by='all', ${input} equals to ${input#} where # is the index of step), but can also be sent individually (group_by='single', ${input} is a list of a single file), or in pairs (group_by='paired', e.g. filename_1.txt and filename_2.txt).\n select=True/False/'fastq'/... select can be True (all input file), False (no input file, the step will be skipped), 'fastq' (ignore file extension and check content of files), or one or more file extensions (e.g. ['sam', 'bam']).\n pass_unselected=True: If files are not used (pass through), unselected files are by default passed directly as output of a step.\n skip=True/False: Skip an step if set to True (which is usually a variable. All input files will be passed directly to output by default.\n  An input option does not substitute ${input} because it determines ${input}. They can however use other variables such as ${cmd_output}. For example,\n${bam_files} : ${input200:len(input200)==1})  select files only if there are more than one input file. This is useful, for example, to merge bam files only if there are more than one input bam files.\n action (required): An action that will be executed by variant tools, sometimes repeatedly for different input files (e.g. for each or each pair of input files). Each action will return a list of output files, which will form the output files of the step. A list of actions can be specified in the format of Action1, Action2, .... These actions will be executed sequentially and the output of a previous action will become the input of the following action. Please check the actions section for a list of available actions. The action= key can be ignored..\n NAME=VALUE (optional): This allows the pipeline step to define some pipeline variable with results obtained by the step. For example, if this step writes an optional flag in file file1.txt, you can use\nflag=${: open(\u0026ldquo;file1.txt\u0026rdquo;).read() }\n  to save its content to a pipeline variable.\nIf an action differ only slightly across pipelines, you can use variable ${pipeline_name} to perform different actions for different pipelines. For example,\n[eu_100,af_100] ..... ${pipeline_name: '-g' if PIPELINE_NAME='eu' else ''}  uses passes an additional option -g to an action for pipeline eu.\nComments in pipeline steps will be displayed in the output of vtools show pipeline:\n[hg19_100] # decompress input files only if they are compressed DecompressFiles(...)  Section options ([pipeline_100: output_alias=hits]) Pipeline steps accept a few options that tells variant tools how to handle input and output files. These options are specified in section head after section names in the format of\n[[p1_10, p2_20 : option1, option2]]  Variant Tools currently supports the following options\n independent. This option tells variant tools that a step does not belong to a pipeline and there is no need to track input and output of it. The variable ${input} will be undefined for this step and its output will not be passed to the next step. This option should be used for steps such as CheckVariantToolsVersion, DownloadResource that are independent of input files.\n no_input: The step does not need any input file to generate output. Because variant tools terminates a pipeline if there is no input file, this option allows the starting or continuation of pipeline with no input file.\n blocking: The step is shared by multiple instance of the pipelines and can only be executed by one instance. If multiple instances are running, only the first one will execute it and the rest of them will wait for the output to be generated. This option should be used for steps to download data, to generate index et al.\n input_alias=another_name and output_alias=another_name: Assign variableanother_nameto the input and output of the step, respectively. This option is very useful to give output of a step a meaningful name so that the subsequent steps can refer to them by this name. In the following example, pipeline variable${accepted_hits}becomes an alias to${output200}after the execution ofhg19_200@@, and can be used in later sections.\n[hg19_200: output_alias=accepted_hits] RunCommand(\u0026lsquo;tophat \u0026hellip;.\u0026rsquo;)\n[hg19_210] \u0026hellip;\n[hg19_200] input: ${accepted_hits} RunCommand(\u0026lsquo;\u0026hellip;\u0026rsquo;)\n  Available actions Actions are functions that are executed by Variant Tools.\nTechnically speaking, pipeline actions are evaluated as a Python expression to obtain a PipelineAction object. That is to say, you can use arbitrary python expressions such as list comprehension for this item.\nGiven an action, variant tools\n Replace ${name} with corresponding pipeline variable NAME. Lambda functions such as {:EXPR}, {NAME:EXPR}, {NAME1,NAME2:EXPR} etc will be evaluated before they are substituted. Evaluate the text as a Python expression to obtain an PipelineAction object that will be called by Variant Tools. Python functions and expressions will be evaluated during this step.  For example, for the following action,\nCheckDirs([\u0026quot;${resource_dir}\u0026quot;, os.path.join('${cache_dir}', '${pipeline_name}')])  will be processed as to\nCheckDirs([\u0026quot;/path/to/resource\u0026quot;, os.path.join('cache', 'EUS')])  with command line option --resource_dir /path/to/resource (or use default value defined in section DEFAULT), and values of pipeline variables CACHE_DIR and PIPELINE_NAME, and finally be evaluated to produce an object CheckDirs with parameters:\nCheckDirs([\u0026quot;/path/to/resource\u0026quot;, 'cache/EUS'])  There are two kinds of pipeline actions\n Built-in actions: Actions that are defined by variant tools.\n Pipeline-defined actions: Actions that are defined by users of variant tools pipeline. They are defined in .py files and need to be imported to a pipeline using action ImportModules.\n  Because of the increasing number of pipeline actions, variant tools provides a command\n% vtools show actions  to list all built-in action (for variant tools and variant simulation tools), and actions defined by pipelines in the variant tools repository. You can check the details of each action using command\n% vtools show action ACTION  For example, you can use command\n% vtools show action TerminateIf Help on class TerminateIf in module variant_tools.pipeline: class TerminateIf(PipelineAction) | Terminate a pipeline if a condition is not met. | | Examples: | TerminateIf(not '${cmd_output}', 'No --output is specified.') | | Methods defined here: | | __call__(self, ifiles, pipeline=None) | Terminate the pipeline if specified condition is met. | | Parameters: | ifiles: unused | pipeline: unused | | Results: | Pass input to output. Does not change pipeline. | | Raises: | A RuntimeError will be raised to terminate the pipeline if | the condition is met. | | __init__(self, cond, message) | Parameters: | cond (boolean): | True or False. In practice, ``cond`` is usually | a lambda function that checks the existence of a file or value | of a pipeline variable. | | message (string): | A message to be outputted when the condition is met. | | ---------------------------------------------------------------------- | Methods inherited from PipelineAction: | | execute(self, ifiles, pipeline=None) | Function called by __call__ for actual action performed on ifiles. A user-defined | action should re-define __call__ or redefine this function and return ``True`` if the | action is completed successfully.  to check the details of action TerminateIf.\nBrief description of built-in actions The following is a partial list of built-in actions defined by variant tools. The descriptions are brief and might have been outdated so please use command above to check the latest documentation.\n CheckVariantToolsVersion(ver): Check the version of variant tools. Stop the pipeline if it is not recent enough to execute the pipeline.\n CheckCommands(cmds): Check the existence of command cmds and raise an error if the command does not exist. Input files of the step is passed directly as output files.\n CheckFiles(files, msg=''): Check the existence of specified files. This can be used to check, for example, the existence of the .jar file of GATK. An error message can be specified.\n CheckDirs(dirs, msg=''): Check the existence of specified directories. An error message can be specified.\n CheckOutput(cmd, patterns, failIfMismatch=True): Check the output of a command and see if it matches one of the specified patterns (see the search function of Python re package for details). The pipeline will be terminated if failIfMismatch is set to True (default). This action is usually used to check the version of commands.\n Check for a specific version of bwa\nCheckOutput(\u0026lsquo;bwa\u0026rsquo;, \u0026lsquo;Version: 0.7.4\u0026rsquo;)\n Check for multiple allowed versions of bwa\nCheckOutput(\u0026lsquo;bwa\u0026rsquo;, \u0026lsquo;Version: 0.7.*\u0026lsquo;)\n Check version of picard\nCheckOutput(\u0026lsquo;ls %(picard_path)s/picard*.jar\u0026rsquo;, \u0026lsquo;picard-1.82\u0026rsquo;)\n Check version of GATK\nCheckOutput(\u0026lsquo;java -jar %(gatk_path)/GenomeAnalysisTK.jar -version\u0026rsquo;, \u0026lsquo;^2.4\u0026rsquo;)\n Check version of MosaikAligner\nCheckOutput(\u0026lsquo;MosaikAligner -version\u0026rsquo;, \u0026lsquo;2.1\u0026rsquo;)\n DownloadResource(resource, dest_dir): Download a list of resources (URLs) (a single string, URLs can be separated by spaces or newlines) to a pipeline resource directory resource_dir. The resources will not be downloaded if the files already exist. .gz files will be decompressed automatically. If both filename and filename.md5 exist, the md5 signature of filename will be compared to filename.md5. resource_dir will be locked during downloading so only one process can execute this step at any time.\n RunCommand(cmd, working_dir=None, output=[], submitter=None): Execute cmd (one command or a list of commands) under working directory working_dir (default to current project directory). A list of output files specified by output will be returned. If output is specified, three additional files, filename.out#, filename.err#, filename.exe_info (where filename is the first file in output) will be produced with command output, command error output, and command execution information, respectively. Command execution information contains command executed, start and ending time, file size and md5 signature of input and output files. If output files already exist, newer than input files, size and md5 checksum of input and output files and command used match what have been recorded in filename.exe_info, the command will not be executed. Because valid filename.exe_info files are only created after commands are completed successfully (not interrupted), a pipeline can be safely resumed if it is terminated due to user or system errors.\n Multiple commands could be executed in a single RunCommand action. The pipeline will terminate if any of the commands returns non-zero code.\n Using option output to specify output files is highly recommended because otherwise the command will be re-executed if the pipeline is re-executed. If the command does not produce any new output (e.g. many vtools commands), you can generate a status output file and use it as output, as in\nRunCommand(cmd=[\u0026lsquo;vtools import ${input: \u0026ldquo; \u0026ldquo;.join(input)} \u0026ndash;build hg19\u0026rsquo;, \u0026lsquo;vtools show genotypes \u0026gt; genotype.lst\u0026rsquo;], output=\u0026lsquo;genotype.lst\u0026rsquo;)\n If a valid working_dir is set, the child process in which the commands are executed will switch to this directory but the current directory of the master process will remain the same. That is to say, all input and output filenames etc are still relative to the project path, but os.path.abspath might be needed if these path are used in the cmd.\n If a submitter is defined, the submission command will be used to run the commands in background (e.g. submitter='sh {} \u0026amp;') or as a separate job (e.g. @@submitter=\u0026lsquo;qsub {}\u0026rsquo;). This allows parallel execution of pipeline steps.\n If no output is specified, input files are passed through as output files.\n  Arbitrary command could be defined for this action, which in theory could destroy all your data or system. It is your responsibility to verify that a pipeline description file does not contain malicious piece of code and we (developers of variant tools) are not responsible for any damage that might have been caused.\n ExecuteRScript(script, working_dir=None, output=[], submitter=None): Execute an in-line R script.\n ExecuteShellScript(script, working_dir=None, output=[], submitter=None): Execute an in-line shell script.\n ExecutePythonScript(script, working_dir=None, output=[], submitter=None): Execute an in-line Python script.\n ExecutePython3Script(script, working_dir=None, output=[], submitter=None): Execute an in-line Python3 script.\n ExecutePerlScript(script, working_dir=None, output=[], submitter=None): Execute an in-line Perl script.\n ExecuteRubyScript(script, working_dir=None, output=[], submitter=None): Execute an in-line Ruby script.\n  Define your own pipeline actions You can define your pipeline actions to perform steps that cannot be performed by an existing command. There are several ways to achieve this.\n For simple tasks that can be achieved using shell script, Python script, R script etc, use actions such as ExecuteShellScript.\n If the steps requires processing of a single file, you can define an in-line action using action ExecutePythonCode. This action looks like\nExecutePythonCode(=\u0026ldquo;\u0026rsquo; with open(\u0026ldquo;${input:input[0]}\u0026ldquo;, \u0026lsquo;r\u0026rsquo;) as input: # process input files # generate output files # set variables to pipeline.VARS (e.g. pipeline.VARS[\u0026lsquo;read_length\u0026rsquo;] = 100) \u0026ldquo;\u0026lsquo;)\n  The difference between ExecutePythonCode and ExecutePythonScript is that ExcutePythonCode will be execute in the current process, and the script passed to ExecutePythonScript will be written to a Python script and called using a separate processed with optional command line options.\n If you have a complex action that involves classes and/or multiple functions, you can define the action in a .py file and import it using action ImportModule. Taking an example from RNASeq_tools.py, the @.py file looks like:\nfrom variant_tools.utils import env, calculateMD5 from variant_tools.pipeline import PipelineAction\nclass CreateRefGeneBed(PipelineAction): \u0026ldquo;\u0026lsquo;This pipeline step converts UCSC refGene.txt to BED format, to be used by tools such as RSeQC.\u0026ldquo;\u0026rsquo; def init(self, txt_file, output): PipelineAction.init(self, \u0026lsquo;CreateRefGeneBed_v1 \u0026ndash;txt_file {} {} \u0026lsquo; .format(txt_file, calculateMD5(txt_file, partial=True)), output) self.txt_file = txt_file\ndef _execute(self, ifiles, pipeline=None): with open(self.txt_file, 'rU') as ifile, open(self.output[0], 'w') as ofile: for line in ifile: ls = line.strip().split('\\t') starts = [int(x) for x in ls[9].strip(',').split(',')] stops = [int(x) for x in ls[10].strip(',').split(',')] lengths = ','.join([str(y-x) for x,y in zip(starts, stops)]) relstarts = ','.join([str(x-int(ls[4])) for x in starts]) ofile.write(\u0026quot;{0}\\t{1}\\t{2}\\t{3}\\t0\\t{4}\\t{5}\\t{6}\\t0\\t{7}\\t{8}\\t{9}\\n\u0026quot;.format( ls[2], ls[4], ls[5], ls[1], ls[3], ls[6], ls[7], ls[8], lengths, relstarts)) return True   This function converts a UCSC refGene.txt to BED format so that it can be used by tools such as RSeQC. Basically,\n A class should be derived from PipelineAction defined in variant_tools.pipeline\n It should call PipelineAction.__init__(self, cmd, output) with proper command line and expected output files so that the action will be skipped if it is called with identical signature.\n Define function _execute(self, ifiles, pipeline) to perform needed action and return output files and returns True if everything is ok. This function can generate output files, and/or set pipeline variables using pipeline.VARS[key]=value.\n Import the module to your pipeline using ImportModules('my_tools.py').\n  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/format10/",
	"title": "Customized",
	"tags": [],
	"description": "",
	"content": " Specification of a variant tools pipeline This page describes the original pipeline format (version 1.0). Please refer to New? if you are editing a new pipeline specification file for variant tools 2.7 and later.\n1. Introduction Variant Tools uses pipeline specification files to define pipelines. A pipeline specification file can define multiple pipelines. It can be stored locally or online in the variant tools repository (or a local repository maintained by your system adminstrator). You can use command\n% vtools show pipelines  to get a list of all publicly available pipelines, and\n% vtools show pipeline SPECFILE  to get the details of pipelines defined in SPECFILE. This output consists of description of the SPECFILE, all pipelines in it, steps of each pipeline, and options of the pipelines.\nA pipeline can be executed by command\n% vtools execute SPECFILE PIPELINE --input XXX --output XXX [OPTIONS]  where SPECFILE can be a local .pipeline file, or name of an online pipeline specification file, PIPELINE is the name of the pipeline defined in SPECFILE. The command line can be simplied to\n% vtools execute SPECFILE -i XXX -o XXX [OPTIONS]  if the spec file only defines one pipeline.\nThe format of pipeline spec files follows the .ini files of the good old days. It is not as fashionable as XML based configuration files but it is easier to read and write, and provides advanced features such as automatic parameter processing.\nThe .ini format is simple to read and write but please note that\n Values of an item can be expanded into multiple lines, e.g.\nname=this is a long text that continues to the second line or the third\n  Consequently, you can expand your comments or commands into several lines as long as you do not start from the first column.\n \u0026quot;%\u0026quot; is used for variable substitution (%(VAR)s) so %% should be used in place of %.\n \u0026rdquo;;\u0026rdquo; prefixed by a whitespace is recognized as inline comment, so you should leave no space before ; if it is part of the value of an item.\n  A pipeline spec file should have a pipleine description section and multiple pipeline step sections.\n2. Section [pipeline description] A pipeline specification file should start with a \u0026ldquo;pipeline description\u0026rdquo; section. This section should have the following keys:\n description: Summary of pipelines defined in this SPECFILE, which should include format and type of input data (raw reads? bam file? paired end?), external commands that are used, a short description of steps involved, and reference to external documentation if available.\n PIPELINE_description: Description of pipeline PIPELINE. PIPELINE has to be a valid pipeline defined in this file (with sections PIPELINE_XX).\n  If you have long descriptions (highly recommended!), you can break it into several paragraphs by adding HTML tags \u0026lt;p\u0026gt; or \u0026lt;br\u0026gt;. Tag \u0026lt;p\u0026gt; starts a new paragraph (two newlines) and tag \u0026lt;br\u0026gt; starts a new line (one newline). You can also use tags  and  to generate itemized lists. For example,\nThis pipeline uses \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;tophat 2.0.13 \u0026lt;li\u0026gt;bowtie 1.1.1 \u0026lt;li\u0026gt;samtools 0.1.19 \u0026lt;li\u0026gt;picard 1.82 \u0026lt;/ul\u0026gt;  will produce output\nThis pipeline uses * tophat 2.0.13 * bowtie 1.1.1 * samtools 0.1.19 * picard 1.82  when the description is outputted using command vtools show pipeline.\n NAME=VAL (optional): Pipeline variables. This is usually a good place to define constant values that will be used by pipeline steps. For example:\nRESOURCE_DIR=${LOCAL_RESOURCE}/pipeline_resource/name_of_pipeline   where ${LOCAL_RESOURCE} is another pipeline variable that has value of project runtime option $local_resource. We will talk about pipeline variables in details later.\nSection [DEFAULT] (command line options) The DEFAULT section defines parameters that can be changed using command line arguments. For example, in the following .pipeline file (partial)\n[DEFAULT] opt_java=-Xmx4g opt_java_comment=parameter passed to the java command, default to -Xmx4g to use a maximum of 4g heap space. [align_5] action=RunCommand(cmd=\u0026quot;java %(opt_java)s SortSam ...\u0026quot;)  The value of opt_java will be used to replace all instances of %(opt_java)s in the pipeline configuration file. The key opt_java has a help message defined by item opt_java_comment, and a default value -Xmx4g. If you query the details of this pipeline using command\n% vtools show pipeline my_pipeline  you will see at the end of the output the following description:\nPipeline parameters: opt_java parameter passed to the java command, default to -Xmx4g to use a maximum of 4g heap space. (default: -Xmx4g)  That is to say, you can pass an alternative value of opt_java to this format using command-line options such as --opt_java -Xmx32g to change the value of this option.\nIf you have a large number of parameters, you can save them to an external file, one item per line, and load them by prefixing filename with a \u0026quot;@\u0026quot; symbol. For example, if you have a file param.cfg with content\n--bwa /path/to/bwa --samtools /path/to/samtools  you can load parameters --bwa /path/to/bwa --samtools /path/to/samtools using \u0026quot;@param.cfg\u0026quot; from command line.\n3. Pipeline variables 3.1 Definition of pipeline variables Two different types of variables can be used in a spec file: command line options and pipeline variables. Command line options are defined in the [DEFAULT] section and are used in the spec file with syntax %(NAME)s. These variables are replaced right after a spec file is loaded and cannot be changed.\nPipeline variables are variables associated with the execution of pipeline. They are added with the progression of the pipeline and provides runtime information for each step.\nAll pipelines starts with the following variables:\n ${CMD_INPUT}: Pipeline input from command line option --input. For example, ${CMD_INPUT} will be ['data.tgz'] for command vtools execute bwa_gatk28_hg19 align --input data.tgz --output data.bam.\n ${CMD_INPUT} will always be a list even if only one input file is passed.\n ${CMD_INPUT} does not have to be a list of files but it must be translated to a list of filenames in the input section of the first step because each steps expects a list of files.\n ${CMD_OUTPUT}: Pipeline output from command line option --output, which will be ['data.bam'] for the above mentioned example. It does not have to a list of files. For example, it can be used to specify output directory or prefix of output files.\n ${VTOOLS_VERSION}: Version of variant tools (e.g. 2.0.2) used to execute the pipeline.\n ${SPEC_FILE}: Full path of the specfile in which the pipeline is defined.\n ${PIPELINE_NAME} and ${MODEL_NAME}: Name of the pipeline. The name MODEL_NAME is preferred when the pipeline is used in variant simulation tools.\n ${PIPELINE_STEP}: Current step in the pipeline (as a string).\n ${REF_GENOME_BUILD}: Primary build of the reference genome of the project (e.g. hg19).\n ${LOCAL_RESOURCE}: Project resource directory (runtime variable $local_resource).\n ${CACHE_DIR}: Project cache directory, which is usually used to store all intermediate files of a pipeline.\n ${TEMP_DIR}: Project temporary directory ($temp_dir), which can be used to store, for example, java temp directories. This directory can be set by runtime option $temp_dir. A system temp directory will be used if the pipeline is executed without a variant tools project.\n {MODEL_NAME} and SEED: Name of the simulation model (pipeline) and seed. Used by Variant Simulation Tools?.\n  Varialbes defined in the [Pipeline Description] section are added before the execution of the pipeline. Then, for each step, variant tools defines\n ${INPUT1}, ${INPUT2}, \u0026hellip;  as input files of the step, and\n ${OUTPUT1}, ${OUTPUT2}, \u0026hellip;  as output files of the step after the completion of each step. Variables can be defined and added to the pipeline after the completion of each step. Because these files are dynamically determined, \u0026ldquo;\u0026lsquo;you can not refer to input and output files of a later step of a pipeline\u0026rdquo;\u0026rsquo;. Because input files will be selected and passed to pipeline actions in groups, a temporary variable\n ${INPUT}  is used to store each group of input files. For example, if the input fastq files are emitted in groups (more about this later), ${INPUT} will be paired filenames. This variable should only be used in the action item of a step.\nUse of Pipline variables It is important to remember that\n Pipeline variables are case-insensitive, read only, and can be only string or list of strings. List of strings are joined by space when they are outputted. All file-list variables such as CMD_INPUT, CMD_OUTPUT, INPUT, INPUTXXX, OUTPUTXXX (where XXX is step of pipeline) are list of strings, even if there is only one file in the list.  For example, if the value of variable CMD_INPUT is ['file1.txt', 'file2.txt'], they will appear as file1.txt file2.txt when ${CMD_INPUT} is used in a command line.\nIf you need to output pipeline variables in any other format, you can use a function form of the variable ${VAR: lambda_func} using Python lambda function. For example,\n${CMD_OUTPUT: os.path.basename(CMD_OUTPUT[0])}  passes value of CMD_OUTPUT to a Python lambda function lambda x: os.path.basename(x[0]), which will be \u0026quot;output.bam\u0026quot; if ${CMD_OUTPUT} equals to \u0026quot;/path/to/output.bam\u0026quot;.\n${INPUT: ','.join(sorted([x for x in INPUT if '_R1_' in x]))}  takes a list of input files, select files with _R1_ in filename, sort them, and output them as comma-separated list.\nThis mechanism is very powerful in that the lambda function can take zero or more than one pipeline variables. For example\n${: \u0026quot;-f\u0026quot; if \u0026quot;%(force)s\u0026quot; == \u0026quot;Yes\u0026quot; else \u0026quot;\u0026quot;}  returns -f if a command line parameter force is set to \u0026ldquo;Yes\u0026rdquo;.\n${INPUT,CMD_OUTPUT: os.path.join(CMD_OUTPUT[0], INPUT[0])}  Use of shell variables (e.g. use a for loop in action RunCommand) is possible but can be tricky because pipeline and shell variables can take the same form. Whereas simple form of shell variables ($VAR instead of ${VAR}) can be used without problem, the brace form ${VAR} will trigger a warning message if VAR is a not valid pipeline variable, and return unexpected results otherwise.\nPipeline action sections [PIPELINE_XX], or [PIPELINE_XX,PIPELINE1_XX], or [*_XX] A pipeline is, roughly speaking, a pipe that connects the input (e.g. raw reads in fastq format) to the output (e.g. aligned reads in bam format), going through a few steps (actions) along the way. A pipeline specification file can define multiple pipelines with different PIPELINE. Steps in a pipeline are numbered and will be executed in such order.\n The same action can be used for multiple pipelines in the same spec file or be called at different steps of the same pipeline. You can even use pipeline variable {pipeline_name} and ${pipeline_step} to allow slightly different actions for different steps. The indexes of actions do not have to be consecutive so align_10, align_20, and align_30 are acceptable. They do not even have to be defined in the order they are be executed.  For each step of a pipeline, we need to know\n What are the input files How to process input files? One by one or altogether? What actions should be applied to the input files? What are the outputs?  Answers of these questions should be specified using the following keys:\n input (optional). List of input files for a step. The default value of the input is the output of the previous step (or the command input for the first step). One or more files could be specified explicitly (separated by space, space in filenames should be escaped by a back slash). For example,\noutput of step 400, not from previous step input=${OUTPUT400}\noutput from multiple steps input=${OUTPUT400} ${OUTPUT500}\nall files in a directory input=${:glob.glob(\u0026rsquo;*.gz\u0026rsquo;)}\nIf your pipeline does not need any input file, you can use the SPECFILE itself as a placeholder. input=${SPECFILE}\n A pipeline will be terminated if there is no input file or if any of the specified input files does not exist.\n input_emitter (optional). How to emit input files to action. By default, all input files are passed together to the action (so ${INPUT} equals to ${INPUTXXX} where XXX is number of pipeline step. An input emitter changes this behavior. Basically, an emitter select input files, divides them into groups and pass them one by one to the action. Unselected files can be discarded or passed directly as step output.\n  Variant Tools currently provides two input emitters:\nEmitInput(group_by='all', select=True, pass_unselected=True): Select input files of certain types, group them, and send input files to action. select can be True (all input file), False (no input file, the step will be skipped), 'fastq' (ignore file extension and check content of files), or one or more file extensions (e.g. ['sam', 'bam']). Eligible files are by default sent altogether (group_by='all') to action (group_by='all', ${INPUT} equals to ${INPUT#} where # is the index of step), but can also be sent individually (group_by='single', ${INPUT} is a list of a single file), or in pairs (group_by='paired', e.g. filename_1.txt and filename_2.txt). Unselected files are by default passed directly as output of a step.\nSkipIf(cond, pass_unselected=True): Skip an step if condition is True. All input files will be passed directly to output by default. This is equvalent to EmitInput(select=not cond, pass_unselected).\nAn input emitter does not substitute ${INPUT} because it determines ${INPUT}. They can however use other variables such as ${CMD_OUTPUT}. For example,\nSkipIf(${INPUT200:len(INPUT200)==1})  select files only if there are more than one input file. This is useful, for example, to merge bam files only if there are more than one input bam files.\n action (required): An action that will be executed by variant tools, sometimes repeatedly for different input files (e.g. for each or each pair of input files). Each action will return a list of output files, which will form the output files of the step. A list of actions can be specified in the format of Action1, Action2, .... These actions will be executed sequentially and the output of a previous action will become the input of the following action. Please check the actions section for a list of available actions.\n comment (optional): description of this step of the pipeline.\n NAME=VALUE (optional): This allows the pipeline step to define some pipeline variable with results obtained by the step. For example, if this step writes an optional flag in file file1.txt, you can use\nFLAG=${: open(\u0026ldquo;file1.txt\u0026rdquo;).read() }\n  to save its content to a pipeline variable. In addition, it is a good\npractice to rename OUTPUTXXX to a more meaningful name to make the pipeline more readable. For example\nACCEPTED_HITS=${OUTPUT440}  assigns the OUTPUT440 to a variable ACCEPTED_HITS so that you can use ACCEPTED_HITS in later actions. Note that the usage of two variables are slightly different because ACCEPTED_HITS is a string where as OUTPUT440 is a list of string.\nA section can define multiple pipeline steps if the same step can be used for multiple steps of a pipeline or for other pipelines in the same file. For example\n[EU_100,EU_200,EU_300] [EU_100,AF_100,GT_100]  can be used to perform the same action for steps 100, 200, and 300 of pipeline EU, or the same step 100 for pipelines EU, AF and GT. In the latter case, you can even use wildcard character\n[*_100]  to define a step that will be executed by all pipelines defined in this file.\nIf an action differ only slightly across pipelines, you can use variable ${PIPELINE_NAME} to perform different actions for different pipelines. For example,\n[eu_100,af_100] action= ..... ${PIPELINE_NAME: '-g' if PIPELINE_NAME='eu' else ''}  uses passes an additional option -g to an action for pipeline eu.\nAvailable actions Actions are functions that are executed by Variant Tools.\nTechnically speaking, pipeline actions are evaluated as a Python expression to obtain a PipelineAction object. That is to say, you can use arbitrary python expressions for this item.\nGiven an action, variant tools\n Replace %(NAME)s with corresponding command line argument NAME. Replace ${NAME} with corresponding pipeline variable NAME. Lambda functions such as {:EXPR}, {NAME:EXPR}, {NAME1,NAME2:EXPR} etc will be evaluated before they are substituted. Evaluate the text as a Python expression to obtain an PipelineAction object that will be called by Variant Tools. Python functions and expressions will be evaluated during this step.  For example, for the following action,\naction=CheckDirs([\u0026quot;%(resource_dir)s\u0026quot;, os.path.join('${CACHE_DIR}', '${PIPELINE_NAME}')])  will be processed as\naction=CheckDirs([\u0026quot;/path/to/resource\u0026quot;, os.path.join('${CACHE_DIR}', '${PIPELINE_NAME}')])  with command line option --resource_dir /path/to/resource (or use default value defined in section DEFAULT), and then to\naction=CheckDirs([\u0026quot;/path/to/resource\u0026quot;, os.path.join('cache', 'EUS')])  if the current pipeline is called EUS, and finally be evaluated to produce an object CheckDirs with parameters:\nCheckDirs([\u0026quot;/path/to/resource\u0026quot;, 'cache/EUS'])  There are two kinds of pipeline actions\n Built-in actions: Actions that are defined by variant tools.\n Pipeline-defined actions: Actions that are defined by users of variant tools pipeline. They are defined in .py files and need to be imported to a pipeline using action ImportModules.\n  Because of the increasing number of pipeline actions, variant tools provides a command\n% vtools show actions  to list all built-in action (for variant tools and variant simulation tools), and actions defined by pipelines in the variant tools repository. You can check the details of each action using command\n% vtools show action ACTION  For example, you can use command\n% vtools show action TerminateIf Help on class TerminateIf in module variant_tools.pipeline: class TerminateIf(PipelineAction) | Terminate a pipeline if a condition is not met. | | Examples: | action=TerminateIf(not '${CMD_OUTPUT}', 'No --output is specified.') | | Methods defined here: | | __call__(self, ifiles, pipeline=None) | Terminate the pipeline if specified condition is met. | | Parameters: | ifiles: unused | pipeline: unused | | Results: | Pass input to output. Does not change pipeline. | | Raises: | A RuntimeError will be raised to terminate the pipeline if | the condition is met. | | __init__(self, cond, message) | Parameters: | cond (boolean): | True or False. In practice, ``cond`` is usually | a lambda function that checks the existence of a file or value | of a pipeline variable. | | message (string): | A message to be outputted when the condition is met. | | ---------------------------------------------------------------------- | Methods inherited from PipelineAction: | | execute(self, ifiles, pipeline=None) | Function called by __call__ for actual action performed on ifiles. A user-defined | action should re-define __call__ or redefine this function and return ``True`` if the | action is completed successfully.  to check the details of action TerminateIf.\nBrief description of built-in actions The following is a partial list of built-in actions defined by variant tools. The descriptions are brief and might have been outdated so please use command above to check the latest documentation.\n CheckVariantToolsVersion(ver): Check the version of variant tools. Stop the pipeline if it is not recent enough to execute the pipeline.\n CheckCommands(cmds): Check the existence of command cmds and raise an error if the command does not exist. Input files of the step is passed directly as output files.\n CheckFiles(files, msg=''): Check the existence of specified files. This can be used to check, for example, the existence of the .jar file of GATK. An error message can be specified.\n CheckDirs(dirs, msg=''): Check the existence of specified directories. An error message can be specified.\n CheckOutput(cmd, patterns, failIfMismatch=True): Check the output of a command and see if it matches one of the specified patterns (see the search function of Python re package for details). The pipeline will be terminated if failIfMismatch is set to True (default). This action is usually used to check the version of commands.\n Check for a specific version of bwa\nCheckOutput(\u0026lsquo;bwa\u0026rsquo;, \u0026lsquo;Version: 0.7.4\u0026rsquo;)\n Check for multiple allowed versions of bwa\nCheckOutput(\u0026lsquo;bwa\u0026rsquo;, \u0026lsquo;Version: 0.7.*\u0026lsquo;)\n Check version of picard\nCheckOutput(\u0026lsquo;ls %(picard_path)s/picard*.jar\u0026rsquo;, \u0026lsquo;picard-1.82\u0026rsquo;)\n Check version of GATK\nCheckOutput(\u0026lsquo;java -jar %(gatk_path)/GenomeAnalysisTK.jar -version\u0026rsquo;, \u0026lsquo;^2.4\u0026rsquo;)\n Check version of MosaikAligner\nCheckOutput(\u0026lsquo;MosaikAligner -version\u0026rsquo;, \u0026lsquo;2.1\u0026rsquo;)\n DownloadResource(resource, dest_dir): Download a list of resources (URLs) (a single string, URLs can be separated by spaces or newlines) to a pipeline resource directory resource_dir. The resources will not be downloaded if the files already exist. .gz files will be decompressed automatically. If both filename and filename.md5 exist, the md5 signature of filename will be compared to filename.md5. resource_dir will be locked during downloading so only one process can execute this step at any time.\n RemoveIntermediateFiles(files): This action replaces specified files with info files (adds extension .file_info) that records the size, MD5 signature and modification date of the original files, usually after the completion of steps that make use of these intermediate files. variant tools will not try to re-execute the step with the existence of such truncated output files, unless a real output file is need to re-execute a later step. This action does not change input pipeline files. Files to be removed needs to be explicitly specified. (e.g. Use RemoveIntermediateFiles('${OUTPUT400}') instead of specifying input=${OUTPUT400})\n RunCommand(cmd, working_dir=None, output=[], submitter=None): Execute cmd (one command or a list of commands) under working directory working_dir (default to current project directory). A list of output files specified by output will be returned. If output is specified, three additional files, filename.out#, filename.err#, filename.exe_info (where filename is the first file in output) will be produced with command output, command error output, and command execution information, respectively. Command execution information contains command executed, start and ending time, file size and md5 signature of input and output files. If output files already exist, newer than input files, size and md5 checksum of input and output files and command used match what have been recorded in filename.exe_info, the command will not be executed. Because valid filename.exe_info files are only created after commands are completed successfully (not interrupted), a pipeline can be safely resumed if it is terminated due to user or system errors.\n Multiple commands could be executed in a single RunCommand action. The pipeline will terminate if any of the commands returns non-zero code.\n Using option output to specify output files is highly recommended because otherwise the command will be re-executed if the pipeline is re-executed. If the command does not produce any new output (e.g. many vtools commands), you can generate a status output file and use it as output, as in\nRunCommand(cmd=[\u0026lsquo;vtools import ${INPUT: \u0026ldquo; \u0026ldquo;.join(INPUT)} \u0026ndash;build hg19\u0026rsquo;, \u0026lsquo;vtools show genotypes \u0026gt; genotype.lst\u0026rsquo;], output=\u0026lsquo;genotype.lst\u0026rsquo;)\n If a valid working_dir is set, the child process in which the commands are executed will switch to this directory but the current directory of the master process will remain the same. That is to say, all input and output filenames etc are still relative to the project path, but os.path.abspath might be needed if these path are used in the cmd.\n If a submitter is defined, the submission command will be used to run the commands in background (e.g. submitter='sh {} \u0026amp;') or as a separate job (e.g. @@submitter=\u0026lsquo;qsub {}\u0026rsquo;). This allows parallel execution of pipeline steps.\n If no output is specified, input files are passed through as output files.\n  Arbitrary command could be defined for this action, which in theory could destroy all your data or system. It is your responsibility to verify that a pipeline description file does not contain malicious piece of code and we (developers of variant tools) are not responsible for any damage that might have been caused.\nDefine your own pipeline actions You can define your pipeline actions to perform steps that cannot be performed by an existing command. Generally speaking, you will need to\n Create a .py file such as my_actions.py with the actions. Taking an example from RNASeq_tools.py, the @.py file should look like:\nfrom variant_tools.utils import env, calculateMD5 from variant_tools.pipeline import PipelineAction\nclass CreateRefGeneBed(PipelineAction): \u0026ldquo;\u0026lsquo;This pipeline step converts UCSC refGene.txt to BED format, to be used by tools such as RSeQC.\u0026ldquo;\u0026rsquo; def init(self, txt_file, output): # NOTE: incrase _v? after the change of this function that might affect output PipelineAction.init(self, \u0026lsquo;CreateRefGeneBed_v1 \u0026ndash;txt_file {} {} \u0026lsquo; .format(txt_file, calculateMD5(txt_file, partial=True)), output) self.txt_file = txt_file\ndef _execute(self, ifiles, pipeline=None): with open(self.txt_file, 'rU') as ifile, open(self.output[0], 'w') as ofile: for line in ifile: # 13 NM_020929 chr11 - 40135750 41481186 40135919 40137842 5 # 40135750,40162350,40341177,40669691,41480980, 40137884,40162403,40341271,40669828,41481186, 0 # LRRC4C cmpl cmpl 0,-1,-1,-1,-1, # ls = line.strip().split('\\t') # # ls[9]: exon start (0-based) # ls[10]: exon end (1-based) # starts = [int(x) for x in ls[9].strip(',').split(',')] stops = [int(x) for x in ls[10].strip(',').split(',')] # # length is the sum of exons lengths = ','.join([str(y-x) for x,y in zip(starts, stops)]) # # ls[4]: gene start # # relative start positions relstarts = ','.join([str(x-int(ls[4])) for x in starts]) # # write each line in BED format # # chromosome # chromStart # chromEnd # name # score, ---unused--- # strand # coding start # coding end # itemRgb ---unused--- # blockCount, namely number of exons # blockStarts, namely relative starting position of the exons # # chr11 40135750 41481186 NM_020929 0 - 40135919 40137842 0 5 # 2134,53,94,137,206 0,26600,205427,533941,1345230 # ofile.write(\u0026quot;{0}\\t{1}\\t{2}\\t{3}\\t0\\t{4}\\t{5}\\t{6}\\t0\\t{7}\\t{8}\\t{9}\\n\u0026quot;.format( ls[2], ls[4], ls[5], ls[1], ls[3], ls[6], ls[7], ls[8], lengths, relstarts)) return True   This function converts a UCSC refGene.txt to BEd format so that it can be used by tools such as RSeQC. Basically,\n A class should be derived from PipelineAction defined in variant_tools.pipeline\n It should call PipelineAction.__init__(self, cmd, output) with proper command line and expected output files so that the action will be skipped if it is called with identical signature.\n Define function _execute(self, ifiles, pipeline) to perform needed action and return output files and returns True if everything is ok. This function can generate output files, and/or set pipeline variables using pipeline.VARS[key]=value.\n Import the module to your pipeline using ImportModules('my_tools.py').\n  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/qc/",
	"title": "Data exploration/QC",
	"tags": [],
	"description": "",
	"content": " Data Exploration and Quality Control Overview Quality control is a key step in association analysis. We may use a variety of criteria to clean our data (criteria directly from original vcf file or statistic summary we are interested in). Variants can also be subsetted based on these properties such as variant information, annotations, summary statistics, etc, which are displayed by vtools show fields.\n vtools select and vtools exclude commands implement variant and genotype level data selection and filtering. We could either focus on subsets of variants of interest (vtools select) or remove non-informative subsets of variants (vtools exclude) after such subsets are created. vtools update and vtools phenotype commands implement variant and sample level summary statistics. We could either get counts for different genotypes, functional variants (vtools update) or total/average of these counts per individual (vtools phenotype).  QC Pipeline in Brief  Variant \u0026amp; Genotype Level QC (vtools select and vtools exclude)\n remove low quality variants which do not pass the variants filter. remove low quality genotypes with low genotype quality score (GQ) remove low quality genotypes with low genotype depth of coverage (GD).   Hardy–Weinberg equilibrium Filter (vtools update)\n remove variants which does not pass Hardy–Weinberg equilibrium criterion (e.g. HWE pvalue \u0026lt; {$10^{-8}$} ).   Basic Summary Statistics on Variant Level (vtools update)\n based on variant level, we can get basic counts of different genotypes (calls, wild types, mutation types, homozygote genotypes, heterozygote genotypes, alternative alleles, etc). based on variant level, we can calculate alternative allele frequency, and subset variants by different allele frequency cutoff defined as common variants or rare variants. based on variant level, we cat get counts of different functional types of variants (synonymous, missense, nonsense, etc). based on variant level, we cat get counts of singletons and doubletons.   Basic Summary Statistics on Sample Level (vtools phenotype)\n based on individual level, we can get basic counts of different genotypes (calls, wild types, mutation types, homozygote genotypes, heterozygote genotypes, alternative alleles, etc) and calculate average counts. based on individual level, we cat get counts of different types of variants (synonymous, missense, nonsense, etc), and calculate average counts. based on individual level, we cat get counts of transitions and transversions, and calculate transitions V.S. transversions ratio (Ti/Tv ratio). based on individual level, we cat get counts of singletons and doubletons, and calculate average counts.   QC Pipeline in Detail  Introductory tutorial: a 30min tutorial using ~100 samples from 1000 Genomes Project   Data bundle  Basic tutorial: a basic demonstration of quality control using exome sequencing data from European and Asian samples of the 1000 genomes project ? Advanced tutorial: an advanced demonstration of quality control using same dataset as the basic tutorial [![][6]][6]  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/discovery/",
	"title": "Discovery",
	"tags": [],
	"description": "",
	"content": " Discover informative variants from a large number of variants Introduction Once you have imported? variants and samples of an exome or whole-genome sequencing project, you are typically facing a master variant table with millions of variants. Depending on the phenotypes of interest and particular research topics, you might want to filter variants for subsequent association analysis, or select variants that are more informative than others for further lab-based analysis. For example, you might be interested in\n Variants in a specific list of genes (cancer genes?) Variants are that novel (not in dbSNP and 1000 genomes project) Variants that exist only in cases but not in control, Variants that are non-synonymous, frame-shifting, predicted to be damaging, or highly conserved during evolution, Variants that are in exon regions of genes, Variants that are in particular pathways  Variant info and annotation fields Variants that satisfies these conditions can be selected from either project-specific properties (sample statistics, quality score etc) or annotation databases (dbSNP or 1000 genome project membership, gene regions etc). Required variant info and annotation fields could be prepared by\n Import? or update? variant info fields from source files, Calculate sample statistics? as variant info fields, and Download and link? project to various annotation databases.  Please refer to relevant documentation pages for details.\nSelection and management of variants After you have required variant info and annotation fields in place, you have conceptually a huge table with variant as rows and variant info and annotation fields as columns. It is then relatively easy to use command vtools select or vtools exclude to select variants of interest. For example, if you have a field num_case as number of alternative alleles in the cases (affected individuals), num_control as number of alternative alleles in controls (unaffected individuals), SIFT_score from database dbNSFP?, you could use condition\n'num_case\u0026gt;0' 'num_control=0' 'SIFT_score\u0026gt;0.95' 'dbSNP.chr is NULL'  to select variants that are available in cases (num_case\u0026gt;0), not in control (num_control=0), predicted to be damaging (SIFT_score\u0026gt;0.95), and is not in dbSNP (dbSNP.chr is NULL). The last condition looks a bit strange but it merely means that there is no value (NULL) for field dbSNP.chr in the large virtual table we have imagined, meaning variants that are not in the dbSNP database.\nSelected variants could be outputted directly but they are more frequently saved to a separate variant table for future reference. Many variant tables could be created based on different selection criteria, and you could use any of these tables whenever a variant table is needed (e.g. after commands vtools select, vtools exclude, vtools output, and vtools export).\nTutorials For more information on the use of these commands, please refer to the following tutorials:\n Analyzing 44 whole genome cases and 200 exome controls, with detailed performance measures ? Analyzing 5 whole-genome samples from Illumina ? Compare variants from the same samples called by Complete Genomics and Illumina ? Select variants belonging to specified genes ?  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/",
	"title": "Documentation",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/format/formats/",
	"title": "Formats",
	"tags": [],
	"description": "",
	"content": " Supported import/update/export file formats variant tools uses file format specification files (.fmt) files to describe file formats so that commands such as vtools import, vtools update and vtools export know how to import data from and export data to files in such formats.\n variant tools can import variants, variant info fields, genotypes, and genotype info fields from a file. The file must contain information about variants (chr, pos, ref, alt), although variant tools is able to obtain information from other sources if some of the variant info fields are missing. (For example, variant tools can retrieve reference alleles from a reference genome). variant tools can update variant info fields and genotype info fields for existing variants and genotypes. The file can be variant-based (contains chr, pos, ref and alt), position-based (contains chra and pos), and range-based (contains chr, starting and ending positions). In the latter cases, a record in the input file can update multiple variants at the specified location or range. variant tools can export variants, variant info fields, genotypes, and genotype info fields to a file. The format description file must define columns, which specify what and in which format to export to each column of the output file.  variant tools can import and export data in the following formats. We try to update descriptions of these formats as soon as possible but please use commands such as\n% vtools show formats % vtools show format basic\nto get the most updated information about these formats.\n| Name | Import | Update | Export | Comment | || | basic? | Y | | Y | Import variants in tab-delimited format, export variants and optional variant info fields and genotypes | | VCF | Y | Y | Y | Variant Call Format (VCF version 4.0 and 4.1) | | CSV? | Y | | Y | csv format | | ANNOVAR? | | | Y | Format of ANNOVAR input file. | | ANNOVAR_variant_function? | Y | | | used to imported annotations from ANNOVAR *.variant_function files. | | ANNOVAR_exonic_variant_function? | Y | | | imports annotations from files generated from ANNOVAR of the form *.exonic_variant_function. | | CASAVA18_snps? | Y | | | Illumina snps.txt format | | CASAVA18_indels? | Y | | | indels.txt from Illumina | | CGA? | Y | | | Complete Genomics CGA masterVarBeta$ID.tsv.bz2 file | | Pileup_indel? | Y | | | Pileup Indel format | | MAP? | Y | | | Import variants from files with only chr and pos information. reference and alternative alleles are retrieved from dbSNP. | | PLINK? | Y | Y | | Import variants and sample genotypes from PLINK file format. Currently only PLINK binary file input is supported. | | Polyphen2? | Y | | Y | Export data in Polyphen2 batch query, import information from results returned by the polyphen2 batch query server. | | TPED? | | | Y | | | twoalleles? | Y | | | Import alleles as allele 1 and 2, use a reference genome to determine which one is reference | | rsname? | Y | | | Import variants from rsnames, using the dbSNP database to query variants |\nCustomize import/export format:\n Using customized format specification? file (.fmt) to import/export arbitrary text format.  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/development/getinvolved/",
	"title": "Get involved",
	"tags": [],
	"description": "",
	"content": " Report bugs and share ideas People variant tools is currently maintained by Dr. Bo Peng (references) from the Department of Bioinformatics and Computational Biology, MD Anderson Cancer Center, Anthony San Lucas from Dr. Paul Scheet\u0026rsquo;s lab at the University of Texas, MD Anderson Cancer Center, and Gao Wang from Dr. Suzanne Leal\u0026rsquo;s group at the Baylor College of Medicine. Other contributed developers are Min Qiao (UT School of Public Health), Dr. Long Ma (Genetics, MD Anderson Cancer Center) and Dr. Jerry Fowler (Epidemiology, MD Anderson Cancer Center). Please feel free to join us if you find this tool useful and would like to contribute to it.\nSpecial Thanks We are grateful to our collaborators who had used variant tools in their research projects and contributed to its evolution:\n Mengyuan Kan (Baylor College of Medicine \u0026amp; Institute of Nutritional Sciences, Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences) for her numerous valuable comments, suggestions and feature requests, as well as her generous contribution to many of the documentation pages.  Issue Tracker We have moved the Variant Tools source code to github where the new development will take place. The new version will overhaul the storage and query model of variant tools and will take a while for it to be ready. In the meantime, we will continue to support Variant Tools, answering questions and fixing bugs through the Variant Tools Issue Tracker.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/genes/hugogene/",
	"title": "HugoGene",
	"tags": [],
	"description": "",
	"content": " HUGO Gene Nomenclature Committee (HGNC) approved gene names The HUGO Gene Nomenclature Committee (HGNC) has assigned unique gene symbols and names to almost 38,000 human loci, of which around 19,000 are protein coding. genenames.org is a curated online repository of HGNC-approved gene nomenclature and associated resources including links to genomic, proteomic and phenotypic information, as well as dedicated gene family pages.\nHGNC The HGNC annotation database is a field database that, by default, annotates another gene name field such as refGene.name2, through its All_Symbols column, which contains all current and previously used gene names. For example, for gene TMEM261 with a previously used name C9orf123, it has two entries in the database,\nname All_Symbols TMEM261 TMEM261 TMEM261 C9orf123  so that the name field will have its HGNC approved name TMEM261. To link to this database, you should do, for example,\n% vtools use HGNC --linked_by refGene.name2 INFO: Downloading annotation database from annoDB/HGNC.ann INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/HGNC-20131029.DB.gz INFO: Using annotation DB HGNC in project test. INFO: The HUGO Gene Nomenclature Committee (HGNC) has assigned unique gene symbols and names to almost 38,000 human loci, of which around 19,000 are protein coding. genenames.org is a curated online repository of HGNC-approved gene nomenclature and associated resources including links to genomic, proteomic and phenotypic information, as well as dedicated gene family pages INFO: 22889 out of 23953 refgene.name2 are annotated through annotation database HGNC WARNING: 30614 out of 53503 values in annotation database HGNC are not linked to the project.  Note that not all names in refGene have an entry in HGNC. Genes that are not in HGNC are mostly LOC????? genes. Then, instead of output refGene.name2, you can output HGNC approved name\n% vtools output variant chr pos HGNC.name  You can, if you are interested, check the change of names using commands\n% vtools select variant 'refGene.name2 != HGNC.name' --output chr pos refGene.name2 HGNC.name --all  although variants that belong to more than one gene will also be selected and outputted.\n% vtools show annotation HGNC Annotation database HGNC (version 20131029) Description: The HUGO Gene Nomenclature Committee (HGNC) has assigned unique gene symbols and names to almost 38,000 human loci, of which around 19,000 are protein coding. genenames.org is a curated online repository of HGNC-approved gene nomenclature and associated resources including links to genomic, proteomic and phenotypic information, as well as dedicated gene family pages Database type: field Reference genome *: All_Symbols name HGNC Approved Symbol All_Symbols All symbols, including Approved and repvious symbols HGNC_ID A unique ID provided by the HGNC. In the HTML results page this ID links to the HGNC Symbol Report for that gene. Approved_Symbol The official gene symbol that has been approved by the HGNC and is publicly available. Symbols are approved based on specific HGNC nomenclature guidelines. In the HTML results page this ID links to the HGNC Symbol Report for that gene. Approved_Name The official gene name that has been approved by the HGNC and is publicly available. Names are approved based on specific HGNC nomenclature guidelines. Status Indicates whether the gene is classified as: Approved - these genes have HGNC-approved gene symbols Entry withdrawn - these previously approved genes are no longer thought to exist Symbol withdrawn - a previously approved record that has since been merged into a another record Locus_Type Specifies the type of locus described by the given entry: gene with protein product, RNA, cluster, etc (h ttp://www.genenames.org/data/gdlw_columndef.html#gd_ap p_sym) Locus_Group Groups locus types together into related sets. See http://www.genenames.org/data/gdlw_columndef.html#gd_a pp_sym for details. Previous_Symbols Symbols previously approved by the HGNC for this gene Previous_Names Gene names previously approved by the HGNC for this gene Synonyms Other symbols used to refer to this gene Name_Synonyms Other names used to refer to this gene Chromosome Indicates the location of the gene or region on the chromosome Date_Approved Date the gene symbol and name were approved by the HGNC Date_Modified If applicable, the date the entry was modified by the HGNC Date_Symbol_Changed If applicable, the date the gene symbol was last changed by the HGNC from a previously approved symbol. Many genes receive approved symbols and names which are viewed as temporary (eg C2orf#) or are non-ideal when considered in the light of subsequent information. In the case of individual genes a change to the name (and subsequently the symbol) is only made if the original name is seriously misleading. Date_Name_Changed If applicable, the date the gene name was last changed by the HGNC from a previously approved name Accession_Numbers Accession numbers for each entry selected by the HGNC Enzyme_IDs Enzyme entries have Enzyme Commission (EC) numbers associated with them that indicate the hierarchical functional classes to which they belong Entrez_Gene_ID Entrez Gene at the NCBI provide curated sequence and descriptive information about genetic loci including official nomenclature, synonyms, sequence accessions, phenotypes, EC numbers, MIM numbers, UniGene clusters, homology, map locations, and related web sites. In the HTML results page this ID links to the Entrez Gene page for that gene. Entrez Gene has replaced LocusLink. Ensembl_Gene_ID This column contains a manually curated Ensembl Gene ID Mouse_Genome_Database_ID MGI identifier. In the HTML results page this ID links to the MGI Report for that gene. Specialist_Database_Links This column contains links to specialist databases with a particular interest in that symbol/gene (also see Specialist Database IDs). Specialist_Database_IDs The Specialist Database Links column contains HTML links to the database in question. This column contains the database ID only. Pubmed_IDs Identifier that links to published articles relevant to the entry in the NCBI's PubMed database. RefSeq_IDs The Reference Sequence (RefSeq) identifier for that entry, provided by the NCBI. As we do not aim to curate all variants of a gene only one selected RefSeq is displayed per gene report. RefSeq aims to provide a comprehensive, integrated, non-redundant set of sequences, including genomic DNA, transcript (RNA), and protein products. RefSeq identifiers are designed to provide a stable reference for gene identification and characterization, mutation analysis, expression studies, polymorphism discovery, and comparative analyses. Gene_Family_Tag Tag used to designate a gene family or group the gene has been assigned to, according to either sequence similarity or information from publications, specialist advisors for that family or other databases. Families/groups may be either structural or functional, therefore a gene may belong to more than one family/group. These tags are used to generate gene family or grouping specific pages at genenames.org and do not necessarily reflect an official nomenclature. Each gene family has an associated gene family tag and gene family description. If a particular gene is a member of more than one gene family, the tags and the descriptions will be shown in the same order. Gene_family_description Name given to a particular gene family. The gene family description has an associated gene family tag. Gene families are used to group genes according to either sequence similarity or information from publications, specialist advisors for that family or other databases. Families/groups may be either structural or functional, therefore a gene may belong to more than one family/group. Record_Type Primary_IDs Secondary_IDs CCDS_IDs The Consensus CDS (CCDS) project is a collaborative effort to identify a core set of human and mouse protein coding regions that are consistently annotated and of high quality. The long term goal is to support convergence towards a standard set of gene annotations. VEGA_IDs This contains a curated VEGA gene ID Locus_Specific_Databases This contains a list of links to databases or database entries pertinent to the gene Entrez_Gene_ID_NCBI Entrez Gene at the NCBI provide curated sequence and descriptive information about genetic loci including official nomenclature, synonyms, sequence accessions, phenotypes, EC numbers, MIM numbers, UniGene clusters, homology, map locations, and related web sites. In the HTML results page this ID links to the Entrez Gene page for that gene. Entrez Gene has replaced LocusLink. OMIM_ID_NCBI Identifier provided by Online Mendelian Inheritance in Man (OMIM) at the NCBI. This database is described as a catalog of human genes and genetic disorders containing textual information and links to MEDLINE and sequence records in the Entrez system, and links to additional related resources at NCBI and elsewhere. In the HTML results page this ID links to the OMIM page for that entry. RefSeq_NCBI The Reference Sequence (RefSeq) identifier for that entry, provided by the NCBI. As we do not aim to curate all variants of a gene only one mapped RefSeq is displayed per gene report. RefSeq aims to provide a comprehensive, integrated, non-redundant set of sequences, including genomic DNA, transcript (RNA), and protein products. RefSeq identifiers are designed to provide a stable reference for gene identification and characterization, mutation analysis, expression studies, polymorphism discovery, and comparative analyses. In the HTML results page this ID links to the RefSeq page for that entry. UniProt_ID The UniProt identifier, provided by the EBI. The UniProt Protein Knowledgebase is described as a curated protein sequence database that provides a high level of annotation, a minimal level of redundancy and high level of integration with other databases. In the HTML results page this ID links to the UniProt page for that entry. Ensembl_ID_Ensembl The Ensembl ID is derived from the current build of the Ensembl database and provided by the Ensembl team. UCSC_ID The UCSC ID is derived from the current build of the UCSC database Mouse_Genome_Database_ID_MGI MGI identifier. In the HTML results page this ID links to the MGI Report for that gene. Rat_Genome_Database_ID_RGD RGD identifier. In the HTML results page this ID links to the RGD Report for that gene.  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_commands/import/",
	"title": "Import",
	"tags": [],
	"description": "",
	"content": " Import variants, genotypes and related information fields 1. Usage % vtools import -h usage: vtools import [-h] [--build BUILD] [--format FORMAT] [--sample_name [SAMPLE_NAME [SAMPLE_NAME ...]]] [-f] [-j N] [-v {0,1,2}] input_files [input_files ...] x Import variants and related sample genotype from one or more delimiter separated files (e.g. VCF and a number of indel formats). positional arguments: input_files A list of failes that will be imported. The file should be delimiter separated with format described by parameter --format. Gzipped files are acceptable. If a preprocessor is defined in the format, input files will be processed by the preprocessor before they are imported. optional arguments: -h, --help show this help message and exit --build BUILD Build version of the reference genome (e.g. hg18) of the input data. If unspecified, it is assumed to be the primary reference genome of the project. If a reference genome that is different from the primary reference genome of the project is specified, it will become the alternative reference genome of the project. The UCSC liftover tool will be automatically called to map input coordinates between the primary and alternative reference genomes. If you are uncertain about the reference genome used in the data, use a recent standard reference genome (e.g. hg19) and validate it after the data is imported (c.f. \u0026quot;vtools admin --validate_build\u0026quot;). --format FORMAT Format of the input text file. It can be one of the variant tools supported file types such as VCF (cf. 'vtools show formats'), or a local format specification file (with extension .fmt). If unspecified, variant tools will try to guess format from file extension. Some file formats accept parameters (cf. 'vtools show format FMT') and allow you to import additional or alternative fields defined for the format. --sample_name [SAMPLE_NAME [SAMPLE_NAME ...]] Name of the samples imported by the input files. The same names will be used for all files if multiple files are imported. If unspecified, headers of the genotype columns of the last comment line (line starts with #) of the input files will be used (and thus allow different sample names for input files). If sample names are specified for input files without genotype, samples will be created without genotype. If sample names cannot be determined from input file and their is no ambiguity (only one sample is imported), a sample with NULL sample name will be created. -f, --force Import files even if the files have been imported before. This option can be used to import from updated file or continue disrupted import, but will not remove wrongfully imported variants from the master variant table. -j N, --jobs N Number of processes to import input file. Variant tools by default uses four processes to import variants and samples genotypes in parallel, and you can use more or less processes by adjusting this parameter. Due to the overhead of inter-process communication, more jobs do not automatically lead to better performance. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1).  2. Importing VCF files VCF is the most commonly used format to store genetic variants and sample genotypes from next-gen sequencing studies. variant tools can import data from plain (.vcf) or compressed (.vcf.gz) vcf format (version 4.0 or higher). Depending on the number of samples a vcf file stores, variant tools can import only variants (even if the vcf file contains sample genotypes, see an example below), import variants with a sample without genotype, and import all samples in a vcf file using specified sample names or sample names obtained from the meta information (see examples above). A limitation is that variant tools ignores phase information of genotypes.\nImport variant and genotype info fields The vcf format can store arbitary variant and genotype information fields. variant tools by default does not import any variant and info fields. However, you may specified the fields you\u0026rsquo;d like to import using option --var_info for variant fields and --geno_info for genotype fields. To import variant or genotype fields from a vcf file, you need to\n know what fields are available from the input vcf file. That is to say, you need to open a file, read its header, and determine what fields are provided. In the current version, genotype fields DP,GQ,GD,HQ,AD,PL,MQ,NS are supported. use command vtools import input_file.vcf --var_info var_fields --geno_info geno_fields to import variants, genotypes and related fields.  If your vcf file is bgzipped and tabix indexed (you can run compress and index your vcf file using commands bgzip and tabix), you can use command vtools show track FILENAME.vcf.gz to get details of the vcf file. The [track][5] function can also be used to retrieve such information when needed so you do not have to import variant info fields into the project.\n If your vcf file contains novel variant and/or geno info fields, or if you would like to import all variant and genotype info fields into the project, you can create a customized .fmt file to import these. This process can be simplified using pipeline import_vcf. The command to use is similar to vtools execute import_vcf --input my_file.vcf --output myvcf.fmt --build hg19.\n Examples:create a project and load some sample data\nLet us first create a project and download a sample project with a bunch of test datasets:\n% vtools init import --parent vt_testData_v3  You can use command vtools show snapshots to get a list of available snapshots\n \nExamples: importing variant and genotype info fields If we have a look at the header of CEU.vcf.gz, we can see\n% gzcat CEU_hg38.vcf | head -15 ##fileformat=VCFv4.0 ##INFO=\u0026lt;ID=DP,Number=1,Type=Integer,Description=\u0026quot;Total Depth\u0026quot;\u0026gt; ##INFO=\u0026lt;ID=HM2,Number=0,Type=Flag,Description=\u0026quot;HapMap2 membership\u0026quot;\u0026gt; ##INFO=\u0026lt;ID=HM3,Number=0,Type=Flag,Description=\u0026quot;HapMap3 membership\u0026quot;\u0026gt; ##INFO=\u0026lt;ID=AA,Number=1,Type=String,Description=\u0026quot;Ancestral Allele, ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/technical/reference/ancestral_alignments/README\u0026quot;\u0026gt; ##reference=human_b36_both.fasta ##FORMAT=\u0026lt;ID=GT,Number=1,Type=String,Description=\u0026quot;Genotype\u0026quot;\u0026gt; ##FORMAT=\u0026lt;ID=DP,Number=1,Type=Integer,Description=\u0026quot;Read Depth\u0026quot;\u0026gt; ##FORMAT=\u0026lt;ID=CB,Number=1,Type=String,Description=\u0026quot;Called by S(Sanger), M(UMich), B(BI)\u0026quot;\u0026gt; ##rsIDs=dbSNP b129 mapped to NCBI 36.3, August 10, 2009 ##INFO=\u0026lt;ID=AC,Number=.,Type=Integer,Description=\u0026quot;Allele count in genotypes\u0026quot;\u0026gt; ##INFO=\u0026lt;ID=AN,Number=1,Type=Integer,Description=\u0026quot;Total number of alleles in called genotypes\u0026quot;\u0026gt; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT NA06985 NA06986 NA06994 NA07000 NA07037 NA07051 NA07346 NA07347 NA07357 NA10847 NA10851 NA11829 NA11830 NA11831 NA11832 NA11840 NA11881 NA11894 NA11918 NA11919 NA11920 NA11931 NA11992 NA11993 NA11994 NA11995 NA12003 NA12004 NA12005 NA12006 NA12043 NA12044 NA12045 NA12144 NA12154 NA12155 NA12156 NA12234 NA12249 NA12287 NA12414 NA12489 NA12716 NA12717 NA12749 NA12750 NA12751 NA12760 NA12761 NA12762 NA12763 NA12776 NA12812 NA12813 NA12814 NA12815 NA12828 NA12872 NA12873 NA12874 1 10533 . G C . PASS AA=.;AC=6;AN=120;DP=423 GT:DP:CB 0|0:6:SMB 0|0:14:SMB 0|0:4:SMB 0|0:3:SMB 0|0:7:SMB 0|0:4:SMB 1|0:6:MB 0|0:3:SMB 0|0:13:SMB 0|0:1:SMB 0|0:14:SMB 0|0:10:SMB 0|0:6:SB 0|0:2:SMB 0|0:6:SMB 0|0:4:SMB 0|0:2:SMB 0|0:15:SMB 0|0:2:SMB 0|0:1:SMB 0|0:26:SMB 0|0:6:SMB 0|1:14:MB 0|0:5:SMB 0|0:3:SMB 0|0:20:SMB 0|0:3:SMB 0|0:2:SMB 0|0:4:SMB 0|0:12:SMB 0|0:1:SMB 0|0:7:SMB 0|0:2:SMB 0|0:25:SMB 0|0:9:SMB 0|1:1:MB 0|0:9:SMB 0|0:1:SMB 0|0:6:SMB 0|0:12:SMB 0|0:7:SMB 0|0:18:SMB 0|0:2:SMB 0|0:2:SM 0|0:38:SMB 0|0:3:SM 0|0:3:SMB 0|0:5:SMB 0|0:5:SMB 0|0:3:SMB 0|0:0:MB 0|0:5:SMB 0|0:7:SMB 0|0:0:SMB 0|0:6:SMB 1|0:5:SMB 0|0:4:MB 0|0:5:SMB 1|0:5:MB 0|1:9:SMB  we can see that this file contains genotype info AA, AC, AN, and DP, and genotype info DP and CB.\n% vtools init import -f % vtools import CEU_hg38.vcf --build hg38 --var_info AA AC AN DP --geno_info DP INFO: Importing variants from CEU_hg38.vcf (1/1) CEU_hg38.vcf: 100% [======================================] 306 10.6K/s in 00:00:00 INFO: 292 new variants (292 SNVs) from 306 lines are imported. Importing genotypes: 100% [===============================] 292 2.7K/s in 00:00:00  The imported data now has variant info field AA, AC, AN, and DP,\n% vtools show fields variant.chr (char) Chromosome name (VARCHAR) variant.pos (int) Position (INT, 1-based) variant.ref (char) Reference allele (VARCHAR, - for missing allele of an insertion) variant.alt (char) Alternative allele (VARCHAR, - for missing allele of an deletion) variant.AA (char) variant.AC (int) variant.AN (int) variant.DP (int)  and genotype info field DP\n% vtools show genotypes -l 5 sample_name filename num_genotypes sample_genotype_fields NA06985 CEU_hg38.vcf 292 DP,GT NA06986 CEU_hg38.vcf 292 DP,GT NA06994 CEU_hg38.vcf 292 DP,GT NA07000 CEU_hg38.vcf 292 DP,GT NA07037 CEU_hg38.vcf 292 DP,GT (55 records omitted)  \nIn above example, DP appears in both INFO and genotype columns of the input vcf file. Since DP could be listed in INFO field to record the total depth of the genotype of all samples in the vcf file.\nHere is another example importing multiple VCF files:\nExamples: import multiple VCF files If we have a look at the meta information of V1.vcf,\n% head -14 V1_hg38.vcf ##fileformat=VCFv4.0 ##INFO=\u0026lt;ID=NS,Number=1,Type=Integer,Description=\u0026quot;Number of Samples With Data\u0026quot;\u0026gt; ##INFO=\u0026lt;ID=DP,Number=1,Type=Integer,Description=\u0026quot;Total Depth\u0026quot;\u0026gt; ##INFO=\u0026lt;ID=AF,Number=.,Type=Float,Description=\u0026quot;Allele Frequency\u0026quot;\u0026gt; ##INFO=\u0026lt;ID=AA,Number=1,Type=String,Description=\u0026quot;Ancestral Allele\u0026quot;\u0026gt; ##INFO=\u0026lt;ID=DB,Number=0,Type=Flag,Description=\u0026quot;dbSNP membership, build 129\u0026quot;\u0026gt; ##INFO=\u0026lt;ID=H2,Number=0,Type=Flag,Description=\u0026quot;HapMap2 membership\u0026quot;\u0026gt; ##FILTER=\u0026lt;ID=q10,Description=\u0026quot;Quality below 10\u0026quot;\u0026gt; ##FORMAT=\u0026lt;ID=GT,Number=1,Type=String,Description=\u0026quot;Genotype\u0026quot;\u0026gt; ##FORMAT=\u0026lt;ID=GQ,Number=1,Type=Integer,Description=\u0026quot;Genotype Quality\u0026quot;\u0026gt; ##FORMAT=\u0026lt;ID=DP,Number=1,Type=Integer,Description=\u0026quot;Read Depth\u0026quot;\u0026gt; ##FORMAT=\u0026lt;ID=HQ,Number=2,Type=Integer,Description=\u0026quot;Haplotype Quality\u0026quot;\u0026gt; ##INFO=\u0026lt;ID=REMAP_ALIGN,Number=1,Type=String,Description=\u0026quot;Alignment type used for remapping (FP=first pass, SP=second pass)\u0026quot;\u0026gt; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT SAMP1 1 14677 . G A 32 PASS DP=6;NS=1;REMAP_ALIGN=FP GT 0/1  DP is listed as a INFO field, along with NS, we can import V1_hg38.vcf, V2_hg38.vcf and V3_hg38.vcf using command\n% vtools init import -f % vtools import V*_hg38.vcf --build hg38 --geno_info DP NS INFO: Importing variants from V1_hg38.vcf (1/3) V1_hg38.vcf: 100% [==================================] 1,619 5.0K/s in 00:00:00 INFO: 1,273 new variants (1,273 SNVs, 332 unsupported) from 1,619 lines are imported. Importing genotypes: 100% [==========================] 1,273 9.6K/s in 00:00:00 INFO: Importing variants from V2_hg38.vcf (2/3) V2_hg38.vcf: 100% [==================================] 1,601 5.2K/s in 00:00:00 INFO: 449 new variants (1,258 SNVs, 329 unsupported) from 1,599 lines are imported. Importing genotypes: 100% [==========================] 1,722 14.3K/s in 00:00:00 INFO: Importing variants from V3_hg38.vcf (3/3) V3_hg38.vcf: 100% [==================================] 1,589 5.3K/s in 00:00:00 INFO: 329 new variants (1,274 SNVs, 301 unsupported) from 1,589 lines are imported. Importing genotypes: 100% [==========================] 2,051 17.1K/s in 00:00:00  DP and NS will be imported as genotype info for each genotype,\n% vtools show fields variant.chr (char) Chromosome name (VARCHAR) variant.pos (int) Position (INT, 1-based) variant.ref (char) Reference allele (VARCHAR, - for missing allele of an insertion) variant.alt (char) Alternative allele (VARCHAR, - for missing allele of an deletion) % vtools show genotypes sample_name filename num_genotypes sample_genotype_fields SAMP1 V1_hg38.vcf 1273 DP,GT,NS SAMP2 V2_hg38.vcf 1258 DP,GT,NS SAMP3 V3_hg38.vcf 1274 DP,GT,NS  If you need total depth, you can obtained from the corresponding genotype field\n% vtools update variant --from_stat 'DP=sum(DP)' 'NS=sum(NS)' INFO: Adding variant info field DP with type INT INFO: Adding variant info field NS with type INT Updating variant: 100% [================================] 2,051 49.1K/s in 00:00:00 INFO: 2051 records are updated  Here DP=sum(DP) looks strange but the first DP is a new variant info and the second DP is the existing genotype info. Now, variant info field DP stands for total depth and NS stands for number of times a variant shows up in the samples.\n%vtools output variant chr pos ref alt DP NS -l 5 1 14677 G A 15 2 1 15820 G T 7 1 1 16103 T G 76 3 1 16378 T C 41 2 1 20129 C T 24 2  \nUsing customized or alternative fields to import genotypes The vcf format accepts a number of parameters to customize the way how genotypes are imported. For example, the --geno option accepts a genotype field. The default GT field import all genotypes assuming that GT is the first field in the genotype columns. However,\n You can use option --geno without value to specify an empty genotype field so that variant tools will not process any genotype. In vcf.fmt we import wild-type genotypes as numeric value 0. This is important for the purpose of association studies. If you are only interested in exploring variants of your sample, and you do not care to discriminate wild-type genotypes from missing genotype calls, you may set --wildtype_value None, which will leave out all wild-type genotypes, resulting in much quicker import and smaller database size. The GT field assumes that GT is the first field in the FORMAT column. However, some variant-calling software produce non-standard vcf files that do not follow this standard. In this case, an alternative field safe_GT can be used (e.g. --geno safe_GT) to import genotypes according to the location of GT in the FORMAT string.  Ignore genotypes of input vcf file\n% vtools init import -f % vtools import CEU_hg38.vcf --build hg38 --var_info AA AC AN DP --geno INFO: Importing variants from CEU_hg38.vcf (1/1) CEU_hg38.vcf: 100% [======================================] 306 13.1K/s in 00:00:00 INFO: 292 new variants (292 SNVs) from 306 lines are imported.  With this command, no genotype is imported\n% vtools show genotypes sample_name filename num_genotypes sample_genotype_fields  \nUsing a customized format file to import additional fields (This function is only supoorted when STOREMODE is set to sqlite.) If you have a field that you would like to import, but does not exist in vcf.fmt, you can add it to a customized format file and use this format file to import the data.\nExamples: Using a customized .fmt file to import additional fields For example, the CB genotype field is commonly used and is not defined in vcf.fmt, according to the meta information, this field is a string. You can then copy ~/.variant_tools/format/vcf.fmt as my_vcf.fmt and add\n[CB_geno] index=9, 10: adj=FieldFromFormat('CB', ':') type=VARCHAR(3) comment=Called by S(Sanger), M(UMich), B(BI)  at the end of this file, and import this field using\n% vtools init import -f % export STOREMODE=\u0026quot;sqlite\u0026quot; % vtools import CEU_hg38.vcf --format my_vcf.fmt --build hg38 --var_info AA AC AN DP --geno_info DP_geno CB_geno INFO: Importing variants from CEU.vcf.gz (1/1) CEU.vcf.gz: 100% [====================================================] 300 12.4K/s in 00:00:00 INFO: 288 new variants (288 SNVs) from 300 lines are imported. Importing genotypes: 100% [=========================================] 18,000 9.0K/s in 00:00:02 Copying genotype: 100% [==============================================] 60 484.0K/s in 00:00:00 % vtools show genotypes -l5 sample_name filename num_genotypes sample_genotype_fields NA06985 CEU.vcf.gz 287 GT,DP_geno,CB_geno NA06986 CEU.vcf.gz 287 GT,DP_geno,CB_geno NA06994 CEU.vcf.gz 287 GT,DP_geno,CB_geno NA07000 CEU.vcf.gz 287 GT,DP_geno,CB_geno NA07037 CEU.vcf.gz 287 GT,DP_geno,CB_geno (55 records omitted)  \n3. General usages and options Command vtools import imports variants, sample genotypes and related information fields from formats other than VCF as well. The imported variants are saved to the master variant table variant of the project, along with their information fields.\nVariant tools can import SNVs, Indels and complex variants with reference and alternative alleles explicitly listed in the source files. It cannot yet handle structural variants such as large indels listed in vcf file as \u0026lt;INS\u0026gt; or DUP:TANDEM\u0026gt;. For details about how different types of variants are imported into variant tools, please refer to here.\n It is sometimes useful to import only variants to a project. The variant info could be added later using command vtools update, or built into an annotation database to reduce the size of the project.\n 3.1 File formats and format specification files (.fmt) (option --format) vtools import can handle input file in many different formats (e.g. .vcf) and their gzipped or bzipped versions (e.g. .vcf.gz). variant tools relies on format specification files to describe a file format. These files (with extension .fmt) tell variant tools how to read from an input file. They are available online and will be downloaded automatically to the local resource directory of variant tools. Please refer to the variant tools input file format for a list of supported formats, or use command vtools show formats to get a list of formats, and vtools show format FMT for details of a format.\nA format specification file defines how to import variants (fields chr, pos, ref, and alt), variant info fields, genotypes, and genotype infor fields from input files. It basically tells command vtools import what fields are available from input file, from which column each field should be read, how to post-process input (e.g convert 0-based positions to 1-based), and how to store the data (data type).\nAlthough variants consists of chromosome, position, reference and alternative alleles, your input does not have to contain all such information. For example, using format rsname, variant tools can import variants from a list of dbSNP IDs.\n Examples: Show supported file formats and details of a format\nCommand vtools show formats lists all supported file formats with a short description.\n% vtools show formats INFO: Upgrading variant tools project to version 2.7.20 ANNOVAR Input format of ANNOVAR. No genotype is defined. ANNOVAR_exonic_variant_function Output from ANNOVAR for files of type *exonic_variant_function, generated from command \u0026quot;path/to/annovar/annotate_variation.pl annovar.txt path/to/annovar/humandb/\u0026quot;. This format imports chr, pos, ref, alt and ANNOVAR annotations. For details please refer to http://www.openbioinformatics.org/annovar/annovar_gene.html ANNOVAR_output Output from ANNOVAR, generated from command \u0026quot;path/to/annovar/annotate_variation.pl annovar.txt path/to/annovar/humandb/\u0026quot;. This format imports chr, pos, ref, alt and ANNOVAR annotations. For details please refer to http://www.openbioinformatics.org/annovar/annovar_gene.html ANNOVAR_variant_function Output from ANNOVAR for files of type \u0026quot;*.variant_function\u0026quot;, generated from command \u0026quot;path/to/annovar/annotate_variation.pl annovar.txt path/to/annovar/humandb/\u0026quot;. This format imports chr, pos, ref, alt and ANNOVAR annotations. For details please refer to http://www.openbioinformatics.org/annovar/annovar_gene.html CASAVA18_indels Input format illumina indels.txt file, created by CASAVA version 1.8 (http://www.illumina.com/support/documentation.ilmn). This format imports chr, pos, ref, alt of most likely genotype, and a Q score for the most likely genotype. CASAVA18_snps Input format illumina snps.txt file, created by CASAVA version 1.8 (http://www.illumina.com/support/documentation.ilmn). This format imports chr, pos, ref, alt of most likely genotype, and a Q score for the most likely genotype. CGA Input format from Complete Genomics Variant file masterVarBeta-[ASM-ID].tsv.bz2, created by Complete Genomcis Analysis Tools (GSA Tools 1.5 or eariler, http://www.completegenomics.com/sequence-data/cgatools/, http://media.completegenom ics.com/documents/DataFileFormats+Standard+Pipeline+2.0.pdf). This format imports chr, pos, ref, alt of only variants that have been fully called and are not equals to ref. (E.g. records with zygosity equal to no-call and half, and varType equal to ref are discarded.) basic A basic variant import/export format that import variants with four tab-delimited columns (chr, pos, ref, alt), and export variants, optional variant info fields and genotypes. csv Import variants (chr, pos, ref, alt) in csv format, or output arbitrary specified fields in csv format map This input format imports variants from files in MAP format (with columns chr, name gen_dist, pos), or any delimiter-separated format with columns chr and pos. Because these input files do not contain reference and alternative alleles of variants, this format queries such information from the dbSNP database using chr and pos. Records that does not exist in dbSNP will be discarded. Records with multiple alternative alleles will lead to multiple records. pileup_indel Input format for samtools pileup indel caller. This format imports chr, pos, ref, alt and genotype. plink Input format for PLINK dataset. Currently only PLINK binary PED file format is supported (*.bed, *.bim \u0026amp; *.fam) polyphen2 To be used to export variants in a format that is acceptable by the polyphen2 server http://genetics.bwh.harvard.edu/pph2/bgi.shtml, and to import the FULL report returned by this server. rsname Import variants (chr, pos, ref, alt) that are queried from dbSNP database using provided rsnames tped Output to TPED format with the first four columns chr name gen_pos pos, and the rest for genotypes. Variant tools cannot import from this format because it does not contain information about reference genome. twoalleles Import variants (chr, pos, ref, alt) from chr, pos, allele1, and allele2, using a reference genome to determine which one is reference vcf Import vcf  You can suppress descriptions to formats using option -v0 to command @@vtools show formats\n If you are interested in a particular format, you can\n% vtools show format basic A basic variant import/export format that import variants with four tab-delimited columns (chr, pos, ref, alt), and export variants, optional variant info fields and genotypes. Columns: 1 chromosome 2 variant position, set --pos_adj to -1 to export variants in 0-based positions. 3 reference allele 4 alternative allele 5 Output variant info fields as one column 6 genotype in numeric style Formatters are provided for fields: gt variant: chr Chromosome pos 1-based position, set --pos_adj to 1 if input position is 0 based. ref Reference allele, '-' for insertion. alt Alternative allele, '-' for deletion. Format parameters: chr_col Column index for the chromosome field (default: 1) pos_col Column index for the position field (default: 2) ref_col Column index for the reference field (default: 3) alt_col Column index for the alternative field (default: 4) pos_adj Set to 1 to import variants with 0-based positions, or to -1 to export variants in 0-based positions. (default: 0) fields Fields to output, simple arithmetics are allowed (e.g. pos+1) but aggregation functions are not supported. (default: )  From the description, we can that format basic import variants from a text file, with fields chr, pos, ref, and alt import from columns 1, 2, 3 and 4. The input columns could be adjust by format parameters chr_col, pos_col, ref_col, and alt_col. This format assumes a 1-based position. If the input data uses 0-based position, parameter pos_adj can be used to adjust input. \n\nIf your input file matches the description of a format, you can use this format to import data. The format should be specified by parameter --format, although this parameter could be ignored if file format can be detected automatically from file extension (e.g. format vcf will be used automatically for files with extension .vcf and .vcf.gz).\nExamples: Import variants using format basic File variants.txt has a list of variants as follows\n% head variants_hg38.txt 1 1014042 G A 1 1014143 C T 1 1014143 C T 1 1042136 T TC 1 1043288 G A 1 6469122 T TTCC 1 6473391 C T 2 272223 G A 2 1436380 A G 2 1542533 C CT  You can import variants using format basic as follows:\n% vtools import variants_hg38.txt --format basic --build hg38 INFO: Importing variants from variants_hg38.txt (1/1) variants_hg38.txt: 100% [=======================================================================================================================================================================] 14 1.4K/s in 00:00:00 INFO: 12 new variants (9 SNVs, 4 insertions, 1 unsupported) from 13 lines are imported. Importing genotypes: 0 0.0/s in 00:00:00  Copying samples: 0 0.0/s in 00:00:00\n% vtools output variant chr pos ref alt -l 10 1 1014042 G A 1 1014143 C T 1 1042137 - C 1 1043288 G A 1 6469123 - TCC 1 6473391 C T 2 272223 G A 2 1436380 A G 2 1542534 - T 10 6018115 G A  \nFormat parameters can be used to adjust how data are imported using a particular format. For example, fields chr, pos, ref, and alt are by default imported from columns 1, 2, 3 and 4 using format basic. The input columns could be adjust by format parameters chr_col, pos_col, ref_col, and alt_col. If the input data uses 0-based position, parameter pos_adj can be used to adjust input.\nUse format parameters to adjust how data are imported If the position used in variants.txt is zero-based (like all data downloaded from UCSC), you can use format parameter --pos_adj 1 to add 1 to import positions:\n% vtools init import -f % vtools import variants.txt --format basic --pos_adj 1 --build hg38 INFO: Importing variants from variants.txt (1/1) variants.txt: 100% [================================================================] 20 2.0K/s in 00:00:00 INFO: 20 new variants (17 SNVs, 1 insertions, 1 deletions, 1 complex variants) from 20 lines are imported. Importing genotypes: 0 0.0/s in 00:00:00 Copying samples: 0 0.0/s in 00:00:00 % vtools output variant chr pos ref alt -l 10 1 203148113 T - 1 203148169 G A 1 203148203 G C 1 203148225 G A 1 203148266 GG T 1 203148285 T C 1 203148295 G T 1 203148360 C A 1 203148361 G A 1 203148361 G C  \n3.2 Sample genotypes, sample names, and samples without genotype (option --sample_name) An input file can have genotype data for zero (e.g. a list of variants), one, or more than one samples (many .vcf files), and genotypes for a sample might be stored in more than one files, it can be confusing how samples are handled in variant tools.\n A list of variants without genotype is by default imported without creating a sample. The variants will be imported to the master variant table and there is no way to trace the origin of the variants if variants from multiple files are imported. A list of variants can be imported as a sample without genotype if a sample name is given. The variants will be imported to the master variant table. A sample will be created with these variants. You can use vtools select variant --samples CONDITION to locate variants belonging to this sample. One or more samples will be created for an input file with one or more samples. Variant tools will try to use sample names specified by parameter --sample_name, or names from header of input file. A NULL sample name will be used if no sample name could be determined.   Sample names could be changed using command vtools admin --rename_samples after they are imported. If genotypes for samples are stored in separate files (e.g. chromosome by chromosome), they will be imported as separate samples. If proper sample names are provided, samples with the same names (and belong to the same physical sample) could be merged using command vtools admin --merge_samples.    Examples: import a list variants and create a sample without genotype If there is no genotype in the input file, no sample is created by default. This is the case for the previous example where only variants are imported:\n% vtools show samples sample_name filename  However, if you would like to trace what variants have been imported from each input file, you can create a sample (without genotype information) by providing parameter --sample_name.\n% vtools init import -f % vtools import variants_hg38.txt --format basic --build hg38 --sample_name noGT INFO: Importing variants from variants_hg38.txt (1/1)  variants_hg38.txt: 100% [===============================] 14 1.5K/s in 00:00:00 INFO: 12 new variants (9 SNVs, 4 insertions, 1 unsupported) from 13 lines are imported. Importing genotypes: 100% [=============================] 13 6.5/s in 00:00:02 Copying samples: 100% [=================================] 2 8.6K/s in 00:00:00 Current storage mode is HDF5, transfrom genotype storage mode\u0026hellip;.. Creating indexes: 100% [================================] 1 638.2/s in 00:00:00 Selecting genotypes: 100% [=============================] 2 2.0/s in 00:00:01 Getting existing variants: 100% [=======================] 12 85.2K/s in 00:00:00\nThere is a sample called noGT,\n% vtools show samples sample_name filename noGT variants.txt  although this sample does not have any genotype fields:\n% vtools show genotypes sample_name filename num_genotypes sample_genotype_fields noGT variants.txt 20  \n3.3 Primary and alternative reference genomes (option --build) Sometimes you can different batches of data that use different reference genomes. For example, your project might involve multiple batches of data over the years and variants from the old and new batches are processed using different versions of pipelines with different reference genome. In addition, you might want to a previous collection of samples or some public dataset as controls to your project, but they might use a different reference genome than your project. variant tools allows you to import data in two reference genomes. All you need to do is to specify the correct build of reference genome for each batch of data using option --build.\nImport datasets in hg19 and hg38 Variants from CEU.vcf.gz uses build hg18 of the reference genome,\n% vtools init import -f % vtools import CEU_hg19.vcf --build hg19 INFO: Importing variants from CEU_hg19.vcf (1/1)  CEU_hg19.vcf: 100% [==================================] 309 17.8K/s in 00:00:00 INFO: 288 new variants (288 SNVs) from 309 lines are imported. Importing genotypes: 100% [===========================] 288 3.1K/s in 00:00:00\nData from variants.txt are in hg19, so we use option --build hg19 to import them,\n% vtools import variants_hg38.txt --format basic --build hg38 WARNING: The new files uses a different reference genome (hg38) from the primary reference genome (hg19) of the project. INFO: Adding an alternative reference genome (hg38) to the project. INFO: Downloading liftOver tool from UCSC liftOver: 100% [====================================] 3,383,268.0 1.3M/s in 00:00:02 INFO: Downloading liftOver chain file from UCSC hg19ToHg38.over.chain.gz: 100% [====================] 140,346.0 132.7K/s in 00:00:01 INFO: Exporting variants in BED format Exporting variants: 100% [=================================] 288 19.5K/s in 00:00:00 INFO: Running UCSC liftOver tool Updating table variant: 100% [==============================] 288 6.6K/s in 00:00:00 Getting existing variants: 100% [==========================] 288 97.4K/s in 00:00:00 INFO: Importing variants from variants_hg38.txt (1/1) variants_hg38.txt: 100% [===================================] 14 1.9K/s in 00:00:00 INFO: 12 new variants (9 SNVs, 4 insertions, 1 unsupported) from 13 lines are imported. WARNING: Sample information is not recorded for a file without genotype and sample name. Importing genotypes: 0 0.0/s in 00:00:00 Copying genotype: 0 0.0/s in 00:00:00 INFO: Mapping new variants at 12 loci from hg38 to hg19 reference genome INFO: Downloading liftOver chain file from UCSC hg38ToHg19.over.chain.gz: 100% [====================] 231,197.0 503.6K/s in 00:00:00 INFO: Running UCSC liftOver tool Updating coordinates: 100% [================================] 13 4.2K/s in 00:00:00  INFO: Coordinates of 12 (13 total, 0 failed to map) new variants are updated.\nWhen you execute the second command, variant tools will\n Liftover the existing project to hg38 using the UCSC liftover tool Get all coordinates from the hg19 input files and map them to hg38. Import the hg38 data files using mapped coordinates, while keeping their hg19 coordinates as alternative coordinates.  variants inputted in this way can be accessed using both reference genomes.\n% vtools output variant chr pos ref alt --build hg19 | tail -10 1 977517 - C 1 978668 G A 1 6529183 - TCC 1 6533451 C T 2 272223 G A 2 1440152 A G 2 1546306 - T 10 6060078 G A 10 6066273 G A 10 8116242 - AA % vtools output variant chr pos ref alt --build hg38 | tail -10 1 1042137 - C 1 1043288 G A 1 6469123 - TCC 1 6473391 C T 2 272223 G A 2 1436380 A G 2 1542534 - T 10 6018115 G A 10 6024310 G A 10 8074279 - AA  \nBecause the UCSC liftover tool does not guarantee all coordinates can be mapped between reference genomes, variants that cannot be mapped back to the primary reference genome will have missing primary coordinates. These variants (with missing primary coordinates) can only be retrieved and annotated through the alternative reference genome. Different variants in one reference genome might be mapped to the same variant in another (e.g. variant 90460203 and 91680930 in hg19 are both mapped to 91044656 in hg18). If two (or more) variants imported from the alternative reference genome are mapped to the same coordinates in the primary reference genome, duplicate entries will appear in the primary reference genome. If you have data in both reference genome (e.g. hg18, hg19), it is suggested that you use the more recent reference genome (e.g. hg19) as the primary reference genome, because latter reference genomes have more variants and less probability of coordinate collision.\n 3.4 Validate build of reference genome and variant positions If you are uncertain about the reference genome of your input data, or if the variant positions are 0- or 1-based, you can use command vtools admin --validate_build to compare reference alleles with the alleles at the corresponding locations on the reference genome. You will notice a large number of mismatch variants if you have used incorrect reference genome or failed to adjust positions of variants from 0-based positions to 1-based.\nExamples: validate if the correct reference genome has been specified\nLet us import variants from variants.txt using hg18,\n% vtools init import -f % vtools import variants_hg38.txt --format basic --build hg19 % vtools admin --validate_build Validate reference alleles: 100% [=======================] 12/3 10.3K/s in 00:00:00  INFO: 8 non-insertion variants are checked. 3 mismatch variants found.\n3 mismatchs are identified, so we let us try using the hg38 build of reference genome,\n% vtools init import -f % vtools import variants_hg38.txt --format basic --build hg38 % vtools admin --validate_build Validate reference alleles: 100% [========================] 12 9.4K/s in 00:00:00  INFO: 8 non-insertion variants are checked. 0 mismatch variants found.\nThe variants are more likely created using hg38. The mismatch variants can be found in the project log file, or be listed with option -v2. It should be verified or removed from the project. \n3.5 Performance optimization (option --jobs and other techniques) variant tools by default uses multiple processes to load data (--jobs 4), which works well for most datasets under most computing environments. Compared to importing data using a single process (--jobs 1), it performs slightly worse for small datasets, but is significantly faster for large files, especially when multiple files are imported. If you have high speed harddrive (e.g. disk array, SSD), you can use more processes to import data although more processes do not automatically translate to better performance due to the overhead of multi-processing and disk I/O scheduling.\nThe following discussion is useful if you set STOREMODE to sqlite. Depending on your computing environment (amount of RAM, speed of harddrive), vtools import could be optimized by setting appropriate runtime options that are compatible with your computer hardware environment. One optimization is to temporarily set an in-ram journal mode, and in-ram cache if the computer has large RAM:\n% vtools admin --set_runtime_option 'sqlite_pragma=synchronous=OFF,journal_mode=MEMORY,cachesize=10000'  The in-ram journal mode will lessen the disk I/O burden, but compromises the database\u0026rsquo;s failure recovery capability. It is therefore recommended to revert the setting after the import is done.\nAnother optimization is to move the temporary directory to a large, separate physical disk. By default the temporary directory locates in one of the system\u0026rsquo;s temporary folders (e.g., /tmp or /var/tmp for Linux). \u0026ldquo;\u0026lsquo;Moving $temp_dir to a different physical disk will greatly improve the performance of vtools import (and vtools associate) because of significantly less movement of reading head of harddrives.\n% vtools admin --set_runtime_option 'temp_dir=/home/HD1/tmp_some_random_name'  The folder\u0026rsquo;s name is arbitrary. It will be created each time a command starts and deleted upon completion of the command. It is very important to make sure that for import and associate commands there is sufficient disk space in the temporary directory, since potentially large temp files will be generated by these commands.\n After data import is finished, we will set journal_mode back to default, for reasons previously discussed.\n% vtools admin --reset_runtime_option sqlite_pragma  Finally, if you need to import a large amount of data from multiple files, it can be helpful to create multiple project, import files one by one (or group by group), and create a parent project from these children projects.\n[This tutorial][4] demonstrates how to import all genotype data from the 1000 genomes project using different techniques. It contains some tips on how to import a large amount of data (the uncompressed 1000 genome data exceed 1 Tb).\n "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/simulation/models/peng2/",
	"title": "Peng2014_ex2",
	"tags": [],
	"description": "",
	"content": " Second example in Peng (2014) Genetic Epidemiology Usage % vtools show simulation Peng2014_ex2 Simulation of case control samples for 20 genes and analyze samples of different sizes (1000, 2000, 3000, 4000 cases and matching number of controls) draw from European, Mexican American (mixed and matched case and control), and from both Asian (cases) and European (controls) populations for a mismatch design. This simulation model has been used to simulate data for the second example in paper \u0026quot;Reproducible Simulations of realistic samples for next-gen sequencing studies using Variant Simulation Tools\u0026quot;. The generated samples are analyzed using Variant Association Tools, first for all variants and then for non-synoymous variants. Available simulation models: European, MexicanAmerican, Mismatch Model \u0026quot;European\u0026quot;: This model draws cases and controls from simulated European population. European_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. European_1: Import required modules. European_10: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. European_30: Create an empty simuPOP population for specified regions. European_40: Evolve and expand the population using a K80 mutation model and a demographic model that models the settlement of new world model of the Mexican American population, without mixing the final populations. European_50: Get allele frequency spectrum in a sample of 700 individuals. European_100: Draw 1000 cases and 1000 controls from the European population. European_110: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. European_120: Export genotype and phenotype simulated samples in vcf and text formats, respectively. European_130: Import data into a variant tools project. European_140: Analyze the project using variant association tools. European_150: Call snpEff to annotate variants. European_160: Select non-synonymous variants according to snpEff annotation. European_170: Analyze the project using non-synonymous variants. European_200: Draw 2000 cases and 2000 controls from the European population. European_210: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. European_220: Export genotype and phenotype simulated samples in vcf and text formats, respectively. European_230: Import data into a variant tools project. European_240: Analyze the project using variant association tools. European_250: Call snpEff to annotate variants. European_260: Select non-synonymous variants according to snpEff annotation. European_270: Analyze the project using non-synonymous variants. European_300: Draw 3000 cases and 3000 controls from the European population. European_310: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. European_320: Export genotype and phenotype simulated samples in vcf and text formats, respectively. European_330: Import data into a variant tools project. European_340: Analyze the project using variant association tools. European_350: Call snpEff to annotate variants. European_360: Select non-synonymous variants according to snpEff annotation. European_370: Analyze the project using non-synonymous variants. European_400: Draw 4000 cases and 4000 controls from the European population. European_410: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. European_420: Export genotype and phenotype simulated samples in vcf and text formats, respectively. European_430: Import data into a variant tools project. European_440: Analyze the project using variant association tools. European_450: Call snpEff to annotate variants. European_460: Select non-synonymous variants according to snpEff annotation. European_470: Analyze the project using non-synonymous variants. Model \u0026quot;MexicanAmerican\u0026quot;: This model draws samples from Mexican American population which is mixed from Eurpean and Mexican populations. MexicanAmerican_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. MexicanAmerican_1: Import required modules. MexicanAmerican_10: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. MexicanAmerican_30: Create an empty simuPOP population for specified regions. MexicanAmerican_40: Evolve and expand the population using a K80 mutation model and a demographic model that models the settlement of new world model of the Mexican American population. MexicanAmerican_50: Get allele frequency spectrum in a sample of 700 individuals. MexicanAmerican_100:Draw 1000 cases and 1000 controls from the mixed Mexican American population. MexicanAmerican_110:Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. MexicanAmerican_120:Export genotype and phenotype simulated samples in vcf and text formats, respectively. MexicanAmerican_130:Import data into a variant tools project. MexicanAmerican_140:Analyze the project using variant association tools. MexicanAmerican_150:Call snpEff to annotate variants. MexicanAmerican_160:Select non-synonymous variants according to snpEff annotation. MexicanAmerican_170:Analyze the project using non-synonymous variants. MexicanAmerican_200:Draw 2000 cases and 2000 controls from the mixed Mexican American population. MexicanAmerican_210:Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. MexicanAmerican_220:Export genotype and phenotype simulated samples in vcf and text formats, respectively. MexicanAmerican_230:Import data into a variant tools project. MexicanAmerican_240:Analyze the project using variant association tools. MexicanAmerican_250:Call snpEff to annotate variants. MexicanAmerican_260:Select non-synonymous variants according to snpEff annotation. MexicanAmerican_270:Analyze the project using non-synonymous variants. MexicanAmerican_300:Draw 3000 cases and 3000 controls from the mixed Mexican American population. MexicanAmerican_310:Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. MexicanAmerican_320:Export genotype and phenotype simulated samples in vcf and text formats, respectively. MexicanAmerican_330:Import data into a variant tools project. MexicanAmerican_340:Analyze the project using variant association tools. MexicanAmerican_350:Call snpEff to annotate variants. MexicanAmerican_360:Select non-synonymous variants according to snpEff annotation. MexicanAmerican_370:Analyze the project using non-synonymous variants. MexicanAmerican_400:Draw 4000 cases and 4000 controls from the mixed Mexican American population. MexicanAmerican_410:Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. MexicanAmerican_420:Export genotype and phenotype simulated samples in vcf and text formats, respectively. MexicanAmerican_430:Import data into a variant tools project. MexicanAmerican_440:Analyze the project using variant association tools. MexicanAmerican_450:Call snpEff to annotate variants. MexicanAmerican_460:Select non-synonymous variants according to snpEff annotation. MexicanAmerican_470:Analyze the project using non-synonymous variants. Model \u0026quot;Mismatch\u0026quot;: This model draws cases from Asian population and controls from European population. Mismatch_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. Mismatch_1: Import required modules. Mismatch_10: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. Mismatch_30: Create an empty simuPOP population for specified regions. Mismatch_40: Evolve and expand the population using a K80 mutation model and a demographic model that models the settlement of new world model of the Mexican American population, without mixing the final populations. Mismatch_50: Get allele frequency spectrum in a sample of 700 individuals. Mismatch_100: Draw 1000 cases from the European population and 1000 controls from the Asian population. Mismatch_110: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. Mismatch_120: Export genotype and phenotype simulated samples in vcf and text formats, respectively. Mismatch_130: Import data into a variant tools project. Mismatch_140: Analyze the project using variant association tools. Mismatch_150: Call snpEff to annotate variants. Mismatch_160: Select non-synonymous variants according to snpEff annotation. Mismatch_170: Analyze the project using non-synonymous variants. Mismatch_200: Draw 2000 cases from the European population and 2000 controls from the Asian population. Mismatch_210: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. Mismatch_220: Export genotype and phenotype simulated samples in vcf and text formats, respectively. Mismatch_230: Import data into a variant tools project. Mismatch_240: Analyze the project using variant association tools. Mismatch_250: Call snpEff to annotate variants. Mismatch_260: Select non-synonymous variants according to snpEff annotation. Mismatch_270: Analyze the project using non-synonymous variants. Mismatch_300: Draw 3000 cases from the European population and 3000 controls from the Asian population. Mismatch_310: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. Mismatch_320: Export genotype and phenotype simulated samples in vcf and text formats, respectively. Mismatch_330: Import data into a variant tools project. Mismatch_340: Analyze the project using variant association tools. Mismatch_350: Call snpEff to annotate variants. Mismatch_360: Select non-synonymous variants according to snpEff annotation. Mismatch_370: Analyze the project using non-synonymous variants. Mismatch_400: Draw 4000 cases from the European population and 4000 controls from the Asian population. Mismatch_410: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. Mismatch_420: Export genotype and phenotype simulated samples in vcf and text formats, respectively. Mismatch_430: Import data into a variant tools project. Mismatch_440: Analyze the project using variant association tools. Mismatch_450: Call snpEff to annotate variants. Mismatch_460: Select non-synonymous variants according to snpEff annotation. Mismatch_470: Analyze the project using non-synonymous variants. Model parameters: regions One or more chromosome regions (separated by ',') in the format of chr :start-end (e.g. chr21:33031597-33041570), or Field:Value from a region- based annotation database (e.g. refGene.name2:TRIM2 or refGene_exon.name:NM_000947). Please visit http://varianttools.sourceforge.net/Simulation for detailed description of this parameter. (default: ccdsGene_exon.name:CCDS12419.1,CCDS46035.1,CCDS4 360.1,CCDS3581.1,CCDS10170.1,CCDS6264.1,CCDS1708.1,CCDS44408.1,CCDS7260.1, CCDS47427.1,CCDS47426.1,CCDS47425.1,CCDS4863.1,CCDS8524.1,CCDS3997.1,CCDS6 035.1,CCDS6036.1,CCDS14332.1,CCDS14331.1,CCDS11625.1) causing_genes A subset of regions from which a phenotype is simulated. (default: ccdsGene_exon.name:CCDS12419.1,CCDS46035.1,CCDS4360.1,CCDS3581.1,CCDS10170 .1) scale Scaling factor to speed up the simulation by scaling down the simulation while boosting mutation, selection and recombination rates. (default: 4)  Model This example simulates a miniature exome sequencing study with variants in the exon regions of 20 genes (isoforms) in the G Protein Coupled Receptors signaling pathway. These genes reside on chromosomes 6, 8, and 10 and chromosome X. The simulated regions overlap with 27 isoforms of 15 genes in the NCBI reference sequences database [Pruitt, et al. 2007]. The coding regions of these genes range from 563 to 1818 base pairs and represents 16.2% of the total simulated region (17,841 of 110,387 bp).\nThe demographic model starts with an ancestral population of 7,300 individuals and evolves for 100,000 generations, following a Settlement of New World model that models the evolution of Africa, Asian, Mexican, and European populations and the formation of the Mexican American population [Gutenkunst, et al. 2009]. The evolutionary process was subject to the influence of a K80 nucleotide mutation model [Kimura 1980] with a mutation rate of 1.8 × 10–8 and a transition transversion ratio of 2, a fine-scale recombination with hotspot model with average recombination rate (per region) ranging from 6.14 × 10–9 to 6.23 × 10–6, and a natural selection model with selection coefficients of 0.0001, 0.0001, and 0.001 for missense, stoploss, and stopgain mutations, respectively. Part of the evolutionary process (80,000 of the 91,200 generation burn-in stage) was shared among replicate simulations by starting the simulations from a saved population. A scaling factor of 4 was used to speed up the simulations.\nA genetic disease caused by non-synonymous mutations in four of the 15 simulated genes is simulated. Under this penetrance model, an individual who carries a missense, stoploss, and stopgain mutation has probabilities of 0.001, 0.001, and 0.01, respectively, to be affected. Individuals will have higher probabilities to be affected if they carry more than one mutation (a multiplicative model is used) and a probability of 0.0001 if they carry no non-synonymous mutation. We drew 1000 and 2000 cases and matching numbers of controls from the simulated populations of size 151,521 using three models. The first model drew cases and controls from the same European population; the second model drew cases and controls from the Mexican American population, which is admixed from the Mexican and European populations; and the third model drew cases from the Asian population and controls from the European population. We applied a burden test proposed by Morris and Zeggini [2010] to each of the simulated datasets, first to all variants, then to only non-synonymous, stopgain, and stoploss variants identified by snpEff [Cingolani, et al. 2012]. Five genes were excluded from the latter analysis because of small numbers of non-synonymous mutations in these genes.\nResults Attach:fig2.png\nAttach:fig2a.png\nThe following figures plot the box-and-whisker plots of negative log10 p-values for association analyses between disease status and all variants (figure a) or all non-synonymous mutations (Figure b) using 1000 (bottom) or 2000 (top) cases and matching numbers of controls. In contrast to the European and Mexican American simulations, which had reasonable false-positive rates (approximately 5% for significance level 0.05) for non-causing genes, analyses of the mismatch simulations yielded high proportions of spurious associations between all genes and disease status. This signifies the importance of using ethnicity-matched samples for case-control association analysis and the danger of using public controls (e.g., data from the 1000 Genomes Project) for association analysis. Because the disease is caused by non-synonymous mutations in the causal genes, limiting association tests to such variants is predictably more powerful than tests based on all variants. It is interesting, however, that association tests using an admixed population are more powerful than tests using all European samples. The reasons behind this phenomenon require further investigation of the distribution of causal variants in the simulated populations.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/simulation/models/peng2/",
	"title": "Peng2014_ex2",
	"tags": [],
	"description": "",
	"content": " Second example in Peng (2014) Genetic Epidemiology 1. Usage % vtools show simulation Peng2014_ex2 Simulation of case control samples for 20 genes and analyze samples of different sizes (1000, 2000, 3000, 4000 cases and matching number of controls) draw from European, Mexican American (mixed and matched case and control), and from both Asian (cases) and European (controls) populations for a mismatch design. This simulation model has been used to simulate data for the second example in paper \u0026quot;Reproducible Simulations of realistic samples for next-gen sequencing studies using Variant Simulation Tools\u0026quot;. The generated samples are analyzed using Variant Association Tools, first for all variants and then for non-synoymous variants. Available simulation models: European, MexicanAmerican, Mismatch Model \u0026quot;European\u0026quot;: This model draws cases and controls from simulated European population. European_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. European_1: Import required modules. European_10: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. European_30: Create an empty simuPOP population for specified regions. European_40: Evolve and expand the population using a K80 mutation model and a demographic model that models the settlement of new world model of the Mexican American population, without mixing the final populations. European_50: Get allele frequency spectrum in a sample of 700 individuals. European_100: Draw 1000 cases and 1000 controls from the European population. European_110: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. European_120: Export genotype and phenotype simulated samples in vcf and text formats, respectively. European_130: Import data into a variant tools project. European_140: Analyze the project using variant association tools. European_150: Call snpEff to annotate variants. European_160: Select non-synonymous variants according to snpEff annotation. European_170: Analyze the project using non-synonymous variants. European_200: Draw 2000 cases and 2000 controls from the European population. European_210: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. European_220: Export genotype and phenotype simulated samples in vcf and text formats, respectively. European_230: Import data into a variant tools project. European_240: Analyze the project using variant association tools. European_250: Call snpEff to annotate variants. European_260: Select non-synonymous variants according to snpEff annotation. European_270: Analyze the project using non-synonymous variants. European_300: Draw 3000 cases and 3000 controls from the European population. European_310: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. European_320: Export genotype and phenotype simulated samples in vcf and text formats, respectively. European_330: Import data into a variant tools project. European_340: Analyze the project using variant association tools. European_350: Call snpEff to annotate variants. European_360: Select non-synonymous variants according to snpEff annotation. European_370: Analyze the project using non-synonymous variants. European_400: Draw 4000 cases and 4000 controls from the European population. European_410: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. European_420: Export genotype and phenotype simulated samples in vcf and text formats, respectively. European_430: Import data into a variant tools project. European_440: Analyze the project using variant association tools. European_450: Call snpEff to annotate variants. European_460: Select non-synonymous variants according to snpEff annotation. European_470: Analyze the project using non-synonymous variants. Model \u0026quot;MexicanAmerican\u0026quot;: This model draws samples from Mexican American population which is mixed from Eurpean and Mexican populations. MexicanAmerican_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. MexicanAmerican_1: Import required modules. MexicanAmerican_10: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. MexicanAmerican_30: Create an empty simuPOP population for specified regions. MexicanAmerican_40: Evolve and expand the population using a K80 mutation model and a demographic model that models the settlement of new world model of the Mexican American population. MexicanAmerican_50: Get allele frequency spectrum in a sample of 700 individuals. MexicanAmerican_100:Draw 1000 cases and 1000 controls from the mixed Mexican American population. MexicanAmerican_110:Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. MexicanAmerican_120:Export genotype and phenotype simulated samples in vcf and text formats, respectively. MexicanAmerican_130:Import data into a variant tools project. MexicanAmerican_140:Analyze the project using variant association tools. MexicanAmerican_150:Call snpEff to annotate variants. MexicanAmerican_160:Select non-synonymous variants according to snpEff annotation. MexicanAmerican_170:Analyze the project using non-synonymous variants. MexicanAmerican_200:Draw 2000 cases and 2000 controls from the mixed Mexican American population. MexicanAmerican_210:Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. MexicanAmerican_220:Export genotype and phenotype simulated samples in vcf and text formats, respectively. MexicanAmerican_230:Import data into a variant tools project. MexicanAmerican_240:Analyze the project using variant association tools. MexicanAmerican_250:Call snpEff to annotate variants. MexicanAmerican_260:Select non-synonymous variants according to snpEff annotation. MexicanAmerican_270:Analyze the project using non-synonymous variants. MexicanAmerican_300:Draw 3000 cases and 3000 controls from the mixed Mexican American population. MexicanAmerican_310:Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. MexicanAmerican_320:Export genotype and phenotype simulated samples in vcf and text formats, respectively. MexicanAmerican_330:Import data into a variant tools project. MexicanAmerican_340:Analyze the project using variant association tools. MexicanAmerican_350:Call snpEff to annotate variants. MexicanAmerican_360:Select non-synonymous variants according to snpEff annotation. MexicanAmerican_370:Analyze the project using non-synonymous variants. MexicanAmerican_400:Draw 4000 cases and 4000 controls from the mixed Mexican American population. MexicanAmerican_410:Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. MexicanAmerican_420:Export genotype and phenotype simulated samples in vcf and text formats, respectively. MexicanAmerican_430:Import data into a variant tools project. MexicanAmerican_440:Analyze the project using variant association tools. MexicanAmerican_450:Call snpEff to annotate variants. MexicanAmerican_460:Select non-synonymous variants according to snpEff annotation. MexicanAmerican_470:Analyze the project using non-synonymous variants. Model \u0026quot;Mismatch\u0026quot;: This model draws cases from Asian population and controls from European population. Mismatch_0: Check the version of variant tools. Version 2.3.1 or higher is required for the execution of this simulation. Mismatch_1: Import required modules. Mismatch_10: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. Mismatch_30: Create an empty simuPOP population for specified regions. Mismatch_40: Evolve and expand the population using a K80 mutation model and a demographic model that models the settlement of new world model of the Mexican American population, without mixing the final populations. Mismatch_50: Get allele frequency spectrum in a sample of 700 individuals. Mismatch_100: Draw 1000 cases from the European population and 1000 controls from the Asian population. Mismatch_110: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. Mismatch_120: Export genotype and phenotype simulated samples in vcf and text formats, respectively. Mismatch_130: Import data into a variant tools project. Mismatch_140: Analyze the project using variant association tools. Mismatch_150: Call snpEff to annotate variants. Mismatch_160: Select non-synonymous variants according to snpEff annotation. Mismatch_170: Analyze the project using non-synonymous variants. Mismatch_200: Draw 2000 cases from the European population and 2000 controls from the Asian population. Mismatch_210: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. Mismatch_220: Export genotype and phenotype simulated samples in vcf and text formats, respectively. Mismatch_230: Import data into a variant tools project. Mismatch_240: Analyze the project using variant association tools. Mismatch_250: Call snpEff to annotate variants. Mismatch_260: Select non-synonymous variants according to snpEff annotation. Mismatch_270: Analyze the project using non-synonymous variants. Mismatch_300: Draw 3000 cases from the European population and 3000 controls from the Asian population. Mismatch_310: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. Mismatch_320: Export genotype and phenotype simulated samples in vcf and text formats, respectively. Mismatch_330: Import data into a variant tools project. Mismatch_340: Analyze the project using variant association tools. Mismatch_350: Call snpEff to annotate variants. Mismatch_360: Select non-synonymous variants according to snpEff annotation. Mismatch_370: Analyze the project using non-synonymous variants. Mismatch_400: Draw 4000 cases from the European population and 4000 controls from the Asian population. Mismatch_410: Create a new project Peng2014_ex2 and link the refGene and ccdsGene_exon databases to the project. Mismatch_420: Export genotype and phenotype simulated samples in vcf and text formats, respectively. Mismatch_430: Import data into a variant tools project. Mismatch_440: Analyze the project using variant association tools. Mismatch_450: Call snpEff to annotate variants. Mismatch_460: Select non-synonymous variants according to snpEff annotation. Mismatch_470: Analyze the project using non-synonymous variants. Model parameters: regions One or more chromosome regions (separated by ',') in the format of chr :start-end (e.g. chr21:33031597-33041570), or Field:Value from a region- based annotation database (e.g. refGene.name2:TRIM2 or refGene_exon.name:NM_000947). Please visit http://varianttools.sourceforge.net/Simulation for detailed description of this parameter. (default: ccdsGene_exon.name:CCDS12419.1,CCDS46035.1,CCDS4 360.1,CCDS3581.1,CCDS10170.1,CCDS6264.1,CCDS1708.1,CCDS44408.1,CCDS7260.1, CCDS47427.1,CCDS47426.1,CCDS47425.1,CCDS4863.1,CCDS8524.1,CCDS3997.1,CCDS6 035.1,CCDS6036.1,CCDS14332.1,CCDS14331.1,CCDS11625.1) causing_genes A subset of regions from which a phenotype is simulated. (default: ccdsGene_exon.name:CCDS12419.1,CCDS46035.1,CCDS4360.1,CCDS3581.1,CCDS10170 .1) scale Scaling factor to speed up the simulation by scaling down the simulation while boosting mutation, selection and recombination rates. (default: 4)  2. Model This example simulates a miniature exome sequencing study with variants in the exon regions of 20 genes (isoforms) in the G Protein Coupled Receptors signaling pathway. These genes reside on chromosomes 6, 8, and 10 and chromosome X. The simulated regions overlap with 27 isoforms of 15 genes in the NCBI reference sequences database [Pruitt, et al. 2007]. The coding regions of these genes range from 563 to 1818 base pairs and represents 16.2% of the total simulated region (17,841 of 110,387 bp).\nThe demographic model starts with an ancestral population of 7,300 individuals and evolves for 100,000 generations, following a Settlement of New World model that models the evolution of Africa, Asian, Mexican, and European populations and the formation of the Mexican American population [Gutenkunst, et al. 2009]. The evolutionary process was subject to the influence of a K80 nucleotide mutation model [Kimura 1980] with a mutation rate of 1.8 × 10–8 and a transition transversion ratio of 2, a fine-scale recombination with hotspot model with average recombination rate (per region) ranging from 6.14 × 10–9 to 6.23 × 10–6, and a natural selection model with selection coefficients of 0.0001, 0.0001, and 0.001 for missense, stoploss, and stopgain mutations, respectively. Part of the evolutionary process (80,000 of the 91,200 generation burn-in stage) was shared among replicate simulations by starting the simulations from a saved population. A scaling factor of 4 was used to speed up the simulations.\nA genetic disease caused by non-synonymous mutations in four of the 15 simulated genes is simulated. Under this penetrance model, an individual who carries a missense, stoploss, and stopgain mutation has probabilities of 0.001, 0.001, and 0.01, respectively, to be affected. Individuals will have higher probabilities to be affected if they carry more than one mutation (a multiplicative model is used) and a probability of 0.0001 if they carry no non-synonymous mutation. We drew 1000 and 2000 cases and matching numbers of controls from the simulated populations of size 151,521 using three models. The first model drew cases and controls from the same European population; the second model drew cases and controls from the Mexican American population, which is admixed from the Mexican and European populations; and the third model drew cases from the Asian population and controls from the European population. We applied a burden test proposed by Morris and Zeggini [2010] to each of the simulated datasets, first to all variants, then to only non-synonymous, stopgain, and stoploss variants identified by snpEff [Cingolani, et al. 2012]. Five genes were excluded from the latter analysis because of small numbers of non-synonymous mutations in these genes.\n3. Results The following figures plot the box-and-whisker plots of negative log10 p-values for association analyses between disease status and all variants (figure a) or all non-synonymous mutations (Figure b) using 1000 (bottom) or 2000 (top) cases and matching numbers of controls. In contrast to the European and Mexican American simulations, which had reasonable false-positive rates (approximately 5% for significance level 0.05) for non-causing genes, analyses of the mismatch simulations yielded high proportions of spurious associations between all genes and disease status. This signifies the importance of using ethnicity-matched samples for case-control association analysis and the danger of using public controls (e.g., data from the 1000 Genomes Project) for association analysis. Because the disease is caused by non-synonymous mutations in the causal genes, limiting association tests to such variants is predictably more powerful than tests based on all variants. It is interesting, however, that association tests using an admixed population are more powerful than tests using all European samples. The reasons behind this phenomenon require further investigation of the distribution of causal variants in the simulated populations.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/regions/phast_cons/",
	"title": "PhastCons",
	"tags": [],
	"description": "",
	"content": " The phastCons database annotates blocks of the genome with conservation scores using the phastCons algorithm (http://compgen.bscb.cornell.edu/phast/help-pages/phastCons.txt). The data that we are using was downloaded from the UCSC genome browser\u0026rsquo;s phastCons46way track that contains conservation data for vertebrates.\nPhastConsElements represents the most conserved regions so it covers a significantly percent of genome than the PhastCons database.\nPhastConsElements vtools show annotation PhastConsElements Description: PhastCons Conservation Scores Database type: range Number of records: 5,163,775 Distinct ranges: 5,163,775 Reference genome hg19: chr, start, end Field: chr Type: string Missing entries: 0 Unique Entries: 88 Field: start Type: integer Comment: Start position in chromosome Missing entries: 0 Unique Entries: 5,093,542 Range: 1 - 249231389 Field: end Type: integer Comment: End position in chromosome Missing entries: 0 Unique Entries: 5,093,841 Range: 12 - 249231641 Field: name Type: string Comment: Name of conserved region Missing entries: 0 Unique Entries: 4,358 Field: score Type: integer Comment: Phast cons score from 0 to 1000 Missing entries: 0 Unique Entries: 580 Range: 177 - 1000  phastCons The following example shows how you can use phastCons to annotate your variants with the average conservation score for the genomic block containing your variant. phastCons.sum_data/phastCons.count would give you this average score - see below to interpret these fields. This value could then be used to rank or filter your variants baed on the conservation score.\nvtools output variant chr pos ref alt phastCons.sum_data/phastCons.count -l 10 1 10434 - C NA 1 10440 C - NA 1 54789 C - 0.0587041015625 1 54790 - T 0.0587041015625 1 63738 ACT - 0.330704101563 1 63738 ACT CTA 0.330704101563 1 81963 - AA 0.161579101562 1 82134 A - 0.161579101562 1 82135 - AAAAAAAAAAAAAA 0.161579101562 1 83120 A - 0.136174804688  Below is a description of the phastCons fields.\nvtools show annotation phastCons Annotation database phastCons (version hg19_20110909) Description: PhastCons Conservation Scores Database type: range Number of records: 2,808,750 Number of distinct ranges: 2,808,750 Reference genome hg19: ['chr', 'start', 'end'] Field: chr Type: string Missing entries: 0 Unique entries: 92 Field: start Type: integer Comment: Start position in chromosome Missing entries: 0 Unique entries: 2,785,871 Range: 1 - 249236922 Field: end Type: integer Comment: End position in chromosome Missing entries: 0 Unique entries: 2,785,911 Range: 148 - 249237548 Field: name Type: string Comment: Name of conserved region Missing entries: 0 Unique entries: 2,808,750 Field: count Type: integer Comment: Number of values in this block Missing entries: 0 Unique entries: 1,024 Range: 1 - 1024 Field: valid_count Type: integer Comment: Number of valid values in this block Missing entries: 0 Unique entries: 1,024 Range: 1 - 1024 Field: lower_limit Type: string Comment: Lowest value in this block Missing entries: 0 Unique entries: 694 Field: data_range Type: string Comment: Spread of values in this block. lower_limit + data_range = upper_limit Missing entries: 0 Unique entries: 1,001 Field: sum_data Type: string Comment: Sum of values in this block (can be used for calculate average and stddev of conservation scores) Missing entries: 0 Unique entries: 417,533 Field: sum_squares Type: string Comment: Sum of values squared in this block (can be used for calculating stddev of conservation scores) Missing entries: 0 Unique entries: 1,501,657  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/tutorial/",
	"title": "Tutorial",
	"tags": [],
	"description": "",
	"content": " Annotating variants using multiple annotation databases, a tutorial Getting annotation databases This tutorial demonstrates how to use various databases to annotate variants in a variant tools project. These databases will be automatically downloaded and saved in directory ~/.variant_tools when they are used in a project. The amount of time required to download these databases depends on the speed of your internet connection, server load, and size of the databases. If you do no want to wait for the downloads and if you have enough disk space, you can download all variant tools resources into your local resource directory using the following commands:\n% wget --mirror http://vtools.houstonbioinformatics.org % rm -rf ~/.variant_tools # remove existing directory if exists % mv vtools.houstonbioinformatics.org ~/.variant_tools  The amount of data to download is 29G as of October 2012, and is expected to grow over time. The --mirror option allows command wget to get all files recursively, skipping files that exist locally.\nDownload a snapshot project with some variants Let us create a project and download a snapshot project called vt_quickStartGuide.\n% vtools init anno INFO: variant tools 2.0.0 : Copyright (c) 2011 - 2012 Bo Peng INFO: San Lucas FA, Wang G, Scheet P, Peng B (2012) Bioinformatics 28(3):421-422 INFO: Please visit http://varianttools.sourceforge.net for more information. INFO: Creating a new project anno % vtools admin --load_snapshot vt_quickStartGuide Downloading snapshot vt_quickStartGuide.tar.gz from online INFO: Snapshot vt_quickStartGuide has been loaded  This project has variants from CEU and JPT populations of the 1000 genomes pilot study. As we can see from the following commands, it has 4,858 variants from two samples:\n% vtools show samples sample_name filename CEU CEU.exon...3.sites.vcf.gz JPT JPT.exon...3.sites.vcf.gz % vtools show tables table #variants date message variant 4,858  Annotating variants Listing available annotation databases These are available annotation databases (as of October 2012) that can be downloaded and used automatically to annotate variants within a variant tools project. You can use the following command to list currently available databases.\n% vtools show annotations CancerGeneCensus-20111215 CancerGeneCensus ccdsGene-hg19_20110909 ccdsGene-hg19_20111206 ccdsGene ccdsGene_exon-hg19_20110909 ccdsGene_exon-hg19_20111206 ccdsGene_exon dbNSFP-hg18_hg19_1.1_2 dbNSFP dbNSFP_light-hg18_hg19_1.0_0 dbNSFP_light dbSNP-hg18_129 dbSNP-hg18_130 dbSNP-hg19_131 dbSNP-hg19_132 dbSNP evs-hg19_20111107 evs evs_5400 keggPathway-20110823 keggPathway knownGene-hg18_20110909 knownGene-hg19_20110909 knownGene knownGene_exon-hg18_20110909 knownGene_exon-hg19_20110909 knownGene_exon phastCons-hg19_20110909 phastCons refGene-hg18_20110909 refGene-hg19_20110909 refGene refGene_exon-hg18_20110909 refGene_exon-hg19_20110909 refGene_exon thousandGenomes-hg19_20110909 thousandGenomes  How do I add an annotation database to my project? To add a gene-based annotation source such as ccdsGene to your project, the following command will accomplish this. If you haven\u0026rsquo;t already downloaded this annotation database with this or another project, vtools will automatically download the database and associate ccdsGene annotations to your project.\n% vtools use ccdsGene  What genes do my variants belong to? There are several annotation sources that could be used to annotate your variants to gene transcripts. Some examples include refGene, knownGene and ccdsGene. To get more details of these databases use vtools show annotation ccdsGene -v2 (or a similar command with refGene or knownGene) as described previously. This command downloads the ccdsGene data source allowing variants to be annotated to transcripts.\nWhat about the exon? Gene-based annotation sources such as ccdsGene, refGene and knownGene have corresponding annotation sources that are exon-based: ccdsGene_exon, refGene_exon and knownGene_exon respectively (provided indirectly through the UCSC Genome Browser database). These exon-based annotation sources contain exon start and end coordinates that are used in lieu of gene start and end coordinates for linking the annotations to your variants.\n% vtools use ccdsGene_exon  What pathways do my variants belong to? This command downloads the keggPathway annotation source allowing variants to be annotated to KEGG pathways indirectly through transcript annotations (provided by the ccdsGene annotation source).\n% vtools use keggPathway --linked_by ccdsGene.name INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/keggPathway.ann INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/keggPathway-20110823.DB.gz : Unsupported scheme. --18:54:24-- http://vtools.houstonbioinformatics.org/annoDB/keggPathway-20110823.DB.gz =\u0026gt; `./keggPathway-20110823.DB.gz' Resolving vtools.houstonbioinformatics.org... 70.39.145.13 Connecting to vtools.houstonbioinformatics.org[70.39.145.13]:80... connected. HTTP request sent, awaiting response... 200 OK Length: 350,847 [application/x-gzip] 100%[=============================================================================\u0026gt;] 350,847 330.94K/s 18:54:26 (329.78 KB/s) - `./keggPathway-20110823.DB.gz' saved [350847/350847] FINISHED --18:54:26-- Downloaded: 350,847 bytes in 1 files INFO: Using annotation DB keggPathway in project quickstart. INFO: kegg pathway for CCDS genes  Now lets filter all of our variants to include only those involved in metabolic pathways. This command uses the pathway annotation source that we just downloaded to find all variants that are on transcripts of proteins known to be involved in metabolic pathways. These variants are then stored in a table called metabolic.\n% vtools select variant 'kgDesc=\u0026quot;Metabolic pathways\u0026quot;' -t metabolic Running: 2,788 2.1K/s in 00:00:01 INFO: 109 variants selected.  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/",
	"title": "Tutorials",
	"tags": [],
	"description": "",
	"content": " Tutorials These tutorials explain steps that are used to analyze real-world sequencing data. We will try to explain the steps in detail but command output are usually ignored for brevity and confidentiality reasons.\n1. Quick Start Guide This is a 10-minute quick start guide using data from the 1000 genomes project. We encourage you to walk through this minimal real-world example to get a feel for the software and assess its helpfulness. \n2. Presentations  Variant Tools Variant Simulation Tools Variant Pipeline Tools  3. Introductory tutorials  A recent presentation about variant tools, with output of commands  A tutorial session in the ACM BCB 2014 meeting   4. Variants screening  Analyzing 44 whole genome cases and 200 exome controls, with detailed performance measures  Analyzing 5 whole-genome samples from Illumina  Compare variants from the same samples called by Complete Genomics and Illumina  Select variants belonging to specified genes  Detailed analysis of one variant   5. Import and export  Import all genotype data from the 1000 genomes project  Generate and import annovar annotations for variants already in vtools  Import variants from a list of variants in an unsupported format  Handling genotypes imported from multiple files (e.g. genotypes of samples are imported chromosome by chromosome)   6. Reference genomes and annotation databases  Working with mouse and other genomes   7. Annotation  Annotating variants using multiple annotation databases   8. Association analysis  Quality control using sequencing data  Association analysis using sequencing data   Parallelization  Use subprojects to manage large projects. This strategy can be used to parallelize variant processing using multiple processors or a cluster   "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/joint_conditional/aggregation-methods/",
	"title": "aggregation methods",
	"tags": [],
	"description": "",
	"content": " Aggregation Methods for Disease and Quantitative Traits Introduction This is implementation of the fixed threshold aggregation methods for disease and quantitative traits. Originally described in Morris and Zeggni 2010[^Andrew P. Morris and Eleftheria Zeggini (2010) An evaluation of statistical approaches to rare variant analysis in genetic association studies. Genetic Epidemiology doi:10.1002/gepi.20450. http://doi.wiley.com/10.1002/gepi.20450^] and known as Gene- or Region-based Analysis of Variants of Intermediate and Low frequency (GRANVIL), the Aggregation method for rare variants codes observed genotype of a genetic region the count of minor alleles: {$$X = \\sum_i^N X_i$$}\nOur program implements the aggregation methods in a logistic regression framework for disease traits analysis (case control data) as BurdenBt method, and a linear regression framework for quantitative traits analysis as BurdenQt method. {$p$} value for aggregation method is based on asymptotic normal distribution of the Wald statistic in generalized linear models. One could incorporate a number of phenotype covariates in collapsing tests and evaluate the significance of the genetics component.\nAdjust for missing genotypes The same --NA_adjust option is avaliable as with collapsing methods? although they slightly differ in details, as described in Auer et al 2013[^personal communication with Paul L. Auer at Fred Hutchinson Cancer Research Center^].\nDetails Command interface vtools show test BurdenBt Name: BurdenBt Description: Burden test for disease traits, Morris \u0026amp; Zeggini 2009 usage: vtools associate --method BurdenBt [-h] [--name NAME] [--mafupper MAFUPPER] [--alternative TAILED] [--NA_adjust] [--moi {additive,dominant,recessive}] Fixed threshold burden test for disease traits (Morris \u0026amp; Zeggini 2009). p-value is based on the significance level of the regression coefficient for genotypes. If --group_by option is specified, the group of variants will be coded using the counts of variants within the group. optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 0.01 --alternative TAILED Alternative hypothesis is one-sided (\u0026quot;1\u0026quot;) or two-sided (\u0026quot;2\u0026quot;). Default set to 1 --NA_adjust This option, if evoked, will replace missing genotype values with a score relative to sample allele frequencies. The association test will be adjusted to incorporate the information. This is an effective approach to control for type I error due to differential degrees of missing genotypes among samples. --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive model. Default set to additive vtools show test BurdenQt Name: BurdenQt Description: Burden test for quantitative traits, Morris \u0026amp; Zeggini 2009 usage: vtools associate --method BurdenQt [-h] [--name NAME] [--mafupper MAFUPPER] [--alternative TAILED] [--NA_adjust] [--moi {additive,dominant,recessive}] Fixed threshold burden test for quantitative traits (Morris \u0026amp; Zeggini 2009). p-value is based on the significance level of the regression coefficient for genotypes. If --group_by option is specified, the group of variants will be coded using the counts of variants within the group. optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 0.01 --alternative TAILED Alternative hypothesis is one-sided (\u0026quot;1\u0026quot;) or two-sided (\u0026quot;2\u0026quot;). Default set to 1 --NA_adjust This option, if evoked, will replace missing genotype values with a score relative to sample allele frequencies. The association test will be adjusted to incorporate the information. This is an effective approach to control for type I error due to differential degrees of missing genotypes among samples. --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive model. Default set to additive  Application  Example using snapshot vt_ExomeAssociation\nvtools associate rare status --covariates gender age bmi exposure -m \u0026quot;BurdenBt --name Burde\\ nBt --alternative 2\u0026quot; --group_by name2 --to_db burdenBt -j8 \u0026gt; burdenBt.txt INFO: 3180 samples are found INFO: 2632 groups are found INFO: Starting 8 processes to load genotypes Loading genotypes: 100% [========================================] 3,180 33.0/s in 00:01:36 Testing for association: 100% [=========================================] 2,632/147 25.3/s in 00:01:43 INFO: Association tests on 2632 groups have completed. 147 failed. INFO: Using annotation DB burdenBt in project test. INFO: Annotation database used to record results of association tests. Created on Wed, 30 Jan 2013 17:39:05 vtools show fields | grep burdenBt burdenBt.name2 name2 burdenBt.sample_size_BurdenBt sample size burdenBt.num_variants_BurdenBt number of variants in each group (adjusted for specified MAF burdenBt.total_mac_BurdenBt total minor allele counts in a group (adjusted for MOI) burdenBt.beta_x_BurdenBt test statistic. In the context of regression this is estimate of burdenBt.pvalue_BurdenBt p-value burdenBt.wald_x_BurdenBt Wald statistic for x (beta_x/SE(beta_x)) burdenBt.beta_2_BurdenBt estimate of beta for covariate 2 burdenBt.beta_2_pvalue_BurdenBt p-value for covariate 2 burdenBt.wald_2_BurdenBt Wald statistic for covariate 2 burdenBt.beta_3_BurdenBt estimate of beta for covariate 3 burdenBt.beta_3_pvalue_BurdenBt p-value for covariate 3 burdenBt.wald_3_BurdenBt Wald statistic for covariate 3 burdenBt.beta_4_BurdenBt estimate of beta for covariate 4 burdenBt.beta_4_pvalue_BurdenBt p-value for covariate 4 burdenBt.wald_4_BurdenBt Wald statistic for covariate 4 burdenBt.beta_5_BurdenBt estimate of beta for covariate 5 burdenBt.beta_5_pvalue_BurdenBt p-value for covariate 5 burdenBt.wald_5_BurdenBt Wald statistic for covariate 5 head burdenBt.txt name2 sample_size_BurdenBt num_variants_BurdenBt total_mac_BurdenBt beta_x_BurdenBt pvalue_BurdenBt wald_x_BurdenBt beta_2_BurdenBt beta_2_pvalue_BurdenBt wald_2_BurdenBt beta_3_BurdenBt beta_3_pvalue_BurdenBt wald_3_BurdenBt beta_4_BurdenBt beta_4_pvalue_BurdenBt wald_4_BurdenBt beta_5_BurdenBt beta_5_pvalue_BurdenBt wald_5_BurdenBt AADACL4 3180 5 138 -0.314582 0.321174 -0.992049 -0.295836 0.0157002 -2.41581 0.031285 4.33616E-09 5.87083 0.129902 1.92805E-40 13.3137 0.437291 0.00133887 3.20752 AAMP 3180 3 35 0.00135633 0.997852 0.0026919 -0.298944 0.0146254 -2.44152 0.0312624 4.39097E-09 5.86875 0.130231 1.24946E-40 13.346 0.43547 0.00139464 3.19576 ABCG8 3180 12 152 -0.432823 0.171192 -1.36838 -0.295762 0.0157794 -2.41398 0.0314772 3.67916E-09 5.89801 0.130108 1.52929E-40 13.331 0.440976 0.001228 3.2323 ABCG5 3180 6 87 0.324674 0.3172 1.00023 -0.2988 0.0146577 -2.44073 0.0312857 4.15942E-09 5.87773 0.130409 9.33403E-41 13.3677 0.439149 0.00127711 3.22107 ABCB10 3180 6 122 0.333178 0.219379 1.22818 -0.301597 0.013796 -2.46253 0.0312644 4.40563E-09 5.8682 0.130493 9.8029E-41 13.3641 0.431826 0.00154525 3.16605 ABHD1 3180 5 29 -0.149027 0.813232 -0.236258 -0.298211 0.0148918 -2.435 0.0312405 4.49306E-09 5.86494 0.130264 1.16337E-40 13.3513 0.436326 0.001369 3.20111 ABCB6 3180 7 151 -0.00762322 0.977401 -0.028327 -0.299001 0.0146089 -2.44193 0.0312671 4.42259E-09 5.86756 0.130228 1.17642E-40 13.3505 0.435506 0.00139372 3.19595 ABI2 3180 1 25 0.982737 0.0422609 2.03094 -0.30075 0.0140623 -2.45567 0.0311325 4.9292E-09 5.84954 0.129821 1.95802E-40 13.3125 0.436794 0.00135518 3.20403 ABL2 3180 4 41 0.192361 0.698251 0.387682 -0.298745 0.0146809 -2.44016 0.0312678 4.39516E-09 5.86859 0.130322 1.10243E-40 13.3553 0.436387 0.00136405 3.20215  QQ-plot\n Attach:burdenBt.jpg\nvtools associate rare bmi \u0026ndash;covariates gender age exposure -m \u0026ldquo;BurdenQt \u0026ndash;name BurdenQt \u0026ndash;a\nlternative 2\u0026rdquo; \u0026ndash;group_by name2 \u0026ndash;to_db burdenQt -j8 \u0026gt; burdenQt.txt\nINFO: 3180 samples are found INFO: 2632 groups are found INFO: Starting 8 processes to load genotypes Loading genotypes: 100% [===========================] 3,180 33.7/s in 00:01:34 Testing for association: 100% [=========================] 2,632\u0026frasl;147 26.2/s in 00:01:40 INFO: Association tests on 2632 groups have completed. 147 failed. INFO: Using annotation DB burdenQt in project test. INFO: Annotation database used to record results of association tests. Created on Wed, 30 Jan 2013 23:01:44\nvtools show fields | grep burdenQt\nburdenQt.name2 name2 burdenQt.sample_size_BurdenQt sample size burdenQt.num_variants_BurdenQt number of variants in each group (adjusted for specified MAF burdenQt.total_mac_BurdenQt total minor allele counts in a group (adjusted for MOI) burdenQt.beta_x_BurdenQt test statistic. In the context of regression this is estimate of burdenQt.pvalue_BurdenQt p-value burdenQt.wald_x_BurdenQt Wald statistic for x (beta_x/SE(beta_x)) burdenQt.beta_2_BurdenQt estimate of beta for covariate 2 burdenQt.beta_2_pvalue_BurdenQt p-value for covariate 2 burdenQt.wald_2_BurdenQt Wald statistic for covariate 2 burdenQt.beta_3_BurdenQt estimate of beta for covariate 3 burdenQt.beta_3_pvalue_BurdenQt p-value for covariate 3 burdenQt.wald_3_BurdenQt Wald statistic for covariate 3 burdenQt.beta_4_BurdenQt estimate of beta for covariate 4 burdenQt.beta_4_pvalue_BurdenQt p-value for covariate 4 burdenQt.wald_4_BurdenQt Wald statistic for covariate 4\nhead burdenQt.txt\nname2 sample_size_BurdenQt num_variants_BurdenQt total_mac_BurdenQt beta_x_BurdenQt pvalue_BurdenQt wald_x_BurdenQt beta_2_BurdenQt beta_2_pvalue_BurdenQt wald_2_BurdenQt beta_3_BurdenQt beta_3_pvalue_BurdenQt wald_3_BurdenQt beta_4_BurdenQt beta_4_pvalue_BurdenQt wald_4_BurdenQt AADACL4 3180 5 138 -0.461457 0.308686 -1.01815 -0.0716573 0.726877 -0.349314 0.0150768 0.0574562 1.90051 -0.939843 2.75155E-05 -4.19925 ABCB10 3180 6 122 0.119 0.814045 0.23523 -0.0795874 0.697984 -0.388079 0.0150143 0.0585374 1.89233 -0.945568 2.50587E-05 -4.2205 ABHD1 3180 5 29 0.00268703 0.997829 0.00272057 -0.0787737 0.700934 -0.384095 0.0150272 0.0583193 1.89397 -0.943247 2.5858E-05 -4.21338 ABCA4 3180 43 492 0.0820913 0.74098 0.330584 -0.0787295 0.701037 -0.383955 0.0150093 0.0586193 1.89172 -0.942885 2.59414E-05 -4.21265 ABI2 3180 1 25 1.19633 0.276415 1.0886 -0.081478 0.691101 -0.397397 0.0150043 0.0586562 1.89144 -0.941765 2.64399E-05 -4.20833 ABL2 3180 4 41 -0.613866 0.475633 -0.713429 -0.0781101 0.703263 -0.380954 0.0150498 0.0579226 1.89697 -0.945432 2.46814E-05 -4.22394 ACADL 3180 5 65 1.30339 0.0536027 1.93075 -0.0819058 0.689433 -0.39966 0.0150828 0.0572499 1.90209 -0.940465 2.6925E-05 -4.20419 ACADM 3180 4 103 0.0561593 0.916101 0.105355 -0.0778643 0.704415 -0.379401 0.0150232 0.0583868 1.89347 -0.942722 2.61415E-05 -4.2109 ACAP3 3180 3 17 0.296682 0.823678 0.222835 -0.07936 0.698787 -0.386993 0.0150257 0.0583418 1.8938 -0.942487 2.61991E-05 -4.2104\n  QQ-plot Attach:burdenQt.jpg\n\n[^#^]\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/other_pipelines/anno_utils/",
	"title": "anno_utils",
	"tags": [],
	"description": "",
	"content": " Annotation utility pipelines Usage % vtools show pipeline anno_utils This file defines a number of pipelines to manipulate variant tools annotation databases. Available pipelines: annFileFromText, annFileFromVcf, annoDB2proj, proj2annoDB Pipeline \u0026quot;annFileFromText\u0026quot;: This pipeline reads a tab, comma or space delimited file, take its header as name of fields, guess the type of each column, and output an .ann file with these fields. The annotation database is assumed to be of type \u0026quot;field\u0026quot; and use the first column as the linked field. The input file of this pipeline should be the text file, and the ouput file should be an .ann file. If the .ann file is created correctly, it can be used to create an annotation database from the input text file. annFileFromText_10: Create a feild description file from input text file. annFileFromText_20: Create an annotation file from fields guessed from input file Pipeline \u0026quot;annFileFromVcf\u0026quot;: This pipeline reads the header of a vcf file and creates an .ann file with chr, pos, ref, alt, and fields from all INFO fields. The input file can be a file (.vcf or .vcf.gz) or a URL (.vcf.gz only). The file must be tabix-indexed if it is bgzipped. The output file is an .ann file, which can be used to create an annotation database for the vcf file. This pipeline tries to guess the reference genome used from the VCF file but you should always check if the correct reference genome is generated. annFileFromVcf_10: Create a feild description file from input text file. annFileFromVcf_20: Create an annotation file from fields guessed from input vcf file Pipeline \u0026quot;annoDB2proj\u0026quot;: This pipeline creates a variant tools project from a variant-based annotation database. The input of this pipeline should be the .DB or .DB.gz file of an annotation database. The output should be name of a directory within which the project will be created. The output directory will be created if it does not exist. Any existing project in that directory will be removed. annoDB2proj_0: Check the existence of command sqlite3, which is required for this pipeline annoDB2proj_10: Decompress .DB.gz file if needed annoDB2proj_20: Dump the structure of the the variant table to cache/$PROJ.schema. annoDB2proj_25: Determine build information for the annotation database annoDB2proj_30: Create a .fmt file for variants in annotation database annoDB2proj_40: Create an input format definition file .fmt annoDB2proj_50: Dump the annotation database to a text file annoDB2proj_60: Create a project if it does not exist annoDB2proj_70: Create a project and import data Pipeline \u0026quot;proj2annoDB\u0026quot;: This pipeline creates an annotation database using variants and variant info fields of a variant tools project. The database can then be used, for example, to filter variants from another project. The input of this pipeline should be a vtools project database ($name.proj), the output is a .ann file ($name.ann). $name.ann, $name.DB and $name.DB.gz will be created. If a variant table is specified through parameter -export, only variants in specified variant table will be dumped. proj2annoDB_0: Check the existence of command sqlite3, which is required for this pipeline proj2annoDB_10: Dump the structure of the the variant table to cache/$PROJ.schema. proj2annoDB_11: Convert .schema to .ann definitions proj2annoDB_20: Create an annotation definition file (.ann) proj2annoDB_30: Dump the variant table to a text file proj2annoDB_40: Create annotation database from dumped text file Pipeline parameters: export A variant table to create annotation database from for pipeline proj2annoDB (default: variant)  Details Converting a project to an annotation database (pipeline proj2annoDB) You might have several projects and would like to use them to analyze a new project. For example, you might want to exclude from a project all variants that exist in a few control project (or projects with normal unaffected samples). You could achieve this by merging all these projects and analyze all variants together, but a more convenient way is to build annotation databases from these project and use them in the new project.\nThe proj2annoDB pipeline defined in anno_utils.pipeline can be used for this purpose. It exports all variants and variant info fields of the master variant table, or a specified variant table (parameter --export to a file and create an annotation database using a generated .ann file.\n Create an annotation database from a project\n% vtools init test % vtools admin --load_snapshot vt_quickStartGuide % vtools execute anno_utils proj2annoDB --input test.proj --output myanno.ann INFO: Executing step proj2annoDB_0 of pipeline anno_utils: Check the existence of command sqlite3, which is required for this pipeline INFO: Command sqlite3 is located. INFO: Executing step proj2annoDB_5 of pipeline anno_utils: Dump project build information INFO: Running \u0026quot;sqlite3 test.proj 'select value from project where name=\u0026quot;build\u0026quot;' \u0026gt; cache/test.proj.build\u0026quot; INFO: Output redirected to cache/test.proj.build.out_10717 and cache/test.proj.build.err_10717 and will be saved to cache/test.proj.build.exe_info after completion of command. INFO: Command \u0026quot;sqlite3 test.proj 'select value from project where name=\u0026quot;build\u0026quot;' \u0026gt; cache/test.proj.build\u0026quot; completed successfully in 00:00:11 INFO: Executing step proj2annoDB_10 of pipeline anno_utils: Dump the structure of the the variant table to cache/$PROJ.schema. INFO: Running \u0026quot;sqlite3 test.proj \u0026quot;.schema variant\u0026quot; \u0026gt; cache/test.proj.schema\u0026quot; INFO: Output redirected to cache/test.proj.schema.out_10717 and cache/test.proj.schema.err_10717 and will be saved to cache/test.proj.schema.exe_info after completion of command. INFO: Command \u0026quot;sqlite3 test.proj \u0026quot;.schema variant\u0026quot; \u0026gt; cache/test.proj.schema\u0026quot; completed successfully in 00:00:11 INFO: Executing step proj2annoDB_11 of pipeline anno_utils: Convert .schema to .ann definitions INFO: Running \u0026quot;echo \u0026quot;None command executed.\u0026quot;\u0026quot; INFO: Output redirected to cache/test.proj.ann_tmp.out_10717 and cache/test.proj.ann_tmp.err_10717 and will be saved to cache/test.proj.ann_tmp.exe_info after completion of command. INFO: Command \u0026quot;echo \u0026quot;None command executed.\u0026quot;\u0026quot; completed successfully in 00:00:00 INFO: Executing step proj2annoDB_20 of pipeline anno_utils: Create an annotation definition file (.ann) INFO: Running \u0026quot;echo '[linked fields]' \u0026gt; myanno.ann; echo 'hg18=chr, pos, ref, alt' \u0026gt;\u0026gt; myanno.ann; echo '[data sources]' \u0026gt;\u0026gt; myanno.ann; echo 'description=Annotation database dumped from project test.proj' \u0026gt;\u0026gt; myanno.ann; echo 'delimiter=\u0026quot;|\u0026quot;' \u0026gt;\u0026gt; myanno.ann; echo 'anno_type=variant' \u0026gt;\u0026gt; myanno.ann; echo 'source_type=txt' \u0026gt;\u0026gt; myanno.ann; cat cache/test.proj.ann_tmp \u0026gt;\u0026gt; myanno.ann\u0026quot; INFO: Output redirected to myanno.ann.out_10717 and myanno.ann.err_10717 and will be saved to myanno.ann.exe_info after completion of command. INFO: Command \u0026quot;echo '[linked fields]' \u0026gt; myanno.ann; echo 'hg18=chr, pos, ref, alt' \u0026gt;\u0026gt; myanno.ann; echo '[data sources]' \u0026gt;\u0026gt; myanno.ann; echo 'description=Annotation database dumped from project test.proj' \u0026gt;\u0026gt; myanno.ann; echo 'delimiter=\u0026quot;|\u0026quot;' \u0026gt;\u0026gt; myanno.ann; echo 'anno_type=variant' \u0026gt;\u0026gt; myanno.ann; echo 'source_type=txt' \u0026gt;\u0026gt; myanno.ann; cat cache/test.proj.ann_tmp \u0026gt;\u0026gt; myanno.ann\u0026quot; completed successfully in 00:00:11 INFO: Executing step proj2annoDB_30 of pipeline anno_utils: Dump the variant table to a text file INFO: Running \u0026quot;sqlite3 test.proj \u0026quot;select * from variant ;\u0026quot; \u0026gt; cache/test.proj.dump\u0026quot; INFO: Output redirected to cache/test.proj.dump.out_10717 and cache/test.proj.dump.err_10717 and will be saved to cache/test.proj.dump.exe_info after completion of command. INFO: Command \u0026quot;sqlite3 test.proj \u0026quot;select * from variant ;\u0026quot; \u0026gt; cache/test.proj.dump\u0026quot; completed successfully in 00:00:11 INFO: Executing step proj2annoDB_40 of pipeline anno_utils: Create annotation database from dumped text file INFO: Running \u0026quot;vtools use myanno.ann --files cache/test.proj.dump --rebuild\u0026quot; INFO: Output redirected to myanno.DB.gz.out_10717 and myanno.DB.gz.err_10717 and will be saved to myanno.DB.gz.exe_info after completion of command. INFO: Command \u0026quot;vtools use myanno.ann --files cache/test.proj.dump --rebuild\u0026quot; completed successfully in 00:00:11  You can export variant from a selected variant table by passing the name of the variant table to parameter --export.\nYou can then use this annotation database to annotation other projects\n% vtools use /path/to/myanno % vtools select variant 'myanno.chr is not NULL' -o chr pos ref alt myanno.AA myanno.AN -l 10 1 1105366 T C T 114 1 1105411 G A G 106 1 1108138 C T c 130 1 1110240 T A T 178 1 1110294 G A A 158 1 3537996 T C C 156 1 3538692 G C G 178 1 3541597 C T C 178 1 3541652 G A G 202 1 3545211 G A G 178  \nConverting a variant-based annotation database to a project (pipeline annoDB2proj) If you would like to study a variant-based annotation database in details, for example, to annotate these variants using other annotation databases, you can convert it to a variant tools project using the annoDB2proj pipeline defined in anno_utils.pipeline. The resulting project has all the variants in the annotation database, but not the annotation fields, so you will have to use the original annotation database to get the annotations.\nAnnotation databases sometimes have multiple annotations for a variant (e.g. more than one dbSNP names for a variant). These variants will be imported only once in the resulting variant tools project.\n Convert database dbSNP to a project The input of this pipeline is the database DB file, which is usually under ~/.variant_tools/annoDB. The output should be name of a directory that holds the created project.\n% vtools init test_proj % vtools execute anno_utils annoDB2proj --input ~/.variant_tools/annoDB/dbSNP-hg19_137.DB.gz --output dbSNP INFO: Executing step annoDB2proj_0 of pipeline anno_utils: Check the existence of command sqlite3, which is required for this pipeline INFO: Command sqlite3 is located. INFO: Executing step annoDB2proj_10 of pipeline anno_utils: Decompress .DB.gz file if needed INFO: Decompressing /Users/bpeng/.variant_tools/annoDB/dbSNP-hg19_137.DB.gz to cache/dbSNP-hg19_137.DB INFO: Executing step annoDB2proj_20 of pipeline anno_utils: Dump the structure of the the variant table to cache/$PROJ.schema. INFO: Running \u0026quot;sqlite3 cache/dbSNP-hg19_137.DB \u0026quot;.schema dbSNP\u0026quot; \u0026gt; cache/dbSNP.schema\u0026quot; INFO: Output redirected to cache/dbSNP.schema.out_9315 and cache/dbSNP.schema.err_9315 and will be saved to cache/dbSNP.schema.exe_info after completion of command. INFO: Command \u0026quot;sqlite3 cache/dbSNP-hg19_137.DB \u0026quot;.schema dbSNP\u0026quot; \u0026gt; cache/dbSNP.schema\u0026quot; completed successfully in 00:00:11 INFO: Executing step annoDB2proj_25 of pipeline anno_utils: Determine build information for the annotation database INFO: Running \u0026quot;sqlite3 cache/dbSNP-hg19_137.DB \u0026quot;select value from dbSNP_info WHERE name = 'build'\u0026quot; \u0026gt; cache/dbSNP.build\u0026quot; INFO: Output redirected to cache/dbSNP.build.out_9315 and cache/dbSNP.build.err_9315 and will be saved to cache/dbSNP.build.exe_info after completion of command. INFO: Command \u0026quot;sqlite3 cache/dbSNP-hg19_137.DB \u0026quot;select value from dbSNP_info WHERE name = 'build'\u0026quot; \u0026gt; cache/dbSNP.build\u0026quot; completed successfully in 00:00:00 INFO: Executing step annoDB2proj_30 of pipeline anno_utils: Create a .fmt file for variants in annotation database INFO: Running \u0026quot;echo \u0026quot;None command executed.\u0026quot;\u0026quot; INFO: Output redirected to cache/dbSNP.fmt_tmp.out_9315 and cache/dbSNP.fmt_tmp.err_9315 and will be saved to cache/dbSNP.fmt_tmp.exe_info after completion of command. INFO: Command \u0026quot;echo \u0026quot;None command executed.\u0026quot;\u0026quot; completed successfully in 00:00:00 INFO: Executing step annoDB2proj_40 of pipeline anno_utils: Create an input format definition file .fmt INFO: Running \u0026quot;echo '[format description]' \u0026gt; cache/dbSNP.fmt; echo 'description=Project created from annotation database /Users/bpeng/.variant_tools/annoDB/dbSNP-hg19_137.DB.gz' \u0026gt;\u0026gt; cache/dbSNP.fmt; echo 'variant=chr, start, refNCBI, alt' \u0026gt;\u0026gt; cache/dbSNP.fmt; echo 'delimiter=\u0026quot;|\u0026quot;' \u0026gt;\u0026gt; cache/dbSNP.fmt; cat cache/dbSNP.fmt_tmp \u0026gt;\u0026gt; cache/dbSNP.fmt\u0026quot; INFO: Output redirected to cache/dbSNP.fmt.out_9315 and cache/dbSNP.fmt.err_9315 and will be saved to cache/dbSNP.fmt.exe_info after completion of command. INFO: Command \u0026quot;echo '[format description]' \u0026gt; cache/dbSNP.fmt; echo 'description=Project created from annotation database /Users/bpeng/.variant_tools/annoDB/dbSNP-hg19_137.DB.gz' \u0026gt;\u0026gt; cache/dbSNP.fmt; echo 'variant=chr, start, refNCBI, alt' \u0026gt;\u0026gt; cache/dbSNP.fmt; echo 'delimiter=\u0026quot;|\u0026quot;' \u0026gt;\u0026gt; cache/dbSNP.fmt; cat cache/dbSNP.fmt_tmp \u0026gt;\u0026gt; cache/dbSNP.fmt\u0026quot; completed successfully in 00:00:11 INFO: Executing step annoDB2proj_50 of pipeline anno_utils: Dump the annotation database to a text file INFO: Running \u0026quot;sqlite3 cache/dbSNP-hg19_137.DB \u0026quot;select * from dbSNP;\u0026quot; \u0026gt; cache/dbSNP.dump\u0026quot; INFO: Output redirected to cache/dbSNP.dump.out_9315 and cache/dbSNP.dump.err_9315 and will be saved to cache/dbSNP.dump.exe_info after completion of command. INFO: Command \u0026quot;sqlite3 cache/dbSNP-hg19_137.DB \u0026quot;select * from dbSNP;\u0026quot; \u0026gt; cache/dbSNP.dump\u0026quot; completed successfully in 00:06:58 INFO: Executing step annoDB2proj_60 of pipeline anno_utils: Create a project if it does not exist INFO: Running \u0026quot;if [ ! -d dbSNP ]; then mkdir dbSNP; fi\u0026quot; INFO: Command \u0026quot;if [ ! -d dbSNP ]; then mkdir dbSNP; fi\u0026quot; completed successfully in 00:00:11 INFO: Executing step annoDB2proj_70 of pipeline anno_utils: Create a project and import data INFO: Running \u0026quot;vtools init -v2 --force dbSNP\u0026quot; INFO: Output redirected to dbSNP/dbSNP.proj.out_9315 and dbSNP/dbSNP.proj.err_9315 and will be saved to dbSNP/dbSNP.proj.exe_info after completion of command. INFO: Command \u0026quot;vtools init -v2 --force dbSNP\u0026quot; completed successfully in 00:00:11 INFO: Running \u0026quot;vtools import /Users/bpeng/Temp/cache/dbSNP.dump --format /Users/bpeng/Temp/cache/dbSNP.fmt --build hg19\u0026quot;  \nCreate an annotation specification file (.ann file) from a local or online VCF file (pipeline annFileFromVcf) The default vtools import command by default imports variants but not related info fields from a vcf file. To access the info fields, you have the choices of\n Use option --var_info to import selected variant info to the project. Use command vtools update to import variant info later when you need them. Use the track() function to retrieve such information for a few variants, or Create an annotation database from the vcf file so that you can access variant info quickly without increasing the size of the project.  The pipeline annFileFromVcf is designed to help you generate an annotation database from an input VCF file (but it also accepts a URL for an online vcf file) by extracting field information from the vcf file and creates an .ann file.\n Create an .ann file from the vcf file from the dbSNP vcf file  The input of this pipeline is the database DB file, which is usually under ~/.variant_tools/annoDB. The output should be name of a directory that holds the created project.\n% vtools init test_proj % vtools execute anno_utils annFileFromVcf --input ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606/VCF/00-All.vcf.gz --output dbSNP.ann INFO: Executing anno_utils.annFileFromVcf_10: Create a feild description file from input text file. [get_local_version] downloading the index file... INFO: Executing anno_utils.annFileFromVcf_20: Create an annotation file from fields guessed from input vcf file INFO: Running echo '# Please refer to http://varianttools.sourceforge.net/Annotation/New' \u0026gt; dbSNP.ann; echo '# for a description of the format of this file.' \u0026gt;\u0026gt; dbSNP.ann; echo '' \u0026gt;\u0026gt; dbSNP.ann; echo '[linked fields]' \u0026gt;\u0026gt; dbSNP.ann; echo 'hg19=chr,pos,ref,alt' \u0026gt;\u0026gt; dbSNP.ann; echo '' \u0026gt;\u0026gt; dbSNP.ann; echo '[data sources]' \u0026gt;\u0026gt; dbSNP.ann; echo 'description=An annotation database created from' ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606/VCF/00-All.vcf.gz \u0026gt;\u0026gt; dbSNP.ann; echo 'version=' \u0026gt;\u0026gt; dbSNP.ann; echo 'anno_type=variant' \u0026gt;\u0026gt; dbSNP.ann; echo 'direct_url=' \u0026gt;\u0026gt; dbSNP.ann; echo 'source_url='ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606/VCF/00-All.vcf.gz \u0026gt;\u0026gt; dbSNP.ann; echo 'source_type=txt' \u0026gt;\u0026gt; dbSNP.ann; echo 'source_pattern=' \u0026gt;\u0026gt; dbSNP.ann; echo '' \u0026gt;\u0026gt; dbSNP.ann; cat cache/00-All.vcf.gz.fields \u0026gt;\u0026gt; dbSNP.ann INFO: Command \u0026quot;echo '# Please refer to http://varianttools.sourceforge.net/Annotation/New' \u0026gt; dbSNP.ann; echo '# for a description of the format of this file.' \u0026gt;\u0026gt; dbSNP.ann; echo '' \u0026gt;\u0026gt; dbSNP.ann; echo '[linked fields]' \u0026gt;\u0026gt; dbSNP.ann; echo 'hg19=chr,pos,ref,alt' \u0026gt;\u0026gt; dbSNP.ann; echo '' \u0026gt;\u0026gt; dbSNP.ann; echo '[data sources]' \u0026gt;\u0026gt; dbSNP.ann; echo 'description=An annotation database created from' ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606/VCF/00-All.vcf.gz \u0026gt;\u0026gt; dbSNP.ann; echo 'version=' \u0026gt;\u0026gt; dbSNP.ann; echo 'anno_type=variant' \u0026gt;\u0026gt; dbSNP.ann; echo 'direct_url=' \u0026gt;\u0026gt; dbSNP.ann; echo 'source_url='ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606/VCF/00-All.vcf.gz \u0026gt;\u0026gt; dbSNP.ann; echo 'source_type=txt' \u0026gt;\u0026gt; dbSNP.ann; echo 'source_pattern=' \u0026gt;\u0026gt; dbSNP.ann; echo '' \u0026gt;\u0026gt; dbSNP.ann; cat cache/00-All.vcf.gz.fields \u0026gt;\u0026gt; dbSNP.ann\u0026quot; completed successfully in 00:00:01  \nThe created .ann file might not have the correct build information and might not be always usable due to, for example, unacceptable field name. Always check the .ann file before you create an annotation database from it.\nCreate an annotation specification file (.ann file) from a text file (pipeline annFileFromText) During the analysis of dataset, you might have some summary report that can be used to direct further analysis, or you might have a text file that annotate some or all fields of your project. This pipeline help you convert these files to an annotation database so that you can use it in the project.\n Create an annotation database from summary statistics outputted from command vtools output For example, the following command counts the number of variants (in a variant table called kg, across all samples) and output know gene ID and the counts to a text file.\n% vtools output kg knownGene.name 'sum(variant.num)' --group_by knownGene.name --header \u0026gt; kg.count  The text file looks like this\n% head -5 kg.count knownGene name sum variant num uc001abt.4 5 uc001abv.1 18 uc001abw.1 32 uc001abx.1 16  If you have a project with all affected samples and would like to identify novel variants that are causing the disease, you might want to remove variants that are very rare in the sample. However, doing so might not be wise because different variants in a gene might have the same effect and each of them is rare. In this case, you might want to remove all variants that appear only once (or very few times) in a gene. The information you obtained in the output of the above command can be useful.\nHowever, you will need to import the genotype counts into the project before you can use it. Because the text file contains annotation information for field knownGene.name, it is best to create an field-based annotation database that annotate this field. Pipeline annFileFromText from anno_utils can help you during this process. For example\n% vtools execute anno_utils annFileFromText -i kg.count -o kg_sum_geno.ann INFO: Executing step annFileFromText_10 of pipeline anno_utils: Create a feild description file from input text file. INFO: Executing step annFileFromText_20 of pipeline anno_utils: Create an annotation file from fields guessed from input file INFO: Running \u0026quot;echo '[linked fields]' \u0026gt; kg_sum_geno.ann; echo '*=knownGene_name' \u0026gt;\u0026gt; kg_sum_geno.ann; echo '' \u0026gt;\u0026gt; kg_sum_geno.ann; echo '[data sources]' \u0026gt;\u0026gt; kg_sum_geno.ann; echo 'description=Field annotation database created by pipeline annFileFromText (in anno_utils.pipeline) from text file kg.count' \u0026gt;\u0026gt; kg_sum_geno.ann; echo 'anno_type=field' \u0026gt;\u0026gt; kg_sum_geno.ann; echo 'header=1' \u0026gt;\u0026gt; kg_sum_geno.ann; echo 'source_url=kg.count' \u0026gt;\u0026gt; kg_sum_geno.ann; echo 'source_type=txt' \u0026gt;\u0026gt; kg_sum_geno.ann;\u0026quot; INFO: Output redirected to kg_sum_geno.ann.out_69301 and kg_sum_geno.ann.err_69301 and will be saved to kg_sum_geno.ann.exe_info after completion of command. INFO: Command \u0026quot;echo '[linked fields]' \u0026gt; kg_sum_geno.ann; echo '*=knownGene_name' \u0026gt;\u0026gt; kg_sum_geno.ann; echo '' \u0026gt;\u0026gt; kg_sum_geno.ann; echo '[data sources]' \u0026gt;\u0026gt; kg_sum_geno.ann; echo 'description=Field annotation database created by pipeline annFileFromText (in anno_utils.pipeline) from text file kg.count' \u0026gt;\u0026gt; kg_sum_geno.ann; echo 'anno_type=field' \u0026gt;\u0026gt; kg_sum_geno.ann; echo 'header=1' \u0026gt;\u0026gt; kg_sum_geno.ann; echo 'source_url=kg.count' \u0026gt;\u0026gt; kg_sum_geno.ann; echo 'source_type=txt' \u0026gt;\u0026gt; kg_sum_geno.ann;\u0026quot; completed successfully in 00:00:11 INFO: Running \u0026quot;cat cache/kg.count.fields \u0026gt;\u0026gt; kg_sum_geno.ann\u0026quot; INFO: Command \u0026quot;cat cache/kg.count.fields \u0026gt;\u0026gt; kg_sum_geno.ann\u0026quot; completed successfully in 00:00:12  The .ann file created looks like\n% cat kg_sum_geno.ann [linked fields] *=knownGene_name [data sources] description=Field annotation database created by pipeline annFileFromText (in anno_utils.pipeline) from text file kg.count anno_type=field header=1 source_url=kg.count source_type=txt delimiter=\u0026quot;\\t\u0026quot; [knownGene_name] index=1 type=VARCHAR(10) [sum_variant_num] index=2 type=INT  And you can use it to create an annotation database from kg.count and link it to the project\n% vtools use kg_sum_geno.ann --linked_by knownGene.name INFO: Importing database kg_sum_geno from source files ['kg.count'] INFO: Importing annotation data from kg.count kg.count: 100% [========================================================] 61,214 32.3K/s in 00:00:01 INFO: 61224 records are handled, 0 ignored. INFO: Using annotation DB kg_sum_geno in project Arun. INFO: Field annotation database created by pipeline annFileFromText (in anno_utils.pipeline) from text file kg.count INFO: 61223 out of 80922 knowngene.name are annotated through annotation database kg_sum_geno  You can then use the sum_variant_num field from the kg_sum_geno database to filter variants:\n% vtools select kg 'kg_sum_geno.sum_variant_num = 1' -t rare_variants Running: 10,468 696.0/s in 00:00:15 INFO: 2717 variants selected.  Compared to the number of singletons in the project, the above command identified a lot less variants.\n% vtools select kg 'variant.num=1' -c Counting variants: 973 346.9/s in 00:00:02 627489  Using vtools select with condition kg_sum_geno.sum_variant_num = 1 will include variants that appear in more than one gene but has count 1 in one of them. It is better to use vtools exclude and condition kg_sum_geno.sum_variant_num \u0026gt; 1 to find out variants that appear in only one gene once.\n(:exampleend\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/variant_calling/bwa_gatk33_b37/",
	"title": "bat_gatk33_b37",
	"tags": [],
	"description": "",
	"content": " Variant calling using BWA and GATK best practice pipeline (b37) This is the same pipeline as bwa_gatk33_hg19? but uses build b37 of the human reference genome.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/format/formats/csv/",
	"title": "csv",
	"tags": [],
	"description": "",
	"content": " Importing and exporting variants in .csv (comma-separated value) format Format description When this format is used to import data, it is similar to the basic? format except that it assumes the use of commas, instead of tabs, as delimiters of the input format.\nWhen this format is used to export variants, it can be used to export arbitrary fields. The command and the resulting ouput are similar to that of the command vtools output --delimiter , (output fields with a delimiter of comma), except that the vtools export --format csv command will properly quote field values when it contains comma, quotation mark etc.\nFields Format: csv Description: Import variants (chr, pos, ref, alt) in csv format, or output arbitrary specified fields in csv format Columns: 1 Output all fields as one column 2 genotype Formatters are provided for fields: gt, * variant: chr Chromosome pos 1-based position ref Reference allele, '-' for insertion. alt Alternative allele, '-' for deletion. Format parameters: chr_col Column index for the chromosome field (default: 1) pos_col Column index for the position field (default: 2) ref_col Column index for the reference field (default: 3) alt_col Column index for the alternative field (default: 4) pos_adj Set to 1 if the input position is zero-based. (default: 0) fields Fields to output, simple arithmetics are allowed (e.g. pos+1) but aggregation functions are not supported. (default: chr,pos,ref,alt) order_by Fields used to order output in ascending order. (default: )  Examples Import variants (similar to format `\u0026lt;a class=\u0026lsquo;createlinktext\u0026rsquo; rel=\u0026lsquo;nofollow\u0026rsquo; href='http://localhost/~iceli/wiki/pmwiki.php?n=Format.Basic?action=edit'\u0026gt;basic\u0026lt;/a\u0026gt;\u0026lt;a rel='nofollow' class='createlink' href='http://localhost/~iceli/wiki/pmwiki.php?n=Format.Basic?action=edit'\u0026gt;?\u0026lt;/a\u0026gt;`) vtools import inputfile.txt --format csv --build hg18  This format assumes 1-based position for input files. If your input file uses zero-based position, you can use paramter --pos_adj 1 to let variant tools adjust the position by 1.\nvtools import inputfile.txt --format csv --pos_adj 1 --build hg18  This format supports parameters\n chr_col pos_col ref_col alt_col  If, for example, your input file has columns chr, start, end, ref, alt, you can import from this file using command\nvtools import inputfile.txt --format csv --ref_col 4 --alt_col 5 --build hg18  ####x Export arbitrary fields and genotypes\nThe following command demonstrate how to export variants and a large number of annotation fields from different annotation databases, with a more descriptive header added to the output file. To repeat this command, you will need to update a variant table with number of variants in cases and controls, mean quality scores (fields case_num, ctrl_num, mean_Q_indel, mean_Q_gt, obtained using command vtools update --from_stat), and use all relevant annotation databases (refGene, thousandGenomes, dbSNP, and dbNSFP).\nvtools export selected_variants --format csv --fields chr pos ref alt refGene.name2 case_num ctrl_num \\ GMAF_INFO dbSNP.name dbSNP.func SIFT_score PolyPhen2_score mean_Q_indel mean_Q_gt \\ --order_by chr pos \\ --header chr pos ref alt 'gene name' '# in cases' '# in ctrl' \\ 'allele freq in 1000 genomes' 'dbSNP ID' 'func (dbSNP)' 'SIFT score' \\ 'PolyPhen2 score' 'mean Quality score (indel)' 'mean Quality score (SNV)' \\ \u0026gt; selected_variants.csv  If you also need to export genotype, you can use a command similar to\nvtools export selected_variants --format csv --samples 1 --fields chr pos ref alt refGene.name2 case_num ctrl_num \\ GMAF_INFO dbSNP.name dbSNP.func SIFT_score PolyPhen2_score mean_Q_indel mean_Q_gt \\ --order_by chr pos \\ --header chr pos ref alt 'gene name' '# in cases' '# in ctrl' \\ 'allele freq in 1000 genomes' 'dbSNP ID' 'func (dbSNP)' 'SIFT score' \\ 'PolyPhen2 score' 'mean Quality score (indel)' 'mean Quality score (SNV)' \\ '%(sample_names)s' \\ \u0026gt; selected_variants.csv  Note here the use of --samples 1 to select all samples by condition 1 (true),, and the use of %(sample_names)s in the header to list all sample names.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/variants/dbnsfp/",
	"title": "dbNSFP",
	"tags": [],
	"description": "",
	"content": " dbNSFP (:skin vtools-annotation\n(:toc\ndbNSFP is an annotation database for non-synonymous SNPs assembled by Xiaoming Liu from the University of Texas School of Public Health (see citation below). With variant tools you can use the dbNSFP database or dbNSFP-light (a version with fewer features) - see which features are offered for each database version below.\ndbNSFP There can be frequent changes of name and their meanings of the fields across versions. Please pay close attention to the comments of fields before you use them.\nFor the latest version dbNSFP 2.4\n For SIFT_score, lower score means more damaging. For Polyphen2 scores, higher score means more damaging. There are multiple scores in fields SIFT_score_all, SIFT_pred_all, Polyphen2_HDIV_score_all, Polyphen2_HVAR_score_all, Polyphen2_HDIV_pred_all and Polyphen2_HVAR_pred_all. If you need a score for selecting most damaging variants, use fields such as SIFT_score, SIFT_pred, Polyphen2_HDIV_score, Polyphen2_HVAR_score and Polyphen2_HVAR_pred. There can be multiple records for a variant so output of vtools output might be surprising (e.g. output score 0.4 with criterion \u0026lsquo;score \u0026gt; 0.9\u0026rsquo;). Use option --all if you would like to see scores for all records.\n% vtools show annotation dbNSFP -v2\nAnnotation database dbNSFP (version hg18_hg19_2_1) Description: dbNSFP version 2.1, maintained by Xiaoming Liu from UTSPH. Please cite \u0026ldquo;Liu X, Jian X, and Boerwinkle E. 2011. dbNSFP: a lightweight database of human non-synonymous SNPs and their functional predictions. Human Mutation. 32:894-899\u0026rdquo; and \u0026ldquo;Liu X, Jian X, and Boerwinkle E. 2013. dbNSFP v2.0: A Database of Human Nonsynonymous SNVs and Their Functional Predictions and Annotations. Human Mutation. 34:E2393-E2402.\u0026rdquo; if you find this database useful. Database type: variant Number of records: 89,617,785 Distinct variants: 84,484,850 Reference genome hg18: chr, hg18_pos, ref, alt Reference genome hg19: chr, pos, ref, alt\nField: chr Type: string Comment: Chromosome number Missing entries: 0 Unique Entries: 24\nField: pos Type: integer Comment: physical position on the chromosome as to hg19 (1-based coordinate) Missing entries: 0 Unique Entries: 28,060,014 Range: 6007 - 249212562\nField: ref Type: string Comment: Reference nucleotide allele (as on the + strand) Missing entries: 0 Unique Entries: 4\nField: alt Type: string Comment: Alternative nucleotide allele (as on the + strand) Missing entries: 0 Unique Entries: 4\nField: aaref Type: string Comment: reference amino acid Missing entries: 0 Unique Entries: 22\nField: aaalt Type: string Comment: alternative amino acid Missing entries: 0 Unique Entries: 22\nField: hg18_pos Type: integer Comment: physical position on the chromosome as to hg19 (1-based coordinate) Missing entries: 44,904 (0.1% of 89,617,785 records) Unique Entries: 28,043,425 Range: 4381 - 247179185\nField: genename Type: string Comment: common gene name Missing entries: 0 Unique Entries: 20,264\nField: Uniprot_acc Type: string Comment: Uniprot accession number. Multiple entries separated by \u0026ldquo;;\u0026rdquo;. Missing entries: 17,068,597 (19.0% of 89,617,785 records) Unique Entries: 55,816\nField: Uniprot_id Type: string Comment: Uniprot ID number. Multiple entries separated by \u0026ldquo;;\u0026rdquo;. Missing entries: 20,254,026 (22.6% of 89,617,785 records) Unique Entries: 37,250\nField: Uniprot_aapos Type: integer Comment: amino acid position as to Uniprot. Multiple entries separated by \u0026ldquo;;\u0026rdquo;. Missing entries: 17,068,597 (19.0% of 89,617,785 records) Unique Entries: 2,687,476 Range: 1 - 9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9\nField: Interpro_domain Type: string Comment: Interpro_domain: domain or conserved site on which the variant locates. Domain annotations come from Interpro database. The number in the brackets following a specific domain is the count of times Interpro assigns the variant position to that domain, typically coming from different predicting databases. Multiple entries separated by \u0026ldquo;;\u0026rdquo;. Missing entries: 60,454,832 (67.5% of 89,617,785 records) Unique Entries: 9,922\nField: cds_strand Type: string Comment: coding sequence (CDS) strand (+ or -) Missing entries: 0 Unique Entries: 5\nField: refcodon Type: string Comment: reference codon Missing entries: 2,270,742 (2.5% of 89,617,785 records) Unique Entries: 1,754\nField: SLR_test_statistic Type: float Comment: SLR test statistic for testing natural selection on codons. A negative value indicates negative selection, and a positive value indicates positive selection. Larger magnitude of the value suggests stronger evidence. Missing entries: 46,683,780 (52.1% of 89,617,785 records) Unique Entries: 511,811 Range: -188.177 - 108.85\nField: codonpos Type: integer Comment: position on the codon (1, 2 or 3) Missing entries: 2,270,742 (2.5% of 89,617,785 records) Unique Entries: 4 Range: 1 - 3;2;3\nField: fold_degenerate Type: integer Comment: degenerate type (0, 2 or 3) Missing entries: 2,270,742 (2.5% of 89,617,785 records) Unique Entries: 79 Range: 0 - 2;2;2;2;2;2;2;2;2;2;2;2;2;2;2;2;2;2;2;2;2;2;2;2;0\nField: Ancestral_allele Type: string Comment: Ancestral allele (based on 1000 genomes reference data). The following comes from its original README file: ACTG - high-confidence call, ancestral state supproted by the other two sequences actg - low- confindence call, ancestral state supported by one sequence only N - failure, the ancestral state is not supported by any other sequence - - the extant species contains an insertion at this postion . - no coverage in the alignment Missing entries: 2,488,820 (2.8% of 89,617,785 records) Unique Entries: 10\nField: Ensembl_geneid Type: string Comment: Ensembl gene id Missing entries: 0 Unique Entries: 20,839\nField: Ensembl_transcriptid Type: string Comment: Ensembl transcript ids (separated by \u0026ldquo;;\u0026rdquo;) Missing entries: 0 Unique Entries: 112,159\nField: aapos Type: integer Comment: : amino acid position as to the protein \u0026ldquo;-1\u0026rdquo; if the variant is a splicing site SNP (2bp on each end of an intron) Missing entries: 0 Unique Entries: 4,315,466 Range: -1 - 9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;9;27;9;9;9;9;35;9;9;9\nField: SIFT_score Type: float Comment: SIFT score, If a score is smaller than 0.05 the corresponding NS is predicted as \u0026ldquo;D(amaging)\u0026rdquo;; otherwise it is predicted as \u0026ldquo;T(olerated)\u0026rdquo;. Missing entries: 12,024,501 (13.4% of 89,617,785 records) Unique Entries: 101 Range: 0 - 1\nField: SIFT_score_converted Type: float Comment: SIFTnew=1-SIFTori. The larger the more damaging. Missing entries: 12,024,501 (13.4% of 89,617,785 records) Unique Entries: 101 Range: 0 - 1\nField: SIFT_pred Type: string Comment: If SIFTori is smaller than 0.05 (SIFTnew\u0026gt;0.95) the corresponding NS is predicted as \u0026ldquo;D(amaging)\u0026rdquo;; otherwise it is predicted as \u0026ldquo;T(olerated)\u0026rdquo;. Missing entries: 12,024,501 (13.4% of 89,617,785 records) Unique Entries: 2\nField: Polyphen2_HDIV_score_max Type: float Comment: The maximum (most damaging) value of Polyphen2 score based on HumDiv, i.e. hdiv_prob. Use Polyphen2_HDIV_score to get a list of all scores. Missing entries: 17,086,068 (19.1% of 89,617,785 records) Unique Entries: 1,001 Range: 0 - 1\nField: Polyphen2_HDIV_score Type: string Comment: Polyphen2 score based on HumDiv, i.e. hdiv_prob. The score ranges from 0 to 1, and the corresponding prediction is \u0026ldquo;probably damaging\u0026rdquo; if it is in [0.957,1]; \u0026ldquo;possibly damaging\u0026rdquo; if it is in [0.453,0.956]; \u0026ldquo;benign\u0026rdquo; if it is in [0,0.452]. Score cutoff for binary classification is 0.5, i.e. the prediction is \u0026ldquo;neutral\u0026rdquo; if the score is smaller than 0.5 and \u0026ldquo;deleterious\u0026rdquo; if the score is larger than 0.5. Multiple entries separated by \u0026ldquo;;\u0026rdquo;. Missing entries: 17,084,053 (19.1% of 89,617,785 records) Unique Entries: 8,590,602\nField: Polyphen2_HDIV_pred Type: string Comment: Polyphen2 prediction based on HumDiv, \u0026ldquo;D\u0026rdquo; (\u0026ldquo;probably damaging\u0026rdquo;), \u0026ldquo;P\u0026rdquo; (\u0026ldquo;possibly damaging\u0026rdquo;) and \u0026ldquo;B\u0026rdquo; (\u0026ldquo;benign\u0026rdquo;). Multiple entries separated by \u0026ldquo;;\u0026rdquo;. Because the availability of multiple values, use expression such as \u0026rsquo;D\u0026rsquo; in Polyphen2_HDIV_pred instead of \u0026rsquo;D\u0026rsquo; = Polyphen2_HDIV_pred to filter variants that are probably damaging. Missing entries: 17,084,053 (19.1% of 89,617,785 records) Unique Entries: 83,942\nField: Polyphen2_HVAR_score_max Type: float Comment: The maximum (most damaging) value of all Polyphen2 score based on HumVar, i.e. hvar_prob. Use Polyphen2_HVAR_score_all to get a list of all scores. Missing entries: 17,086,068 (19.1% of 89,617,785 records) Unique Entries: 1,001 Range: 0 - 1\nField: Polyphen2_HVAR_score Type: string Comment: Polyphen2 score based on HumVar, i.e. hvar_prob. The score ranges from 0 to 1, and the corresponding prediction is \u0026ldquo;probably damaging\u0026rdquo; if it is in [0.909,1]; \u0026ldquo;possibly damaging\u0026rdquo; if it is in [0.447,0.908]; \u0026ldquo;benign\u0026rdquo; if it is in [0,0.446]. Score cutoff for binary classification is 0.5, i.e. the prediction is \u0026ldquo;neutral\u0026rdquo; if the score is smaller than 0.5 and \u0026ldquo;deleterious\u0026rdquo; if the score is larger than 0.5. Multiple entries separated by \u0026ldquo;;\u0026rdquo;. Missing entries: 17,084,053 (19.1% of 89,617,785 records) Unique Entries: 10,999,020\nField: Polyphen2_HVAR_pred Type: string Comment: Polyphen2 prediction based on HumVar, \u0026ldquo;D\u0026rdquo; (\u0026ldquo;porobably damaging\u0026rdquo;), \u0026ldquo;P\u0026rdquo; (\u0026ldquo;possibly damaging\u0026rdquo;) and \u0026ldquo;B\u0026rdquo; (\u0026ldquo;benign\u0026rdquo;). Multiple entries separated by \u0026ldquo;;\u0026rdquo;. Because the availability of multiple values, use expression such as \u0026rsquo;D\u0026rsquo; in Polyphen2_HVAR_pred instead of \u0026rsquo;D\u0026rsquo; = Polyphen2_HVAR_pred to filter variants that are probably damaging. Missing entries: 17,084,053 (19.1% of 89,617,785 records) Unique Entries: 83,681\nField: LRT_score Type: float Comment: The original LRT two-sided p-value (LRTori). Missing entries: 21,548,464 (24.0% of 89,617,785 records) Unique Entries: 826,817 Range: 0 - 1\nField: LRT_score_converted Type: float Comment: Converted LRT original p-value (LRTnew). We converted the LRTori to a score suggested by our Human Muation (2011) paper: LRTnew=1-LRTori*0.5 if Omega=1. Missing entries: 21,548,464 (24.0% of 89,617,785 records) Unique Entries: 1,168,826 Range: 0 - 1\nField: LRT_pred Type: string Comment: LRT prediction, D(eleterious), N(eutral) or U(nknown) Missing entries: 21,548,464 (24.0% of 89,617,785 records) Unique Entries: 3\nField: MutationTaster_score Type: float Comment: MutationTaster score Missing entries: 1,143,911 (1.3% of 89,617,785 records) Unique Entries: 598,533 Range: 0 - 1\nField: MutationTaster_score_converted Type: float Comment: The converted score suggested by our Human Mutation (2011) paper: if the prediction is \u0026ldquo;A\u0026rdquo; or \u0026ldquo;D\u0026rdquo; MTnew=MTori; if the prediction is \u0026ldquo;N\u0026rdquo; or \u0026ldquo;P\u0026rdquo;, MTnew=1-MTori. Missing entries: 4,373,664 (4.9% of 89,617,785 records) Unique Entries: 999,050 Range: 0 - 1\nField: MutationTaster_pred Type: string Comment: MutationTaster prediction, \u0026ldquo;A\u0026rdquo; (\u0026ldquo;disease_causing_automatic\u0026rdquo;), \u0026ldquo;D\u0026rdquo; (\u0026ldquo;disease_causing\u0026rdquo;), \u0026ldquo;N\u0026rdquo; (\u0026ldquo;polymorphism\u0026rdquo;) or \u0026ldquo;P\u0026rdquo; (\u0026ldquo;polymorphism_automatic\u0026rdquo;) Missing entries: 1,143,911 (1.3% of 89,617,785 records) Unique Entries: 4\nField: MutationAssessor_score Type: float Comment: MutationAssessor functional impact combined score (MAori) Missing entries: 14,986,410 (16.7% of 89,617,785 records) Unique Entries: 2,145 Range: -5.545 - 5.975\nField: MutationAssessor_score_converted Type: float Comment: Scaled to 0-1: MAnew=(MAori-(-5.545))/(5.975-(-5.545)) Missing entries: 14,986,410 (16.7% of 89,617,785 records) Unique Entries: 2,139 Range: 0 - 1\nField: MutationAssessor_pred Type: string Comment: MutationAssessor\u0026rsquo;s functional impact of a variant : predicted functional (high, medium), predicted non- functional (low, neutral)\u0026rdquo; Please refer to Reva et al. Nucl. Acids Res. (2011) 39(17):e118 for details Missing entries: 14,986,410 (16.7% of 89,617,785 records) Unique Entries: 4\nField: FATHMM_score Type: float Comment: FATHMM default score (weighted for human inherited- disease mutations with Disease Ontology); If a score is smaller than -1.5 the corresponding NS is predicted as \u0026ldquo;D(AMAGING)\u0026rdquo;; otherwise it is predicted as \u0026ldquo;T(OLERATED)\u0026rdquo;. If there\u0026rsquo;s more than one scores associated with the same NS due to isoforms, the smallest score (most damaging) was used. Please refer to Shihab et al Hum. Mut. (2013) 34(1):57-65 for details Missing entries: 19,342,889 (21.6% of 89,617,785 records) Unique Entries: 2,135 Range: -16.13 - 10.64\nField: FATHMM_score_converted Type: float Comment: Scaled to 0-1 and reverse direction (the larger the more damaging): FATHMMnew=1-(FATHMMori-(-16.13))/(10.64-(-16.13)) Missing entries: 19,342,889 (21.6% of 89,617,785 records) Unique Entries: 2,135 Range: 0 - 1\nField: FATHMM_pred Type: string Comment: If a FATHMM_score is \u0026lt;=-1.5 the corresponding NS is predicted as \u0026ldquo;D(AMAGING)\u0026rdquo;; otherwise it is predicted as \u0026ldquo;T(OLERATED)\u0026rdquo;. Missing entries: 19,342,889 (21.6% of 89,617,785 records) Unique Entries: 2\nField: GERP_NR Type: float Comment: GERP++ neutral rate Missing entries: 541,067 (0.6% of 89,617,785 records) Unique Entries: 1,258 Range: 0.0465 - 6.17\nField: GERP_RS Type: float Comment: GERP++ RS score, the larger the score, the more conserved the site. Missing entries: 541,067 (0.6% of 89,617,785 records) Unique Entries: 8,412 Range: -12.3 - 6.17\nField: PhyloP_score Type: float Comment: PhyloP score, the larger the score, the more conserved the site. Missing entries: 64,695 (0.1% of 89,617,785 records) Unique Entries: 10,245 Range: -11.958 - 2.941\nField: mg29way_pi Type: string Comment: The estimated stationary distribution of A, C, G and T at the site, using SiPhy algorithm based on 29 mammals genomes. Missing entries: 0 Unique Entries: 7,239,991\nField: mg29way_logOdds Type: float Comment: SiPhy score based on 29 mammals genomes. The larger the score, the more conserved the site. Missing entries: 1,348,155 (1.5% of 89,617,785 records) Unique Entries: 223,955 Range: 0.0003 - 37.9718\nField: LRT_Omega Type: float Comment: estimated nonsynonymous-to-synonymous-rate ratio (reported by LRT) Missing entries: 21,548,464 (24.0% of 89,617,785 records) Unique Entries: 842,708 Range: 0 - 7780.54\nField: UniSNP_ids Type: string Comment: \u0026ldquo;rs numbers from UniSNP, which is a cleaned version of dbSNP build 129, in format: rs number1;rs number2;\u0026hellip;\u0026rdquo; Missing entries: 89,510,596 (99.9% of 89,617,785 records) Unique Entries: 100,701\nField: KGp1_AC Type: integer Comment: Alternative allele count in the whole 1000Gp1 data. Missing entries: 89,278,976 (99.6% of 89,617,785 records) Unique Entries: 2,172 Range: 0 - 2184\nField: KGp1_AF Type: float Comment: Alternative allele frequency in the whole 1000Gp1 data. Missing entries: 89,278,976 (99.6% of 89,617,785 records) Unique Entries: 2,571 Range: 0 - 1\nField: KGp1_AFR_AC Type: integer Comment: Alternative allele counts in the 1000Gp1 African descendent samples. Missing entries: 89,278,976 (99.6% of 89,617,785 records) Unique Entries: 493 Range: 0 - 492\nField: KGp1_AFR_AF Type: float Comment: Alternative allele frequency in the 1000Gp1 African descendent samples. Missing entries: 89,278,976 (99.6% of 89,617,785 records) Unique Entries: 1,062 Range: 0 - 1\nField: KGp1_EUR_AC Type: integer Comment: Alternative allele counts in the 1000Gp1 European descendent samples. Missing entries: 89,278,976 (99.6% of 89,617,785 records) Unique Entries: 759 Range: 0 - 758\nField: KGp1_EUR_AF Type: float Comment: Alternative allele frequency in the 1000Gp1 European descendent samples. Missing entries: 89,278,976 (99.6% of 89,617,785 records) Unique Entries: 1,185 Range: 0 - 1\nField: KGp1_AMR_AC Type: integer Comment: Alternative allele counts in the 1000Gp1 American descendent samples. Missing entries: 89,278,976 (99.6% of 89,617,785 records) Unique Entries: 363 Range: 0 - 362\nField: KGp1_AMR_AF Type: float Comment: Alternative allele frequency in the 1000Gp1 American descendent samples. Missing entries: 89,278,976 (99.6% of 89,617,785 records) Unique Entries: 735 Range: 0 - 1\nField: KGp1_ASN_AC Type: integer Comment: Alternative allele counts in the 1000Gp1 Asian descendent samples. Missing entries: 89,278,976 (99.6% of 89,617,785 records) Unique Entries: 573 Range: 0 - 572\nField: KGp1_ASN_AF Type: float Comment: Alternative allele frequency in the 1000Gp1 Asian descendent samples. Missing entries: 89,278,976 (99.6% of 89,617,785 records) Unique Entries: 939 Range: 0 - 1\nField: ESP6500_AA_AF Type: float Comment: Alternative allele frequency in the Afrian American samples of the NHLBI GO Exome Sequencing Project (ESP6500 data set). Missing entries: 88,817,528 (99.1% of 89,617,785 records) Unique Entries: 27,424 Range: 0 - 1\nField: ESP6500_EA_AF Type: float Comment: Alternative allele frequency in the European American samples of the NHLBI GO Exome Sequencing Project (ESP6500 data set). Missing entries: 88,817,528 (99.1% of 89,617,785 records) Unique Entries: 22,975 Range: 0 - 1\n  As a quick example, one can use dbNSFP to annotate all of the \u0026ldquo;damaging\u0026rdquo; non-synonymous variants from a list of variants. In this example, we find all of the variants predicted to be damaging by SIFT and PolyPhen2 from the master variant table, and we record these variants into a new table called \u0026ldquo;damaging_ns_snps\u0026rdquo;.\nvtools select variant \u0026quot;SIFT_pred = 'D' OR PolyPhen2_HDIV_pred like '%D%'\u0026quot; -t damaging_ns_snps  dbNSFP_gene % vtools use dbNSFP_gene --linked_by refGene.name2 % vtools show annotation dbNSFP_gene -v2 Annotation database dbNSFP_gene (version 2_1) Description: dbNSFP_gene version 2.1, maintained by Dr. Xiaoming Liu from UTSPH. Please cite \u0026quot;Liu X, Jian X, and Boerwinkle E. 2011. dbNSFP: a lightweight database of human non-synonymous SNPs and their functional predictions. Human Mutation. 32:894-899\u0026quot; and \u0026quot;Liu X, Jian X, and Boerwinkle E. 2013. dbNSFP v2.0: A Database of Human Nonsynonymous SNVs and Their Functional Predictions and Annotations. Human Mutation. 34:E2393-E2402.\u0026quot; if you find this database useful. Database type: field Reference genome *: Gene_name Gene_name Gene symbol from HGNC Ensembl_gene Ensembl gene id (from HGNC) chr Chromosome number (from HGNC) Gene_old_names Old gene sybmol (from HGNC) Gene_other_names Other gene names (from HGNC) Uniprot_acc Uniprot acc number (from HGNC and Uniprot) Uniprot_id Uniprot id (from HGNC and Uniprot) Entrez_gene_id Entrez gene id (from HGNC) CCDS_id CCDS id (from HGNC) Refseq_id Refseq gene id (from HGNC) ucsc_id UCSC gene id (from HGNC) MIM_id MIM gene id (from HGNC) Gene_full_name Gene full name (from HGNC) Pathway_Uniprot Pathway(s) the gene belongs to (from Uniprot) Pathway_ConsensusPathDB Pathway(s) the gene belongs to (from ConsensusPathDB) Function_description Function description of the gene (from Uniprot) Disease_description Disease(s) the gene caused or associated with (from Uniprot) MIM_phenotype_id MIM id(s) of the phenotype the gene caused or associated with (from Uniprot) MIM_disease MIM disease name(s) with MIM id(s) in \u0026quot;[]\u0026quot; (from Uniprot) Trait_association_GWAS Trait(s) the gene associated with (from GWAS catalog) GO_Slim_biological_process GO Slim terms for biological process GO_Slim_cellular_component GO Slim terms for cellular component GO_Slim_molecular_function GO Slim terms for molecular function Expression_egenetics Tissues/organs the gene expressed in (egenetics data from BioMart) Expression_GNF_Atlas Tissues/organs the gene expressed in (GNF/Atlas data from BioMart) Interactions_IntAct Other genes the gene interacted with (from IntAct) gene name followed by Pubmed id in \u0026quot;[]\u0026quot; Interactions_BioGRID Other genes the gene interacted with (from BioGRID) gene name followed by Pubmed id in \u0026quot;[]\u0026quot; Interactions_ConsensusPathDB Other genes the gene interacted with (from ConsensusPathDB) gene name followed by interaction confidence in \u0026quot;[]\u0026quot; P_HI Estimated probability of haploinsufficiency of the gene from doi:10.1371/journal.pgen.1001154) P_rec Estimated probability that gene is a recessive disease gene from doi:10.1126/science.1215040) Known_rec_info Known recessive status of the gene (from DOI] 10.1126/science.1215040) \u0026quot;lof-tolerant = seen in homozygous state in at least one 1000G individual\u0026quot; \u0026quot;recessive = known OMIM recessive disease\u0026quot; original annotations from DOI:10.1126/science.1215040) Essential_gene Essential (\u0026quot;E\u0026quot;) or Non-essential phenotype-changing (\u0026quot;N\u0026quot;) based on Mouse Genome Informatics database. from doi:10.1371/journal.pgen.1003484  dbNSFP_light This light version of dbNSFP is only available for dbNSFP 1.0.\nvtools show annotation dbNSFP_light -v2 Annotation database dbNSFP_light (version hg18_hg19_1.3) Description: dbNSFP_light version 1.0, maintained by Xiaoming Liu from UTSPH. Please cite \u0026quot;Liu X, Jian X, and Boerwinkle E. 2011. dbNSFP: a lightweight database of human non-synonymous SNPs and their functional predictions. Human Mutation. 32:894-899\u0026quot; if you find this database useful. Database type: variant Number of records: 73,968,886 Number of distinct variants: 73,754,006 Reference genome hg18: ['chr', 'pos', 'ref', 'alt'] Reference genome hg19: ['chr', 'pos', 'ref', 'alt'] Field: chr Type: string Missing entries: 0 Unique Entries: 24 Field: pos Type: integer Missing entries: 0 Unique Entries: 24,918,243 Range: 4381 - 247179185 Field: ref Type: string Comment: Reference nucleotide allele (as on the + strand) Missing entries: 0 Unique Entries: 4 Field: alt Type: string Comment: Alternative nucleotide allele (as on the + strand) Missing entries: 0 Unique Entries: 4 Field: aaref Type: string Comment: reference amino acid Missing entries: 0 Unique Entries: 21 Field: aaalt Type: string Comment: alternative amino acid Missing entries: 0 Unique Entries: 21 Field: hg19pos Type: integer Comment: physical position on the chromosome as to hg19 (1-based coordinate) Missing entries: 33 (0.0% of 73,968,886 records) Unique Entries: 24,900,697 Range: 15925 - 249212562 Field: PhyloP_score Type: float Comment: PhyloP score, phyloPnew=1-0.5x10^phyloPori if phyloPori\u0026gt;0 or phyloPnew=0.5x10^phyloPori if phyloPori\u0026lt;0 Missing entries: 21,677 (0.0% of 73,968,886 records) Unique Entries: 6,237 Range: 0 - 0.995645X Field: SIFT_score Type: float Comment: SIFT score, SIFTnew=1-SIFTori Missing entries: 570,924 (0.8% of 73,968,886 records) Unique Entries: 167 Range: 0 - 195561991 Field: Polyphen2_score Type: float Comment: Polyphen2 score, i.e. pph2_prob Missing entries: 10,400,231 (14.1% of 73,968,886 records) Unique Entries: 1,005 Range: 0 - T Field: LRT_score Type: float Comment: LRT score, LRTnew=1-LRTorix0.5 if \u0026lt;1, or LRTnew=LRTorix0.5 if \u0026gt;=1 Missing entries: 7,795,201 (10.5% of 73,968,886 records) Unique Entries: 780,594 Range: 0 - T Field: LRT_pred Type: string Comment: LRT prediction, D(eleterious), N(eutral) or U(nknown) Missing entries: 7,795,201 (10.5% of 73,968,886 records) Unique Entries: 17 Field: MutationTaster_score Type: float Comment: MutationTaster score Missing entries: 5,514,812 (7.5% of 73,968,886 records) Unique Entries: 999,920 Range: 0 - W Field: MutationTaster_pred Type: string Comment: MutationTaster prediction, \u0026quot;A\u0026quot; (\u0026quot;disease_causing_automatic\u0026quot;), \u0026quot;D\u0026quot; (\u0026quot;disease_causing\u0026quot;), \u0026quot;N\u0026quot; (\u0026quot;polymorphism\u0026quot;) or \u0026quot;P\u0026quot; (\u0026quot;polymorphism_automatic\u0026quot;) Missing entries: 5,514,843 (7.5% of 73,968,886 records) Unique Entries: 6 Field: LRT_Omega Type: float Comment: estimated nonsynonymous-to-synonymous-rate ratio (reported by LRT) Missing entries: 7,795,201 (10.5% of 73,968,886 records) Unique Entries: 837,566 Range: 0 - 0.995645X Field: GERP_NR Type: float Comment: GERP++ netral rate Missing entries: 0 Unique Entries: 1,218 Range: 0 - 195561992 Field: GERP_RS Type: float Comment: GERP++ RS score Missing entries: 0 Unique Entries: 8,344 Range: -11.6 - T Field: uniprot_acc Type: string Comment: Uniprot accession number Missing entries: 0 Unique Entries: 18,766 Field: uniprot_id Type: string Comment: Uniprot ID number Missing entries: 0 Unique Entries: 17,552 Field: uniprot_aapos Type: integer Comment: amino acid position as to Uniprot Missing entries: 0 Unique Entries: 8,815 Range: 0.53741 - Y  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_report/discordance_rate/",
	"title": "discordance_rate",
	"tags": [],
	"description": "",
	"content": " Usage % vtools_report discordance_rate -h usage: vtools_report discordance_rate [-h] [-s [SAMPLES [SAMPLES ...]]] [--genotypes [GENOTYPES [GENOTYPES ...]]] [-v {0,1,2}] Report discordance rate, namely the number of genotype calls that differ between a pair of samples divided by the total number of SNPs for which both calls are non-missing, between pairs of samples. The statistics can be calculated for all samples or selected samples specified by parameter --samples. This command output a n by n matrix with sample names in the header. Items (i,j) in this matrix is numbers in the format of diff/all for i \u0026gt;= j, and the actual ratio for i \u0026lt; j. This rate is affected by runtime option treat_missing_as_wildtype which assumes that variants that do not appear in a sample (or filtered by quality score etc) are wildtype alleles. optional arguments: -h, --help show this help message and exit -s [SAMPLES [SAMPLES ...]], --samples [SAMPLES [SAMPLES ...]] Limiting variants from samples that match conditions that use columns shown in command 'vtools show sample' (e.g. 'aff=1', 'filename like \u0026quot;MG%\u0026quot;'). --genotypes [GENOTYPES [GENOTYPES ...]] Limiting genotypes from samples that match conditions that involves genotype fields (e.g. filter by quality score, with fields shown in command 'vtools show genotypes'). If a variant is filtered for one sample but not another, it will be included if runtime option $treat_missing_as_wildtype is set to True, and discarded otherwise. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information of vtools and vtools_report. Debug information are always recorded in project and vtools_report log files.  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/misc/keggpathway/",
	"title": "keggPathway",
	"tags": [],
	"description": "",
	"content": " About keggPathway This database provides KEGG pathway IDs and a pathway description for genes with CCDS IDs. If you would like to annotate variants to these KEGG pathways, you first need to annotate your variants with CCDS IDs. Variant tools databases such as ccdsGene annotates variants with CCDS IDs (see example below).\nFields  ccdsId CCDS gene ID KgID Kegg pathway ID KgDesc Description of pathway  keggPathway vtools show annotation keggPathway -v2 Annotation database keggPathway (version 20110823) Description: kegg pathway for CCDS genes Database type: attribute Number of records: 19,584 Reference genome *: ['ccdsId'] Field: ccdsId Type: string Comment: CCDS gene ID Missing entries: 0 Unique entries: 6,949 Field: KgID Type: string Comment: Kegg pathway ID Missing entries: 0 Unique entries: 209 Field: KgDesc Type: string Comment: Description of pathway Missing entries: 0 Unique entries: 209  Examples First we need to use dbNSFP in our project to annotate our variants with CCDS IDs:\nvtools use ccdsGene  We then load the keggPathway database linked by ccdsGene.name\nvtools use keggPathway --linked_by ccdsGene.name INFO: Opening project RA.proj WARNING: Cannot locate annotation database /Users/bpeng/vtools/ccdsKeggPathway WARNING: Cannot open annotation database /Users/bpeng/vtools/ccdsKeggPathway INFO: Downloading annotation database from https://cge.mdanderson.org/~bpeng1/User/annoDB/keggPathway.DB keggPathway.DB: 100.0% [=====================================\u0026gt;] 252 0.3/s in 00:00:00 INFO: Failed to download database or downloaded database unusable. INFO: Downloading keggPathway.txt.gz keggPathway.txt.gz: 100.0% [=====================================\u0026gt;] 107,677 103.0K/s in 00:00:01 INFO: Importing database keggPathway from sourece files ['/var/folders/7O/7OzyfGRoH+i7iQCDzTkba++++TQ/-Tmp-/tmpKqPYoN/keggPathway.txt.gz'] INFO: Importing annotation data from /var/folders/7O/7OzyfGRoH+i7iQCDzTkba++++TQ/-Tmp-/tmpKqPYoN/keggPathway.txt.gz keggPathway.txt.gz: 100.0% [=====================================\u0026gt;] 11,719 26.8K/s in 00:00:00 INFO: 19584 records handled, 0 ignored. INFO: Creating indexes (this can take quite a while) INFO: Using annotation DB keggPathway in project RA.  At the end of vtools show fields output, we can see\nkeggPathway.ccdsId CCDS gene ID keggPathway.KgID Kegg pathway ID keggPathway.KgDesc Description of pathway  Now, we can see which pathways our variants belong to:\nvtools output NS_SNV chr pos ref alt genename kgID kgDesc -l 10 INFO: Opening project RA.proj INFO: Writing output 1 878522 T C NOC2L NA NA 1 899101 G C PLEKHN1 NA NA 1 939471 G A ISG15 hsa04622 RIG-I-like receptor signaling pathway 1 1190055 C G UBE2J2 hsa04120 Ubiquitin mediated proteolysis 1 1190055 C G UBE2J2 hsa05012 Parkinson's disease 1 1216741 C T SCNN1D NA NA 1 1541790 T C MIB2 NA NA 1 1656111 G A SLC35E2 NA NA 1 1675900 G T NADK hsa00760 Nicotinate and nicotinamide metabolism 1 1675900 G T NADK hsa01100 Metabolic pathways  and we can select variants that belong to a pathway, for example,\nvtools select NS_SNV 'kgID=\u0026quot;hsa00760\u0026quot;' --output chr pos ref alt genename kgDesc INFO: Opening project RA.proj INFO: Writing output 1 1675900 G T NADK Metabolic pathways 1 1675900 G T NADK Nicotinate and nicotinamide metabolism 11 70847195 G C NADSYN1 Metabolic pathways 11 70847195 G C NADSYN1 Nicotinate and nicotinamide metabolism 11 70862326 A C NADSYN1 Metabolic pathways 11 70862326 A C NADSYN1 Nicotinate and nicotinamide metabolism 16 29615851 A G QPRT Metabolic pathways 16 29615851 A G QPRT Nicotinate and nicotinamide metabolism 2 18629604 C T NT5C1B Metabolic pathways 2 18629604 C T NT5C1B Nicotinate and nicotinamide metabolism 2 18629604 C T NT5C1B Purine metabolism 2 18629604 C T NT5C1B Pyrimidine metabolism 2 18629604 C T NT5C1B Metabolic pathways 2 18629604 C T NT5C1B Nicotinate and nicotinamide metabolism 2 18629604 C T NT5C1B Purine metabolism 2 18629604 C T NT5C1B Pyrimidine metabolism 2 201242634 A G AOX1 Drug metabolism - cytochrome P450 2 201242634 A G AOX1 Metabolic pathways 2 201242634 A G AOX1 Nicotinate and nicotinamide metabolism 2 201242634 A G AOX1 Tryptophan metabolism 2 201242634 A G AOX1 Tyrosine metabolism 2 201242634 A G AOX1 Valine, leucine and isoleucine degradation 2 201242634 A G AOX1 Vitamin B6 metabolism 4 15318290 G A BST1 Calcium signaling pathway 4 15318290 G A BST1 Metabolic pathways 4 15318290 G A BST1 Nicotinate and nicotinamide metabolism 6 86255952 A G NT5E Metabolic pathways 6 86255952 A G NT5E Nicotinate and nicotinamide metabolism 6 86255952 A G NT5E Purine metabolism 6 86255952 A G NT5E Pyrimidine metabolism 10 104924699 T C NT5C2 Metabolic pathways 10 104924699 T C NT5C2 Nicotinate and nicotinamide metabolism 10 104924699 T C NT5C2 Purine metabolism 10 104924699 T C NT5C2 Pyrimidine metabolism 16 29613945 C T QPRT Metabolic pathways 16 29613945 C T QPRT Nicotinate and nicotinamide metabolism 4 15318350 G A BST1 Calcium signaling pathway 4 15318350 G A BST1 Metabolic pathways 4 15318350 G A BST1 Nicotinate and nicotinamide metabolism 6 132103113 G A ENPP3 Metabolic pathways 6 132103113 G A ENPP3 Nicotinate and nicotinamide metabolism 6 132103113 G A ENPP3 Pantothenate and CoA biosynthesis 6 132103113 G A ENPP3 Purine metabolism 6 132103113 G A ENPP3 Riboflavin metabolism 6 132103113 G A ENPP3 Starch and sucrose metabolism 2 201234575 A G AOX1 Drug metabolism - cytochrome P450 2 201234575 A G AOX1 Metabolic pathways 2 201234575 A G AOX1 Nicotinate and nicotinamide metabolism 2 201234575 A G AOX1 Tryptophan metabolism 2 201234575 A G AOX1 Tyrosine metabolism 2 201234575 A G AOX1 Valine, leucine and isoleucine degradation 2 201234575 A G AOX1 Vitamin B6 metabolism 5 102922572 T C NUDT12 Nicotinate and nicotinamide metabolism 5 102922572 T C NUDT12 Peroxisome 14 20010446 G A PNP Metabolic pathways 14 20010446 G A PNP Nicotinate and nicotinamide metabolism 14 20010446 G A PNP Purine metabolism 14 20010446 G A PNP Pyrimidine metabolism 2 18629637 G T NT5C1B Metabolic pathways 2 18629637 G T NT5C1B Nicotinate and nicotinamide metabolism 2 18629637 G T NT5C1B Purine metabolism 2 18629637 G T NT5C1B Pyrimidine metabolism 2 18629637 G T NT5C1B Metabolic pathways 2 18629637 G T NT5C1B Nicotinate and nicotinamide metabolism 2 18629637 G T NT5C1B Purine metabolism 2 18629637 G T NT5C1B Pyrimidine metabolism 11 70869465 C T NADSYN1 Metabolic pathways 11 70869465 C T NADSYN1 Nicotinate and nicotinamide metabolism 5 43691831 C T NNT Metabolic pathways 5 43691831 C T NNT Nicotinate and nicotinamide metabolism 1 1675941 G A NADK Metabolic pathways 1 1675941 G A NADK Nicotinate and nicotinamide metabolism 6 86255962 T C NT5E Metabolic pathways 6 86255962 T C NT5E Nicotinate and nicotinamide metabolism 6 86255962 T C NT5E Purine metabolism 6 86255962 T C NT5E Pyrimidine metabolism 4 15389158 C T CD38 Calcium signaling pathway 4 15389158 C T CD38 Hematopoietic cell lineage 4 15389158 C T CD38 Metabolic pathways 4 15389158 C T CD38 Nicotinate and nicotinamide metabolism 11 70870707 G A NADSYN1 Metabolic pathways 11 70870707 G A NADSYN1 Nicotinate and nicotinamide metabolism 5 43736078 A G NNT Metabolic pathways 5 43736078 A G NNT Nicotinate and nicotinamide metabolism 11 70886273 G A NADSYN1 Metabolic pathways 11 70886273 G A NADSYN1 Nicotinate and nicotinamide metabolism 17 70638943 G A NT5C Metabolic pathways 17 70638943 G A NT5C Nicotinate and nicotinamide metabolism 17 70638943 G A NT5C Purine metabolism 17 70638943 G A NT5C Pyrimidine metabolism 9 76873744 T G C9orf95 Nicotinate and nicotinamide metabolism 6 132086873 A G ENPP3 Metabolic pathways 6 132086873 A G ENPP3 Nicotinate and nicotinamide metabolism 6 132086873 A G ENPP3 Pantothenate and CoA biosynthesis 6 132086873 A G ENPP3 Purine metabolism 6 132086873 A G ENPP3 Riboflavin metabolism 6 132086873 A G ENPP3 Starch and sucrose metabolism  The result of the above example can be confusing because the output displays multiple pathways, not only the one we specified. The reason is that this query is identifying variants in your specified pathway and then it generates a report of these variants with all the pathways that they might be in. Genes often belong to multiple pathways. You can filter the output again, or output only the variant information (chromosome, position) if you would like to get a list of unique variants.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/utilities/_md5sumd/",
	"title": "md5sumd",
	"tags": [],
	"description": "",
	"content": " Generate and check with MD5 checksum for files and directories ChangeLog  Apr. 19, 2013: Minor error message improvement. Mar. 20, 2013: Version 1.0.1 with format change to handle non-ASCII filenames. February, 2013: Initial public release of version 1.0.  Download  Source code: md5sumd? (use python or python3 to run it) Windows executable: md5sumd.exe? MacOSX executable: md5sumd_macosx.zip? (decompress to get a binary file)  NOTE: If you have a filesystem with non-ASCII filenames encoded not in UTF-8, the directory md5sum might not work across platform unless you use the Python 3 version of the script (use python3 on source code). There is no binary distribution for the Python3 version due to packaging difficulties.\nRational When we transfer or backup a large number of files, it is difficult to verify if the files have been copied correctly. Although it is possible to compare files and directories with original source using dedicated file/directory comparison tools, or commands such as rsync -acv, the source data is not always available and it can be very slow to compare two large directories.\nThis script tries to address this problem by extending the standard md5sum program to allow it to handle directories, and produce partial checksum during the handling of large files. The MD5 checksum of the directory is generated by calculating the MD5 checksum of all files and subdirectories, and generate a checksum from a manifest file from these values. Entries in the manifest file are sorted so that the order at which files are processed does not affect the directory checksum. Because the manifest file contains file size information, the choice to calculate MD5 checksum based only on 1G of data (not necessarily the first 1G) of large files should be safe.\nIf you are extremely impatient, you can skip the rest of this page and use command\n% md5sumd * -v | gzip \u0026gt; .manifest.md5.gz  to generate a fingerprint for all files under a directory and save it to file .manifest.md5.gz, and use command\n% md5sumd -c .manifest.md5.gz  to check if the content of the directory has been altered during file transferring, system failure, or unintentional changes.\nUsage % md5sumd -h usage: md5sumd [-h] [--version] [-c [CHECKSUM]] [-v] [FILE_OR_DIR [FILE_OR_DIR ...]] A tool that calculates the MD5 checksum of files and directories, and use it to check the integrity of these files and directories. It has a interface that is similar to the md5sum command, with support for checksum of directories. positional arguments: FILE_OR_DIR Calculate MD5 signature of one or more files and directories and print MD5 checksums to the standard output. optional arguments: -h, --help show this help message and exit --version show program's version number and exit -c [CHECKSUM], --check [CHECKSUM] Check the content of one or more files and directories using a file that contains the checksum of these files and directories. Gippped checksum file is acceptable. If a file is unspecified or is -, read from the standard input. -v, --verbose If specified, this program will output checksum for all files when the checksum of a directory is calculated. Such information will help the --check command to figure out what files have been changed if a directory checksum mismatch happens. This option will also enable a progress bar for file scanning.  Details Comparing two directories Let us calculate the MD5 of a directory:\n% md5sumd vtools b93f839744cd53fb87981c8254cc7511 vtools  If we copy the directory to somewhere else, we can see the signature is still the same\n% cp -r vtools ~/Temp % md5sumd ~/Temp/vtools b93f839744cd53fb87981c8254cc7511 ~/Temp/vtools/  If we change anything in that directory, the signature will be different\n% rm ~/Temp/vtools/*.pyc % md5sumd ~/Temp/vtools c71b7236b19feb1682f1c7039e5df8f2 ~/Temp/vtools/  Use directory md5 checksum to validate directory content Now let us save the md5 checksum to a file,\n% md5sumd vtools \u0026gt; vtools.md5 % md5sumd -c vtools.md5 vtools: OK  When we transfer the directory to another place, we can still use this command to validate its content as long as the directory name is not changed. Now, if we change the directory, and check again,\n% rm -rf vtools/cache % md5sumd --check vtools.md5 vtools: FAILED  Getting detailed information about directory changes. It can be frustrating when a directory checksum mismatch happens but you have no idea what has been changed. An interesting feature of the md5sumd command is that it can generate and output detailed file-level MD5 information and use it to figure out what exactly have been changed to a directory.\n% md5sumd vtools -v \u0026gt; vtools.md5 Scanning 34366 files: 100%[====================================] 2,095,623,045 48.6M/s in 00:00:430  As you can see, the --verbose option even enables a progress bar, which can be helpful for directories that contain a large number of files. The output of this command has a lot more information, and it is interesting to see that there are 1,843,428 files of a total size of 28,615,195,835 under this directory.\n% head -5 vtools.md5 2efce10e113804fc8a6b4e81ffd54f2e vtools ## MD5 type num_files num_dirs filesize total_num_files total_filesize name #2efce10e113804fc8a6b4e81ffd54f2e d 34366 2760 2095623045 1843428 28615195835 vtools #d75dc7768044f85895001913ae2a19b1 - 1 0 191368 1 191368 vtools/MANIFEST #80e0735f4483d04b6cd28cff95b9b28c - 1 0 4260 1 4260 vtools/MANIFEST.in  Then, if we change the directory a little bit and check it with the --check option,\n% rm -f vtools/*pyc % rm vtools/source/*temp % md5sumd -c vtools.md5 vtools/source: directory modified. vtools/source/cgatools_wrap_py3.cpp_temp: file removed. vtools/source/cgatools_py3.py_temp: file removed. vtools/source/assoTests_wrap_py3.cpp_temp: file removed. vtools/source/vt_sqlite3_py3.py_temp: file removed. vtools/setup.pyc: file removed. vtools/source/assoTests_py3.py_temp: file removed. vtools: FAILED  Working with multiple files and directories Although the main strength of md5sumd is its ability to calculate directory md5, it works well with files as well. For example, we can generate a md5 for all files and directories under a directory using command:\n% cd vtools % md5sumd -v * \u0026gt; vtools.md5 Scanning 65 files under annotation: 100%[============================] 194,919 17.0M/s in 00:00:000 Scanning 32123 files under boost_1_49_0: 100%[===================] 281,585,238 16.4M/s in 00:00:170 Scanning 700 files under build: 100%[============================] 180,236,646 97.0M/s in 00:00:010 Scanning 38 files under cgatools: 100%[===============================] 205,326 7.0M/s in 00:00:000 Scanning 10 files under dist: 100%[=============================] 103,912,176 265.9M/s in 00:00:000 Scanning 15 files under format: 100%[==================================] 33,932 5.0M/s in 00:00:000 Scanning 485 files under gsl: 100%[=================================] 1,758,005 7.2M/s in 00:00:000 Scanning 28 files under libplinkio: 100%[=============================] 138,531 9.9M/s in 00:00:000 Scanning 659 files under pyinstaller: 100%[========================] 9,993,226 33.3M/s in 00:00:000 Scanning 39 files under source: 100%[=============================] 2,637,686 156.2M/s in 00:00:000 Scanning 43 files under sqlite: 100%[=============================] 5,511,571 188.0M/s in 00:00:000 Scanning 121 files under test: 100%[==========================] 1,507,339,718 307.4M/s in 00:00:040  If anything has been changes, we can check the change of contents using command\n% rm test/*DB* % md5sumd --check vtools.md5 MANIFEST: OK MANIFEST.in: OK MANIFEST_local.txt: OK README: OK annotation: OK boost_1_49_0: OK build: OK build_executable.py: OK call_variants.py: OK cgatools: OK code_style.cfg: OK dist: OK format: OK gsl: OK libplinkio: OK manage_resource.py: OK pyinstaller: OK release.py: OK setup.py: OK source: OK sqlite: OK test/dbSNP.DB: file removed. test/gwasCatalog.DB: file removed. test/evs.DB: file removed. test/testNSFP-1.1_0.DB.gz: file removed. test/testThousandGenomes.DB: file removed. test/evs-hg19_20111107.DB.gz: file removed. test/dbSNP.DB-journal: file removed. test/evs-hg19_20111107.DB: file removed. test/testNSFP.DB: file removed. test: FAILED vtools: OK vtools.md5: FAILED vtools.spec: OK vtools_report: OK vtools_report.log: OK vtools_report.spec: OK  Support for gzipped checksum file The md4sumd command can read directly from a gzipped checksum file. This is useful when the checksum file gets large when the --verbose option is used to list checksums of all files and directories under a large directory. For example, you can generate a checksum file using command\n% md5sumd vtools gsl -v | gzip \u0026gt; checksum.gz  and check it directory using command\n% md5sumd --check checksum.gz  Check md5 checksum read from standard input The md5sumd --check command will read from standard input if no filename (python 2.7 or higher) or a filename with name - is specified. For example,\n% md5sumd vtools gsl | md5sumd -c - vtools: OK gsl: OK  Note that md5sumd -c - does not accept gzipped stream directly so if you have a gzipped manifest, you will need to pipe it through gzip -d before it is sent to the md5sumd -c - command.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/functions/mut_sequence/",
	"title": "mut_sequence",
	"tags": [],
	"description": "",
	"content": " Mutated sequence around variant site Usage Function mut_sequence(chr, start, end) returns the mutated sequence between start and end on chromosome chr of the reference genome (primary reference genome unless parameter --build is used to specify an alternative reference genome). If end is unspecified, mut_sequence(chr, pos) returns the mutated allele at the specified location.\nSimply put, function mut_sequence in\n% vtools output variant chr pos 'mut_sequence(chr, pos)'  returns the alternative allele at the variant site for SNPs, - for deletion, and XXXR for insertion of XXX before reference allele R.\n% vtools output variant chr pos 'mut_sequence(chr, pos, pos+5)'  returns the 5-base sequence at and after the variant sites with the variant for all variants in the master variant table.\nFunction mut_sequence will be identical to ref_sequence if the variant is outside of the specified region (e.g. different chr).\nDetails  Examples: output mutated sequence around variants Let us get a test project\n% vtools admin --load_snapshot vt_simple Downloading snapshot vt_simple.tar.gz from online INFO: Snapshot vt_simple has been loaded  It is not very useful but we can see the mutated sequence at the variant location,\n% vtools output variant chr pos ref alt 'mut_sequence(chr, pos)' -l 10 1 4540 G A A 1 5683 G T T 1 5966 T G G 1 6241 T C C 1 9992 C T T 1 9993 G A A 1 10007 G A A 1 10098 G A A 1 14775 G A A 1 16862 A G G  It is more useful to see the context of the variants\n% vtools output variant chr pos ref alt 'ref_sequence(chr, pos-1, pos+1)' 'mut_sequence(chr, pos-1, pos+1)' -l 10 1 4540 G A GGA GAA 1 5683 G T TGC TTC 1 5966 T G GTG GGG 1 6241 T C ATG ACG 1 9992 C T GCG GTG 1 9993 G A CGG CAG 1 10007 G A GGC GAC 1 10098 G A CGA CAA 1 14775 G A CGT CAT 1 16862 A G GAA GGA  Let us import some indels\n% vtools init test -f % vtools import SAMP3_complex_variants.vcf --build hg19 INFO: Importing variants from /Users/bpeng1/vtools/test/vcf/SAMP3_complex_variants.vcf (1/1) SAMP3_complex_variants.vcf: 100% [=======================] 184 20.8K/s in 00:00:00 INFO: 135 new variants (1 SNVs, 77 insertions, 58 deletions, 7 complex variants) from 184 lines are imported. Importing genotypes: 0 0.0/s in 00:00:00 Copying samples: 0 0.0/s in 00:00:00  and check how the sequences are affected\n% vtools output variant chr pos ref alt 'ref_sequence(chr, pos-1, pos+1)' 'mut_sequence(chr, pos-1, pos+1)' -l 10 1 10434 - C ACC ACCC 1 10440 C - ACC A-C 1 54788 C - TCC T-C 1 54790 - T CTT CTTT 1 63737 TAC - CTA C-- 1 63738 ACT CTA TAC TCT 1 81963 - AA TAA TAAAA 1 82134 - AAAAAAAAAAAAAA CAA CAAAAAAAAAAAAAAAA 1 82134 A - CAA C-A 1 83119 A - CAA C-A  (:exampleend\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/create_your_test/programming-in-vat/",
	"title": "programming in VAT",
	"tags": [],
	"description": "",
	"content": " Identify genotype - phenotype association Usage % vtools associate -h usage: vtools associate [-h] [--covariates [COVARIATES [COVARIATES ...]]] [--var_info [VAR_INFO [VAR_INFO ...]]] [--geno_info [GENO_INFO [GENO_INFO ...]]] [-m METHODS [METHODS ...]] [-g [GROUP_BY [GROUP_BY ...]]] [-s [COND [COND ...]]] [--genotypes [COND [COND ...]]] [--discard_samples [EXPR [EXPR ...]]] [--discard_variants [EXPR [EXPR ...]]] [--to_db annoDB] [-f] [-j N] [-v {0,1,2}] variants phenotypes Call one or more statistical association tests and return test results as fields to variants tested. optional arguments: -h, --help show this help message and exit -j N, --jobs N Number of processes to carry out association tests. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1). Genotype, phenotype, and covariates: variants Table of variants to be tested. phenotypes A list of phenotypes that will be passed to the association statistics calculator. Currently only a single phenotype is allowed. --covariates [COVARIATES [COVARIATES ...]] Optional phenotypes that will be passed to statistical tests as covariates. Values of these phenotypes should be integer or float. --var_info [VAR_INFO [VAR_INFO ...]] Optional variant information fields (e.g. minor allele frequency from 1000 genomes project) that will be passed to statistical tests. The fields could be any annotation fields of with integer or float values, including those from used annotation databases (use \u0026quot;vtools show fields\u0026quot; to see a list of usable fields). --geno_info [GENO_INFO [GENO_INFO ...]] Optional genotype fields (e.g. quality score of genotype calls, cf. \u0026quot;vtools show genotypes\u0026quot;) that will be passed to statistical tests. Note that the fields should exist for all samples that are tested. Association tests: -m METHODS [METHODS ...], --methods METHODS [METHODS ...] Method of one or more association tests. Parameters for each method should be specified together as a quoted long argument (e.g. --methods \u0026quot;m --alternative 2\u0026quot; \u0026quot;m1 --permute 1000\u0026quot;), although the common method parameters can be specified separately, as long as they do not conflict with command arguments. (e.g. --methods m1 m2 -p 1000 is equivalent to --methods \u0026quot;m1 -p 1000\u0026quot; \u0026quot;m2 -p 1000\u0026quot;.). You can use command 'vtools show tests' for a list of association tests, and 'vtools show test TST' for details about a test. Customized association tests can be specified as mod_name.test_name where mod_name should be a Python module (system wide or in the current directory), and test_name should be a subclass of NullTest. -g [GROUP_BY [GROUP_BY ...]], --group_by [GROUP_BY [GROUP_BY ...]] Group variants by fields. If specified, variants will be separated into groups and are tested one by one. Select and filter samples and genotypes: -s [COND [COND ...]], --samples [COND [COND ...]] Limiting variants from samples that match conditions that use columns shown in command 'vtools show sample' (e.g. 'aff=1', 'filename like \u0026quot;MG%\u0026quot;'). Each line of the sample table (vtools show samples) is considered as samples. If genotype of a physical sample is scattered into multiple samples (e.g. imported chromosome by chromosome), they should be merged using command vtools admin. --genotypes [COND [COND ...]] Limiting genotypes to those matching conditions that use columns shown in command 'vtools show genotypes' (e.g. 'GQ\u0026gt;15'). Genotypes failing such conditions will be regarded as missing genotypes. --discard_samples [EXPR [EXPR ...]] Discard samples that match specified conditions within each test group (defined by parameter --group_by). Currently only expressions in the form of \u0026quot;%(NA)\u0026gt;p\u0026quot; is providedted to remove samples that have more 100*p percent of missing values. --discard_variants [EXPR [EXPR ...]] Discard variant sites based on specified conditions within each test group. Currently only expressions in the form of '%(NA)\u0026gt;p' is provided to remove variant sites that have more than 100*p percent of missing genotypes. Note that this filter will be applied after \u0026quot;--discard_samples\u0026quot; is applied, if the latter also is specified. Output of test statistics: --to_db annoDB Name of a database to which results from association tests will be written. Groups with existing results in the database will be ignored unless parameter --force is used. -f, --force Analyze all groups including those that have recorded results in the result database.  Details Please check the VAT homepage? for details.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/",
	"title": "Application",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/",
	"title": "Association",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/association_analysis/",
	"title": "Association analysis",
	"tags": [],
	"description": "",
	"content": " Association Analysis Statistical Tests for Genotype/phenotype Associations The VAT association command We will introduce the basic usage of this command without diving into each association test. For a complete demonstration of all the tests please refer to the documentation for VAT (on the sidebar of this webpage).\nGetting started The general interface of vtools associate is as follows\n% vtools associate -h usage: vtools associate [-h] [--covariates [COVARIATES [COVARIATES ...]]] [--var_info [VAR_INFO [VAR_INFO ...]]] [--geno_info [GENO_INFO [GENO_INFO ...]]] [-m METHODS [METHODS ...]] [-g [GROUP_BY [GROUP_BY ...]]] [-s [COND [COND ...]]] [--genotypes [COND [COND ...]]] [--discard_samples [EXPR [EXPR ...]]] [--discard_variants [EXPR [EXPR ...]]] [--to_db annoDB] [-f] [-j N] [-v {0,1,2}] variants phenotypes Call one or more statistical association tests and return test results as fields to variants tested. optional arguments: -h, --help show this help message and exit -j N, --jobs N Number of processes to carry out association tests. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1). Genotype, phenotype, and covariates: variants Table of variants to be tested. phenotypes A list of phenotypes that will be passed to the association statistics calculator. Currently only a single phenotype is allowed. --covariates [COVARIATES [COVARIATES ...]] Optional phenotypes that will be passed to statistical tests as covariates. Values of these phenotypes should be integer or float. --var_info [VAR_INFO [VAR_INFO ...]] Optional variant information fields (e.g. minor allele frequency from 1000 genomes project) that will be passed to statistical tests. The fields could be any annotation fields of with integer or float values, including those from used annotation databases (use \u0026quot;vtools show fields\u0026quot; to see a list of usable fields). --geno_info [GENO_INFO [GENO_INFO ...]] Optional genotype fields (e.g. quality score of genotype calls, cf. \u0026quot;vtools show genotypes\u0026quot;) that will be passed to statistical tests. Note that the fields should exist for all samples that are tested. Association tests: -m METHODS [METHODS ...], --methods METHODS [METHODS ...] Method of one or more association tests. Parameters for each method should be specified together as a quoted long argument (e.g. --method \u0026quot;m --alternative 2\u0026quot; \u0026quot;m1 --permute 1000\u0026quot;), although the common method parameters can be specified separately, as long as they do not conflict with command arguments. (e.g. --method m1 m2 -p 1000 is equivalent to --method \u0026quot;m1 -p 1000\u0026quot; \u0026quot;m2 -p 1000\u0026quot;.). You can use command 'vtools show tests' for a list of association tests, and 'vtools show test TST' for details about a test. Customized association tests can be specified as mod_name.test_name where mod_name should be a Python module (system wide or in the current directory), and test_name should be a subclass of NullTest. -g [GROUP_BY [GROUP_BY ...]], --group_by [GROUP_BY [GROUP_BY ...]] Group variants by fields. If specified, variants will be separated into groups and are tested one by one. Select and filter samples and genotypes: -s [COND [COND ...]], --samples [COND [COND ...]] Limiting variants from samples that match conditions that use columns shown in command 'vtools show sample' (e.g. 'aff=1', 'filename like \u0026quot;MG%\u0026quot;'). Each line of the sample table (vtools show samples) is considered as samples. If genotype of a physical sample is scattered into multiple samples (e.g. imported chromosome by chromosome), they should be merged using command vtools admin. --genotypes [COND [COND ...]] Limiting genotypes to those matching conditions that use columns shown in command 'vtools show genotypes' (e.g. 'GQ\u0026gt;15'). Genotypes failing such conditions will be regarded as missing genotypes. --discard_samples [EXPR [EXPR ...]] Discard samples that match specified conditions within each test group (defined by parameter --group_by). Currently only expressions in the form of \u0026quot;%(NA)\u0026gt;p\u0026quot; is providedted to remove samples that have more 100*p percent of missing values. --discard_variants [EXPR [EXPR ...]] Discard variant sites based on specified conditions within each test group. Currently only expressions in the form of '%(NA)\u0026gt;p' is provided to remove variant sites that have more than 100*p percent of missing genotypes. Note that this filter will be applied after \u0026quot;--discard_samples\u0026quot; is applied, if the latter also is specified. Output of test statistics: --to_db annoDB Name of a database to which results from association tests will be written. Groups with existing results in the database will be ignored unless parameter --force is used. -f, --force Analyze all groups including those that have recorded results in the result database.  Each association test method (-m/--method) has its own commandline interface. To show all available association tests,\n% vtools show tests BurdenBt Burden test for disease traits, Morris \u0026amp; Zeggini 2009 BurdenQt Burden test for quantitative traits, Morris \u0026amp; Zeggini 2009 CFisher Fisher's exact test on collapsed variant loci, Li \u0026amp; Leal 2008 ....  To show usage of a particular test,\n% vtools show test CFisher Name: CFisher Description: Fisher's exact test on collapsed variant loci, Li \u0026amp; Leal 2008 usage: vtools associate --method CFisher [-h] [--name NAME] [-q1 MAFUPPER] [-q2 MAFLOWER] [--alternative TAILED] [--midp] [--moi {additive,dominant,recessive}] Collapsing test for case-control data (CMC test, Li \u0026amp; Leal 2008). Different from the original publication which jointly test for common/rare variants using Hotelling's t^2 method, this version of CMC will binaries rare variants (default frequency set to 0.01) within a group defined by \u0026quot;--group_by\u0026quot; and calculate p-value via Fisher's exact test. A \u0026quot;mid-p\u0026quot; option is available for one-sided test to obtain a less conservative p-value estimate. optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. Default set to \u0026quot;CFisher\u0026quot; -q1 MAFUPPER, --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 0.01 -q2 MAFLOWER, --maflower MAFLOWER Minor allele frequency lower limit. All variants having sample MAF\u0026gt;m2 will be included in analysis. Default set to 0.0 --alternative TAILED Alternative hypothesis is one-sided (\u0026quot;1\u0026quot;) or two-sided (\u0026quot;2\u0026quot;). Default set to 1 --midp This option, if evoked, will use mid-p value correction for one-sided Fisher's exact test. --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive model. Default set to additive  A basic association test requires the following input:\n variants to be analyzed (see vtools show tables) a variant table previously created for a subset of variants phenotype to be analyzed (see vtools show samples -l1) phenotype covariates to be incorporated (--covariates) samples to be analyzed (--samples) genotype quality conditions, if low quality genotypes are not previously purged from database (--genotypes) missing data filters (--discard_samples and --discard_variants) association analysis method association testing group unit (--group_by. Will perform single variant analysis if unspecified.) output database filename (--to_db) number of CPU processors to be used for parallel computing  Missing values are not allowed in phenotype/covariates data. Samples having missing values in phenotype or any covariates will be removed and you will receive a warning message. If you want to retain samples having missing values in covariates we suggest you manually fill them with specified values (vtools phenotype --set ... --samples ...). For quantitative traits the value can be the sample mean, and for qualitative traits be the most likely category.\nIn this tutorial we demonstrate basic association analysis of a disease phenotype and a quantitative phenotype (simulated traits status and bmi). We choose to include covariate phenotypes gender and age when we demonstrate the multivariate analysis.\nAssociation analysis for common variants For single variant analysis with disease trait:\n% vtools associate common status \\ --covariates gender age \\ --discard_variants \u0026quot;%(NA)\u0026gt;0.1\u0026quot; \\ --method \u0026quot;LogitRegBurden --name SNV --alternative 2\u0026quot; \\ --to_db SNV \\ -j8 \u0026gt; SNV.txt  {$p$} values calculated by this command are based on Wald statistic of logistic regression analysis. To evaluate p-values empirically,\n% vtools associate common status \\ --covariates gender age \\ --discard_variants \u0026quot;%(NA)\u0026gt;0.1\u0026quot; \\ --method \u0026quot;LogitRegBurden --name SNV_permute --alternative 2 -p 100000000 --\\ adaptive 5e-5\u0026quot; \\ --to_db SNV \\ -j8 \u0026gt; SNV_permute.txt  we use a maximum of 100 million permutations per test, with an adaptive criteria {$p=5 \\times 10^{-5}$}. It takes about 15 seconds to complete the analysis on 1711 groups analytically and about 15 minutes on the same data using permutation based p-value evaluations.\nBy setting --name (inside the --method option) to a different name SNV_permute it is possible to insert new results from permutation tests to the same database SNV.DB while keeping the results from the previous non-permutation based analysis intact.\nAssociation analysis for rare variants Instead of analyzing them individually, rare variants are usually grouped into association units and are analyzed by groups. For exome analysis association units are genes. The --group_by/-g option can be used to create flexible grouping themes for rare variant analysis from variant fields or annotation databases. For example the name2 field in the refGene database can be used to classify variants into genes for analysis:\n% vtools associate rare status \\ --covariates gender age \\ --discard_samples \u0026quot;%(NA)\u0026gt;0.1\u0026quot; \\ --discard_variants \u0026quot;%(NA)\u0026gt;0.1\u0026quot; \\ --method \u0026quot;BurdenBt --name BurdenTest --alternative 2\u0026quot; \\ --group_by name2 \\ --to_db BurdenTest \\ -j8 \u0026gt; BurdenTest.txt  Permutation based analysis and other association methods (vtools show tests for disease traits and quantitative traits) are available but will not be demonstrated here.\nResuming previously terminated analysis Exome-wide association scan typically consists of thousands of tests for gene-based analysis, and up to a million tests for single variant analysis. In many cases an association command may be interrupted before all tests are completed (e.g., commands terminated due to running out of reserved CPU time on clusters, etc). If you have used --to_db option in the previous command, then resuming the analysis is simple: just re-run the exact command that was interrupted. The program will skip the records that exist in the result database and only carry out the ones that are missing. If you want to start all over, you may apply a --force option to the association command so that the existing result database will be overwritten, regardless of the data it already contains.\nSetting a timeout for permutation based association analysis Although with the \u0026quot;adaptive permutation\u0026quot; approach most permutation tests in an exome-wide a\\ ssociation scan would terminate early after a few thousand permutations, for scans involvin\\ g up to a million association tests you are likely to see some tests running for hours, rep\\ orting very small p-values in the end. These tests will temporarily hold up the computation\\ resource (they have to be finished first before the rest of tests get started). We provide\\ an option to set a time limit per test, in addition to using the adaptive permutation. Thi\\ s option is useful particularly when your computation resource is tight, or if you use a cl\\ uster that offers limited walltime, or if your sample size is small and result in extreme v\\ alues of test statistic. To set the association timeout to 1 hour (3600s): % vtools admin --set_runtime_option association_timeout=3600 % vtools show  After association scan is complete you can track and redo these timed out tests with larger or no timeout value,\n% vtools select variant \u0026quot;test_pvalue \u0026lt; 0\u0026quot; --table TO_REDO % vtools admin --reset_runtime_option association_timeout  and re-run the association command with --force option so that the updated results will be written to the database previously generated with the --to_db option.\nReset temporary data folder for association analysis We implemented a mechanism to optimally organize and access the genotype data for association testing. Temporary association databases will be generated on the fly and removed after the analysis is complete. By default these databases will be placed in the operating system\u0026rsquo;s temp path (usually /tmp or /var/tmp on Unix-like system). We may need to specify a temporary folder for association testing that 1) has large disk space and 2) locates on a different physical harddrive than the original project database bundle. Using a small disk for the temporary data may cause program crash (in which case you will receive an error message complaining about disk space) or degraded performance (in which case you will receive a warning message). To reset the temp folder, use\n% vtools admin --set_runtime_option temp_dir=/path/to/an/empty/directory  Other runtime options for association analysis Two other runtime options associate_num_of_readers and treat_missing_as_wildtype for association testing are available but will not be discussed here. Please use the following command to see the usage of these runtime options:\n% vtools show runtime_options  Viewing and Interpreting Association Results View association analysis results (This feature is under development)\nvtools_report commands plot_qq and plot_manhattan to present the association analysis results in QQ plot or Manhattan plot:\nusage: aviewer [-h] [--version] {qq,manhattan,manhattan_plain} ... Association Viewer, generating QQ / Manhattan plots of p-values from association analysis. Input data should be in the format of the output from 'vtools associate' command and be piped to the program as stdin. positional arguments: {qq,manhattan,manhattan_plain} qq QQ plot via ggplot2 manhattan Manhattan plot via ggplot2 manhattan_plain Manhattan plot implementation not using ggplot2 optional arguments: -h, --help show this help message and exit --version show program's version number and exit  This program generates graphs for {$p$} values, allowing for\n multiple association results plotted on the same / different pages various color, shape and legend themes to choose from text labels for siginificant p-values on the graph text labels for specified variants/genes on the graph marks for significance levels (Bonforroni correction or user specified value)  Online Dataset Examples You can use our snapshot for association vt_ExomeAssociation to test out the VAT association features. This is a non-trivial dataset of ~30k variants and ~3k samples with simulated phenotypes\n% vtools init test % vtools show snapshots % vtools admin --load_snapshot vt_ExomeAssociation  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/single_gene/c_alpha-test/",
	"title": "C-alpha test",
	"tags": [],
	"description": "",
	"content": " C-alpha Test for Protective Variants Introduction This implements the {$C(\\alpha)$} test (Neale et al 2011[^Benjamin M. Neale, Manuel A. Rivas, Benjamin F. Voight, David Altshuler, Bernie Devlin, Marju Orho-Melander, Sekar Kathiresan, Shaun M. Purcell, Kathryn Roeder and Mark J. Daly (2011) Testing for an Unusual Distribution of Rare Variants. PLoS Genetics doi:10.1371/journal.pgen.1001322. http://dx.plos.org/10.1371/journal.pgen.1001322^]) for disease traits, to test for the hypothesis of rare variants disease association under the particular assumption that rare variants observed in cases and controls is a mixture of phenotypically deleterious, protective and neutral variants. Instead of using a cumulative dosage (or \u0026ldquo;burden\u0026rdquo;) based summary statistic over a gene region, it directly contrasts the observed and expected distribution of minor alleles in cases and controls at each locus as an evidence of \u0026ldquo;unusual distribution\u0026rdquo;, and combine evidences from multiple loci (whether it be an evidence of protective or deleterious) to formulate the {$C(\\alpha)$} statistic: {$$T=\\sum_{i=1}^m[(y_i-n_ip_0)^2-n_ip_0(1-p_0)]$$}\nThe original paper evaluates p-value of the test under large sample normal assumption, which usually would not hold for the real world data. Implementation in this program also allows permutation based {$C(\\alpha)$} test, if parameter -p/--permutations is set greater than 0.\nDetails Command interface vtools show test Calpha Name: Calpha Description: c-alpha test for unusual distribution of variants between cases and controls, Neale et al 2011 usage: vtools associate --method Calpha [-h] [--name NAME] [-q1 MAFUPPER] [-q2 MAFLOWER] [-p N] [--adaptive C] [--moi {additive,dominant,recessive}] c-alpha test for unusual distribution of variants between cases and controls, Neale et al 2011. It tests for deviation of variance of minor allele counts in cases/ctrls from its exception based on binomial distribution. The statistic is asymptotically normally distributed. p-value can be evaluated using either permutation or asymptotic distribution as described in Neale et al 2011, although it is recommended to use permutation to estimate a reliable p-value. Calpha test is a two-tailed test optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. -q1 MAFUPPER, --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 0.01 -q2 MAFLOWER, --maflower MAFLOWER Minor allele frequency lower limit. All variants having sample MAF\u0026gt;m2 will be included in analysis. Default set to 0.0 -p N, --permutations N Number of permutations --adaptive C Adaptive permutation using Edwin Wilson 95 percent confidence interval for binomial distribution. The program will compute a p-value every 1000 permutations and compare the lower bound of the 95 percent CI of p-value against \u0026quot;C\u0026quot;, and quit permutations with the p-value if it is larger than \u0026quot;C\u0026quot;. It is recommended to specify a \u0026quot;C\u0026quot; that is slightly larger than the significance level for the study. To disable the adaptive procedure, set C=1. Default is C=0.1 --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive model. Default set to additive  Application  Example using snapshot vt_ExomeAssociation\nvtools associate rare status -m \u0026quot;Calpha --name Calpha -p 5000\u0026quot; --group_by name2 --to_db cal\\ pha -j8 \u0026gt; calpha.txt INFO: 3180 samples are found INFO: 2632 groups are found Loading genotypes: 100% [=====================] 3,180 27.6/s in 00:01:55 Testing for association: 100% [=====================] 2,632/591 11.6/s in 00:03:46 INFO: Association tests on 2632 groups have completed. 591 failed. INFO: Using annotation DB calpha in project test. INFO: Annotation database used to record results of association tests. Created on Wed, 30 Jan 2013 15:54:03 vtools show fields | grep calpha calpha.refGene_name2 refGene_name2 calpha.sample_size_Calpha sample size calpha.num_variants_Calpha number of variants in each group (adjusted for specified MAF calpha.total_mac_Calpha total minor allele counts in a group (adjusted for MOI) calpha.statistic_Calpha test statistic. calpha.pvalue_Calpha p-value head calpha.txt name2 sample_size_Calpha num_variants_Calpha total_mac_Calpha statistic_Calpha pvalue_Calpha std_error_Calpha num_permutations_Calpha AADACL4 3180 5 138 0.0229344 0.407592 1.08434 1000 AAMP 3180 3 35 -0.444631 0.601399 0.896954 1000 ABCD3 3180 3 42 -0.911816 0.93007 1.0528 1000 ABCB6 3180 7 151 -0.751779 0.757243 1.05563 1000 ABCG8 3180 12 152 -0.0149743 0.36963 0.981793 1000 ABHD1 3180 5 29 -0.744439 0.845155 1.0768 1000 ABCB10 3180 6 122 1.14261 0.12094 1.02364 2000 ABL2 3180 4 41 -0.76715 0.966034 0.866904 1000 ACADL 3180 5 65 -0.50523 0.642358 0.943209 1000  \n[^#^]\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/customized/",
	"title": "Customized",
	"tags": [],
	"description": "",
	"content": " Create annotation database Because you write your own .ann file, please consider using pipelines in anno_utils, which can usually create .ann file from some data sources with pre-defined formats.\nDefine a new annotation database If you would like to use an annotation source that is not currently supported by variant tools, you could send us and email if the data source is publicly available, or write an annotation specification file to create your own annotation database. This file describes various aspects of an annotation database such as\n Type of annotation (variant, positional, range and field) The reference genome(s) it uses, Description of the database, including license and citation, Where to get the database and/or its source, and Fields that the annotation database will provide  An annotation file follows a windows .ini format. It is divided into several sections, each with several key=entry lines. Lines that start with a # or ; are comments and are ignored. Inline comments starts with ;. An annotation file should always starts with line\n#Variant tools schema version 1.0  An annotation file should have sections linked fields and data sources, followed by sections that describe each field.\nSection [linked fields] A database can provide one or more sets of linked fields by which it is linked to the master variant table of the project. Each line should have format\nbuild=field1,field2,...  where build is the build of a reference genome, or \u0026lsquo;*\u0026rsquo; if this annotation database can be linked to project with any referenge genome.\nOne or more fields can be specified as \u0026lsquo;linked fields\u0026rsquo;:\n for variant annotation database, they should be names of chr, pos, ref, and alt fields. for position annotation database, they should be names of chr and pos fields. for range annotation database, they should be names of chr, start pos and ending pos fields. for field annotation database, they should be names of fields that link to the master variant table.  For example, it a variant-based database provides coordinates for both hg18 and hg19, the build lines will be similar to\nhg18=chr,hg18_pos,ref,alt hg19=chr,hg19_pos,ref,alt  where chr, hg18_pos, hg19_pos, ref, alt are fields defined below.\nSection [data sources] This section can have keys\n description: description of the database encoding (optional): encoding of the input file. If you see errors such as \u0026quot;codec can't decode byte 0xe7 in position 21480\u0026quot;, you should perhaps add encoding=ISO-8859-1 to your .ann file. preprocessor (optional): A preprocessor to pre-process files before it can be imported. A common preprocessor is Dos2Unix() which converts files with \\r as newline character to unix format (with \\n as newline character. header (optional): variant tools by default treats lines with a leading # as header and skip them during data importing. The header will also be used to probe sample names for some formats (e.g. .vcf). If your input file does not use such a header, you can override this behavior by specifying the number of lines to skip (header=1), or a pattern by which headers are matched (e.g. use header=^%.* for header lines starting with %, see documents of the Python re package for details). anno_type: can be one of \u0026lsquo;variant\u0026rsquo;, \u0026lsquo;position\u0026rsquo;, \u0026lsquo;range\u0026rsquo; or \u0026lsquo;field\u0026rsquo; direct_url: URL to download annotation database directly. If no URL is given, variant tools will always build the database from source. delimiter: delimiter to define columns in the input file. Default to tab (delimiter='\\t'). If your input can be either tab or space delimited, use delimiter=None. source_type: type of source files, we currently supported tab based text file (txt) and vcf file. source_url: How to obtain source file to be imported. If variant tools fail to download the database directly, it will get the source file and try to import data from it. The source url can be  A local file. This is rarely used because a user who builds annotation from a local file usually specify it using option --files of the vtools use command. A \u0026lt;a class='urllink' href='ftp://' rel='nofollow'\u0026gt;ftp://\u0026lt;/a\u0026gt; or \u0026lt;a class='urllink' href='http://' rel='nofollow'\u0026gt;http://\u0026lt;/a\u0026gt; (or other) URLs (white space delimited). variant tools will try to download the file using a http client. A sql in the format of sql://user@password:select something from a database. variant tools will try to connect to a sql server using specified username and password, run the query and use the result as input source file. Only a mysql server is supported at this time.  source_pattern: pattern of source files (used to exclude README etc) version: version of the database, which is not necessarily version of the data source. The convension is sourceVersion_dbVersion. If unspecified, vtools will try to get it from filename. For example, dbNSFP-1.1_0.db will have version number 1.1_0.  Field sections Fields sections describe the fields that will be imported. Each of them can have\n index: index(es) of field, which can be\n A 1-based index of the column in the database. The value at this column of the input file will be used for this field.\n A tuple syntax with multiple indexes separated by ',', for example 5,7). A list of values at specified columns will be passed to an adjust function to produce values of the field.\n  type: can be any SQL allowed types such as \u0026ldquo;INTEGER\u0026rdquo;, \u0026ldquo;FLOAT\u0026rdquo;, \u0026ldquo;INTEGER NOT NULL\u0026rdquo;, or \u0026ldquo;DECIMAL(7,6) NOT NULL\u0026rdquo;\n comment (optional) a description of the field\n adj (optional): Functions or functors to extract or modify one or more values from the field value. variant tools provides a number of functors to help the processing of different fields. For example,\n IncreaseBy(inc=1) (increase value by inc). This is usually used to adjust 0-based position to 1-based position that is used by variant tools.\n MapValue(map) (map value to another). This function is used to map input value to another one, for example, MapValue({'het': '1', 'hom': '2'}) maps value \u0026lsquo;het\u0026rsquo; to \u0026lsquo;1\u0026rsquo; and \u0026lsquo;hom\u0026rsquo; to \u0026lsquo;2\u0026rsquo;. Note that the mapped values should be strings or None.\n Nullify(val) (treat value as NULL). This is usually used to adjust input NA values to NULL in the database.\n **RemoveLeading(val)\u0026lt;/strong\u0026gt; (remove leading characters). This is usually used to remove leadingchrfrom inputs with chromosomes such aschr1,chr2, because \u0026lt;em\u0026gt;variant tools\u0026lt;/em\u0026gt; only stores1,2@@, etc. \n ExtractField(index, sep=';', default=None) (field of a column): Split the item by sep and return the index-th field (1-based). Return default is there are less than index fields. For example, ExtractField(2, ':') extracts 20 from 10:20:30. \n Multiple functors/functions can be used sequentially. For example, ExtractValue('CEU:'), ExtractField(1, '/') extracts value 12 from YRI:20/222;CEU:12/45 (the first extractor gets 12/45, the second extractor gets 12), and ExtractValue('CEU:'), SplitField('/') extracts values 12 and 45 from YRI:20/222;CEU:12/45.\n If none of the provided extractors can be used, you can define your own function. For example, lambda x: x[6:].replace(\u0026quot;,\u0026quot;, \u0026quot;\u0026quot;) extracts 24000 from COUNT=24,000. You can also mix function with variant tools provided extractor ExtractValue(\u0026quot;COUNT=\u0026quot;), lambda x: x.replace(\u0026quot;,\u0026quot;, \u0026quot;\u0026quot;)]) to extract 24000 from values such as ASD;COUNT=24,000;MAF=0.5.\n If the return value of at least one of the fields is a tuple of more than one values (e.g. result from functor SplitField), multiple records will be generated from this line. Non-tuple values of other fields will be copied automatically. For example, if three fields have values A1, (B1,), (C1, C2), they will produce two records of A1, B1, C1 and A1, None, C2.\n If you would like to exclude certain records, you can use adj to produce invalid records that will be excluded during importing. For example, a record with None alternative allele, or a field with NOT NULL type will be ignored, or a genotype with None mutation type will be ignored.\n  Import and test Once you have written a .ann file, you can create an annotation database using command\nvtools use /path/to/file.ann  or\nvtools use /path/to/file.ann --files source_files  if you have source files available.\nOnce the database is created and used correctly, you can have a look at it using command\nvtools show annotation ANNODB -v2  to get the basic information of the annotation database, or\nvtools show table ANNODB  to display the actual data.\nPlease pay attention to invalid records and statistics of each field (e.g. missing values) to make sure the database has been created correctly.\nExamples For example\n[SIFT_pred] index=20 adj=Nullify('NA') type=VARCHAR(2) NULL comment=SIFT prediction, D(amaging) or T(olerated)  specifies a field that predicts if a variant is damaging, with value D or T.\n[HD_INFO] index=8 adj=ExtractFlag('HD') type=INTEGER comment=Marker is on high density genotyping kit (50K density or greater). The snp may have phenotype associations present in dbGaP.  specifies a field that is imported from the HD flag of column 8 with delimiter ;. This is a common format when the annotations are created from the info column of a vcf file.\n Example for a variant annotation database with multiple reference genomes: dbNSFP.ann Example for a variant annotation database created from a .vcf file thousandGenomes.ann Example for a field annotation database keggPathway.ann    "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/misc/encode/",
	"title": "ENCODE",
	"tags": [],
	"description": "",
	"content": " ENCODE Download bigWig and bigBed files and use the track() function to annotate variants. More details will follow.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/genes/entrezgene/",
	"title": "EntrezGene",
	"tags": [],
	"description": "",
	"content": " EntrezGene % vtools show annotation EntrezGene.DB Annotation database EntrezGene (version 20131028) Description: Entrez Gene (www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=gene) is NCBI's database for gene-specific information. It does not include all known or predicted genes; instead Entrez Gene focuses on the genomes that have been completely sequenced, that have an active research community to contribute gene- specific information, or that are scheduled for intense sequence analysis. This database contains Entrez gene info database for Homo Sapiens, downloaded from ftp://ftp.ncbi.nih.gov/gene/DATA/GENE_INFO/Mammalia/Homo_sap iens.gene_info.gz. Database type: range Reference genome hg19: chr, start, end chr chromosome name, the same as field chromosome start Start location of the gene, retrieved from EntrezGene2RefSeq. end End location of the gene, retrieved from EntrezGene2RefSeq. tax_id the unique identifier provided by NCBI Taxonomy for the species or strain/isolate GeneID the unique identifier for a gene (ASN1: geneid) Symbol the default symbol for the gene (ASN1: gene-\u0026gt;locus) LocusTag the LocusTag value (ASN1: gene-\u0026gt;locus-tag) Synonyms bar-delimited set of unofficial symbols for the gene dbXrefs bar-delimited set of identifiers in other databases for this gene. The unit of the set is database:value. chromosome the chromosome on which this gene is placed. for mitochondrial genomes, the value 'MT' is used. map_location the map location for this gene description a descriptive name for this gene type_of_gene the type assigned to the gene according to the list of options. provided in http://www.ncbi.nlm.nih.gov/IEB/T oolBox/CPP_DOC/lxr/source/src/objects/entrezgene/entre zgene.asn Symbol_from_nomenclature_authority If exists (not NULL), indicates that this symbol is from a nomenclature authority Full_name_from_nomenclature_authority If exists (not NULL), indicates that this full name is from a nomenclature authority Nomenclature_status If exists (not NULL), indicates the status of the name from the nomenclature authority (O for official, I for interim) Other_designations pipe-delimited set of some alternate descriptions that have been assigned to a GeneID '-' indicates none is being reported. Modification_date the last date a gene record was updated, in YYYYMMDD format  EntrezGene2RefSeq This is a field database that links gene_id to information to refGene.\n% vtools show annotation EntrezGene2RefSeq Annotation database EntrezGene2RefSeq (version 20131028) Description: This database is a comprehensive report of the accessions that are related to a Entrez GeneID. It includes sequences from the international sequence collaboration, Swiss-Prot, and RefSeq. This database only keeps record for human genome with reference genome Reference GRCh37.p13 Primary Assembly, and it also only keeps sequence on reference assembly (ref seq with assession type NC_). Database type: field Reference genome *: GeneID tax_id the unique identifier provided by NCBI Taxonomy for the species or strain/isolate GeneID the unique identifier for a gene status status of the RefSeq values are: INFERRED, MODEL, NA, PREDICTED, PROVISIONAL, REVIEWED, SUPPRESSED, VALIDATED RNA_nucleotide_accession_version may be null (-) for some genomes RNA_nucleotide_gi the gi for an RNA nucleotide accession (e.g. NP_047184.1, NC_004871.1) protein_accession_version will be null (-) for RNA-coding genes protein_gi the gi for a protein accession, '-' if not applicable genomic_nucleotide_accession_version may be null (-) if a RefSeq was provided after the genomic accession was submitted genomic_nucleotide_gi the gi for a genomic nucleotide accession, '-' if not applicable start_position_on_the_genomic_accession position of the gene feature on the genomic accession, adjusted to be 1-based end_position_on_the_genomic_accession position of the gene feature on the genomic accession, adjusted to be 1-based orientation orientation of the gene feature on the genomic accession, '?' if not applicable assembly the name of the assembly '-' if not applicable mature_peptide_accession_version will be null (-) if absent mature_peptide_gi the gi for a mature peptide accession, '-' if not applicable Symbol the default symbol for the gene  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/help/",
	"title": "Help",
	"tags": [],
	"description": "",
	"content": " Usage of variant tools commands Structure of commands vtools uses a subcommand system that is similar to svn. For example, command\n% vtools select variant 'sift_score \u0026lt; 0.05' -t table  consists of:\n command vtools subcommand select that specify operation, positional arguments variant that specifies a variant table and 'sift_score \u0026lt; 0.05' that specify operant, which in this case are the variant table to select from, and condition by which the variants are selected. optional argument -t table. In contrast to positional arguments, optional arguments are used for options that may be optional or have common default values.  Available subcommands vtools has a growing number of subcommands. To check the available subcommands, please use command vtools -h.\n% vtools -h usage: vtools [-h] [--version] {init,import,phenotype,show,liftover,use,update,select,exclude,compare,output,export,remove,associate,admin,execute} ... A variant calling, processing, annotation and analysis tool for next- generation sequencing studies. optional arguments: -h, --help show this help message and exit --version show program's version number and exit subcommands: {init,import,phenotype,show,liftover,use,update,select,exclude,compare,output,export,remove,associate,admin,execute} init Create a new project, or a subproject from an existing parent project, or merge several existing projects into one import Import variants and related sample genotype from files in specified formats phenotype Manage sample phenotypes show Display content of a project liftover Set alternative reference genome and update alternative coordinates of all variant tables use Prepare (download or import if necessary) and use an annotation database update Add or update fields of existing variants and genotype using information from specified existing fields, sample genotype, or external files select Output or save select variants that match specified conditions exclude Output or save variants after excluding variants that match specified conditions compare Compare two variant tables, count or output intersect and difference to other tables output Output variants in tab or comma separated format export Export samples (variants and genotypes) in specified format remove Remove project or its contents such as variant tables, fields, and annotation databases. associate Test association between variants and phenotypes admin Perform various administrative tasks including merge and rename samples. execute Execute a pipeline or a SQL query Use 'vtools cmd -h' for details about each command. Please contact Bo Peng (bpeng at mdanderson.org) if you have any question.  Logging and option --verbosity (-v) variant tools, by default, outputs information lines (starts with INFO and WARNING) and progress bars during the execution of commands. Additionally the information lines and detailed debug information (starts with DEBUG) are written to a project log file ($name.log). If something goes wrong, you can check this file for details. One particular feature of this file is that it saves date and time of each log message so that you can measure the performance of operations if needed.\nThe verbosity level of command line output can be controlled by option --verbosity LEVEL, where LEVEL can be\n ``: suppress all output except for warning and errors (no INFO or DEBUG) 1: display/log progress information, including progress bars on screen output (no DEBUG) 2: display/log progress and debug information.  Examples:\n% vtools init test -v2 DEBUG: DEBUG: vtools init test -v2 -f DEBUG: Using temporary directory /var/folders/bm/jnrrj61x185cw6rzzsxplkd00000gn/T/tmp0n22aZ INFO: variant tools 1.0.3 : Copyright (c) 2011 - 2012 Bo Peng INFO: San Lucas FA, Wang G, Scheet P, Peng B (2012) Bioinformatics 28(3):421-422 INFO: Please visit http://varianttools.sourceforge.net for more information. INFO: Creating a new project test DEBUG: Creating core tables DEBUG: Creating table project DEBUG: Creating table filename DEBUG: Creating table variant DEBUG: Creating table sample % less test.log 2012-10-22 20:24:10,328: DEBUG: 2012-10-22 20:24:10,329: DEBUG: vtools init test -v2 -f 2012-10-22 20:24:10,329: DEBUG: Using temporary directory /var/folders/bm/jnrrj61x185cw6rzzsxplkd00000gn/T/tmp0n22aZ 2012-10-22 20:24:10,329: INFO: variant tools 1.0.3 : Copyright (c) 2011 - 2012 Bo Peng 2012-10-22 20:24:10,329: INFO: San Lucas FA, Wang G, Scheet P, Peng B (2012) Bioinformatics 28(3):421-422 2012-10-22 20:24:10,329: INFO: Please visit http://varianttools.sourceforge.net for more information. 2012-10-22 20:24:10,330: INFO: Creating a new project test 2012-10-22 20:24:10,338: DEBUG: Creating core tables 2012-10-22 20:24:10,338: DEBUG: Creating table project 2012-10-22 20:24:10,377: DEBUG: Creating table filename 2012-10-22 20:24:10,384: DEBUG: Creating table variant 2012-10-22 20:24:10,391: DEBUG: Creating table sample  If, for example for a production pipeline you do not want any debug information in the log file, you can set a runtime option logfile_verbosity to control the level of verbosity in the log file. For example,\n% vtools admin --set_runtime_option logfile_verbosity=0  will suppress any logfile output (except for warnings). \nThe verbosity level when the project is created is the default verbosity level of the project. That is to say, if you create the project using `vtools init test -v0, the subsequent vtools command will have a default verbosity level of 0.\nSave output to files Output from vtools can be saved to files via standard output redirection. The progress/warning/errors information will be displayed on screen while only the standard output will be written to files.\n Examples: direct output to files If you load a project from online and output its variants as follows:\n% vtools init simple % vtools admin --load_snapshot vt_simple % vtools output variant chr pos ref alt -v2 \u0026gt; output.txt DEBUG: DEBUG: vtools output variant chr pos ref alt -v2 DEBUG: Using temporary directory /var/folders/bm/jnrrj61x185cw6rzzsxplkd00000gn/T/tmpBzRAJy DEBUG: Opening project simple.proj DEBUG: Running query SELECT variant.chr ,variant.pos ,variant.ref ,variant.alt FROM variant ;  the output is written to file output.txt while debug information continues to be displayed and written to log file.\n% head -n 5 output.txt 1 4540 G A 1 5683 G T 1 5966 T G 1 6241 T C 1 9992 C T  \nConditions used in variant tools commands One of the key features of the command line interface of variant tools is that its use of conditions. For example, vtools select variant COND finds variants in table variant that match specified COND, vtools select --samples COND finds variants that belong to samples that match certain COND, and vtools init --parent DIR --genotypes COND copies genotypes that match specific conditions from parent project DIR to a new project.\nGenerally speaking, conditions are arbitrary SQL expressions that involves fields in the project. The syntax is described in here, but generally speaking, you need to first determine the fields that can be used, the type of fields. Generally speaking,\n vtools show fields lists all variant info and annotation fields that can be used for selecting variants. vtools show genotypes lists all fields in the genotype tables that can be used to select genotypes. vtools show samples lists all fields in the sample table that can be used to select samples.  You can then select records using expressions,\n For numeric fields (e.g. pos), you can use expressions such as pos \u0026gt; 1000, pos = 12345, and pos BETWEEN 2000 AND 3000. For character strings (e.g. chr, ref, and alt), you can use expressions such as chr = '13', length(ref) = 1, filename like 'INT%'. Here length is a function to get the length of field chr. A complete list of usable functions is available here. Operator IN is sometimes very useful. E.g. ref IN ('A', 'C'). To test if there is a value at a field, use expression such as chr IS NULL or chr IS NOT NULL.  Multiple conditions are allowed. For example \u0026quot;ref='A'\u0026quot; \u0026quot;alt='C'\u0026quot; means \u0026quot;ref='A\u0026quot; AND alt='c'\u0026quot;. If you need OR condition, you can write that explicitly, e.g. \u0026quot;ref='A\u0026quot; OR alt='c'\u0026quot;.\nFor example,\n Condition dbSNP.chr IS NOT NULLL selects variants that are in dbSNP database. This is because all records in dbSNP has value at field chr. vtools select variant --samples \u0026quot;filename LIKE 'CEU%'\u0026quot; get variants that belong to all samples with filename starting at CEU. Condition \u0026quot;((ref='A' AND alt='G') OR (ref='G' AND alt='A') OR (ref='C' AND alt='T') OR (ref='T' AND alt='C'))\u0026quot; matches all transition mutations. Condition \u0026quot;ref=\u0026lt;small\u0026gt;'\u0026quot; select all insertions, and \u0026quot;alt='\u0026lt;/small\u0026gt;\u0026quot; select all deletions, and \u0026quot;ref != \u0026lt;small\u0026gt;'\u0026quot; \u0026quot;alt != '\u0026lt;/small\u0026gt;\u0026quot; \u0026quot;length(ref)=1\u0026quot; \u0026quot;length(alt)=1\u0026quot; selects all SNVs. vtools remove genotypes \u0026quot;DP \u0026lt; 10\u0026quot; removes all genotypes with depth less than 10. vtools export ... --samples 1 export genotypes at all samples because condition 1 means TRUE for all samples.  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/simulation/models/",
	"title": "Models",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/case44ctrl20/",
	"title": "Performance",
	"tags": [],
	"description": "",
	"content": " Processing 44 whole genome cases and 200 exome controls 1. Data source Whole genome-sequencing data for 44 cases, with SNV and indel data in separate files, and 200 exome controls. This tutorial demonstrates the same set of commands used in the home page presentation but uses the complete dataset. The dataset used in this tutorial is not publicly available.\n2. Import data Create a project\n# Performance data is collected on a Mac Workstation with 2x2.26G Quad-Core Xeon processor with 8G RAM, using variant tools v1.0rc1. % vtools init RA  Import control data in hg19. The presentation imports case data (hg18) first, but as discussed here, it is better to use newer reference genome as the primary reference genome.\n# It takes 15min to import a total of 12.8M variants (3M unique) and 12M genotypes. % vtools import ../data/Ctrl/*.vcf --build hg19 --geno safe_GT  Here we use option --geno safe_GT because the data does not follow VCF format specification and do not put genotype as the first FORMAT field.\nImporting case data from 44 VCF files. Because the case data use a different reference genome, an alternative reference genome (hg18) is added to the project. Existing variants and new variants are mapped to hg18 and hg19, respectively, so that all variants have coordinates in both reference genomes (except for those that cannot be mapped).\n# It takes 3hr 30min (3hr with `--jobs 2`) to import 161M variants (11M new distinct ones), 161M genotypes. Peak memory usage is 2.7G. % vtools import ../data/hg18/*.vcf --build hg18  The indel data are stored in separate files in pileup format. They are imported using the alternative reference genome (hg18) and are mapped to hg19 afterwards.\n# It takes 1hr 30min to import 36M variants (4.6M new), 36M genotypes. Peak memory usage is 3.8G. % vtools import ../data/indel/*.indel --format pileup_indel --build hg18  After all three sets of data are imported, the project\n has 18M variants, including 1.8M insertions and 2.9M deletions has 210M genotypes in 288 samples (in variant tools term, because SNVs and INDELs of cases are stored separately) takes 4.2G diskspace (RA.proj: 1.25G, RA_genotype.DB: 2.92G)  If you have more data, you can create several subprojects, each import part of the data, and then merge the subprojects to create a parent project with all data. Because subprojects can import data simultaneously, this strategy allows you to import data more efficiently. Added benefits include separate (and faster) analysis in subprojects, faster re-creation of the main project if needed, and easy management of different batches/versions of data. Please refer to this tutorial for more details.\n 3. Sample statistics # 3.8G RAM, 30min % vtools update variant --from_stat 'num=#(alt)' 'hom=#(hom)' 'het=#(het)' 'other=#(other)'  You can then view the number of variants in the sample using command vtools output:\n% vtools output variant chr pos ref alt num hom het -l 10  To calculate sample statistics in cases and controls, we mark samples with affection status according to their filenames\n# finish within 1 second % vtools phenotype --set aff=2 --samples 'filename like \u0026quot;%MG%\u0026quot;' % vtools phenotype --set aff=2 --samples 'filename like \u0026quot;%NA%\u0026quot;' % vtools phenotype --set aff=1 --samples 'aff is NULL'  Then, we can calculate number of variants in cases and controls separately:\n# Use 25min and 5min respectively % vtools update variant --from_stat 'case_num=#(alt)' --samples aff=2 % vtools update variant --from_stat 'ctrl_num=#(alt)' --samples aff=1 % vtools output variant chr pos ref alt num case_num ctrl_num -l 5  4. Annotate and select variants # Downloading dbNSFP can be SLOW, but using it is fast. % vtools use dbNSFP % vtools output variant chr pos ref alt SIFT_score PolyPhen2_score -l 15  Select variants that belong to dbNSFP (nonsynonymous SNVs in CCDS genes), this will naturally exclude all indels:\n# This step takes 20min, using 28M of RAM % vtools select variant 'dbNSFP.chr is not NULL' -t NS % vtools output NS chr pos ref alt SIFT_score PolyPhen2_score -l 10  We can further select from the NS table using SIFT and PolyPhen 2 scores provided by dbNSFP. Note that in this database, higher scores indicate higher probability of damaging.\n# These queries take 20, 5 and 5min. % vtools select NS 'SIFT_score \u0026gt; 0.95' -t NS_damaging % vtools select NS 'SIFT_score \u0026gt; 0.95' 'PolyPhen2_score \u0026gt; 0.95' -t NS_damaging_pp2 % vtools select NS 'SIFT_score \u0026gt; 0.95 OR PolyPhen2_score \u0026gt; 0.95' -t NS_or # All these operations are fast % vtools show tables % vtools compare NS_damaging NS_or -c % vtools compare NS_damaging NS_or --B_diff_A NS_pp2 % vtools output NS_pp2 chr pos ref alt SIFT_score PolyPhen2_score -l 10  Use ccds gene and keggPathway annotation databases to annotate variants with gene names\n# These operations are fast % vtools use ccdsGene % vtools use ccdsGene_exon % vtools use keggPathway --linked_by ccdsGene.name % vtools output NS chr pos ccdsGene.name KgDesc -l 20  Select variants that belong to certain pathway\n% vtools select NS 'kgID=\u0026quot;hsa00760\u0026quot;' --output chr pos ref alt ccdsGene.name kgDesc -l 20  5. Use annovar to provide gene-based annotation The following commands export variants in table NS in ANNOVAR format, run ANNOVAR to annotate it, and import the result back:\n# Update from ANNOVAR result takes 3m42s % vtools export NS --format ANNOVAR annovar.input % ../annovar/annotate_variation.pl annovar.input ../annovar/humandb/ --build hg19 % vtools update variant --from_file annovar.input.exonic_variant_function --format ANNOVAR_output # Returns instantly % vtools select NS 'mut_type = \u0026quot;stopgain SNV\u0026quot;' --output chr pos ref alt mut_type -l 20  6. More examples on output and select This command demonstrates the use of simple arithmetic in the output of fields\n# It takes 3m11s to output 18M variants % vtools output variant chr 'pos-1' pos ref alt \u0026gt; Bed_output  You can also output fields from annotation databases. They all (conceptually) belong to the master variant table and can be use like other fields.\nThe first command take 19m to run, but the second command and repeated run of the first command take only 7s, because the underlying database engine has optimized such queries.\n % vtools output NS chr pos ref alt case_num ctrl_num SIFT_score \u0026gt; outfile % vtools output NS chr pos ref alt case_num ctrl_num SIFT_score --build hg18 \u0026gt; outfile_hg18  Count the number of variants is easy. The following two commands count the number of insertions and deletions\n# 30s each % vtools select variant 'ref=\u0026quot;-\u0026quot;' --count % vtools select variant 'alt=\u0026quot;-\u0026quot;' --count  We can count the total number of genotypes using the sum of field num, which is the sample allele count for each variant. Similarly, we can count the total number of transition mutations.\n# Two commands take 13s and 1min respectively. % vtools output variant 'sum(num)' % vtools select variant \u0026quot;(ref='A' AND alt='G') OR (ref='G' AND alt='A') \\ OR (ref='C' AND alt='T') OR (ref='T' AND alt='C')\u0026quot; --output 'sum(num)'  The following command count the number of transition and transversion mutations and output transition/transversion ratio, for each allele count.\n# This command takes 48min to execute % vtools_report trans_ratio variant -n num --by_count  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/simulation/",
	"title": "Simulation",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/administration/stylesheet/",
	"title": "Style sheet",
	"tags": [],
	"description": "",
	"content": "table.zebra tr:nth-child(odd) {\nbackground-color: #f3f3f3;  }\ntable.zebra {\npadding-top: 10px; padding-bottom: 10px; /* font-family: \u0026quot;Lucida Sans Unicode\u0026quot;, \u0026quot;Lucida Grande\u0026quot;, Sans-Serif; */ font-size: 14px; /* margin: 45px; */ /* width: 480px; */ text-align: left; border-collapse: collapse;  }\ntable.zebra th {\nfont-size: 16px; font-weight: normal; padding: 10px 8px; /* color: #039; */  }\ntable.zebra td {\npadding: 8px;  /* text-align:left; */\n/* color: #669; */  }\n.escaped {\nfont-family: Consolas, Menlo, Monaco, Lucida Console, Liberation Mono, DejaVu Sans Mono, Bitstream Vera Sans Mono, Courier New, monospace, serif;  }\n.frame\n{ border:0px solid #CCCCCC;  padding: 2px 0px 10px 10px; background-color:#eeeeee; }\ncode {\nfont-family: Consolas, Menlo, Monaco, Lucida Console, Liberation Mono, DejaVu Sans Mono, Bitstream Vera Sans Mono, Courier New, monospace, serif;  padding: 0px 2px 0px 2px;\nbackground-color: #eeeeee;  }\n.cmd {\ndisplay: block; padding: 10px 0px 2px 10px; font-family: Consolas, Menlo, Monaco, Lucida Console, Liberation Mono, DejaVu Sans Mono, Bitstream Vera Sans Mono, Courier New, monospace, serif;  /* Menlo, Monaco, Consolas, \u0026ldquo;Courier New\u0026rdquo;, monospace; */\nfont-weight: bold; word-break: break-all; word-wrap: break-word; background-color: #eeeeee; /*#f9f9f9; */ /* #f5f5f5; */ /* border-top:1px solid #cccccc; */  /* border-right:1px solid #cccccc; / / border-bottom:1px solid #cccccc; */\n/* border: 1px solid rgba(0, 0, 0, 0.15); */ /* border-left:4px solid #0000FF; -webkit-border-top-right-radius: 5px; -moz-border-top-right-radius: 5px; border-top-right-radius: 5px; -webkit-border-bottom-right-radius: 5px; -moz-border-bottom-right-radius: 5px; border-bottom-right-radius: 5px; */  }\na, a:visited {\ncolor: #4a6b82;  }\na:link { text-decoration:none; }\na:visited { text-decoration:none; }\na:hover { text-decoration:underline; }\na:active { text-decoration:underline; }\n/* a, a:link, a:visited, a:active {\ncolor: #662255; border-bottom: none; text-decoration:none; /*text-shadow: 1px 1px 1px #999 */  } a:hover {\ncolor: #662255; background-color:yellow; /*border-bottom: 1px dotted #3366cc;*/  }\n /  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/variant_calling/",
	"title": "Variant calling",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/variant_calling/bwa_gatk28_hg19/",
	"title": "bwa_gatk28_hg19",
	"tags": [],
	"description": "",
	"content": " Calling variants using BWA and GATK best practice pipeline Usage % vtools show pipeline bwa_gatk28_hg19 A pipeline to align raw reads from fastq or BAW/SAM files using BWA and GATK best practice. It uses hg19 of human reference genome and assumes paired-end reads in plain text and compressed formats. Available pipelines: align, call Pipeline \u0026quot;align\u0026quot;: Align raw reads from input files using bwa, gatk, and picard. This pipeline accepts raw input files in plain text format, SAM/BAM format, and their compressed versions (.zip, .tar.gz, .tgz, .bz2, .tbz2 etc). All input files are assumed to be raw reads from the same sample. This pipeline generates a calibrated bam file (--output), and its reduced version if an additional output file is specified. align_0: Check the version of variant tools (version 2.1.1 and above is required to execute this pipeline) align_1: Download required resources to resource directory align_10: Check existence of commands bwa, samtools and java align_11: Check the version of bwa. Version is 0.7.4 is recommended align_12: Check the version of picard. Version is 1.82 is recommended. align_13: Check the version of GATK. Version 2.8 is recommended. align_20: Check existence of class files for Picard and GATK align_30: Build bwa index for build hg19 of reference genome align_40: Build samtools index for build hg19 of reference genome align_100: Convert bam files to paired fastq files if the input is in bam/sam format. Other input files are returned untouched. align_101: Decompress all input files (.tgz2, .tar, .tar.gz, .gz, .tgz, .zip etc) to a cache directory. Uncompressed files are hard-linked to the cache directory. align_200: Check the format of the input fastq file and write an option file with option -I if the sequences are in Illumina 1.3+ format. align_201: Call bwa aln to produce .sai files align_300: Determine (guess) a read group tag and write to a .RG file. align_301: Running bwa sampe for paired end reads, using read group tag saved in a .RG file align_302: Check the proportion of aligned reads and exit if there are less than 80% of aligned reads. align_303: If in production mode, remove fastq files dumped from bam files align_400: Merge per-lane sam files into a single bam file. This step is skipped if there is only one input file. align_500: Sort merged bam file using picard SortSam align_501: If in production mode, remove decompressed fastq and individual bam files after a single bam file has been produced. align_600: Mark duplicates using picard MarkDuplicates command align_601: Remove _sorted.bam file after deduplication is completed. align_610: Index dedupped bam file using samtools align_700: Realign indels create indel realigner target align_710: Apply indel realigner target to bam file align_711: If in production mode, remove bam files before realignment steps align_800: Create base recalibrator target align_810: Apply base recalibrator target align_811: If in production mode, remove bam files before realignment steps align_900: Generated bam file with reduced reads if more than one output file is specified Pipeline \u0026quot;call\u0026quot;: Call and validate variants (SNPs and Indels) from one or more input bam files. This pipeline accepts one or more bam files as input and a vcf file as output. If multiple input files are specified, multi-sample variant calling will be performed. call_0: Check the version of variant tools (version 2.1.1 and above is required to execute this pipeline) call_10: Check existence of commands bwa, samtools and java call_13: Check the version of GATK call_20: Check existence of class files for GATK call_100: Use unified genotyper to get raw variants call_200: Recalibrate SNPs call_210: Recalibrate INDELs call_300: Apply SNP recalibration call_310: Apply INDEL recalibration Pipeline parameters: name Name of the job to be executed. All intermediate files generated from this pipeline will be saved to $CACHE_DIR/$NAME where $CACHE_DIR is the cache directory of the project. (default: bwa_gatk28_hg19) strict_prog_version Whether or not use other version of programs if the exact version does not exist. Setting it to False allows variant tools to use other versions of the programs. (default: False) production If set to True or 1, all intermediate files will be removed. The whole pipeline would need to be rerun if a different parameter or different version of external program is used. (default: False) bwa path to bwa. Default to 'bwa' (use $PATH to determine actual path) (default: bwa) samtools path to samtools. Default to 'samtools' (use $PATH to determine actual path) (default: samtools) java path to java. Default to 'java' (use $PATH to determine actual path) (default: java) picard_path Path to picard jar files gatk_path Path to GATK jar file GenomeAnalysisTK.jar opt_java Option to java program. -Djava.io.tmpdir is frequently used to set java temporary directory if system temporary partition is not big enough. (default: -Xmx4g -XX:-UseGCOverheadLimit) opt_bwa_index Option to command 'bwa index' opt_bwa_aln Option to command 'bwa aln' opt_bwa_sampe Option to command 'bwa sampe' opt_samtools_faidx Option to command 'samtools faidx' opt_samtools_index Option to command 'samtools index' opt_picard_sortsam Option to picard SortSam.jar (default: VALIDATION_STRINGENCY=LENIENT) opt_picard_mergesamfiles Option to picard MergeSamFiles.jar (default: MAX_RECORDS_IN_RAM=5000000) opt_picard_samtofastq Option to picard SamToFastq.jar (default: VALIDATION_STRINGENCY=LENIENT NON_PF=true) opt_picard_markduplicates Option to picard MarkDuplicates.jar opt_gatk_realignertargetcreator Option to command gatk RealignerTargetCreator opt_gatk_indelrealigner Option to command gatk IndelRealigner (default: --filter_mismatching_base_and_quals) opt_gatk_baserecalibrator Option to command gatk BaseRecalibrator (default: -rf BadCigar) opt_gatk_printreads Option to command gatk PrintReads opt_gatk_reducereads Option to command gatk ReduceReads opt_gatk_unifiedgenotyper Option to command gatk UnifiedGenotyper (default: -rf BadCigar -stand_call_conf 50.0 -stand_emit_conf 10.0 -dcov 200 -A AlleleBalance -A QualByDepth -A HaplotypeScore -A MappingQualityRankSumTest -A ReadPosRankSumTest -A FisherStrand -A RMSMappingQuality -A InbreedingCoeff -A Coverage) opt_gatk_variantrecalibrator Option to command gatk VarintRecalibrator opt_gatk_variantrecalibrator_snp Option to command gatk VarintRecalibrator -mode SNP (default: -percentBad 0.01 -minNumBad 1000 -an QD -an MQRankSum -an ReadPosRankSum -an FS -an DP) opt_gatk_variantrecalibrator_indel Option to command gatk VarintRecalibrator -mode INDEL (default: --maxGaussians 4 -percentBad 0.01 -minNumBad 1000 -an DP -an FS -an ReadPosRankSum -an MQRankSum) opt_gatk_applyrecalibration Option to command gatk ApplyRecalibrator (default: --ts_filter_level 99.9) opt_gatk_applyrecalibration_snp Option to command gatk ApplyRecalibrator -mode SNP opt_gatk_applyrecalibration_indel Option to command gatk ApplyRecalibrator -mode INDEL  Details Set up environment This pipeline uses the following external commands:\n bwa samtools Picard GATK (Optional) pysam if you will be dealing with non paired-end data.  You can add path to bwa and samtools to $PATH or pass full path name to options bwa=/path/to/bwa and samtools=/path/to/samtools. Paths to Picard and GATK should be passed using options gatk_path and picard_path.\nTest the environment After you installed the programs, you should running the following commands to test if everything works ok:\n# create a new project and download test data (an online snapshot) % vtools init test --parent vt_illuminaTestData % vtools execute bwa_gatk28_hg19 align --input illumina_test_seq.tar.gz --output test.bam \\ --gatk_path /path/to/gatk --picard_path /path/to/picard --strict_prog_version False  Executing the pipeline in production mode The pipeline will by default keep all intermediate files. If you restart the pipeline with different parameter or a different version of an external file, only the affected steps will be repeated. Intermediate files will be reused if available. This allows you to examine and fine-tune the pipeline to make sure it works as expected.\nBecause intermediate files can be large, an option --production true is provided to execute the pipeline in production mode. In this mode, most intermediate files will be removed after the completion of the steps that make use of them. The pipeline can resume from the right step if it is interrupted, but has to be re-executed from the beginning if a result file is removed.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/variants/dbsnp/",
	"title": "dbSNP",
	"tags": [],
	"description": "",
	"content": " dbSNP annotation databases The default version of our dbSNP annotation is currently referring to dbSNP143 (using hg38 coordinates) as shown below. However, users can also retrieve older versions of dbSNP: dbSNP141, dbSNP138, dbSNP137, dbSNP135, dbSNP132, dbSNP131, dbSNP130, dbSNP129. The 129 and 130 versions use hg18 as a reference genome, 131, 132, 135, 137, 138 and 141 use hg19 and 143 uses hg38. The archived versions can be used by a variant tools project by referring to their specific names - for example: dbSNP-hg18_129.\n dbSNP143 has many more flags and fields than previous versions. It also does not contain all variants that are defined in dbSNP141 and earlier. A dbSNP entry might match multiple variants. For example, rs111688037 matches variants T-\u0026gt;A and T-\u0026gt;C at chr6:31602679.  version % vtools show annotation dbSNP -v1 Annotation database dbSNP (version hg38_143) Description: dbSNP version 143, created using vcf file downloaded from NCBI Database type: variant Reference genome hg38: chr, pos, ref, alt chr (char) pos (int) name (char) DB SNP ID (rsname) ref (char) Reference allele (as on the + strand) alt (char) Alternative allele (as on the + strand) FILTER (char) Inconsistent Genotype Submission For At Least One Sample RS (int) dbSNP ID (i.e. rs number) RSPOS (int) Chr position reported in dbSNP RV (int) RS orientation is reversed VP (char) Variation Property. Documentation is at ftp://ftp.ncbi.nlm.nih.gov/snp/specs/dbSNP_BitField_latest.pdf GENEINFO (char) Pairs each of gene symbol:gene id. The gene symbol and id are delimited by a colon (\u0026lt;/summary\u0026gt; and each pair is delimited by a vertical bar (|) dbSNPBuildID (int) First dbSNP Build for RS SAO (int) Variant Allele Origin: 0 - unspecified, 1 - Germline, 2 - Somatic, 3 - Both SSR (int) Variant Suspect Reason Codes (may be more than one value added together) 0 - unspecified, 1 - Paralog, 2 - byEST, 4 - oldAlign, 8 - Para_EST, 16 - 1kg_failed, 1024 - other WGT (int) Weight, 00 - unmapped, 1 - weight 1, 2 - weight 2, 3 - weight 3 or more VC (char) Variation Class PM_flag (int) Variant is Precious(Clinical,Pubmed Cited) TPA_flag (int) Provisional Third Party Annotation(TPA) (currently rs from PHARMGKB who will give phenotype data) PMC_flag (int) Links exist to PubMed Central article S3D_flag (int) Has 3D structure - SNP3D table SLO_flag (int) Has SubmitterLinkOut - From SNP-\u0026gt;SubSNP-\u0026gt;Batch.link_out NSF_flag (int) Has non-synonymous frameshift A coding region variation where one allele in the set changes all downstream amino acids. FxnClass = 44 NSM_flag (int) Has non-synonymous missense A coding region variation where one allele in the set changes protein peptide. FxnClass = 42 NSN_flag (int) Has non-synonymous nonsense A coding region variation where one allele in the set changes to STOP codon (TER). FxnClass = 41 REF_flag_flag (int) Has reference A coding region variation where one allele in the set is identical to the reference sequence. FxnCode = 8 SYN_flag (int) Has synonymous A coding region variation where one allele in the set does not change the encoded amino acid. FxnCode = 3 U3_flag (int) In 3' UTR Location is in an untranslated region (UTR). FxnCode = 53 U5_flag (int) In 5' UTR Location is in an untranslated region (UTR). FxnCode = 55 ASS_flag (int) In acceptor splice site FxnCode = 73 DSS_flag (int) In donor splice-site FxnCode = 75 INT_flag (int) In Intron FxnCode = 6 R3_flag (int) In 3' gene region FxnCode = 13 R5_flag (int) In 5' gene region FxnCode = 15 OTH_flag (int) Has other variant with exactly the same set of mapped positions on NCBI refernce assembly. CFL_flag (int) Has Assembly conflict. This is for weight 1 and 2 variant that maps to different chromosomes on different assemblies. ASP_flag (int) Is Assembly specific. This is set if the variant only maps to one assembly MUT_flag (int) Is mutation (journal citation, explicit fact): a low frequency variation that is cited in journal and other reputable sources VLD_flag (int) Is Validated. This bit is set if the variant has 2+ minor allele count based on frequency or genotype data. G5A_flag (int) \u0026gt;5% minor allele frequency in each and all populations G5_flag (int) \u0026gt;5% minor allele frequency in 1+ populations HD_flag (int) Marker is on high density genotyping kit (50K density or greater). The variant may have phenotype associations present in dbGaP. GNO_flag (int) Genotypes available. The variant has individual genotype (in SubInd table). KGValidated_flag (int) 1000 Genome validated KGPhase1_flag (int) 1000 Genome phase 1 (incl. June Interim phase 1) KGPilot123_flag (int) 1000 Genome discovery all pilots 2010(1,2,3) KGPROD_flag (int) Has 1000 Genome submission OTHERKG_flag (int) non-1000 Genome submission PH3_flag (int) HAP_MAP Phase 3 genotyped: filtered, non-redundant CDA_flag (int) Variation is interrogated in a clinical diagnostic assay LSD_flag (int) Submitted from a locus-specific database MTP_flag (int) Microattribution/third-party annotation(TPA:GWAS,PAGE) OM_flag (int) Has OMIM/OMIA NOC_flag (int) Contig allele not present in variant allele list. The reference sequence allele at the mapped position is not present in the variant allele list, adjusted for orientation. WTD_flag (int) Is Withdrawn by submitter If one member ss is withdrawn by submitter, then this bit is set. If all member ss' are withdrawn, then the rs is deleted to SNPHistory NOV_flag (int) Rs cluster has non-overlapping allele sets. True when rs set has more than 2 alleles from different submissions and these sets share no alleles in common. CAF (char) An ordered, comma delimited list of allele frequencies based on 1000Genomes, starting with the reference allele followed by alternate alleles as ordered in the ALT column. Where a 1000Genomes alternate allele is not in the dbSNPs alternate allele set, the allele is added to the ALT column. The minor allele is the second largest value in the list, and was previuosly reported in VCF as the GMAF. This is the GMAF reported on the RefSNP and EntrezSNP pages and VariationReporter COMMON (int) RS is a common SNP. A common SNP is one that has at least one 1000Genomes population with a minor allele of frequency \u0026gt;= 1% and for which 2 or more founders contribute to that minor allele frequency.  version 141 and earlier % vtools show annotation dbSNP-hg19_141 -v2 Annotation database dbSNP (version hg19_141) Description: dbSNP version 141 Database type: variant Number of records: 58,691,269 Distinct variants: 57,577,990 Reference genome hg19: chr, start, refNCBI, alt Field: chr Type: string Missing entries: 0 Unique Entries: 25 Field: start Type: integer Comment: start position in chrom (1-based) Missing entries: 0 Unique Entries: 48,758,859 Range: 56 - 249240605 Field: end Type: integer Comment: end position in chrom (1-based). start=end means zero-length feature Missing entries: 0 Unique Entries: 48,957,633 Range: 56 - 249240605 Field: name Type: string Comment: dbSNP reference SNP identifier Missing entries: 0 Unique Entries: 58,096,504 Field: strand Type: string Comment: which DNA strand contains the observed alleles Missing entries: 0 Unique Entries: 2 Field: refNCBI Type: string Comment: Reference genomic sequence from dbSNP Missing entries: 0 Unique Entries: 164,868 Field: refUCSC Type: string Comment: Reference genomic sequence from UCSC lookup of chrom,chromStart, chromEnd Missing entries: 0 Unique Entries: 187,096 Field: observed Type: string Comment: Strand-specific observed alleles Missing entries: 0 Unique Entries: 205,862 Field: alt Type: string Comment: alternate allele on the '+' strand Missing entries: 0 Unique Entries: 30,716 Field: molType Type: string Comment: sample type, can be one of unknown, genomic or cDNA Missing entries: 0 Unique Entries: 3 Field: class Type: string Comment: Class of variant (single, in-del, het, named, mixed, insertion, deletion etc Missing entries: 0 Unique Entries: 6 Field: valid Type: string Comment: validation status, can be unknown, by-cluster, by-frequency, by-submitter, by-2hit-2allele, by-hapmap, and by-1000genomes Missing entries: 0 Unique Entries: 63 Field: avHet Type: float Comment: Average heterozygosity from all observations Missing entries: 0 Unique Entries: 39,766 Range: 0 - 0.999999 Field: avHetSE Type: float Comment: Standard error for the average heterozygosity Missing entries: 0 Unique Entries: 46,007 Range: 0 - 0.305748 Field: func Type: string Comment: Functional cetegory of the SNP (coding-synon, coding-nonsynon, intron, etc.) Missing entries: 0 Unique Entries: 648 Field: locType Type: string Comment: Type of mapping inferred from size on reference. Missing entries: 0 Unique Entries: 6  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/regions/genomic_super_dups/",
	"title": "genomicSuperDups",
	"tags": [],
	"description": "",
	"content": "See this blog Why You Should Care About Segmental Duplications for some nice explanation.\nvtools show annotation genomicSuperDups -v2 Annotation database genomicSuperDups (version hg19_20130626) Description: Duplications of \u0026gt;1000 Bases of Non-RepeatMasked Sequence (\u0026gt;90 percent similar). Database type: range Number of records: 51,599 Distinct ranges: 40,832 Reference genome hg19: chr, start, end Field: chr Type: string Comment: Reference sequence chromosome or scaffold Missing entries: 0 Unique Entries: 80 Field: start Type: integer Comment: Start position in chromosome Missing entries: 0 Unique Entries: 30,451 Range: 1 - 249235635 Field: end Type: integer Comment: End position in chromosome Missing entries: 0 Unique Entries: 30,690 Range: 1832 - 249240008 Field: name Type: string Comment: Other chromosome involved Missing entries: 0 Unique Entries: 30,525 Field: otherChr Type: string Comment: Other chromosome or scaffold Missing entries: 0 Unique Entries: 80 Field: otherStart Type: integer Comment: Start position of other region Missing entries: 0 Unique Entries: 30,451 Range: 0 - 249235634 Field: otherEnd Type: integer Comment: End position in chromosome Missing entries: 0 Unique Entries: 30,690 Range: 1832 - 249240008 Field: otherSize Type: integer Comment: Total size of other chromosome Missing entries: 0 Unique Entries: 80 Range: 19913 - 249250621 Field: alignL Type: integer Comment: spaces/positions in alignment Missing entries: 0 Unique Entries: 13,141 Range: 1001 - 777920 Field: indelN Type: integer Comment: number of indels Missing entries: 0 Unique Entries: 436 Range: 0 - 993 Field: indelS Type: integer Comment: indel spaces Missing entries: 0 Unique Entries: 4,617 Range: 0 - 92315 Field: matchB Type: integer Comment: aligned bases that match Missing entries: 0 Unique Entries: 12,497 Range: 1000 - 766171 Field: mismatchB Type: integer Comment: aligned bases that do not match Missing entries: 0 Unique Entries: 12,623 Range: 900 - 766171 Field: transitionsB Type: integer Comment: number of transitions Missing entries: 0 Unique Entries: 2,659 Range: 0 - 9703 Field: transversionsB Type: integer Comment: number of transversions Missing entries: 0 Unique Entries: 1,880 Range: 0 - 5953 Field: fracMatch Type: float Comment: fraction of matching bases Missing entries: 0 Unique Entries: 1,442 Range: 0 - 4002 Field: fracMatchIndel Type: float Comment: fraction of matching bases with indels Missing entries: 0 Unique Entries: 21,193 Range: 0.9 - 1 Field: jcK Type: float Comment: K-value calculated with Jukes-Cantor Missing entries: 0 Unique Entries: 21,393 Range: 0.88604 - 1 Field: k2K Type: float Comment: Kimura K Missing entries: 0 Unique Entries: 23,215 Range: 0 - 0.107326  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/format/formats/plink/",
	"title": "plink",
	"tags": [],
	"description": "",
	"content": " Import variants and sample genotypes from PLINK format Introduction PLINK is a widely used program for analyzing genotypic data for Genome-wide Association Studies (GWAS). It can be considered as standard input format for genotyping array data. An intermediate type of genetic data between genotyping arrays and exome sequencing is the exome genotyping array, or exome chip. Unlike its GWAS counterpart which focuses on relatively common variants, exome chips contain primarily non-singleton coding variants seen in existing whole genome and exome sequencing data, plus a small proportion of non-protein-altering variants such as GWAS tag SNPs, ancestry informative markers, etc. Since exome chips are essentially genotyping arrays, they are often distributed in PLINK data format. Variant tools can thus handle exome chip input and perform rare variants association analysis for exome chip samples.\nThe standard PLINK files can be a bundle of plain text files (PED \u0026amp; MAP dataset, or its transpose, TPED \u0026amp; FAM dataset), or a bundle of binary files (BED, BIM \u0026amp; FAM). PLINK provides commands to convert between text and binary formats. Since PLINK files do not specify for a variant which allele is reference and which is alternative, importing data to a variant tools project requires matching each variant to the reference sequence to determine reference and alternative alleles; complementary strand will be used when necessary. Variant tools performs the matching procedure against hg18 or hg19 reference genomes. Other reference genome builds are not supported.\nCurrently only PLINK binary format (BED, BIM \u0026amp; FAM) is valid input. You need to use PLINK to convert text to binary format if necessary.\nA variant locus will be ignored if it is not polymorphic in input data.\nFormat specification vtools show format plink Format: plink Description: Input format for PLINK dataset. Currently only PLINK binary PED file is supported (*.bed, *.bim \u0026amp; *.fam) Preprocessor: PlinkConverter($build) Columns: None defined, cannot export to this format variant: chr Chromosome pos 1-based Position of the snp ref Reference allele alt Alternative allele Genotype: GT Gentoype coded as 0 (ref ref), 1 (ref alt) and 2 (alt alt) No configurable parameter is defined for this format.  As with other vtools import formats, importing PLINK data requires specification of format file (--format) and input data. Unlike with other formats, however, input filename for PLINK binary data is the base file name without extension. For example if you have X.bed, X.bim and X.fam files then the import command should be\nvtools import /path/to/X --format plink --build hg19 --jobs $N INFO: Preprocessing files X to generate intermediate input files for import INFO: Determining major/minor allele from data Decoding X: 100% [===============================] 149,141 9.1K/s in 00:00:16 INFO: Importing variants from cache/X.plink (1/1) X.plink: 100% [========================] 162,433 49.3K/s in 00:00:03 INFO: 149,141 new variants (149,141 SNVs) from 149,142 lines are imported. Importing genotypes: 100% [======================] 668,901,870 630.4K/s in 00:17:41 Copying genotype: 100% [========================] 4,485 194.8/s in 00:00:23  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_report/sam_info/",
	"title": "sam_info",
	"tags": [],
	"description": "",
	"content": " Output coverage and other information of variants in specified SAM/BAM files This command is deprecated with the new track function with BAM tracks.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/functions/track/",
	"title": "track",
	"tags": [],
	"description": "",
	"content": " Extract annotation from external files Usage Function track(filename, field) returns annotation information at column col (optional) in file filename, at position (chr, pos at primary or alternative reference genome) of each variant. For example, function\n% vtools output variant chr pos ref alt \u0026quot;track('1000g.vcf.gz', 'info')\u0026quot;  single quote (') should be used for string literals in SQL functions. Double quote (\u0026quot;) should be avoided although it sometimes works.\noutput the \u0026ldquo;info\u0026rdquo; column of file 1000g.vcf.gz, for variants at location chr and pos.\nThis function currently accepts four types of track files:\n Local or online bgzipped and tabix-indexed vcf files with extension .vcf.gz. bigWig files that provides dense and continuous data for a region. bigBed files with 3 required columns and 9 optional columns. Annotation tracks in BED format can be converted to this format using program bedToBigBed. Local or online indexed BAM files with extension .bam. This format does not contain \u0026lsquo;columns\u0026rsquo; as other formats do but it provides alignment information for the variants.  The allowed and default values of the second option field vary for different file formats. Generally speaking, numeric values such as 1, 2, \u0026hellip; returns the col-th column of the input data file, with the exception that `returns1(match or not) for all matched records. String values such as\u0026ldquo;chrom\u0026rdquo;,\u0026ldquo;chromStart\u0026rdquo;,\u0026ldquo;info\u0026rdquo;` return values at specified column as strings.\nDetails Display information about tracks Before you use each track, it is important to run command\n% vtools show track FilenameOrURL  to get the detailed information about the track file, and the available fields and their types.\n As a shortcut to enter track function for multiple files, you can use wildcast characters in the first parameter (filename) of the track function. This will result in multiple track() function calls for each matching filename. For example, if you have A01.BAM and A02.BAM in the current directory, function track('A*.BAM', 'calls') is equivalent to track('A01.BAM', 'calls') track('A02.BAM', 'calls'). The return values of the returned field will be numeric if the column contains numeric data (e.g. flag, score, position). Only the first record will be returned if a variant matches multiple records in the track file. If an option all=1 is passed to field (e.g. track('my.bam', 'info?all=1')), the track function will output all matching records as string, separated by a delimiter |. This function automatically chooses correct chromosome name (adding chr to chromosome name if needed), and position (adjust to 0-based position if needed) to match records in the track file. The return values are not adjusted. That is to say, columns such as pos will be 0-based for 0-based track files (e.g. bigBed files), and 1-based for 1-based track files (e.g. vcf).  Please refer to here for more details of command vtools show, especially a brief description of the BAM header.\nTabixed vcf tracks VCF files that can be used as tracks must be bgzipped and tabix-indexed. Regular vcf files can be converted to this format using commands bgzip my.vcf and tabix -p vcf my.vcf.gz. Parameter col for this format can be 1 (chrom), 2 (start, 1-based), 3 (name), 4 (ref), 5 (alt alleles), 6 (qual), 7 (filter), 8 (info), 9 (format string), 10 and more (for genotype columns for sample col-9); names of the columns \u0026quot;chrom\u0026quot;, \u0026quot;pos\u0026quot;, \u0026quot;name\u0026quot;, \u0026quot;ref\u0026quot;, \u0026quot;alt\u0026quot;, \u0026quot;qual\u0026quot;, \u0026quot;filter\u0026quot;, \u0026quot;info\u0026quot;, \u0026quot;format\u0026quot;; name of information fields available in the vcf file in the format of info.FIELD; name of samples for genotype columns, and name of genotype info fields in the format of SAMPLE.FIELD. If no col is specified, a default value 8 is passed to display the full INFO column of the vcf file.\n Examples: Annotate variants using vcf tracks Let us get some test data, and index the vcf file using the tabix program\n% vtools init track % tabix -p vcf CEU_hg38.vcf.gz % vtools import CEU_hg38.vcf.gz --build hg38 INFO: Importing variants from CEU_hg38.vcf.gz (1/1) CEU_hg38.vcf.gz: 100% [===================================] 306 10.4K/s in 00:00:00 INFO: 292 new variants (292 SNVs) from 306 lines are imported. Importing genotypes: 100% [================================] 292 2.7K/s in 00:00:00  The track information can be displayed using command\n% vtools show track CEU.vcf.gz | head -30 Version VCF v4.0 Number of fields: 69 Header: (exclude INFO and FORMAT lines) ##reference=human_b36_both.fasta ##rsIDs=dbSNP b129 mapped to NCBI 36.3, August 10, 2009 Available columns (with type VARCHAR if unspecified or all=1): 0 (INTEGER) 1 if matched chr (1, chrom) chromosome pos (2, INTEGER) position (1-based) name (3) name of variant ref (4) reference allele alt (5) alternative alleles qual (6) qual filter (7) filter info (8, default) variant info fields info.DP (INTEGER) Total Depth info.HM2 (INTEGER, flag) HapMap2 membership info.HM3 (INTEGER, flag) HapMap3 membership info.AA Ancestral Allele, ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/technical/reference/ancestral_alignments/README info.AC (INTEGER) Allele count in genotypes info.AN (INTEGER) Total number of alleles in called genotypes format (9) genotype format NA06985 (10) genotype for sample NA06985 NA06985.GT Genotype for sample NA06985 NA06985.DP (INTEGER) Read Depth for sample NA06985 NA06985.CB Called by S(Sanger), M(UMich), B(BI) for sample NA06985 NA06986 (11) genotype for sample NA06986 NA06986.GT Genotype for sample NA06986  We can use the track function to display the info column in the original vcf file,\n% vtools output variant chr pos \u0026quot;track('CEU_hg38.vcf.gz')\u0026quot; -l 5 1 10533 AA=.;AC=6;AN=120;DP=423 1 51479 AA=.;AC=29;AN=120;DP=188 1 51928 AA=.;AC=5;AN=120;DP=192 1 54586 AA=C;AC=2;AN=120;DP=166 1 54676 AA=T;AC=2;AN=120;DP=131  The default parameter col=8 is used to extract the info column of the info file. You can display other tracks such as name\n% vtools output variant chr pos \u0026quot;track('CEU_hg38.vcf.gz', 'name')\u0026quot; -l 5 1 10533 . 1 51479 . 1 51928 . 1 54586 . 1 54676 rs2462492  Values of individual info fields could be specified by info.FIELD where FIELD is the name of info field.\n% vtools output variant chr pos \u0026quot;track('CEU_hg38.vcf.gz', 'info.DP')\u0026quot; -l 5 1 10533 423 1 51479 188 1 51928 192 1 54586 166 1 54676 131  If you know the name of the sample (in the vcf file, this example happens to has samples from this file),\n% vtools show samples -l 5 sample_name filename NA06985 CEU_hg38.vcf.gz NA06986 CEU_hg38.vcf.gz NA06994 CEU_hg38.vcf.gz NA07000 CEU_hg38.vcf.gz NA07037 CEU_hg38.vcf.gz (55 records omitted)  you can get the genotype columns using sample name\n% vtools output variant chr pos \u0026quot;track('CEU_hg38.vcf.gz', 'NA06986')\u0026quot; -l 5 1 10533 0|0:14:SMB 1 51479 0|1:16:SMB 1 51928 0|0:7:SM 1 54586 0|0:6:SM 1 54676 0|0:12:SM  With the format information abtained from\n% vtools output variant chr pos \u0026quot;track('CEU.vcf.gz', 'format')\u0026quot; -l 5 1 10533 GT:DP:CB 1 51479 GT:DP:CB 1 51928 GT:DP:CB 1 54586 GT:DP:CB 1 54676 GT:DP:CB  we can list fields of the genotype columns,\n% vtools output variant chr pos \u0026quot;track('CEU.vcf.gz', 'NA06986.GT')\u0026quot; -l 5 1 10533 0|0 1 51479 0|1 1 51928 0|0 1 54586 0|0 1 54676 0|0  \nA very useful feature of the vcf track is that you can use vcf files from online by specifying a URL instead of a local filename.\n Examples: Annotate variants using online vcf files We would like to annotate our variants using VCF files from the hg19 version of 1000 genomes project. To make use of data from the 1000 genomes project, we need to first lift over our project:\n% vtools liftover hg19 INFO: Exporting variants in BED format Exporting variants: 100% [==========================] 288 67.3K/s in 00:00:00 INFO: Running UCSC liftOver tool Updating table variant: 100% [======================] 288 21.8K/s in 00:00:00  To pass the correct coordinates, option --build hg19 is needed:\n% vtools output variant chr pos \u0026quot;track('http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20110521/ALL.chr1.phase1_release_v3.20101123.snps_indels_svs.genotypes.vcf.gz', 'info')\u0026quot; \\ % -l 5 --build hg19 1 10533 . 1 51479 RSQ=0.7414;AVGPOST=0.9085;AA=T;AN=2184;THETA=0.0131;AC=235;VT=SNP;LDAF=0.1404;SNPSOURCE=LOWCOV;ERATE=0.0012;AF=0.11;ASN_AF=0.0035;AMR_AF=0.16;AFR_AF=0.03;EUR_AF=0.22 1 51928 . 1 54586 . 1 54676 LDAF=0.1528;RSQ=0.6989;AA=T;AN=2184;AC=267;VT=SNP;AVGPOST=0.8998;SNPSOURCE=LOWCOV;THETA=0.0110;ERATE=0.0037;AF=0.12;ASN_AF=0.02;AMR_AF=0.20;AFR_AF=0.09;EUR_AF=0.18  \nAvailable variant and genotype info fields are determined from the header of input vcf file. Columns such as info.AA is unacceptable if AA is not defined in the header.\nbigWig tracks The bigWig tracks contains numeric values for locations (ranges). The default col value for this format is 4 (the value column), but you can specify 1 (chrom), 2 (start, 0-based), 3 (end, 1-based), 4 (value), and \u0026quot;chrom\u0026quot;, \u0026quot;chromStart\u0026quot;, \u0026quot;chromEnd\u0026quot;, and \u0026quot;value\u0026quot;.\n Examples: Use bigWig tracks to annotate and select variants Let us create a project in hg19, import some data, and download a bigWig track from the UCSC ENCODE website:\n% wget http://hgdownload.cse.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeOpenChromFaire/wgEncodeOpenChromFaireFrontalcortexocSig.bigWig % vtools init track -f % vtools import indels.vcf --build hg19 INFO: Importing variants from indels.vcf (1/1) indels.vcf: 100% [============================================] 184 12.3K/s in 00:00:00 INFO: 137 new variants (1 SNVs, 77 insertions, 58 deletions, 7 complex variants) from 184 lines are imported. Importing genotypes: 0 0.0/s in 00:00:00 Copying samples: 0 0.0/s in 00:00:00  The detailed information about this track can be obtained by\n% vtools show track wgEncodeOpenChromFaireFrontalcortexocSig.bigWig Version: 4 Primary data size 1320909131 Zoom levels: 10 Chrom count: 23 Chrom size: chr1 249250621 chr10 135534747 chr11 135006516 chr12 133851895 chr13 115169878 chr14 107349540 chr15 102531392 chr16 90354753 chr17 81195210 chr18 78077248 chr19 59128983 chr2 243199373 chr20 63025520 chr21 48129895 chr22 51304566 chr3 198022430 chr4 191154276 chr5 180915260 chr6 171115067 chr7 159138663 chr8 146364022 chr9 141213431 chrX 155270560 Bases covered: 2951253637 Mean: 0.004807 Min: 0.000000 Max: 0.592400 std: 0.004469 Number of fields: 4 Available columns (with type VARCHAR if unspecified or all=1): 0 (INTEGER) 1 if matched chrom (1) chromosome chromStart (2, INTEGER) start position (0-based) chromEnd (3, INTEGER) end position (1-based) value (4, FLOAT) value  and we can show the track values for each variant using command\n% vtools output variant chr pos ref alt \u0026quot;track('wgEncodeOpenChromFaireFrontalcortexocSig.bigWig')\u0026quot; -l 5 1 10434 - C 0.00089999998454 1 10440 C - 0.00089999998454 1 54789 C - 0.00719999987632 1 54790 - T 0.00719999987632 1 63738 ACT - 0.00710000004619  In addition to output, the track can also be used to select variants,\n% vtools select variant \u0026quot;track('wgEncodeOpenChromFaireFrontalcortexocSig.bigWig') \u0026gt; 0.001\u0026quot; \\ --output chr pos ref alt \u0026quot;track('wgEncodeOpenChromFaireFrontalcortexocSig.bigWig')\u0026quot; -l 5 1 54789 C - 0.00719999987632 1 54790 - T 0.00719999987632 1 63738 ACT - 0.00710000004619 1 63738 ACT CTA 0.00710000004619 1 81963 - AA 0.0120000001043  \nbigBed tracks BigBed is a compressed indexed BED format that contains three mandatory columns and nine optional columns. The default col value for this format is `(return 1 for matched records), but you can be specify items such as1(chrom) andchromStart(start, 0-based) according to output of commandvtools show track BIGBEDFILE`.\n Examples: Use bigBed tracks to annotate variants Let us create a project in hg19, import some data, and download a bigWig track from the UCSC ENCODE website:\n% wget http://hgdownload.cse.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeDukeAffyExon/wgEncodeDukeAffyExonUrothelUt189SimpleSignalRep2.bigBed % vtools init track % vtools import indels.vcf --build hg19 INFO: Importing variants from indels.vcf (1/1) indels.vcf: 100% [============================================] 184 12.3K/s in 00:00:00 INFO: 137 new variants (1 SNVs, 77 insertions, 58 deletions, 7 complex variants) from 184 lines are imported. Importing genotypes: 0 0.0/s in 00:00:00 Copying samples: 0 0.0/s in 00:00:00  This tracks provides the following information:\n% vtools show track wgEncodeDukeAffyExonUrothelUt189SimpleSignalRep2.bigBed Version: 4 Item count: 38378 Primary data size: 798350 Zoom levels: 7 Chrom count: 24 Chrom size: chr1 249250621 chr10 135534747 chr11 135006516 chr12 133851895 chr13 115169878 chr14 107349540 chr15 102531392 chr16 90354753 chr17 81195210 chr18 78077248 chr19 59128983 chr2 243199373 chr20 63025520 chr21 48129895 chr22 51304566 chr3 198022430 chr4 191154276 chr5 180915260 chr6 171115067 chr7 159138663 chr8 146364022 chr9 141213431 chrX 155270560 chrY 59373566 Bases covered 1143378960 Mean depth: 1.055693 Min depth: 1.000000 Max depth: 18.000000 Std of depth: 0.310857 Number of fields: 9 Available columns (with type VARCHAR if unspecified or all=1): chrom (1) Chromosome (or contig, scaffold, etc.) chromStart (2, INTEGER) Start position in chromosome chromEnd (3, INTEGER) End position in chromosome name (4) Name of item score (5, INTEGER) Score from 0-1000. Capped number of reads strand (6) + or - signalValue (7, FLOAT) Measurement of expression value of the gene exonCount (8, INTEGER) Number of exons used to estimate expression value constituitiveExons (9, INTEGER) Number of constituitive exons used to estimate the expression value  The track provides provides numeric annotation for each variant,\n% vtools output variant chr pos ref alt \u0026quot;track('wgEncodeDukeAffyExonUrothelUt189SimpleSignalRep2.bigBed')\u0026quot; -l5 1 10434 - C . 1 10440 C - . 1 54789 C - . 1 54790 - T . 1 63738 ACT - .  The first five variant does not overlap with any regions in the bigBed file, but we can select variants using track membership:\n% vtools select variant \u0026quot;track('wgEncodeDukeAffyExonUrothelUt189SimpleSignalRep2.bigBed') = 1\u0026quot; -t encode Running: 0 0.0/s in 00:00:00 INFO: 28 variants selected.  and lists fields from the bigBed file for these variants\n% vtools output encode chr pos ref alt \u0026quot;track('wgEncodeDukeAffyExonUrothelUt189SimpleSignalRep2.bigBed', 4)\u0026quot; -l5 1 761958 - T LINC00115 1 768117 GTTTT - RP11-206L10.11 1 768117 - GTTTT RP11-206L10.11 1 768118 - TT RP11-206L10.11 1 768625 - A RP11-206L10.11  and\n% vtools output encode chr pos ref alt \u0026quot;track('wgEncodeDukeAffyExonUrothelUt189SimpleSignalRep2.bigBed', 'score')\u0026quot; -l5 1 761958 - T 692 1 768117 GTTTT - 659 1 768117 - GTTTT 659 1 768118 - TT 659 1 768625 - A 659  \nIndexed BAM tracks Tracks in BAM format provides information regarding aligments, namely the reads that cover the starting position of each variant. If the variant is called from the provided BAM file, the BAM track provides information regarding the reads from which variants are called.\nvariant tools currently only use the starting location of variants so it ignores reads that overlap but do not cover the starting position of a variant (e.g. an insertion).\nA BAM track accepts the following fields,\n coverage: number of reads that cover the starting position of each variant. This is the default field. calls: nucleotide of the reads at the variant location. This allows you to show the number of reference and alternative alleles for SNV variants, but not so informative for indels. reads: display a small piece of nucleotide sequence around the variant location (default to 5, namely the variant location and 4 base after it), separated by |. _ will be displayed if the position goes beyond the end of a read. A parameter can be specified in the form of reads?start=-5\u0026amp;width=10 to change the starting point and width of displayed sequence. qual: A list of phred base quality of reads at the location. avg_qual: Average qual scores of all reads. mapq: A list of phred-scaled quality of alignment at the location. avg_mapq: Average map qual scores of all reads. Any tag values listed at the end of command vtools show track.  Parameters can be used to limit the reads to count or display, and change the way reads are displayed. The bam track currently supports the following options:\n type: If set to `(matched to reference sequence),1(unmatched single nucleotide),2(insertion) and3` (deletion), only reads that are matched, unmatched (single nucleotide), insertion or deletion at the variant location is counted or outputted. Note that nucleotide before the insertion will be matched to reference genome, but they are not counted as matched. min_mapq: limits the reads to those with mapq scores that exceed the specified value. min_qual: limits the reads to those with qual scores that execeed the specified value. color=[1|0]: display variant location in blue, and insertions in green for reads field. limit: limit the number of reads or calls to display if the depth of coverage is high. delimiter: character (e.g. \\t to separate reads in the reads output (| is used by default). show_seq=[1|0]: A . is used by default when the nucleotide matches the reference genome at the location. The actual nucleotide sequence will be displayed if this option is set to 1.  You can count the number of reads that match (or unmatch) the reference genome using parameter coveragetype=0@@.\n Examples: Use BAM files to check the details of variant calls.  Now suppose that we have a project with a list of variants (due to the size of BAM files, original data is not provided), we select the variants based on the sample from which they are called:\n% vtools select variant --samples \u0026quot;sample_name = 'WGS4_9'\u0026quot; -t ex49 INFO: 1 samples are selected by condition: sample_name = 'WGS4_9' Running: 3,959 164.5/s in 00:00:24 INFO: 1191 variants selected.  We first need to check the available information that can be retrived\n$ vtools show track LP6005253-DNA_A02.bam Header: @HD VN:1.0 SO:coordinate @PG ID:CASAVA VN:CASAVA-1.9.0a1_110909 CL:/illumina/development/casava/CASAVA-VariantCalling-2.12a_gVCF/bin/configureBuild.pl --targets all bam --inSampleDir=/illumina/build/services/Projects/MDAnderson_Thompson2/LP6005253-DNA_A02/Aligned/D1LTMACXX_Aligned_MDAnderson_Thompson2_LP6005253-DNA_A02_121222_SN1012_0268_BD1LTMACXX_CE_L5/Sample_LP6005253-DNA_A02 --inSampleDir=/illumina/build/services/Projects/MDAnderson_Thompson2/LP6005253-DNA_A02/Aligned/D1LTMACXX_Aligned_MDAnderson_Thompson2_LP6005253-DNA_A02_121222_SN1012_0268_BD1LTMACXX_CE_L6/Sample_LP6005253-DNA_A02 --inSampleDir=/illumina/build/services/Projects/MDAnderson_Thompson2/LP6005253-DNA_A02/Aligned/D1LTMACXX_Aligned_MDAnderson_Thompson2_LP6005253-DNA_A02_121222_SN1012_0268_BD1LTMACXX_CE_L7/Sample_LP6005253-DNA_A02 --outDir=/scratch/LP6005253-DNA_A02 --samtoolsRefFile=/illumina/scratch/services/Genomes/FASTA_UCSC/HumanNCBI37_UCSC/HumanNCBI37_UCSC_XX.fa --indelsSaveTempFiles --variantsConsensusVCF --jobsLimit=12 --variantsPrintUsedAlleleCounts --variantsWriteRealigned --sortKeepAllReads --bamChangeChromLabels=OFF --sgeQueue=prod-s.q @SQ SN:chr1 LN:249250621 @SQ SN:chr2 LN:243199373 @SQ SN:chr3 LN:198022430 @SQ SN:chr4 LN:191154276 @SQ SN:chr5 LN:180915260 @SQ SN:chr6 LN:171115067 @SQ SN:chr7 LN:159138663 @SQ SN:chrX LN:155270560 @SQ SN:chr8 LN:146364022 @SQ SN:chr9 LN:141213431 @SQ SN:chr10 LN:135534747 @SQ SN:chr11 LN:135006516 @SQ SN:chr12 LN:133851895 @SQ SN:chr13 LN:115169878 @SQ SN:chr14 LN:107349540 @SQ SN:chr15 LN:102531392 @SQ SN:chr16 LN:90354753 @SQ SN:chr17 LN:81195210 @SQ SN:chr18 LN:78077248 @SQ SN:chr20 LN:63025520 @SQ SN:chr19 LN:59128983 @SQ SN:chr22 LN:51304566 @SQ SN:chr21 LN:48129895 @SQ SN:chrM LN:16571 Chrom size: 24 chr1 249250621 chr2 243199373 chr3 198022430 chr4 191154276 chr5 180915260 chr6 171115067 chr7 159138663 chrX 155270560 chr8 146364022 chr9 141213431 chr10 135534747 chr11 135006516 chr12 133851895 chr13 115169878 chr14 107349540 chr15 102531392 chr16 90354753 chr17 81195210 chr18 78077248 chr20 63025520 chr19 59128983 chr22 51304566 chr21 48129895 chrM 16571 Available fields (with type VARCHAR if unspecified or all=1): 0 (INTEGER) 1 if depth is over 0, NULL otherwise coverage (INTEGER) Number of reads that cover the starting position of the variant calls nucleotide of the reads at the variant location reads nucleotide sequence around the variant location qual A list of phred base quality of reads at the location avg_qual (FLOAT) Average qual score of all reads mapq A list of phred base quality of alignment at the location avg_mapq (FLOAT) Average mapq score of all reads Tags and flag that can be outputed or used in filters, with values from the 1st record: AM C (int) : 0 BC Z (string) : 0 XD Z (string) : 49A12AC19C11C4 SM i (int32) : 0 AS i (int32) : 511 flag int flag : 0x63 (paired, unmapped according to bits 1 \u0026amp; 3) Parameters start (default to 0), width (default to 5) and color (default to 0) can be used with reads to adjust the window around variant, and use colors for insertions and variant allele, with syntax reads?start=-5\u0026amp;width=10\u0026amp;color=1. min_qual, min_mapq and TAG=VAL (or \u0026gt;, \u0026gt;=, \u0026lt;, \u0026lt;=, !=) can be used for all fields to limit the reads to the ones with mapq and qual scores that exceed the specified value, and tag satisfying specified conditions. Parameter limit limits the number of reads or calls to display if the depth of coverage is high.  The depth of coverage of these variants could be obtained using the BAM track,\n% vtools output ex49 chr pos ref alt \u0026quot;track('LP6005253-DNA_A02.bam')\u0026quot; -l5 1 1138963 C T 26 1 1470808 G A 37 1 6161109 C T 27 1 6314785 T C 32 1 9990112 A G 43  The quality of reads and alignment can be displayed using fields qual and mapq,\n% vtools output ex49 chr pos ref alt \u0026quot;track('LP6005253-DNA_A02.bam', 'qual')\u0026quot; -l5 1 1138963 C T 34,34,32,30,33,39,40,41,31,34,23,25,37,33,34,40,40,2,11,31,33,24,2,40,39,35 1 1470808 G A 31,2,37,35,35,33,33,35,33,29,41,35,35,33,33,2,35,5,35,35,36,40,31,40,31,26,23,38,33,39,31,41,40,30,35,34,34 1 6161109 C T 10,31,32,39,31,39,41,41,35,2,22,40,38,28,39,40,39,35,41,20,40,35,39,38,35,30,34 1 6314785 T C 2,34,37,2,33,2,31,27,37,10,24,39,33,36,31,35,35,36,33,33,38,41,41,29,38,38,39,23,35,35,31,35 1 9990112 A G 34,34,37,37,35,36,36,33,36,36,41,31,37,39,36,40,38,36,41,38,37,41,35,25,38,40,40,40,36,41,41,39,37,34,30,36,36,41,41,36,39,37,37 % vtools output ex49 chr pos ref alt \u0026quot;track('LP6005253-DNA_A02.bam', 'mapq')\u0026quot; -l5 1 1138963 C T 254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,241,254,254,254,254,254,254,254,254 1 1470808 G A 254,194,254,254,254,254,254,254,254,254,254,254,254,254,254,149,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254 1 6161109 C T 254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254 1 6314785 T C 254,254,254,254,254,254,254,254,254,231,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254 1 9990112 A G 254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254,254  We can exclude some reads depending on quality scores, using parameters min_qual or min_mapq,\n% vtools output ex49 chr pos ref alt \u0026quot;track('LP6005253-DNA_A02.bam', 'coverage?min_qual=30')\u0026quot; -l5 1 1138963 C T 20 1 1470808 G A 31 1 6161109 C T 22 1 6314785 T C 24 1 9990112 A G 42  Read TAGs can also be outputed or used in filter conditions. For example, this bam file has tags AM, BC, XD, SM and AS, you can list the AS values of all reads using command\n% vtools output ex49 chr pos ref alt 'ref_sequence(chr, pos-3, pos+3)' \u0026quot;track('LP6005253-DNA_A02.bam', 'AS?min_qual=35')\u0026quot; -l5 1 1138963 C T AGCCTCC 1007|1001|1001|966|941|1006|816|946|1002 1 1470808 G A GGCGGCC 1007|475|783|951|998|878|967|968|1004|967|967|962|962|935|1004|1008|963|998 1 6161109 C T TACCGTG 897|922|927|830|967|965|936|997|997|832|774|961|966|922|937|949|964 1 6314785 T C CGATGGG 939|517|0|925|968|965|962|912|968|967|855|0|924|962|923|919 1 9990112 A G ATCATTA 964|966|968|1007|965|1003|1008|1008|991|963|989|963|906|872|1008|1007|965|962|968|1002|963|1007|963|966|1006|937|912|1008|966|1008|962|1008|1008|1005|1008|1008  or its values to filter reads:\n% vtools output ex49 chr pos ref alt 'ref_sequence(chr, pos-3, pos+3)' \u0026quot;track('LP6005253-DNA_A02.bam', 'coverage?AS\u0026gt;1000')\u0026quot; -l5 1 1138963 C T AGCCTCC 5 1 1470808 G A GGCGGCC 7 1 6161109 C T TACCGTG 0 1 6314785 T C CGATGGG 1 1 9990112 A G ATCATTA 18  \n Count and display calls and reads for reads of different types\nThe track function can also be used to display calls (nucleotide at the variant site) and reads (nucleotide sequences around the variant site). To demonstrate the features more clearly, we will use a project with more types of variants.\nFirst, we can display the nucleotide at the variant site using the calls parameter,\n% bam=/path/to/a/bam/file % vtools output exon1 chr pos ref alt \u0026quot;track('${bam}', 'calls?limit=20')\u0026quot; 1 118420020 - T IIIII.I.I.I..III.I.I 1 159023386 G A .AAAAA..A.AA..A..A.A 1 160398161 G A A.A.AA....A..AAA..A. 1 180772617 C T .T..TTT..TT.T.TTTT.T 3 12581722 T C C.C.......C.C....CC. 4 1945715 A T .N..T..TTTTT.T..T.TT 5 137089865 C G .G..G.G..GGGG...G... 8 42878531 TCCT - .................... 12 65449852 C A AA.A.A..AA.AAA..AAAA 16 11929051 T C CC..CCC.........C... 16 17197814 G A AA..A.AAAAA..AA.AAAA 17 78938525 G A A......AAA....AAAAAA 17 79525590 C G .GG.GGG..GG...G.G... 17 79687655 C T ....T.TTT.TTT..TTN.T 19 34843754 CCCCACCCCAGC - ..........**.*......  The output shows\n Nucleotides that match the reference sequence are displayed as .. Deletions are displayed as *. Insertions are displayed as I.  You can display the reads around the variant site, using the reads parameter:\n% vtools output exon1 chr pos ref alt \u0026quot;track('${bam}', 'reads?limit=5')\u0026quot; 1 118420020 - T T.....|T.....|T.....|T.....|T..... 1 159023386 G A .. |A... |A....|A....|A.... 1 160398161 G A A |.. |A.. |... |A.... 1 180772617 C T . |T.. |.... |.....|T.... 3 12581722 T C C |.. |C.. |.... |..... 4 1945715 A T .... |N....|.....|.....|T.... 5 137089865 C G .....|G....|.....|.....|G.... 8 42878531 TCCT - . |.... |.... |.....|..... 12 65449852 C A A |A.. |.... |A....|..... 16 11929051 T C C. |C....|.....|.....|C.... 16 17197814 G A A. |A.. |.... |.....|A.... 17 78938525 G A A.. |.... |.... |.....|..... 17 79525590 C G .. |G... |G... |.....|G.... 17 79687655 C T . |.....|.....|.....|T.... 19 34843754 CCCCACCCCAGC - .. |.. |... |.....|.....  Parameter limit-5 is used to avoid lengthy output.\nParameters start and width can be used to specify the window of sequences to display:\n% vtools output exon1 chr pos ref alt \u0026quot;track('${bam}', 'reads?limit=5\u0026amp;start=-5\u0026amp;width=8\u0026amp;color=1\u0026amp;show_seq=1')\u0026quot; 1 118420020 - T GTTACTTTT|GTTACTTTT|GTTACTTTT|GTTACTTTT|GTTACTTTT 1 159023386 G A AAGTGGT |AAGTGATG|AAGTGATG|AAGTGATG|AAGTGATG 1 160398161 G A CTTCCA |CTTCCGT |CTTCCATG|CTTCCGTG|CTTCCATG 1 180772617 C T TACTAC |TACTATGC|TACTACGC|TACTACGC|TACTATGC 3 12581722 T C GGTTGC |GGTTGTG |GGTTGCGC|GGTTGTGC|GGTTGTGC 4 1945715 A T AAATGACC|AAANNNCC|AAATGACC|AAATGACC|AAATGTCC 5 137089865 C G TGGAGCCA|TGGAGGCA|TGGAGCCA|TGGAGCCA|TGGAGGCA 8 42878531 TCCT - CTTCCT |CTTCCTCC|CTTCCTCC|CTTCCTCC|CTTCCTCC 12 65449852 C A ACTTAA |ACTTAAAT|ACTTACAT|ACTTAAAT|ACTTACAT 16 11929051 T C TTTTTCT |TTTTTCTC|TTTTTTTC|TTTTTTTC|TTTTTCTC 16 17197814 G A GAGAGAA |GAGAGAAA|GAGAGGAA|GAGAGGAA|GAGAGAAA 17 78938525 G A CAGGCACT|CAGGCGCT|CAGGCGCT|CAGGCGCT|CAGGCGCT 17 79525590 C G CTCCCCT |CTCCCGTT|CTCCCGTT|CTCCCCTT|CTCCCGTT 17 79687655 C T CAGACC |CAGACCAC|CAGACCAC|CAGACCAC|CAGACTAC 19 34843754 CCCCACCCCAGC - GCAGACC |GCAGACC |GCAGACCC|GCAGACCC|GCAGACCC  Parameter color=1 will make the insertion displayed in green, and nucleotide at variant site displayed in blue on terminal. Parameter show_seq displays real sequence instead of . for matched nucleotides.\nYou can also specify the types of reads so that you can count or display just a subsets of reads. For example, you can display all reads on the forward strand\n% vtools output exon1 chr pos ref alt \u0026quot;track('${bam}', 'reads?limit=5\u0026amp;start=-5\u0026amp;width=8\u0026amp;color=1\u0026amp;show_seq=1\u0026amp;strand=+')\u0026quot; 1 118420020 - T GTTACTTTT|GTTACTTTT|GTTACTTTT|GTTACTTTT|GTTACTTTT 1 159023386 G A AAGTGATG|AAGTGATG|AAGTGATG|AAGTGATG|AAGTGGTG 1 160398161 G A CTTCCATG|CTTCCATG|CTTCCATG|CTTCCATG|CTTCCATG 1 180772617 C T TACTACGC|TACTACGC|TACTATGC|TACTATGC|TACTACGC 3 12581722 T C GGTTGTG |GGTTGCGC|GGTTGTGC|GGTTGTGC|GGTTGTGC 4 1945715 A T AAANNNCC|AAATGACC|AAATGACC|AAATGTCC|AAATGACC 5 137089865 C G TGGAGCCA|TGGAGGCA|TGGAGCCA|TGGAGCCA|TGGAGGCA 8 42878531 TCCT - CTTCCTCC|CTTCCTCC|CTTCCTCC|CTTCCTCC|CTTCCTCC 12 65449852 C A ACTTACAT|ACTTAAAT|ACTTAAAT|ACTTAAAT|ACTTAAAT 16 11929051 T C TTTTTCTC|TTTTTTTC|TTTTTTTC|TTTTTTTC|TTTTTTTC 16 17197814 G A GAGAGAA |GAGAGAAA|GAGAGGAA|GAGAGAAA|GAGAGAAA 17 78938525 G A CAGGCACT|CAGGCGCT|CAGGCGCT|CAGGCGCT|CAGGCGCT 17 79525590 C G CTCCCGTT|CTCCCGTT|CTCCCGTT|CTCCCCTT|CTCCCCTT 17 79687655 C T CAGACCAC|CAGACCAC|CAGACCAC|CAGACCAC|CAGACTAC 19 34843754 CCCCACCCCAGC - GCAGACCC|GCAGACCC|GCAGACCC|GCAGACCC|GCAGACCC  Or display just the mismatch single-nucleotides\n% vtools output exon1 chr pos ref alt \u0026quot;track('${bam}', 'reads?limit=5\u0026amp;start=-5\u0026amp;width=8\u0026amp;type=1')\u0026quot; 1 118420020 - T 1 159023386 G A .....A..|.....A..|.....A..|.....A..|.....A.. 1 160398161 G A .....A |.....A..|.....A..|.....A..|.....A.. 1 180772617 C T .....T..|.....T..|.....T..|.....T..|.....T.. 3 12581722 T C .....C |.....C..|.....C..|.....C..|.....C.. 4 1945715 A T ...NNN..|.....T..|.....T..|.....T..|.....T.. 5 137089865 C G .....G..|.....G..|.....G..|.....G..|.....G.. 8 42878531 TCCT - 12 65449852 C A .....A |.....A..|.....A..|G....A..|.....A.. 16 11929051 T C .....C. |.....C..|.....C..|.....C..|.....C.. 16 17197814 G A .....A. |.....A..|.....A..|.....A..|.....A.. 17 78938525 G A .....A..|.....A..|.....A..|.....A..|.....A.. 17 79525590 C G .....G..|.....G..|.....G..|.....G..|.....G.. 17 79687655 C T .....T..|.....T..|.....T..|.....T..|.....T.. 19 34843754 CCCCACCCCAGC -  For example, we can output the number of reads that match (type 0), mismatch (type 1), insert before (type 2), or delete (type 3) the nucleotide sequence at the variant site:\nvtools output exon1 chr pos ref alt \u0026quot;track('${bam}')\u0026quot; \\ \u0026quot;track('${bam}', 'coverage?type=0')\u0026quot; \\ \u0026quot;track('${bam}', 'coverage?type=1')\u0026quot; \\ \u0026quot;track('${bam}', 'coverage?type=2')\u0026quot; \\ \u0026quot;track('${bam}', 'coverage?type=3')\u0026quot; \\ \u0026quot;track('${bam}', 'coverage?type=3\u0026amp;strand=+')\u0026quot; \\ \u0026quot;track('${bam}', 'coverage?type=3\u0026amp;strand=-')\u0026quot; 1 118420020 - T 25 9 0 16 0 0 0 1 159023386 G A 43 18 25 0 0 0 0 1 160398161 G A 50 23 27 0 0 0 0 1 180772617 C T 40 17 23 0 0 0 0 3 12581722 T C 107 63 44 0 0 0 0 4 1945715 A T 64 29 35 0 0 0 0 5 137089865 C G 81 41 40 0 0 0 0 8 42878531 TCCT - 50 27 0 14 9 3 6 12 65449852 C A 65 30 35 0 0 0 0 16 11929051 T C 69 37 32 0 0 0 0 16 17197814 G A 57 19 38 0 0 0 0 17 78938525 G A 88 47 41 0 0 0 0 17 79525590 C G 58 31 27 0 0 0 0 17 79687655 C T 95 54 41 0 0 0 0 19 34843754 CCCCACCCCAGC - 64 30 0 0 34 16 18  The last two functions are interesting as it shows the number of reads on forward and reverse strands that shows the deletion. This information can be usful because the variant might not be real if it exists mostly on one of the strands.\n\nAn option color=1 can be used with the read field to display insertions and variant allele in color (green and blue respectively). This is very helpful if you have long reads and reads that contain indels.\nOnline BAM tracks can also be used so you do not have to download large BAM files in order to use them.\n Examples: obtain depth of coverage of variants using online BAM files\n% vtools output variant chr pos \u0026quot;track('ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data/HG00096/alignment/HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522.bam')\u0026quot; -l5 [bam_index_load] attempting to download the remote index file. 1 533 0 1 41342 1 1 41791 4 1 44449 7 1 44539 12  (:exampleend\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/other_pipelines/transmission/",
	"title": "transmission",
	"tags": [],
	"description": "",
	"content": " Identification of recessive and de novo variants for family-based design This pipeline is an extension to command vtools_report transmission, the differences are\n vtools_report transmission find recessive and de novo mutations and create variant tables for each offspring. This pipeline assumes the first offspring is the affected one and remove de novo and recessive variants of the second offspring from the list. It creates a single variant table for the results.\n This pipeline creates a bunch of variant tables for variants that are in different annotation databases.\n  Usage % vtools show pipeline transmission Pipelines to detect different types of variants that are transmitted from parents to offspring. Available pipelines: denovo, recessive Pipeline \u0026quot;denovo\u0026quot;: This pipeline identifies de novo mutations from a family of unaffected parents, affected offspring, and optional unaffected siblings. It can be applied either to the current project (no --input is specified), or a snapshot (--input) for which the snapshot will be loaded and overwrite the existing project. The parameter --parents and --offspring are required to specify the name of parents, proband (affected offspring), and one optional sibling. Parameter --name is recommended to give all variant tables a prefix. This pipeline will produce tables $name_denovo (variants that are observed only in the proband), A table $name_denovo_SNP will be created with all SNP markers in table $name_denovo. And, depending on values of parameter --databases, it can produce tables $table_1kg for variants in 1000 genomes project, $table_dbSNP for variants in dbSNP project, and $table_refGene, $table_refGene_exon, $table_ccdsGene, $table_ccdsGene_exon, $table_CancerGenomeCensus, $table_COSMIC, $table_dbNSFP, $table_phastCons, $table_phastConsElements, $table_genomicSuperDups for tables in respective annotation databases. It is up to you to select variants based on these membership tables using the 'vtools compare' command. The project will be saved to a snapshot if a name (or filename with extension .tar or .tar.gz) is specified as the output. denovo_0: Load specified snapshot if a snapshot is specified. Otherwise use the existing project. denovo_5: Check the version of variant tools (version 2.2.1 and above is required to execute this pipeline) denovo_10: Import all annotation databases denovo_20: Locate de novo variants of the proband denovo_50: Create variant tables according to their membership in different annotation databases denovo_100: Save the project to a snapshot if an output is specified. denovo_200: Summarize the results. Pipeline \u0026quot;recessive\u0026quot;: This pipeline identifies recessive mutations from a family of unaffected parents, affected offspring, and optional unaffected siblings. Recessive variant is defined as variants that are homozygous in the affected offspring (proband), heterozygous in both parents, and heterozygous or wildtype in a sibling (if available). The pipeline can be applied either to the current project (no --input is specified), or a snapshot (--input) for which the snapshot will be loaded and overwrite the existing project. The parameter --parents and --offspring are required to specify the name of parents, proband (affected offspring), and one optional sibling. Parameter --name is recommended to give all variant tables a prefix. This pipeline will produce tables $name_recessive (variants that are observed only in the proband). A table $name_denovo_SNP will be created with all SNP markers in table $name_denovo. And, depending on values of parameter --databases, it can produce tables $table_1kg for variants in 1000 genomes project, $table_dbSNP for variants in dbSNP project, and $table_refGene, $table_refGene_exon, $table_ccdsGene, $table_ccdsGene_exon, $table_CancerGenomeCensus, $table_COSMIC, $table_dbNSFP, $table_phastCons, $table_phastConsElements, $table_genomicSuperDups for tables in respective annotation databases. It is up to you to select variants based on these membership tables using the 'vtools compare' command. Two optional output files are allowed. The project will be saved to a snapshot if a name (or filename with extension .tar or .tar.gz) is specified as the output. recessive_0: Load specified snapshot if a snapshot is specified. Otherwise use the existing project. recessive_5: Check the version of variant tools (version 2.2.1 and above is required to execute this pipeline) recessive_10: Import all annotation databases recessive_20: Locate recessive variants of the proband (homozygous only in proband) and save variants in table $name_recessive recessive_50: Create variant tables according to their membership in different annotation databases recessive_100: Save the project to a snapshot if an output is specified. recessive_200: Summarize the results. Pipeline parameters: parents offspring name Name of the family. All generated tables will be prefixed with this name. (default: family) databases Databases for which membership tables will be produced. (default: thousandGenom es,dbSNP,refGene,ccdsGene,refGene_exon,ccdsGene_exon,CosmicCodingMuts,CosmicNon CodingVariants,dbNSFP,phastCons,phastConsElements,genomicSuperDups)  Details Identification of de novo variants in a family with affected offspring This pipeline executes a series of vtools commands to identify de novo variants in a family with affected offsprng, unaffected parents, and an optional unaffected sibling.\nThe pipeline either applies to the existing project, or load a snapshot if a snapshot is specified using parameter --input. For a project with two unaffected parents, affected offspring (proband), and an optional sibling, this pipeline\n identify variants for each sample identify variants that appear only in the affected offspring, save it to a variant table $name_denovo identify a subset of variants that have no other parental variants at the variant sites, save it to table $name_denovo_site identify variants that belong to a number of annotation databases and save them to their respective variant tables.  The pipeline writes a summary of tables created to the standard output, and save the project to a snapshot if a name or filename is assigned to parameter --output.\nFor example, the following command\n% vtools execute transmission denovo --input poly_data.tar \\ --parents WGS3_2 WGS3_3 --offspring WGS3_1 --output denovo.tar \\ \u0026gt; logfile  produces a log file\n% cat logfile SUMMARY: Identification of de novo variants for family family Members: WGS3_2 WGS3_3 (unaffected parents), WGS3_1 (affected offspring) Number of genotypes: WGS3_2 : 4367814 WGS3_3 : 4455890 WGS3_1 : 4343418 de novo variants: family_denovo : 113553 (de novo variants for family family ) family_denovo_SNP: 63578 (de novo SNP variants for family family ) Database membership: family_denovo_in_thousandGenomes: 18330 (de novo variants in database thousandGenomes) family_denovo_in_dbSNP: 71921 (de novo variants in database dbSNP) family_denovo_in_refGene: 40037 (de novo variants in database refGene) family_denovo_in_ccdsGene: 28427 (de novo variants in database ccdsGene) family_denovo_in_refGene_exon: 1099 (de novo variants in database refGene_exon) family_denovo_in_ccdsGene_exon: 235 (de novo variants in database ccdsGene_exon) family_denovo_in_CosmicCodingMuts: 73 (de novo variants in database CosmicCodingMuts) family_denovo_in_CosmicNonCodingVariants: 111 (de novo variants in database CosmicNonCodingVariants) family_denovo_in_dbNSFP: 148 (de novo variants in database dbNSFP) family_denovo_in_phastCons: 101916 (de novo variants in database phastCons) family_denovo_in_phastConsElements: 3502 (de novo variants in database phastConsElements) family_denovo_in_genomicSuperDups: 24836 (de novo variants in database genomicSuperDups)  Identification of recessive variants in a family with affected offspring This pipeline works similarly to the denovo pipeline (with the same input, output and other options), but tried to identify variants that are recessive in the affected offspring, heterozygous in parents, and wildtype or heterozygous in the unaffected sibling, if available.\nVariants on sex chromosomes are handled in the same way as variants on autosomes. There must be some genotyping error if you observe recessive variants on chromosome Y. If you observe recessive variants on chromosome X, it means the variant is heterozygous for mother, and exists in father.\nWhat is next? The pipelines identify recessive or de novo variants and create a bunch of tables. You usually should filter the list more using combination of memberships, quality scores, and other information. For example, if you are looking for novel variants that are not in 1000 genomes, in exon regions, with high conservation score, not in genomic duplication regions, you can select the variants using command\n% vtools compare --expression 'mylist=family_denovo - family_denovo_in_thousandGenomes - \\ (family_denovo - (family_denovo_in_refGene_exon | family_denovo_phastConsElements)) - \\ family_denovo_genomicSuperDups'  and start looking closely at these variants, using commands such as\n% vtools output mylist chr pos ref alt 'ref_sequence(chr, pos, pos+20)' \u0026quot;track('mydata.bam', 'reads')\u0026quot;  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_commands/update/",
	"title": "update",
	"tags": [],
	"description": "",
	"content": " Add new or update existing variant and genotype info fields 1. Usage % vtools update -h usage: vtools update [-h] [--from_file FROM_FILE [FROM_FILE ...]] [--build BUILD] [--format FORMAT] [-j N] [--sample_name [SAMPLE_NAME [SAMPLE_NAME ...]]] [--set [EXPR [EXPR ...]]] [--from_stat [EXPR [EXPR ...]]] [-s [COND [COND ...]]] [--genotypes [COND [COND ...]]] [-v {0,1,2}] table Add or update fields of existing variants and genotype from other fields, statistics of genotypes and genotype info, or files that annotate variants or their locations (e.g. Read annotation from ANNOVAR output files, import additional variant or genotype fields from .vcf files). positional arguments: table variants to be updated. optional arguments: -h, --help show this help message and exit -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1). Update from files: --from_file FROM_FILE [FROM_FILE ...] A list of files that will be used to add or update existing fields of variants. The file should be delimiter separated with format described by parameter --format. Gzipped files are acceptable. If input files contains genotype information, have been inputted before, and can be linked to the samples they created without ambiguity (e.g. single sample, or samples with detectable sample names), genotypes and their information will also be updated. --build BUILD Build version of the reference genome (e.g. hg18) of the input files, which should be the primary (used by default) or alternative (if available) reference genome of the project. An alternative reference genome will be added to the project if needed. --format FORMAT Format of the input text file. It can be one of the variant tools supported file types such as ANNOVAR_output (cf. 'vtools show formats'), or a local format specification file (with extension .fmt). Some formats accept parameters (cf. 'vtools show format FMT') and allow you to update additional or alternative fields from the input file. -j N, --jobs N Number of processes to import input file. Variant tools by default uses a single process for reading and writing, and can use one or more dedicated reader processes (jobs=2 or more) to process input files. Due to the overhead of inter-process communication, more jobs do not automatically lead to better performance. --sample_name [SAMPLE_NAME [SAMPLE_NAME ...]] Name of the samples to be updated by the input files. If unspecified, headers of the genotype columns of the last comment line (line starts with #) of the input files will be used (and thus allow different sample names for input files). Sample names will be used to identify samples to be updated. Filename will be used to uniquely identify a sample if mutliple samples with the same name exist in the project. No genotype info will be updated if samples cannot be unquely determined. Set value from existing fields: --set [EXPR [EXPR ...]] Add a new field or updating an existing field using a constant (e.g. mark=1) or an expression using other fields (e.g. freq=num/120, refgene=refGene.name). If multiple values are returned for a variant, only one of them will be used. Parameter samples could be used to limit the affected variants. In addition, special function are provided, including 'HWE_exact' (exact test of Hardy-Weinberg Equilibrium) and 'Fisher_exact' (Fisher's exact test for case/ctrl association). Set fields from sample statistics: --from_stat [EXPR [EXPR ...]] One or more expressions such as meanQT=avg(QT) that aggregate genotype info (e.g. QT) of variants in all or selected samples to specified fields (e.g. meanQT). Functions sum, avg, max, and min are currently supported. In addition, special functions #(GT), #(hom), #(het), #(alt), #(other), #(missing), #(wtGT), #(mutGT), and maf(), are provided to count the number of valid genotypes (not missing), homozygote genotypes, heterozygote genotypes, alternative alleles (#(het) + 2*#(hom) + #(other)), genotypes with two different alternative alleles, missing genotypes (number of samples - #(GT)), number of non-missing wildtype genotypes (#(GT) - #(hom) - #(het) - #(other)), number of non-wildtype genotypes (#(hom) + #(het) + #(other)), and minor allele frequency. The maf() function treats chromosomes 1 to 22 as autosomes, X and Y as sex chromosomes, and other chromosomes as single-copy manifolds. It requires a phenotype named sex or gender that codes male/female by 1/2, M/F or Male/Female if maf of variants on sex chromosomes are calculated. This function by default calculates allele frequency among existing-alleles, but will treat all missing values as wild type alleles if runtime option treat_missing_as_wildtype is set to true. -s [COND [COND ...]], --samples [COND [COND ...]] Limiting variants from samples that match conditions that use columns shown in command 'vtools show sample' (e.g. 'aff=1', 'filename like \u0026quot;MG%\u0026quot;'). --genotypes [COND [COND ...]] Limiting variants from samples that match conditions that use columns shown in command 'vtools show genotypes' (e.g. 'GQ\u0026gt;15').  2. Details Command vtools update updates variant info fields (and to a lesser extend genotype info fields) by adding more fields or updating values at existing fields. It does not add any new variant or genotype, and does not change existing variant, sample, or genotype. Using three parameters --from_file, --from_stat, and --set, variant information fields could be updated from external file, sample genotypes, and existing fields.\n  An illustration about vtools update  -- \n2.1 Import variant info from external files in standard formats (--from_file) Option --from_file allows command vtools update to update variant and/or genotype info fields by reading info from an external file. This process is similar to vtools import but has two major differences:\n vtools update does not import any new variant even if the external file has more variants. vtools update can add or update fields from position, range or field based input files. That is to say, you could update fields from input files that describes variants at particular locations or chromosomsal regions. Variants belonging to the same location or region will share the updated info.  The variant or genotype fields that will be added or updated depends on the file format (cf. vtools show formats). File formats accept parameters to specify what fields to import. For example, parameters --var_info and --geno_info can be used with format vcf to specify which variant and genotype info fields to be updated from a vcf file.\n Examples: create a project\nLet us create a directory update and import an empty project with a few test vcf files V1_hg38.vcf, V2_hg38.vcf and V3_hg38.vcf,\n% mkdir update % cd update % vtools init update % vtools admin --load_snapshot vt_testData  The project does not have any variant so we import some from these VCF files:\n% vtools import V*_hg38.vcf --build hg38 INFO: Importing variants from V1_hg38.vcf (1/3) V1_hg38.vcf: 100% [==================================] 1,619 5.5K/s in 00:00:00 INFO: 1,273 new variants (1,273 SNVs, 332 unsupported) from 1,619 lines are imported. INFO: Importing variants from V2_hg38.vcf (2/3) V2_hg38.vcf: 100% [==================================] 1,601 6.6K/s in 00:00:00 INFO: 449 new variants (449 SNVs, 329 unsupported) from 1,594 lines are imported. INFO: Importing variants from V3_hg38.vcf (3/3) V3_hg38.vcf: 100% [==================================] 1,589 6.6K/s in 00:00:00 INFO: 329 new variants (329 SNVs, 301 unsupported) from 1,589 lines are imported. Importing genotypes: 100% [==========================] 7,946 4.0K/s in 00:00:02 Copying samples: 100% [==============================] 6 19.6K/s in 00:00:00 INFO: 2,051 new variants (2,051 SNVs, 962 unsupported) from 4,802 lines (3 samples) are imported.  \n Examples: import additional fields from source files As we can see from the output of vtools show fields, this project does not have any variant info field,\n% vtools show fields variant.chr (char) Chromosome name (VARCHAR) variant.pos (int) Position (INT, 1-based) variant.ref (char) Reference allele (VARCHAR, - for missing allele of an insertion) variant.alt (char) Alternative allele (VARCHAR, - for missing allele of an deletion)  Because the input file has two variant info fields DP (depth of coverage) and NS (number in sample), we can add these two fields to our project using commands\n% vtools update variant --from_file V*_hg38.vcf --var_info DP NS INFO: Using primary reference genome hg38 of the project. Getting existing variants: 100% [======================] 2,051 220.8K/s in 00:00:00 INFO: Updating variants from V1_hg38.vcf (1/3) V1_hg38.vcf: 100% [======================================] 1,619 7.9K/s in 00:00:00 INFO: Fields DP, NS of 1,273 variants are updated INFO: Updating variants from V2_hg38.vcf (2/3) V2_hg38.vcf: 100% [======================================] 1,599 6.9K/s in 00:00:00 INFO: Fields DP, NS of 1,258 variants are updated INFO: Updating variants from V3_hg38.vcf (3/3) V3_hg38.vcf: 100% [======================================] 1,589 8.9K/s in 00:00:00 INFO: Fields DP, NS of 1,274 variants are updated  The project now has two variant info fields DP and NS,\n% vtools show fields variant.chr (char) Chromosome name (VARCHAR) variant.pos (int) Position (INT, 1-based) variant.ref (char) Reference allele (VARCHAR, - for missing allele of an insertion) variant.alt (char) Alternative allele (VARCHAR, - for missing allele of an deletion) variant.DP (int) variant.NS (int)  and we can output them with variants\n% vtools output variant chr pos ref alt DP NS -l 5 1 14677 G A 9 1 1 15820 G T 7 1 1 16103 T G 24 1 1 16378 T C 23 1 1 20129 C T 13 1  \n Examples: add genotype info field We have just added two variant info fields DP and NS from input vcf files, but what we did probably does not make any sense. This is because DP and NS describes variants in each sample so the same variants from different samples will have different depth, and sample count should probaby be added together to reflect the total sample count. That is to say, DP here should better be considered as genotype field instead of variant field.\nVariant tools is flexible enough to handle such a situation (check vtools show format vcf for details). By specifying field DP in parameter --geno_info, this field will be added as genotype info field and be processed for each sample:\n% vtools update variant --from_file V*_hg38.vcf --geno_info DP INFO: Using primary reference genome hg38 of the project. Getting existing variants: 100% [======================] 2,051 364.8K/s in 00:00:00 INFO: Updating variants from V1_hg38.vcf (1/3) V1_hg38.vcf: 100% [====================================] 1,619 11.5K/s in 00:00:00 INFO: Fields of 0 variants and geno fields of 1,277 genotypes are updated INFO: Updating variants from V2_hg38.vcf (2/3) V2_hg38.vcf: 100% [=====================================] 1,599 11.8K/s in 00:00:00 INFO: Fields of 0 variants and geno fields of 1,264 genotypes are updated INFO: Updating variants from V3_hg38.vcf (3/3) V3_hg38.vcf: 100% [=====================================] 1,589 11.5K/s in 00:00:00 INFO: Fields of 0 variants and geno fields of 1,276 genotypes are updated  The project now has a genotype info field DP, with coverage depth for each genotype.\n% vtools show genotypes sample_name filename num_genotypes sample_genotype_fields SAMP1 V1_hg38.vcf 1273 GT,DP SAMP2 V2_hg38.vcf 1258 GT,DP SAMP3 V3_hg38.vcf 1274 GT,DP  Variant tools depends on filename to determine which sample to update from each input file so the original input files must be used to update genotype info fields.\n\n Examples: adding annotation info from ANNOVAR output\nSuppose that we would like to use ANNOVAR to annotate our variants. The basic step is to export the variants in ANNOVAR input format and call ANNOVAR.\n% vtools export variant --format ANNOVAR --samples \u0026quot;filename in ('V1_hg38.vcf')\u0026quot; \u0026gt; ann.in INFO: Genotypes of 1 samples are exported. Writing: 100% [=============================================================================================================================================================================] 2,051 71.6K/s in 00:00:00 INFO: 2051 lines are exported from variant table variant % perl annotate_variation.pl ann.in humandb/ --buildver hg38 NOTICE: The --geneanno operation is set to ON by default NOTICE: Output files were written to ann.in.variant_function, ann.in.exonic_variant_function NOTICE: Reading gene annotation from humandb/hg38_refGene.txt ... Done with 75153 transcripts (including 18511 without coding sequence annotation) for 28071 unique genes NOTICE: Processing next batch with 2051 unique variants in 2051 input lines NOTICE: Reading FASTA sequences from humandb/hg38_refGeneMrna.fa ... Done with 0 sequences WARNING: A total of 17 sequences cannot be found in humandb/hg38_refGeneMrna.fa  We then want to update our project with ANNOVAR annotations. Because gene annotation of ANNOVAR generates two output files, two output file formats are available. One of the formats is ANNOVAR_exonic_variant_function,\n% vtools show format ANNOVAR_exonic_variant_function Output from ANNOVAR for files of type *exonic_variant_function, generated from command \u0026quot;path/to/annovar/annotate_variation.pl annovar.txt path/to/annovar/humandb/\u0026quot;. This format imports chr, pos, ref, alt and ANNOVAR annotations. For details please refer to http://www.openbioinformatics.org/annovar/annovar_gene.html Columns: None defined, cannot export to this format variant: chr Chromosome pos 1-based position, hg18 ref Reference allele, '-' for insertion. alt Alternative allele, '-' for deletion. Variant info: mut_type the functional consequences of the variant. Other fields (usable through parameters): genename Gene name (for the first exon if the variant is in more than one exons, but usually the names for all exons are the same). function the gene name, the transcript identifier and the sequence change in the corresponding transcript Format parameters: var_info Fields to be outputted, can be one or both of mut_type and function. (default: mut_type)  As you can see, this is a variant based format. It has a default variant info field mut_type, but you can add more fields using parameter var_info. To update variants,\n% vtools update variant --format ANNOVAR_exonic_variant_function --from_file ann.in.exonic_variant_function INFO: Using primary reference genome hg38 of the project. Getting existing variants: 100% [======================] 2,051 396.0K/s in 00:00:00 INFO: Updating variants from ann.in.exonic_variant_function (1/1) ann.in.exonic_variant_function: 100% [======================] 29 7.6K/s in 00:00:00 INFO: Field mut_type of 29 variants are updated  By default, field mut_type is added.\n% vtools show fields variant.chr (char) Chromosome name (VARCHAR) variant.pos (int) Position (INT, 1-based) variant.ref (char) Reference allele (VARCHAR, - for missing allele of an insertion) variant.alt (char) Alternative allele (VARCHAR, - for missing allele of an deletion) variant.DP (int) variant.NS (int) variant.mut_type (char)  To update additional variant/genotype fields, use --var_info of the ANNOVAR_exonic_variant_function format:\n% vtools update variant --format ANNOVAR_exonic_variant_function \\ --from_file ann.in.exonic_variant_function \\ --var_info mut_type function INFO: Using primary reference genome hg38 of the project. Getting existing variants: 100% [======================] 2,051 288.2K/s in 00:00:00 INFO: Updating variants from ann.in.exonic_variant_function (1/1) ann.in.exonic_variant_function: 100% [======================] 29 5.8K/s in 00:00:00 INFO: Fields mut_type, function of 29 variants are updated  Fields specified by option --var_info are added. Now we have one more field function\n% vtools show fields variant.chr (char) Chromosome name (VARCHAR) variant.pos (int) Position (INT, 1-based) variant.ref (char) Reference allele (VARCHAR, - for missing allele of an insertion) variant.alt (char) Alternative allele (VARCHAR, - for missing allele of an deletion) variant.DP (int) variant.NS (int) variant.mut_type (char) variant.function (char)  \n2.2 Import variant info from external files in customized formats (--from_file) During the analysis of variants, it is common to have annotations in different formats from various sources (e.g. from annotation servers such as regulome DB). Although variant tools has a growing number of formats, it is sometimes needed to create your own format files to import annotations.\n Examples: Update annotation for variants presented by rsnames Let us first create some data with rsname.Because this sample project uses hg18, we cannot use the default dbSNP database and has to use\n% vtools use dbSNP-hg38_143 INFO: Choosing version dbSNP-hg38_143 from 10 available databases. INFO: Downloading annotation database annoDB/dbSNP-hg38_143.ann INFO: Using annotation DB dbSNP as dbSNP in project update. INFO: dbSNP version 143, created using vcf file downloaded from NCBI  Let us find some variants with rsname and output it\n% vtools select variant 'dbSNP.func = \u0026quot;intron\u0026quot;' --output dbSNP.name dbSNP.func \u0026gt; dbSNP.info  The file looks like:\n% head -10 dbSNP.info rs3131969 intron rs3131968 intron rs3131967 intron rs3115859 intron rs3131966 intron rs3131964 intron rs3115858 intron rs12567639 intron rs3131963 intron rs3115853 intron  To update your variants with this information, you will need a format file that knows how to get chr, pos, ref and alt from rsname. Fortunately, the map format provides such an example so we can adapt it to the following format:\n[format description] description=a format that determins chr, pos, ref, alt from rsname using a dbSNP database variant=chr,pos,ref,alt variant_info=func [DEFAULT] db_file=dbSNP.DB # # NOTE: Functor FieldFromDB(db, res, fields) matches input(s) from # columns 'index' (column 1 in this example), compare it with field # 'fields' (name), and return results 'res' (chr, start, refNCBI, # alt). You can get a list of fields by 'vtools use dbSNP-hg18_130', # and run 'vtools show fields' # [chr] index=1 type=VARCHAR(20) adj=FieldFromDB(\u0026quot;%(db_file)s\u0026quot;, \u0026quot;chr\u0026quot;, \u0026quot;name\u0026quot;) [pos] index=1 adj=FieldFromDB(\u0026quot;%(db_file)s\u0026quot;, \u0026quot;start\u0026quot;, \u0026quot;name\u0026quot;) type=INTEGER NOT NULL [ref] index=1 adj=FieldFromDB(\u0026quot;%(db_file)s\u0026quot;, \u0026quot;refNCBI\u0026quot;, \u0026quot;name\u0026quot;) type=VARCHAR(255) [alt] index=1 type=VARCHAR(255) adj=FieldFromDB(\u0026quot;%(db_file)s\u0026quot;, \u0026quot;alt\u0026quot;, \u0026quot;name\u0026quot;) [func] index=2 type=VARCHAR(255)  We can then use this format (named rsname.fmt) to import variant info func to the project:\n% vtools update variant --format rsname --from_file dbSNP.info --db_file dbSNP-hg38_143.DB INFO: Using primary reference genome hg38 of the project. Getting existing variants: 100% [====================================] 1,611 229.7K/s in 00:00:00 INFO: Updating variants from dbSNP.info (1/1) dbSNP.info: 100% [=======================================================] 209 3.0K/s in 00:00:00 INFO: Field func of 209 variants are updated  The project now has another field variant.func (to differentiate from dbSNP.func),\n% select variant 'dbSNP.func = \u0026quot;intron\u0026quot;' --output chr pos ref alt dbSNP.name variant.func -l 10 1 744045 A G rs3131969 intron 1 744055 A G rs3131968 intron 1 744197 T C rs3131967 intron 1 744366 G A rs3115859 intron 1 744827 C T rs3131966 intron 1 745750 C G rs3131964 intron 1 745753 A T rs3115858 intron 1 746131 G A rs12567639 intron 1 746243 T A rs3131963 intron 1 747503 G A rs3115853 intron  \n Examples: Update annotation from position-based data\nNow, suppose we have another file with only chr and pos information:\n% vtools output variant chr pos dbSNP.molType dbSNP.class \u0026gt; moltype.txt  This file looks like\n% head -10 moltype.txt 1 4540 NA NA 1 5683 genomic single 1 5966 NA NA 1 6241 genomic single 1 6241 genomic single 1 9992 genomic single 1 9993 genomic single 1 10007 NA NA 1 10098 genomic single 1 10098 genomic single  Because this file does not have ref and alt information, we will have to treat it as position-based. That is to say, if there are multiple variants at a chromosomal location, they will updated with the same information. The format to use, is therefore\n[format description] description=A position based format to update variant information position=chr,pos variant_info=molType, molClass [chr] index=1 type=VARCHAR(20) [pos] index=2 type=INTEGER NOT NULL [molType] index=3 type=VARCHAR(255) [molClass] index=4 type=VARCHAR(255)  With position.fmt saved in the project directory, the following command can be used to update variants with additional fields molType and molClas:\n% vtools update variant --format position --from_file moltype.txt INFO: Using primary reference genome hg18 of the project. Getting existing variants: 100% [====================================] 1,611 226.1K/s in 00:00:00 INFO: Updating variants from moltype.txt (1/1) moltype.txt: 100% [====================================================] 1,679 8.3K/s in 00:00:00 INFO: Fields molType, molClass of 1,689 variants are updated % vtools output variant chr pos ref alt variant.molType molClass -l 10 1 4540 G A NA NA 1 5683 G T genomic single 1 5966 T G NA NA 1 6241 T C genomic single 1 9992 C T genomic single 1 9993 G A genomic single 1 10007 G A NA NA 1 10098 G A genomic single 1 14775 G A genomic single 1 16862 A G genomic single  \n2.3 Calculate genotype statistics for each variant (--from_stat) Option --from_stat adds fields to variant tables with summary statistics from sample genotypes. This parameter accepts expressions in the format of VAR_INFO=FUNC(GENO_INFO) where VAR_INFO is the variant information field to be added or updated, FUNC is a function or expression, and GENO_INFO is genotype or genotype info. If you are only interested in genotype statistics, some specially defined FUNC(GENO_INFO) can be used. A list of acceptable aggregating functions is available here.\n Examples: statistics of genotype info fields Each genotype in our samples has a field DP, which is the coverage depth. To assess the quality of a variant, it is useful to calculate average depth across all samples as a variant info field. The aggregating function to use is avg:\n% vtools update variant --from_stat 'avg_DP=avg(DP)' Counting variants: 0.0% [=========================================] in 00:00:00 INFO: Adding variant info field avg_DP with type FLOAT Updating variant: 100% [===============================] 2,051 52.3K/s in 00:00:00 INFO: 2051 records are updated  Depth of genotypes across three samples are averaged and save to a new variant info field avg_DP. It is different from the DP we saved before because that DP is the depth of one of the genotypes:\n% vtools output variant chr pos ref alt DP avg_DP -l5 1 14677 G A 9 7.5 1 15820 G T 7 7.0 1 16103 T G 24 25.333333333333332 1 16378 T C 23 20.5 1 20129 C T 13 12.0  \nA locus has a wildtype allele and can have one or more alternative alleles. Assuming a wildtype allele 0, an alternative allele 1, and an additional alternative allele 2 if exists, a sample can have genotype 0/0, 0/1, 0/2, 1\u0026frasl;1, 2\u0026frasl;2, and 1\u0026frasl;2 at a locus on an autosome. vtools update --from_stat counts such genotype for all (or selected) variants using the following special functions:\n #(GT): the total number of genotypes #(alt): number of alternative alleles (non-zero alleles 1 or 2) #(hom): number of homozygote (genotype 1\u0026frasl;1 or 2\u0026frasl;2) #(het): number of heterozygote (genotype 0/1 or 0/2) #(other): number of heterozygote with two alternative alleles (genotype 1\u0026frasl;2). #(wtGT): number of wildtype genotypes (#(GT) - #(hom) - #(het) - #(other)) #(mutGT): number of non-wildtype genotypes (#(hom) + #(het) + #(other)) #(missing): number of missing genotypes (sample size - #(GT)) maf(): minor allele frequency. The frequency is the smaller of #(alt) / #all_alleles and 1 - #(alt) / #all_alleles. The total number of alleles is determined by type of chromosome, sex of samples, and how to treat missing values. More specifically, if runtime option treat_missing_as_wildtype is set to False (default), #all_alleles is  2 * #(GT) for variants on autosomes # GT for females + #GT for males for variants on chromosome X # GT for males for variants on chromosome Y, and #(GT) for variants on other chromosomes.   If treat_missing_as_wildtype is set to true, all missing values are counted as wildtype allele so #all_alleles is * 2 * number of samples for variants on autosomes * 2 * number of males + number of females for variants on chromosome X * number of males for variants on chromosome Y * number of samples for varants on other chromosomes\nNote that genotype 1\u0026frasl;1 an 2\u0026frasl;2 are counted for different variants (0,1) and (0,2), and #(other) is counted for both variants. Therefore, #(alt) equals #(hom) X 2 + #(het) + #(other)*2.\n Examples: sample statistics Using these special functions, we can calculate many sample statistics as various variant info fields:\n% vtools update variant --from_stat 'total=#(GT)' 'num=#(alt)' 'hom=#(hom)' 'het=#(het)' 'other=#(other)' INFO: Adding variant info field num with type INT INFO: Adding variant info field hom with type INT INFO: Adding variant info field het with type INT INFO: Adding variant info field other with type INT INFO: Adding variant info field total with type INT Updating variant: 100% [================================] 2,051 62.4K/s in 00:00:00 INFO: 2051 records are updated  As you can see, genotypes are not available in all samples and the first five variants are all appear as heterozygotes.\n% vtools output variant chr pos ref alt total num hom het other -l5 1 14677 G A 2 2 0 2 0 1 15820 G T 1 1 0 1 0 1 16103 T G 3 3 0 3 0 1 16378 T C 2 2 0 2 0 1 20129 C T 2 2 0 2 0  You can use the maf function to calculate minor allele frequency\n% vtools update variant --from_stat 'maf=maf()' Counting variants: 100% [====================================] 3 29.4/s in 00:00:00 INFO: Resetting values at existing field maf Updating variant: 100% [================================] 2,051 23.0K/s in 00:00:00 INFO: 2051 records are updated  This case is easy because all variants are on an autosome.\n% vtools output variant chr pos ref alt total num hom het maf -l5 1 14677 G A 2 2 0 2 0.5 1 15820 G T 1 1 0 1 0.5 1 16103 T G 3 3 0 3 0.5 1 16378 T C 2 2 0 2 0.5 1 20129 C T 2 2 0 2 0.5  However, because this dataset does not record wildtype alleles, the minior allele frequencies are 0.5 if all genotypes are heterozygotes. To calculate minor allele frequency for all samples, you should set runtime option treat_missing_as_wildtype as true,\n% vtools admin --set_runtime_option treat_missing_as_wildtype=true INFO: Option treat_missing_as_wildtype is set to True  In this case, missing genotypes are counted,\n$ vtools update variant --from_stat 'maf1=maf()' Updating variant: 100% [================================] 2,051 24.1K/s in 00:00:00 INFO: 2051 records are updated  and the results (in field maf1) are number of aleternative alleles devided by 6.\n% vtools output variant chr pos ref alt num \u0026quot;2*total\u0026quot; maf maf1 -l 5 1 14677 G A 2 4 0.5 0.3333333333333333 1 15820 G T 1 2 0.5 0.16666666666666666 1 16103 T G 3 6 0.5 0.5 1 16378 T C 2 4 0.5 0.3333333333333333 1 20129 C T 2 4 0.5 0.3333333333333333  \nAll statistics are by default calculated for all samples in the project. But we can limit calculations on subset of samples by --samples and/or --genotypes.\n Option --samples \u0026quot;[condition]\u0026quot; can be used to limit the statistics to a subset of samples, for example, all affected individuals. [condition] should be an SQL expression using one or more columns shown in vtools show samples. For example,\n aff='1' select all samples with affection status equals to 1. some_measure\u0026gt;0.95 select all samples with some_measure greater than 0.95. filename like 'MG%' select all samples from files with filename starts with \u0026ldquo;MG\u0026rdquo;. sample_name like 'CEU%' select all samples with sample name starts with \u0026ldquo;CEU\u0026rdquo;.   Option --genotypes \u0026quot;[condition]\u0026quot; can be used to limit the statistics to a subset of samples having genotypes satisfying a [condition] defined by an SQL expression using one or more columns shown in vtools show genotypes. For example,\n GT=0 select only the wildtype genotypes GQ\u0026gt;20 select variants having genotype quality greater than 20    Examples: statistics for subsets of samples and genotypes This project has three samples:\n% vtools show samples sample_name filename SAMP1 V1_hg38.vcf SAMP2 V2_hg38.vcf SAMP3 V3_hg38.vcf  Suppose two samples from files V1.vcf and V2.vcf are affected and we would like to calculate genotype count for only these two samples, we could use parameter --samples to limit our calculation:\n% vtools update variant --from_stat \u0026quot;cases_het=#(het)\u0026quot; --samples \u0026quot;filename in ('V1_hg38.vcf', 'V2_hg38.vcf')\u0026quot; INFO: 2 samples are selected Counting variants: 100% [================================] 2 23.4/s in 00:00:00 INFO: Adding variant info field cases_het with type INT Updating variant: 100% [============================] 2,051 95.2K/s in 00:00:00 INFO: 2051 records are updated  We can also limit the statistics to genotypes that satisfy certain conditions (e.g. with high coverage):\n% vtools update variant --from_stat \u0026quot;cases_het_highDP=#(het)\u0026quot; --samples \u0026quot;filename in ('V1_hg38.vcf', 'V2_hg38.vcf')\u0026quot; --genotypes 'DP\u0026gt;15' INFO: 2 samples are selected Counting variants: 100% [====================================] 2 20.2/s in 00:00:00 INFO: Adding variant info field cases_het_highDP with type INT Updating variant: 100% [================================] 2,051 92.8K/s in 00:00:00 INFO: 2051 records are updated % vtools output variant chr pos ref alt cases_het cases_het_highDP -l5 1 14677 G A 1 0 1 15820 G T 1 0 1 16103 T G 2 1 1 16378 T C 1 1 1 20129 C T 1 0  \n Examples: update variant info of subsets of variants If you are interested only in variants in a variant table, you could also only update statistics for variants in specified variant tables. For example, we can select all variants that belong to all three samples and creates a table in_all:\n% vtools select variant 'total=3' -t in_all Running: 1 519.4/s in 00:00:00 INFO: 646 variants selected.  Then we can add a field case_hom to count the number of homozygotes for only these variants:\n% vtools update in_all --from_stat 'case_hom=#(hom)' --samples \u0026quot;filename in ('V1_hg38.vcf', 'V2_hg38.vcf')\u0026quot; INFO: 2 samples are selected Counting variants: 100% [====================================] 2 18.1/s in 00:00:00 INFO: Adding variant info field case_hom with type INT Updating in_all: 100% [===================================] 646 63.6K/s in 00:00:00 INFO: 646 records are updated % vtools output in_all chr pos ref alt case_hom -l 5 1 16103 T G 0 1 20144 G A 0 1 30860 G C 0 1 30923 G T 2 1 41842 A G 2  \n2.4 Add fields based on other variant or annotation fields (--set) Option --set evaluates expressions from existing variant info fields and assign results to a new or existing variant info field. For example, once you have calculated allele count, you could calculate allele frequency based on sample size using expression --set 'maf=m/(n*2.0)' where m is field name calculated as \u0026ldquo;m=#(alt)\u0026rdquo; and n is sample size, which might not be \u0026quot;n=#(GT)\u0026quot; if there are missing data. Note that the denominator should be n*2.0, not n*2, because SQL requires the denominator be a FLOAT type, not INTEGER.\n Examples: set fields from variant info fields We can try to calculate the allele frequency using number of aleternative alleles and number of genotypes as follows:\n% vtools update variant --set \u0026quot;maf=num/(total*2.0)\u0026quot; INFO: Adding field maf  However, because samples from this project is called individually and wildtype alleles are not recorded, there are a lot of missing data. If we assume missing data as non-recorded wildtype alleles, we should add missing data to the denominator of the expression. To do this, we need to first calculate a field for missing genotypes:\n% vtools update variant --from_stat 'missing=#(missing)' Counting variants: 100% [===================================] 3 289.1/s in 00:00:00 INFO: Resetting values at existing field missing Updating variant: 100% [================================] 2,051 41.5K/s in 00:00:00 INFO: 2051 records are updated  And then calculate the real allele frequency\n% vtools update variant --set \u0026quot;real_maf=num/((total+missing)*2.0)\u0026quot; INFO: Adding field real_maf  Two allele frequencies are different\n% vtools output variant chr pos ref alt num total missing maf real_maf -l5 1 14677 G A 2 2 1 0.5 0.3333333333333333 1 15820 G T 1 1 2 0.5 0.16666666666666666 1 16103 T G 3 3 0 0.5 0.5 1 16378 T C 2 2 1 0.5 0.3333333333333333 1 20129 C T 2 2 1 0.5 0.3333333333333333  \nIn addition to variant info fields, annotation fields could also be used in these expressions and set variant info fields. There is usually no such need to copy annotation fields to variant info fields though. Moreoever, because one variant might have more than one annotation value for an annotation field (e.g. a variant might belong to two isoforms of a gene), copying annotation fields to variant info fields might loss information.\n Examples: set variant info field from annotation fields\n% vtools use refGene INFO: Choosing version refGene-hg38_20170201 from 5 available databases. INFO: Downloading annotation database annoDB/refGene-hg38_20170201.ann INFO: Using annotation DB refGene as refGene in project update. INFO: Known human protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq). % vtools update variant --set refgene=refGene.name INFO: Adding variant info field refgene Updating variant: 100% [============================] 2,647 36.2K/s in 00:00:00  We can select variants that belong to a gene and output it\n% vtools select variant 'refGene is not NULL' -t in_gene Running: 1 475.3/s in 00:00:00 INFO: 469 variants selected. % vtools output in_gene chr pos ref alt refGene -l 5 1 14677 G A NR_024540 1 15820 G T NR_024540 1 16103 T G NR_024540 1 16378 T C NR_024540 1 20129 C T NR_024540  \n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/joint_conditional/weighted-methods/",
	"title": "weighted methods",
	"tags": [],
	"description": "",
	"content": " Weighted Burden Test for Disease and Quantitative Traits Introduction This implements a collection of weighted aggregation tests. Different from plain aggregation methods? which assumes equal contribution of each locus from the genetic region under investigation, the weighted methods assigns a \u0026ldquo;weight\u0026rdquo; to each variant site such that each site differs from another by the weight they are assigned, and these weights will contribute to the aggregated \u0026ldquo;burden\u0026rdquo;, e.g., {$$X=\\sum_i^N\\omega_iX_i$$} where {$\\omega_i$}\u0026rsquo;s are the weights. The weights often reflect the relative importance of a variant in terms of its contribution to phenotype.\nThe weighting approach was first proposed by Madsen and Browning 2010[^Bo Eskerod Madsen and Sharon R. Browning (2009) A Groupwise Association Test for Rare Mutations Using a Weighted Sum Statistic. PLoS Genetics doi:10.1371/journal.pgen.1000384. http://dx.plos.org/10.1371/journal.pgen.1000384^] with the assumption that \u0026ldquo;rarer\u0026rdquo; variants tend to be more important (the WSS statistic?). This weighting theme is by far the most popular weights and has been adapted into a number of methods emerged later, such as Lin and Tang 2011[^Dan-Yu Lin and Zheng-Zheng Tang (2011) A General Framework for Detecting Disease Associations with Rare Variants in Sequencing Studies. The American Journal of Human Genetics doi:10.1016/j.ajhg.2011.07.015. http://linkinghub.elsevier.com/retrieve/pii/S0002929711003090^] and Wu et al 2011[^MichaelC. Wu, Seunggeun Lee, Tianxi Cai, Yun Li, Michael Boehnke and Xihong Lin (2011) Rare-Variant Association Testing for Sequencing Data with the Sequence Kernel Association Test. The American Journal of Human Genetics doi:10.1016/j.ajhg.2011.05.029. http://linkinghub.elsevier.com/retrieve/pii/S0002929711002229^]. Other weighting themes such as KBAC and RBT weightings have different assumptions but they are also based solely on internal information from data. Price et al 2010[^Alkes L. Price, Gregory V. Kryukov, Paul I.W. de Bakker, Shaun M. Purcell, Jeff Staples, Lee-Jen Wei and Shamil R. Sunyaev (2010) Pooled Association Tests for Rare Variants in Exon-Resequencing Studies. The American Journal of Human Genetics doi:10.1016/j.ajhg.2010.04.005. http://linkinghub.elsevier.com/retrieve/pii/S0002929710002077^] proposed the use of \u0026ldquo;external\u0026rdquo; weights, i.e., using functional annotation sources to calculate weight for rare variants. This weighting theme can also be naturally integrated into many rare variants methods.\nImplementation of WeightedBurdenBt and WeightedBurdenQt are similar to aggregation methods? but allows the use of the following weighting themes:\n WSS? weight, based on entire sample WSS? weight, based on controls or sample with above/below average phenotype values RBT? weight KBAC? weight External weights from annotation  Permutation methods have to be used to obtain {$p$} value for WSS (control based), KBAC and RBT weighting themes.\nDetails Command interface vtools show test WeightedBurdenBt Name: WeightedBurdenBt Description: Weighted genotype burden tests for disease traits, using one or many arbitrary external weights as well as one of 4 internal weighting themes usage: vtools associate --method WeightedBurdenBt [-h] [--name NAME] [--mafupper MAFUPPER] [--alternative TAILED] [-p N] [--permute_by XY] [--adaptive C] [--extern_weight [EXTERN_WEIGHT [EXTERN_WEIGHT ...]]] [--weight {Browning_all,Browning,KBAC,RBT}] [--NA_adjust] [--moi {additive,dominant,recessive}] Weighted genotype burden tests for disease traits, using one or many arbitrary external weights as well as one of 4 internal weighting themes. External weights (variant/genotype annotation field) are passed into the test by --var_info and --geno_info options. Internal weighting themes are one of \u0026quot;Browning_all\u0026quot;, \u0026quot;Browning\u0026quot;, \u0026quot;KBAC\u0026quot; or \u0026quot;RBT\u0026quot;. p-value is based on logistic regression analysis and permutation procedure has to be used for \u0026quot;Browning\u0026quot;, \u0026quot;KBAC\u0026quot; or \u0026quot;RBT\u0026quot; weights. optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 0.01 --alternative TAILED Alternative hypothesis is one-sided (\u0026quot;1\u0026quot;) or two-sided (\u0026quot;2\u0026quot;). Default set to 1 -p N, --permutations N Number of permutations --permute_by XY Permute phenotypes (\u0026quot;Y\u0026quot;) or genotypes (\u0026quot;X\u0026quot;). Default is \u0026quot;Y\u0026quot; --adaptive C Adaptive permutation using Edwin Wilson 95 percent confidence interval for binomial distribution. The program will compute a p-value every 1000 permutations and compare the lower bound of the 95 percent CI of p-value against \u0026quot;C\u0026quot;, and quit permutations with the p-value if it is larger than \u0026quot;C\u0026quot;. It is recommended to specify a \u0026quot;C\u0026quot; that is slightly larger than the significance level for the study. To disable the adaptive procedure, set C=1. Default is C=0.1 --extern_weight [EXTERN_WEIGHT [EXTERN_WEIGHT ...]] External weights that will be directly applied to genotype coding. Names of these weights should be in one of '--var_info' or '--geno_info'. If multiple weights are specified, they will be applied to genotypes sequentially. Note that all weights will be masked if --use_indicator is evoked. --weight {Browning_all,Browning,KBAC,RBT} Internal weighting themes inspired by various association methods. Valid choices are: 'Browning_all', 'Browning', 'KBAC' and 'RBT'. Default set to 'Browning_all'. Except for 'Browning_all' weighting, tests using all other weighting themes has to calculate p-value via permutation. For details of the weighting themes, please refer to the online documentation. --NA_adjust This option, if evoked, will replace missing genotype values with a score relative to sample allele frequencies. The association test will be adjusted to incorporate the information. This is an effective approach to control for type I error due to differential degrees of missing genotypes among samples. --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive model. Default set to additive vtools show test WeightedBurdenQt Name: WeightedBurdenQt Description: Weighted genotype burden tests for quantitative traits, using one or many arbitrary external weights as well as one of 4 internal weighting themes usage: vtools associate --method WeightedBurdenQt [-h] [--name NAME] [--mafupper MAFUPPER] [--alternative TAILED] [-p N] [--permute_by XY] [--adaptive C] [--extern_weight [EXTERN_WEIGHT [EXTERN_WEIGHT ...]]] [--weight {Browning_all,Browning,KBAC,RBT}] [--NA_adjust] [--moi {additive,dominant,recessive}] Weighted genotype burden tests for quantitative traits, using one or many arbitrary external weights as well as one of 4 internal weighting themes. External weights (variant/genotype annotation field) are passed into the test by --var_info and --geno_info options. Internal weighting themes are one of \u0026quot;Browning_all\u0026quot;, \u0026quot;Browning\u0026quot;, \u0026quot;KBAC\u0026quot; or \u0026quot;RBT\u0026quot;. p-value is based on linear regression analysis and permutation procedure has to be used for \u0026quot;Browning\u0026quot;, \u0026quot;KBAC\u0026quot; or \u0026quot;RBT\u0026quot; weights. optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 0.01 --alternative TAILED Alternative hypothesis is one-sided (\u0026quot;1\u0026quot;) or two-sided (\u0026quot;2\u0026quot;). Default set to 1 -p N, --permutations N Number of permutations --permute_by XY Permute phenotypes (\u0026quot;Y\u0026quot;) or genotypes (\u0026quot;X\u0026quot;). Default is \u0026quot;Y\u0026quot; --adaptive C Adaptive permutation using Edwin Wilson 95 percent confidence interval for binomial distribution. The program will compute a p-value every 1000 permutations and compare the lower bound of the 95 percent CI of p-value against \u0026quot;C\u0026quot;, and quit permutations with the p-value if it is larger than \u0026quot;C\u0026quot;. It is recommended to specify a \u0026quot;C\u0026quot; that is slightly larger than the significance level for the study. To disable the adaptive procedure, set C=1. Default is C=0.1 --extern_weight [EXTERN_WEIGHT [EXTERN_WEIGHT ...]] External weights that will be directly applied to genotype coding. Names of these weights should be in one of '--var_info' or '--geno_info'. If multiple weights are specified, they will be applied to genotypes sequentially. Note that all weights will be masked if --use_indicator is evoked. --weight {Browning_all,Browning,KBAC,RBT} Internal weighting themes inspired by various association methods. Valid choices are: 'Browning_all', 'Browning', 'KBAC' and 'RBT'. Default set to 'Browning_all'. Except for 'Browning_all' weighting, tests using all other weighting themes has to calculate p-value via permutation. For details of the weighting themes, please refer to the online documentation. --NA_adjust This option, if evoked, will replace missing genotype values with a score relative to sample allele frequencies. The association test will be adjusted to incorporate the information. This is an effective approach to control for type I error due to differential degrees of missing genotypes among samples. --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive mode. Default set to additive  Application  Example using snapshot vt_ExomeAssociation\nvtools associate rare status --covariates age gender bmi exposure -m \u0026quot;WeightedBurdenBt --na\\ me WeightedBurdenBt --alternative 2\u0026quot; --group_by name2 --to_db weightedburdenBt -j8 \u0026gt; weight\\ edburdenBt.txt INFO: 3180 samples are found INFO: 2632 groups are found INFO: Starting 8 processes to load genotypes Loading genotypes: 100% [===============================================] 3,180 23.6/s in 00:02:15 Testing for association: 100% [=====================================================] 2,632/195 4.5/s in 00:09:48 INFO: Association tests on 2632 groups have completed. 195 failed. INFO: Using annotation DB weightedburdenBt in project test. INFO: Annotation database used to record results of association tests. Created on Thu, 31 Jan 2013 21:36:29 vtools show fields | grep weightedburdenBt weightedburdenBt.name2 name2 weightedburdenBt.sample_size_WeightedBurdenBt sample size weightedburdenBt.num_variants_WeightedBurdenBt number of variants in each group (adjusted for specified MAF weightedburdenBt.total_mac_WeightedBurdenBt total minor allele counts in a group (adjusted for MOI) weightedburdenBt.beta_x_WeightedBurdenBt test statistic. In the context of regression this is estimate of weightedburdenBt.pvalue_WeightedBurdenBt p-value weightedburdenBt.wald_x_WeightedBurdenBt Wald statistic for x (beta_x/SE(beta_x)) weightedburdenBt.beta_2_WeightedBurdenBt estimate of beta for covariate 2 weightedburdenBt.beta_2_pvalue_WeightedBurdenBt p-value for covariate 2 weightedburdenBt.wald_2_WeightedBurdenBt Wald statistic for covariate 2 weightedburdenBt.beta_3_WeightedBurdenBt estimate of beta for covariate 3 weightedburdenBt.beta_3_pvalue_WeightedBurdenBt p-value for covariate 3 weightedburdenBt.wald_3_WeightedBurdenBt Wald statistic for covariate 3 weightedburdenBt.beta_4_WeightedBurdenBt estimate of beta for covariate 4 weightedburdenBt.beta_4_pvalue_WeightedBurdenBt p-value for covariate 4 weightedburdenBt.wald_4_WeightedBurdenBt Wald statistic for covariate 4 weightedburdenBt.beta_5_WeightedBurdenBt estimate of beta for covariate 5 weightedburdenBt.beta_5_pvalue_WeightedBurdenBt p-value for covariate 5 weightedburdenBt.wald_5_WeightedBurdenBt Wald statistic for covariate 5 head weightedburdenBt.txt name2 sample_size_WeightedBurdenBt num_variants_WeightedBurdenBt total_mac_WeightedBurdenBt beta_x_WeightedBurdenBt pvalue_WeightedBurdenBt wald_x_WeightedBurdenBt beta_2_WeightedBurdenBt beta_2_pvalue_WeightedBurdenBt wald_2_WeightedBurdenBt beta_3_WeightedBurdenBt beta_3_pvalue_WeightedBurdenBt wald_3_WeightedBurdenBt beta_4_WeightedBurdenBt beta_4_pvalue_WeightedBurdenBt wald_4_WeightedBurdenBt beta_5_WeightedBurdenBt beta_5_pvalue_WeightedBurdenBt wald_5_WeightedBurdenBt AAMP 3180 3 35 0.0449657 0.979459 0.0257468 0.0312612 4.39155E-09 5.86873 -0.298905 0.0146383 -2.44121 0.130226 1.2303E-40 13.3472 0.435497 0.00139398 3.19589 AADACL4 3180 5 138 -2.46402 0.191324 -1.30667 0.0313048 4.31926E-09 5.87148 -0.294729 0.0160925 -2.40681 0.129824 2.23801E-40 13.3025 0.437296 0.00134129 3.207 ABHD1 3180 5 29 -1.40549 0.502329 -0.67083 0.0312599 4.37216E-09 5.86946 -0.297393 0.0151487 -2.42881 0.13027 1.21612E-40 13.348 0.437962 0.00131275 3.21318 ABCG8 3180 12 152 -0.597925 0.598611 -0.526399 0.0313146 4.24769E-09 5.87425 -0.297519 0.0151294 -2.42927 0.130098 1.44734E-40 13.3351 0.436695 0.00135537 3.20399 ABI2 3180 1 25 4.90399 0.0422609 2.03094 0.0311325 4.9292E-09 5.84954 -0.30075 0.0140623 -2.45567 0.129821 1.95802E-40 13.3125 0.436794 0.00135518 3.20403 ABCA12 3180 28 312 -0.387274 0.567616 -0.571566 0.0312492 4.47694E-09 5.86553 -0.298553 0.0147626 -2.43815 0.13023 1.19773E-40 13.3492 0.437199 0.00134108 3.20704 ABCA4 3180 43 492 -0.0845646 0.866958 -0.167524 0.0312627 4.36946E-09 5.86956 -0.298887 0.0146353 -2.44128 0.130242 1.12648E-40 13.3537 0.435417 0.00139682 3.19531 ABCB6 3180 7 151 -0.349842 0.782487 -0.276079 0.0313125 4.21645E-09 5.87547 -0.299545 0.0144307 -2.44636 0.130211 1.1897E-40 13.3497 0.435621 0.00138786 3.19716 ABCD3 3180 3 42 -1.24687 0.595311 -0.531156 0.0312676 4.44499E-09 5.86672 -0.301058 0.0139996 -2.45727 0.130189 1.06821E-40 13.3577 0.436778 0.00135205 3.2047  QQ-plot Attach:weightedburdenBt.jpg\nvtools associate rare bmi --covariates age gender exposure -m \u0026quot;WeightedBurdenQt --name Weig\\ htedBurdenQt --alternative 2\u0026quot; --group_by name2 --to_db weightedburdenQt -j8 \u0026gt; weightedburde\\ nQt.txt INFO: 3180 samples are found INFO: 2632 groups are found Loading genotypes: 100% [===============================] 3,180 24.4/s in 00:02:10 Testing for association: 100% [===================================] 2,632/147 22.2/s in 00:01:58 INFO: Association tests on 2632 groups have completed. 147 failed. INFO: Using annotation DB weightedburdenQt in project test. INFO: Annotation database used to record results of association tests. Created on Thu, 31 Jan 2013 21:51:44 vtools show fields | grep weightedburdenQt weightedburdenQt.name2 name2 weightedburdenQt.sample_size_WeightedBurdenQt sample size weightedburdenQt.num_variants_WeightedBurdenQt number of variants in each group (adjusted for specified MAF weightedburdenQt.total_mac_WeightedBurdenQt total minor allele counts in a group (adjusted for MOI) weightedburdenQt.beta_x_WeightedBurdenQt test statistic. In the context of regression this is estimate of weightedburdenQt.pvalue_WeightedBurdenQt p-value weightedburdenQt.wald_x_WeightedBurdenQt Wald statistic for x (beta_x/SE(beta_x)) weightedburdenQt.beta_2_WeightedBurdenQt estimate of beta for covariate 2 weightedburdenQt.beta_2_pvalue_WeightedBurdenQt p-value for covariate 2 weightedburdenQt.wald_2_WeightedBurdenQt Wald statistic for covariate 2 weightedburdenQt.beta_3_WeightedBurdenQt estimate of beta for covariate 3 weightedburdenQt.beta_3_pvalue_WeightedBurdenQt p-value for covariate 3 weightedburdenQt.wald_3_WeightedBurdenQt Wald statistic for covariate 3 weightedburdenQt.beta_4_WeightedBurdenQt estimate of beta for covariate 4 weightedburdenQt.beta_4_pvalue_WeightedBurdenQt p-value for covariate 4 weightedburdenQt.wald_4_WeightedBurdenQt Wald statistic for covariate 4 head weightedburdenQt.txt name2 sample_size_WeightedBurdenQt num_variants_WeightedBurdenQt total_mac_WeightedBurdenQt beta_x_WeightedBurdenQt pvalue_WeightedBurdenQt wald_x_WeightedBurdenQt beta_2_WeightedBurdenQt beta_2_pvalue_WeightedBurdenQt wald_2_WeightedBurdenQt beta_3_WeightedBurdenQt beta_3_pvalue_WeightedBurdenQt wald_3_WeightedBurdenQt beta_4_WeightedBurdenQt beta_4_pvalue_WeightedBurdenQt wald_4_WeightedBurdenQt AADACL4 3180 5 138 -3.3906 0.159775 -1.40616 0.0150701 0.0575284 1.89996 -0.0698905 0.733286 -0.340787 -0.940103 2.72704E-05 -4.20129 AAMP 3180 3 35 5.33715 0.0927374 1.68164 0.0148223 0.0617461 1.86878 -0.0767246 0.708183 -0.374331 -0.939547 2.75008E-05 -4.19938 ABCB10 3180 6 122 0.652166 0.773271 0.288123 0.0150189 0.0584545 1.89296 -0.0795645 0.698049 -0.38799 -0.945327 2.49634E-05 -4.22137 ABCB6 3180 7 151 -0.938172 0.653007 -0.449631 0.0151034 0.0571025 1.90322 -0.0803477 0.695236 -0.391795 -0.943322 2.57074E-05 -4.21471 ABCG5 3180 6 87 -3.04695 0.171201 -1.36867 0.0147558 0.0630148 1.85974 -0.0732971 0.720746 -0.357493 -0.953839 2.10114E-05 -4.26027 ABHD1 3180 5 29 -1.47831 0.509375 -0.659886 0.0150935 0.05722 1.90232 -0.0777012 0.704752 -0.378948 -0.940358 2.73267E-05 -4.20082 ABCG8 3180 12 152 -2.29054 0.152981 -1.42942 0.0151166 0.0567651 1.90581 -0.0738058 0.71887 -0.360001 -0.940705 2.69354E-05 -4.2041 ABI2 3180 1 25 5.96983 0.276415 1.0886 0.0150043 0.0586562 1.89144 -0.081478 0.691101 -0.397397 -0.941765 2.64399E-05 -4.20833 ABL2 3180 4 41 -1.52705 0.578314 -0.555906 0.0150917 0.057261 1.902 -0.0773202 0.706151 -0.377064 -0.943905 2.54124E-05 -4.21733  QQ-plot Attach:weightedburdenQt.jpg\n\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/development/",
	"title": "Development",
	"tags": [],
	"description": "",
	"content": " Home of Variant Tools A presentation about variant tools (Oct, 3rd, 2013)\nvariant tools is a software tool for the manipulation, annotation, selection, simulation, and analysis of variants in the context of next-gen sequencing analysis. Unlike some other tools used for Next-Gen sequencing analysis, variant tools is project based and provides a whole set of tools to manipulate and analyze genetic variants. Please refer to what you can do with variant tools for a list of features provided by variant tools.\nNews  May 10, 2016: We have released a docker container for variant tools called `mdabioinfo/varianttools`, which allows users to test variant tools without installing it. Jan 20th, 2016: Release of variant tools 2.7.0, with significantly improved variant pipeline tools and support for arbitrary reference genome. Jan 15th, 2015: Release of variant tools 2.6.1, which fixes some issues with Python 3. Dec 20th, 2014: Release of variant tools 2.6.0. This version cleans up the pipeline code to assist users to write customized pipelines and actions. Nov 10th, 2014: Release of variant tools 2.5.1, which is a maintenance release that address a bug with 2.5.0 on the use of user-specified temp_dir. Manhattan and QQ plot engine is also updated to work with ggplot2 version 1.0.0 (backward compatibility is dropped). Oct 15th, 2014: Release of variant tools 2.5.0 with new variant tools repository. The variant tools repository used by variant tools 2.4.0 and earlier has been discontinued. Please upgrade to variant tools 2.5.0 to access the new repository. Aug 15th, 2014: Release of variant tools 2.4.0. Feb 27th, 2014: Release of variant tools 2.3.0. Jan 16th, 2014: Release of variant tools 2.2.0. Nov 6th, 2013: Release of variant tools 2.1.0, which adds a few useful features such as functions \u0026lt;a class='createlinktext' rel='nofollow' href='http://localhost/~iceli/wiki/pmwiki.php?n=Vtools.Genotype?action=edit'\u0026gt;genotype()\u0026lt;/a\u0026gt;\u0026lt;a rel='nofollow' class='createlink' href='http://localhost/~iceli/wiki/pmwiki.php?n=Vtools.Genotype?action=edit'\u0026gt;?\u0026lt;/a\u0026gt; and \u0026lt;a class='createlinktext' rel='nofollow' href='http://localhost/~iceli/wiki/pmwiki.php?n=Vtools.Samples?action=edit'\u0026gt;samples()\u0026lt;/a\u0026gt;\u0026lt;a rel='nofollow' class='createlink' href='http://localhost/~iceli/wiki/pmwiki.php?n=Vtools.Samples?action=edit'\u0026gt;?\u0026lt;/a\u0026gt; SQL function, and the --as option to command vtools use. Oct 9, 2013: Release of variant tools 2.0.1, which is a maintenance release of version 2.0.0. Aug 27, 2013: Release of variant tools 2.0. This is a major release of variant tools with many new features. Please check ChangeLog? for details.\n more \u0026hellip;\n May 16, 2013: Release of variant tools 1.0.6, which contains a lot of small features and bug fixes.\n Mar 20, 2013: Release of variant tools 1.0.5. This release adds commands vtools admin --update_resource and vtools_report sequences, and allows the use of arbitrary characters for names of variant tables.\n Feb 20, 2013: Release of variant tools 1.0.4. This release comes with numerous bug fixed and new minor features. Please check the ChangeLog for details.\n Oct 21, Nov 10, Nov 26, and Nov 29. 2012: Release of variant tools 1.0.3a, b, c and d to address various small issues.\n Sep 25, 2012: Release of variant tools version 1.0.3, with new features and improvements in vtools associate, vtools update, vtools phenotype and vtools_report commands.\n Jul 9th, 2012: Release of variant tools version 1.0.3rc1. Other than a few bug fixes and major performance improvements, this release introduces new commands vtools associate and vtools admin, with more than 20 association tests implemented under a unified association test framework.\n Jan 24th, 2012: Release of variant tools version 1.0.2. This release fixes a major bug that causes duplicate output in commands vtools output and vtools export when range-based annotation databases are used. All users are recommended to upgrade.\n Jan 2nd, 2012: Release of variant tools version 1.0.1. This version contains a few new features and bug fixes, and more importantly, dramatic performance improvement for many commands. Please refer to ChangeLog? for details about this release.\n Dec 30th, 2011: the gwasCatalog annotation source is available for download. See examples? of how to use gwasCatalog? to find published GWA hits that are near your variants.\n Dec 15th, 2011: Two new annotation sources are available: Cancer Gene Census from the Cancer Genome Project, and the 5400 exomes EVS annotation database from the NHLBI Exome Sequencing Project.\n Dec 4th, 2011: An application note that describes variant tools has been published online in Bioinformatics.\n Nov 13, 2011: Release of variant tools version 1.0.\n Jan 24th, 2012: Release of variant tools version 1.0.2. This release fixes a major bug that causes duplicate output in commands vtools output and vtools export when range-based annotation databases are used. All users are recommended to upgrade.\n Jan 2nd, 2012: Release of variant tools version 1.0.1. This version contains a few new features and bug fixes, and more importantly, dramatic performance improvement for many commands. Please refer to ChangeLog? for details about this release.\n Dec 30th, 2011: the gwasCatalog annotation source is available for download. See examples? of how to use gwasCatalog? to find published GWA hits that are near your variants.\n Dec 15th, 2011: Two new annotation sources are available: Cancer Gene Census from the Cancer Genome Project, and the 5400 exomes EVS annotation database from the NHLBI Exome Sequencing Project.\n Dec 4th, 2011: An application note that describes variant tools has been published online in Bioinformatics.\n Nov 13, 2011: Release of variant tools version 1.0.\n Nov 7, 2011: A new annotation source called EVS (Exome Variant Server)? is available consisting of exome sequencing variants from the NHLBI Exome Sequencing Project (ESP). This data was retrieved from the project\u0026rsquo;s EVS server and contains population-specific allele frequencies (currently for European Americans and African Americans) and various functional annotations for predicted variants in approximately 2500 exomes.\n Nov 2, 2011: Release of release candidate version 1.0rc3. This version adds option --jobs to a number of vtools commands and allow them to execute in multiple threads or processes. User interface is further cleaned for the final 1.0 release. As a result, support for the MySQL backend is temporarily disabled.\n Oct 16, 2011: Release of release candidate version 1.0rc2. This version has a new option --children for command vtools init, which allows the creation of a project by merging multiple subprojects.\n Oct 7, 2011: Release of release candidate version 1.0rc1. This version has a new vtools export command that can export in ANNOVAR and VCF formats.\n Sep 27, 2011: Release of the second beta. This version contains full Python 3 support and a much more powerful vtools import command.\n Sep 10, 2011: Release of 1.0 beta.\n July 15, 2011: Initial public release.\n  The integrative design of variant tools If you have used other sequencing or association analysis tools such as bedtools and pseq, you will be surprised that variant tools usually does not give you a nice report with a list of variants or genes with some useful information after performing an analysis. Instead, all the information, including results of analysis, are saved in the project in a consistent manner. An extra step is needed to output the information you need. In other words, the management and presentation of information regarding variants are two different processes, and you typically add more and more information to your project during analysis of your data. The end result is that you have immediate access to a large amount of information for the variants you are interested in, which can in turn help you perform more in-depth analysis. Using a fabricated and unusually long command,\n% vtools output # 2 myvariants # 1 chr pos ref alt # 3 hom_case hom_ctrl # 4 dbNSFP.SIFT_score dbSNP.name refGene.name2 # 5 asso1.p_value asso2.p_value # 6 \u0026ldquo;ref_sequence(chr, pos - 5, pos + 5)\u0026rdquo; # 7\n\u0026ldquo;track(\u0026lsquo;LP056A.BAM\u0026rsquo;)\u0026rdquo; # 8 \u0026ldquo;genotype(\u0026lsquo;WGS1\u0026rsquo;)\u0026rdquo; # 9 \u0026ldquo;samples()\u0026rdquo;\n myvariants contains a list of variants, which is a subset of the master variant table (all the variant of your project) and is typically created using command vtools select. Command vtools output output information for all variants in myvariant, which include chr, pos, ref, alt constitute a variant, namely location and type of a mutation. hom_case and hom_ctrl are number of homozygous genotypes of this variant in cases and controls. These are called variant info fields and are added to the project using command vtools update --from_stat dbNSFP.SIFT_score, dbSNP.name and refGene.name2 are annotation information from different annotation databases. Annotation databases are not part of the project. They are connected to the project using command vtools use. asso1.p_value and asso2.p_value are results of two different association analysis. These are annotation databases created by command vtools associate. \u0026lt;a class='createlinktext' rel='nofollow' href='http://localhost/~iceli/wiki/pmwiki.php?n=Vtools.Commands?action=edit'\u0026gt;ref_sequence\u0026lt;/a\u0026gt;\u0026lt;a rel='nofollow' class='createlink' href='http://localhost/~iceli/wiki/pmwiki.php?n=Vtools.Commands?action=edit'\u0026gt;?\u0026lt;/a\u0026gt;(chr, pos-5, pos+5) is a function provided by variant tools to retrieve the reference sequence around the variant. Here 5 basepair of the up and downstream of each variant is returned. \u0026lt;a class='createlinktext' rel='nofollow' href='http://localhost/~iceli/wiki/pmwiki.php?n=Vtools.Commands?action=edit'\u0026gt;track\u0026lt;/a\u0026gt;\u0026lt;a rel='nofollow' class='createlink' href='http://localhost/~iceli/wiki/pmwiki.php?n=Vtools.Commands?action=edit'\u0026gt;?\u0026lt;/a\u0026gt;() is a function to extract information from external files. In this example, the depth of coverage at the location of the variant in the specified bam file is returned. \u0026lt;a class='createlinktext' rel='nofollow' href='http://localhost/~iceli/wiki/pmwiki.php?n=Vtools.Commands?action=edit'\u0026gt;genotype\u0026lt;/a\u0026gt;\u0026lt;a rel='nofollow' class='createlink' href='http://localhost/~iceli/wiki/pmwiki.php?n=Vtools.Commands?action=edit'\u0026gt;?\u0026lt;/a\u0026gt;('WGS1') is another function to get the genotype of this variant in sample WGS1, for example, 1 for heterozygote and 2 for homozygote. Function samples() lists the samples that contain the variant.  As you can see, individual commands such as vtools use and vtools update do not produce any output, but adds information to the project that can be displayed along with others. Then, it is important to remember that all such information can be used to select, prioritize, and analyze your variants. Another fabricated command would look like\n% vtools select # 1 myvariants # 2 \u0026ldquo;refGene.name2=\u0026lsquo;BRCA1\u0026rsquo;\u0026rdquo; # 3 \u0026lsquo;dbNSFP.SIFT_score \u0026gt; 0.95\u0026rsquo;\n\u0026lsquo;hom_case \u0026gt; 15\u0026rsquo; \u0026lsquo;hom_ctrl = 0\u0026rsquo; # 4 \u0026lsquo;asso1.p_value \u0026lt; 0.05 OR asso2.p_value \u0026lt; 0.05\u0026rsquo; # 5 \u0026ndash;to_table significant # 6\n Command vtools select selects variants according to their properties It starts from table myvariants, which was itself selected using some other crieteria, The variants must be in gene BRCA1 and must have \u0026gt; 0.95 SIFT scores (probably damagin) it should appear in at least 15 of the cases as homozygote, and not available (as homozygote) in any of the controls and it should be significant in one of the association tests, the selected variant are written to another table names significant.  In summary,** variant tools is NOT designed to be a black-box tool that analyzes your data and generates a nice-looking report with a list of candidate variants or genes. It is a platform under which you can analyze your data using several methods, compare and analyze results, re-compare and re-analyze, and again using different methods or annotation sources, based on the information abtained from your previous analyses.** The unique advantage of variant tools is that you generally do not need to write a bunch of scripts to connect input output of different tools and parse and compare results in different formats, and you have easy access to a huge amount of information that help you select, prioritize and analyze your variants, all from your command line. However, because of the uniqueness of this design, please read through the Concepts? section of this website before using variant tools.\nThings you can do with variant tools    Catagory Tasks     Variant calling Call variants from raw reads in FASTQ or BAM (convert to FASTQ first) formats using the GATK best practice pipeline.?   Import variants Import variants and genotypes in VCF format, with options to import specified variant and genotype info fields.?    Import all info and genotype fields, including customized fields from VCF files.    Import SNP and Indel variants from the Illumina CASAVA pipeline before version 1.8 (text files), and variants called from the Complete Genomics pipeline?.    Pipeline to import variants from the recent versions of the Illumina CASAVA pipeline (in VCF format) that provides variant calls from two probabilistic models.?    Import variants in text? or CSV? files.    Import variants from files in Plink format?    Import variants from a list of rsnames (dbSNP IDs)?, or just chromsome and positions?, variant information are retrieved from the dbSNP database.    Import data in arbitrary format by defining customized format-description file?.   Reference genome Native support for build hg18 and hg19 of the human genome, and other genomes such as the mouse genome. Reference genomes of the human genomes are downloaded automatically when they are used.    Variants in different reference genomes can be imported and analyzed together?, through automatic mapping between primary and alternative reference genomes.    Supports the use of annotations in a different reference genome by mapping genomic coordinates across reference genomes?    Easily retrieve reference sequences around variant sites through function ref_sequence?. This allows you to check if variants are in, for example, mononucleotide or short-tandem repeat sequences.    Validate the build of reference genome? if you are uncertain about the reference genome used in the data.   Variant annotation Standardize annotations from different sources so that you do not have to worry about inconsistencies between the use of chromosome names (with/without leading chr), genomic positions (0- or 1-based) and other nomenclatures.    Annotations are automatically downloaded from online repository, or build from source if needed. Annotation databases are automatically updated although you can use a prior version, or use different versions of the same annotation database at the same time.    Detailed descriptions of available annotation databases are readily available from command vtools show annotation.    Supports CCDS?, Entrez?, Known Gene?, and ref seq? definitions of genes, which allow you to identify variants in genes, exon regions, or upstream/downstream of these genes.    Standardize gene names through the use of HUGO Gene Nomenclature Committee approved gene names?    Identify variants in Catalogue of Somatic Mutations in Cancer? or within Database of Genomic Variants?.    Identify variants in all versions of dbSNP databases?, Exome Sequencing project?, the thousand genomes project?, and the HapMap project?    Annotate variants with SIFT, PolyPhen, MutationTaster and many other prediction scores from dbNSFP?.    Check for variants that are in the GWAS Catalog? database, or variants that are within certain range of GWAS hits.    Identify variants in highly conserved regions through the phastCons? database, or variants in genomic duplication regions?.    Pipelines to automatically annotate variants using ANNOVAR? and snpEff?    Allow the creation of annotation databases from your own data in vcf format?    Convert variants in a variant tools project to an annotation database to be used by another project?, or convert an annotation database to a project for detailed analysis?    Users can define and create their own annotation databases through [[Annotation/New   External Annotation Retrieve calls, reads, quality, and coverage information from BAM files?, filtered by quality score, strand, type, or flags, and use such information to select variants. This provides a command line alternative to IGV to check raw reads for called variants.    Retreive variant info and genotype information from local or online tabix indexed vcf.gz files?, this allows you, for example, to obtain variant info from vcf files on the 1000 genomes website.    Retrive annotation from bigWig? or bigBed? files, from the ENCODE project   Samples and Phenotypes Import and keep track of samples using filename and sample names.    Rename samples? and merge genotypes from multiple input files?.    Arbitrary sample information such as sex, BMI, and ethnicity can be saved as phenotype and used for sample selection or association analysis.    Calculation of number of genotypes, alternative alleles, homozygotes, heterzygotes and other types of genotypes in all or subset of samples.?    Calculate minimal, maximum, average values of genotype info (e.g. quality score) across all or selected samples for each variant.?   Variant Selection Use sample statistics to select, for example, homozygous variants with acceptable quality that appear only in cases?.    Select variants based on their membership in annotation databases such as dbSNP and thousand genomes project?.    Select variants from multiple conditions that involves multiple variant and annotation info fields (e.g. SIFT score)?.    Variants selected by different criteria are kept in multiple variant tables, with meta information.    Compare variant tables and examine differences between two or more variant tables?.    Identify De Novo mutations from family based samples, identify variants that share the same sites with an existing set of variants.?    Pipelines to identify de novo or recessive mutations that might cause the phenotype of an affected offspring in a family of unaffected parents?   Output variants Output a large number of variant info and annotation fields across different annotation databases altogether?.    Output expressions of variant info and annotation fields, including vtools-specific SQL functions.    Output reference sequence? around variant site, genotypes? of one or more samples, and samples? that harbor the variants.    Output summary statistics (e.g. count, average) of variants and variant info fields, grouped by specified fields.   Export variants Export? variants in vcf format, with variant and annotation info, and genotypes.    Export variants in other formats such as ANNOVAR? and Plink? to be analyzed by these programs.    Export variants with variant info and annotation fields in csv format.   Association analysis Use more than 20 association analysis methods to associate variants and genes with qualitative or quantitative traits?.    Execute multiple association tests across the genome using multiple processes.    Results of association analyses are saved as annotation databases and are used to annotate individual variants, regardless of groups used to analyze data    Draw manhantan and other figures? from association test results    Perform meta analysis? from association test results   Reports Print reference sequences? for particular regions, or gene, exome etc    Calculate discordance rate? between samples.    Calculate average depth of coverage?, number of SNPs and Indels? for all or selected samples.    Calculate transition transversion ratio? for all or selected variants.    Scatter, box plot, histgram plots for variant info fields?, genotype info fields?, and phenotypes?   Data Management A project can be saved, transferred and loaded easily as snapshots?. A number of online snapshots are provided for learning purposes.    Remove genotypes? based on different criteria (e.g. quality score), or remove variants in a variant table?.    Merge data from several sub projects? (e.g. adding data from different batches).    Split project into sub projects? to focus on particular sets of variants or samples.    A resource management system to download and update resources on demand, or in batch.    Please refer to a list of tutorials? to get started.\nCitation for variant tools Please cite\nF. Anthony San Lucas, Gao Wang, Paul Scheet, and Bo Peng (2012) Integrated annotation and analysis of genetic variants from next-generation sequencing studies with variant tools, Bioinformatics 28 (3): 421-422.\nfor Variant Tools and\nGao Wang, Bo Peng and Suzanne M. Leal (2014) Variant Association Tools for Quality Control and Analysis of Large-Scale Sequence and Genotyping Array Data, The American Journal of Human Genetics 94 (5): 770–83.\nfor Variant Association Tools, and\nBo Peng (2014) Reproducible Simulations of Realistic Samples for Next-Generation Sequencing Studies Using Variant Simulation Tools, Genetic Epidemiology.\nfor Variant Simulation Tools if you find variant tools helpful and use it in your publication. Thank you.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/genes/",
	"title": "Genes",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/illumina5/",
	"title": "Illumina",
	"tags": [],
	"description": "",
	"content": " Analyze five samples from Illumina, a tutorial 1. Data source Whole genome-sequencing data for 4 cases and 1 control. Raw data and called variants are provided by Illumina. The SNV and Indel variants are called using CASAVA v18 and are stored separately for each chromosome.\n2. Import data Create a project\n# Performance data is collected on a Mac Workstation with 2x2.26G Quad-Core Xeon processor with 8G RAM. % vtools init ILLUMINA --force  Import data that are outputted from CASAVA v18. The data are organized by sample. Indels and SNPs are stored in different folders and in different formats. Because these are text files, we need to specify sample names to them.\n# It takes about 1 hour to import a total of 7.1 million variants. A maximum of 1G RAM is used. % for dir in Data/SS* % do name=${dir##*/} echo \u0026quot;Processing\u0026quot;, $name vtools import --format CASAVA18_indels $dir/Variations/indels/*.txt --sample $name --build hg19 vtools import --format CASAVA18_snps $dir/Variations/snps/*.txt --sample $name --build hg19 % done  You can use command \u0026ldquo;vtools show samples\u0026rdquo; to show a list of samples. You will notice that genotypes for each patient are spread to 24 samples in variant tools term.\n Our data consists of four cases and one control, we can add an aff table to the sample table to differentiate them:\nvtools phenotype --set aff=1 --samples \u0026quot;sample_name='SS113'\u0026quot; vtools phenotype --set aff=2 --samples \u0026quot;sample_name!='SS113'\u0026quot;  The first command sets 48 samples (24 indel files and 24 SNP files) for one patient as control (aff=1). The second command sets the rest of the samples as cases (aff=2).\n3. Find variants that only occur in cases In order to find variants that are in cases but not in controls, we use command sample_stat to count the number of variants:\n#These commands take about 15min, and use 1.55G of RAM. % vtools update variant --from_stat 'case_num=#(alt)' 'case_hom=#(hom)' 'case_het=#(het)' --samples 'aff=2' % vtools update variant --from_stat 'ctrl_num=#(alt)' 'ctrl_hom=#(hom)' 'ctrl_het=#(het)' --samples 'aff=1'  When can then find all variants that\n All heterozygous in cases, none in control All homozygous in cases, none in control Homozygous or heterozygous in cases, none in control\nThese are done in seconds. % vtools select variant \u0026lsquo;case_het=4\u0026rsquo; \u0026lsquo;ctrl_num=0\u0026rsquo; -t case_het4_ctrl_0 % vtools select variant \u0026lsquo;case_hom=4\u0026rsquo; \u0026lsquo;ctrl_num=0\u0026rsquo; -t case_hom4_ctrl_0 % vtools select variant \u0026lsquo;case_hom + case_het =4\u0026rsquo; \u0026lsquo;ctrl_num=0\u0026rsquo; -t case_4_ctrl_0\n  You can check the number of variants in these tables using command \u0026ldquo;vtools show tables\u0026rdquo;.\n 4. Narrowing down to a region of interest See available annotation databases, and use the refGene database\n% vtools show annotations % vtools use refGene-hg19_20110909  Display the variants in refGene NM_006805.\n# This command takes about 1min % vtools select variant 'refGene.name = \u0026quot;NM_007505\u0026quot;' --output chr pos ref alt  We can select a wilder region around this gene using ranges:\n# This command returns in 1 second % vtools select case_4_ctrl_0 'chr=\u0026quot;5\u0026quot;' 'pos \u0026lt; 117300000' 'pos \u0026gt; 117000000' \\ --output chr pos ref alt refGene.name case_het case_hom  To see a list of fields that could be outputted, use command \u0026ldquo;vtools show fields\u0026rdquo;.\n 5. Use ANNOVAR to annotate variants in case_4_ctrl_0. # It takes 8s to export 300K variants and 54s to import results. %vtools export case_4_ctrl_0 ann_input --format ANNOVAR %../annovar/annotate_variation.pl ann_input ../annovar/humandb --build hg19 %vtools update --from_file variant ann_input.exonic_variant_function --format ANNOVAR_output\\ --var_info mut_type genename function  vtools import --format ANNOVAR_output by default only import info mut_type. You can use command vtools show format ANNOVAR_output to see available fields and use parameter -var_info to import them.\n Now, we can select variants according to their function.\n# Query finishes in 5s % vtools select variant 'function is not NULL' -t exonic  6. Filter by dbSNP and 1000 genomes membership We would like to remove variants that belong to dbSNP and 1000 genomes because they are unlikely to be causal. We first need to use the relevant databases\n% vtools use dbSNP % vtools use /path/to/thousandGenomes-hg19_20110909.DB  and exclude variants by\n# Two queries take less than 1s. % vtools exclude exonic \u0026quot;dbSNP.chr is not NULL\u0026quot; -t nonDBSNP % vtools exclude nonDBSNP 'thousandGenome.chr is not NULL' -t nonDBSNP_1000g  7. Filter by quality score The CASAVA import format imports one quality score during importing, that is the phred scaled quality score for indels and snps. The name of these geno fields are Q_indel and Q_max_gt (Use command vtools show genotypes to see these fields). To get the mean quality score for each variant, we use commands\n# This command uses 7.5min and 2.5G of RAM because it involves multiple genotype tables % vtools update variant --from_stat 'mean_Q_indel=avg(Q_indel)' \\ 'mean_Q_max_gt=avg(Q_max_gt)'  To see if a variant has \u0026lsquo;above average\u0026rsquo; quality, you can calculate the average quality score of all variants, using command\n% vtools output variant 'avg(mean_Q_indel)' 'avg(mean_Q_max_gt)'  If we determine that any variants that have Q_indel \u0026lt; 300 and Q_max_gt \u0026lt; 100 are of low quality, you can exclude them as follows\n# This command takes 15s to execute % vtools exclude nonDBSNP_1000g 'mean_Q_max_gt \u0026lt; 400 OR mean_Q_indel \u0026lt; 100' -t result  8. Output selected variants Finally, we can output selected variants with their annotations using command\ndbNSFP is large and might take several hours to download\n % vtools use dbNSFP % vtools output result chr pos ref alt case_het case_hom genename mut_type SIFT_score PolyPhen2_score  We use dbNSFP here because this database contains SIFT and PolyPhen2 score for some of the variants.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/single_gene/kbac-test/",
	"title": "KBAC test",
	"tags": [],
	"description": "",
	"content": " Kernel Based Adaptive Clustering Method Introduction This is implementation for the KBAC statistic in Liu and Leal 2010[^Dajiang J. Liu and Suzanne M. Leal (2010) A Novel Adaptive Method for the Analysis of Next-Generation Sequencing Data to Detect Complex Trait Associations with Rare Variants Due to Gene Main Effects and Interactions. PLoS Genetics doi:10.1371/journal.pgen.1001156. http://dx.plos.org/10.1371/journal.pgen.1001156^]. It carries out case-control association testing for rare variants for whole exome association studies. Briefly, consider a gene of length n which harbors m rare variants. Genotype on the m variant sites \u0026amp; the disease status (case/control) are known for each individual. The program takes as input the m-site genotype and disease status (case/control) data files, and computes a p-value indicating the significance of association. Permutation has to be used to obtain valid p-values.\nAn R package is also available for use with standalone text dataset.\nNote a couple of differences between this implementation and the original version:\n The original paper provides 3 kernel options: hypergeometric, binomial and Gaussian kernels. The hypergeometric kernel generally performs best and is implemented. Other kernels are not implemented. The --alternative 2 option implements the spirit of the RBT test[^Iuliana Ionita-Laza, Joseph D. Buxbaum, Nan M. Laird and Christoph Lange (2011) A New Testing Strategy to Identify Rare Variants with Either Risk or Protective Effect on Disease. PLoS Genetics doi:10.1371/journal.pgen.1001289. http://dx.plos.org/10.1371/journal.pgen.1001289^] by performing two KBAC tests under both protective and deleterious assumptions and use the larger of the two statistics thus calculated as the final KBAC statistic.  Details Command interface vtools show test KBAC Name: KBAC Description: Kernel Based Adaptive Clustering method, Liu \u0026amp; Leal 2010 usage: vtools associate --method KBAC [-h] [--name NAME] [-q1 MAFUPPER] [-q2 MAFLOWER] [--alternative TAILED] [-p N] [--adaptive C] [--moi {additive,dominant,recessive}] Kernel Based Adaptive Clustering method, Liu \u0026amp; Leal 2010. Genotype pattern frequencies, weighted by a hypergeometric density kernel function, is compared for differences between cases and controls. p-value is calculated using permutation for consistent estimate with different sample sizes (the approximation method of the original publication is not implemented). Two- sided KBAC test is implemented by calculating a second statistic with case/ctrl label swapped, and the larger of the two statistic is used as two- sided test statistic optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. -q1 MAFUPPER, --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 0.01 -q2 MAFLOWER, --maflower MAFLOWER Minor allele frequency lower limit. All variants having sample MAF\u0026gt;m2 will be included in analysis. Default set to 0.0 --alternative TAILED Alternative hypothesis is one-sided (\u0026quot;1\u0026quot;) or two-sided (\u0026quot;2\u0026quot;). Default set to 1 -p N, --permutations N Number of permutations --adaptive C Adaptive permutation using Edwin Wilson 95 percent confidence interval for binomial distribution. The program will compute a p-value every 1000 permutations and compare the lower bound of the 95 percent CI of p-value against \u0026quot;C\u0026quot;, and quit permutations with the p-value if it is larger than \u0026quot;C\u0026quot;. It is recommended to specify a \u0026quot;C\u0026quot; that is slightly larger than the significance level for the study. To disable the adaptive procedure, set C=1. Default is C=0.1 --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive model. Default set to additive  Application  Example using snapshot vt_ExomeAssociation\nvtools associate rare status -m \u0026quot;KBAC --name kbac -p 5000\u0026quot; --group_by refGene.name2 --to_db\\ kbac -j8 \u0026gt; kbac.txt INFO: 3180 samples are found INFO: 2632 groups are found INFO: Starting 8 processes to load genotypes Loading genotypes: 100% [=====================] 3,180 34.4/s in 00:01:32 Testing for association: 100% [=====================] 2,632/591 18.9/s in 00:02:19 INFO: Association tests on 2632 groups have completed. 591 failed. INFO: Using annotation DB kbac in project test. INFO: Annotation database used to record results of association tests. Created on Wed, 30 Jan 2013 05:26:43 vtools show fields | grep kbac kbac.refGene_name2 refGene_name2 kbac.sample_size_kbac sample size kbac.num_variants_kbac number of variants in each group (adjusted for specified MAF kbac.total_mac_kbac total minor allele counts in a group (adjusted for MOI) kbac.statistic_kbac test statistic. kbac.pvalue_kbac p-value kbac.std_error_kbac Empirical estimate of the standard deviation of statistic kbac.num_permutations_kbac number of permutations at which p-value is evaluated head kbac.txt refGene_name2 sample_size_kbac num_variants_kbac total_mac_kbac statistic_kbac pvalue_kbac std_error_kbac num_permutations_kbac ABCG5 3180 6 87 0.00610092 0.353646 0.00629806 1000 ABCB6 3180 7 151 0.00375831 0.633367 0.00807416 1000 ABCB10 3180 6 122 0.0157014 0.0973805 0.00733189 5000 ABCG8 3180 12 152 -0.00160383 0.876124 0.00861691 1000 ABCA4 3180 43 492 0.0293608 0.387612 0.0142427 1000 ABHD1 3180 5 29 -0.000709548 0.732268 0.00400521 1000 ABCA12 3180 28 312 0.015846 0.509491 0.011858 1000 ABL2 3180 4 41 0.000628395 0.553447 0.00456862 1000 ACADL 3180 5 65 0.00239811 0.501499 0.00545028 1000  \n[^#^]\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/other_pipelines/",
	"title": "Other pipelines",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/post_assoc/",
	"title": "Post-assoc analysis",
	"tags": [],
	"description": "",
	"content": " Representing and Interpreting Association Results "
},
{
	"uri": "https://vatlab.github.io/vat-docs/administration/trafficstat/",
	"title": "Traffic statistics",
	"tags": [],
	"description": "",
	"content": "table.zebra tr:nth-child(odd) {\nbackground-color: #f3f3f3;  }\ntable.zebra {\npadding-top: 10px; padding-bottom: 10px; /* font-family: \u0026quot;Lucida Sans Unicode\u0026quot;, \u0026quot;Lucida Grande\u0026quot;, Sans-Serif; */ font-size: 14px; /* margin: 45px; */ /* width: 480px; */ text-align: left; border-collapse: collapse;  }\ntable.zebra th {\nfont-size: 16px; font-weight: normal; padding: 10px 8px; /* color: #039; */  }\ntable.zebra td {\npadding: 8px;  /* text-align:left; */\n/* color: #669; */  }\n.escaped {\nfont-family: Consolas, Menlo, Monaco, Lucida Console, Liberation Mono, DejaVu Sans Mono, Bitstream Vera Sans Mono, Courier New, monospace, serif;  }\n.frame\n{ border:0px solid #CCCCCC;  padding: 2px 0px 10px 10px; background-color:#eeeeee; }\ncode {\nfont-family: Consolas, Menlo, Monaco, Lucida Console, Liberation Mono, DejaVu Sans Mono, Bitstream Vera Sans Mono, Courier New, monospace, serif;  padding: 0px 2px 0px 2px;\nbackground-color: #eeeeee;  }\n.cmd {\ndisplay: block; padding: 10px 0px 2px 10px; font-family: Consolas, Menlo, Monaco, Lucida Console, Liberation Mono, DejaVu Sans Mono, Bitstream Vera Sans Mono, Courier New, monospace, serif;  /* Menlo, Monaco, Consolas, \u0026ldquo;Courier New\u0026rdquo;, monospace; */\nfont-weight: bold; word-break: break-all; word-wrap: break-word; background-color: #eeeeee; /*#f9f9f9; */ /* #f5f5f5; */ /* border-top:1px solid #cccccc; */  /* border-right:1px solid #cccccc; / / border-bottom:1px solid #cccccc; */\n/* border: 1px solid rgba(0, 0, 0, 0.15); */ /* border-left:4px solid #0000FF; -webkit-border-top-right-radius: 5px; -moz-border-top-right-radius: 5px; border-top-right-radius: 5px; -webkit-border-bottom-right-radius: 5px; -moz-border-bottom-right-radius: 5px; border-bottom-right-radius: 5px; */  }\na, a:visited {\ncolor: #4a6b82;  }\na:link { text-decoration:none; }\na:visited { text-decoration:none; }\na:hover { text-decoration:underline; }\na:active { text-decoration:underline; }\n/* a, a:link, a:visited, a:active {\ncolor: #662255; border-bottom: none; text-decoration:none; /*text-shadow: 1px 1px 1px #999 */  } a:hover {\ncolor: #662255; background-color:yellow; /*border-bottom: 1px dotted #3366cc;*/  }\n /  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_commands/",
	"title": "Vtools commands",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/variant_calling/bwa_gatk28_b37/",
	"title": "bwa_gatk28_b37",
	"tags": [],
	"description": "",
	"content": " Calling variants using BWA and GATK best practice pipeline (b37) This pipeline is identical to bwa_gatk28_hg19? except that it uses the b37 reference genome.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/regions/cytoband/",
	"title": "cytoBand",
	"tags": [],
	"description": "",
	"content": "cytoBand defines cytogenic bands. This annotation source gives the approximate location of these bands as seen on Giemsa-stained chromosomes. This data was downloaded from the UCSC Genome Browser database (http://genome.ucsc.edu/cgi-bin/hgTables).\nThe following fields are available for annotation.\nvtools show annotation cytoBand -v2 DEBUG: Opening project temp.proj DEBUG: Loading annotation database cytoBand DEBUG: Loading annotation database gwasCatalog Annotation database cytoBand (version hg19_20111216) Description: Cyto Band Database type: range Number of records: 862 Number of distinct ranges: 862 Reference genome hg19: ['chr', 'begin', 'end'] Field: chr Type: chromosome Missing entries: 0 Unique Entries: 24 Field: begin Type: integer Comment: start position on chromosome Missing entries: 0 Unique Entries: 667 Range: 1 - 243700001 Field: end Type: integer Comment: end position on chromosome Missing entries: 0 Unique Entries: 690 Range: 2200000 - 249250621 Field: name Type: string Comment: name of cytogenic band Missing entries: 0 Unique Entries: 259 Field: gieStain Type: string Comment: giemsa stain results Missing entries: 0 Unique Entries: 8  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/functions/genotype/",
	"title": "genotype",
	"tags": [],
	"description": "",
	"content": " genotypes of one or more samples Usage This function is only supported when STOREMODE is set to sqlite. Genotype information for a variant is not directly available in variant tools commands such as vtools output because these commands only output variant info or annotation fields. Function genotype can be used to retrieve genotypes of one or more samples from the genotype tables. In its single-sample mode, this function accepts a sample name and an optional field to display,\ngenotype(sample_name, params='')  where params can have be multiple parameters joined by \u0026amp;. For example, functions\ngenotype('WGS1') genotype('WGS1', 'field=DP')  returns the genotype (0 for homozygous wild type, 1 for heterzygous alternative, 2 for homozygous alternative, and -1 for one of the double alternative alleles) or genotype field DP of sample WGS1. '.' will be returned if sample WGS1 does not contain the variant.\nDetails  Examples: Use genotype function to get genotypes of samples\nLet us get a simple project and name the samples properly\n% vtools admin --load_snapshot vt_simple % vtools admin --rename_samples \u0026quot;filename='V2.vcf'\u0026quot; SAMP2 % vtools admin --rename_samples \u0026quot;filename='V3.vcf'\u0026quot; SAMP3 % vtools show samples sample_name filename SAMP1 V1.vcf SAMP2 V2.vcf SAMP3 V3.vcf  There are about 1000 genotypes in three samples:\n% vtools show genotypes sample_name filename num_genotypes sample_genotype_fields SAMP1 V1.vcf 989 GT SAMP2 V2.vcf 990 GT SAMP3 V3.vcf 988 GT  Now, in addition to the variant inforation, we would like to see the genotype of variants in sample SAMP1\n% vtools output variant chr pos ref alt \u0026quot;genotype('SAMP1')\u0026quot; -l 10 1 4540 G A 1 1 5683 G T 1 1 5966 T G 1 1 6241 T C 1 1 9992 C T 1 1 9993 G A 1 1 10007 G A 1 1 10098 G A 2 1 14775 G A 2 1 16862 A G 2  The genotype can also be used to select variants. For example, the following command select variants when their genotypes in SAMP1 is heterzygous. When we output genotypes of these variants in two samples, some of them are not available in SAMP2 and are displayed as missing (.).\n% vtools select variant \u0026quot;genotype('SAMP1')=1\u0026quot; --output chr pos ref alt \\ \u0026quot;genotype('SAMP1')\u0026quot; \u0026quot;genotype('SAMP2')\u0026quot; -l 10 1 4540 G A 1 . 1 5683 G T 1 . 1 5966 T G 1 1 1 6241 T C 1 . 1 9992 C T 1 . 1 9993 G A 1 . 1 10007 G A 1 1 1 20723 G C 1 1 1 29539 C T 1 . 1 39161 T C 1 .  In addition to genotype, you can use the genotype() funciton to display other genotype info fields (c.f. vtools show genotypes, for example, for a project with genotype info field DP_geno, we can specify name of the genotype info field as a second parameter:\n% vtools init genotype -f % vtools import CEU.vcf.gz --geno_info DP_geno --build hg18 % vtools output variant chr pos ref alt \u0026quot;genotype('NA12874')\u0026quot; \u0026quot;genotype('NA12874', 'field=DP_geno')\u0026quot; -l 10 1 533 G C 1 9 1 41342 T A 0 3 1 41791 G A 0 2 1 44449 T C 0 0 1 44539 C T 0 0 1 44571 G C 0 0 1 45162 C T 0 1 1 52066 T C 1 3 1 53534 G A 0 0 1 75891 T C 0 0  \nThe first parameter can also be a condition based on which several samples are selected (default to all samples). In this case, this function will return a list of genotypes (for default field='GT') or other fields. Two additional parameters are acceptable (joined by \u0026amp;):\n delimiter: Delimiter, defalt to ,. missing: If a sample does not contain the variant, output this string instead of ignoreing the sample.  For example, functions\ngenotype() genotype('aff=1') genotype('BMI\u0026gt;20', 'field=DP_geno\u0026amp;missing=.')  returns genotypes of all samples, samples with aff=1, and depth of coverage of of all samples with BMI \u0026gt; 20, respectively.\n Examples: Display genotypes of multiple samples It is straightforward to list genotypes of all samples that contain the variant:\n% vtools init genotype -f % vtools admin --load_snapshot vt_simple % vtools import CEU.vcf.gz --geno_info DP_geno --build hg18 % vtools remove genotypes 'GT=0' % vtools output variant chr pos ref alt \u0026quot;genotype()\u0026quot; -l 10 1 533 G C 1,1,1,1,1,1 1 41342 T A 1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,2,1,1,1,1,1,2,1,1,1 1 41791 G A 1,1,1,1,1 1 44449 T C 1,1 1 44539 C T 1,1 1 44571 G C 1,1,1,1,1,1,1 1 45162 C T 1,2,1,1,1,1,2,1,1,1,1,2,1,1,1,2 1 52066 T C 1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1 1 53534 G A 1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1 1 75891 T C 2,1,2,1,1,1,2,1  If you would like to limit the samples, you can pass a condition (c.f. vtools show samples)\n% vtools phenotype --from_file phenotype.txt % vtools output variant chr pos ref alt \u0026quot;genotype('BMI\u0026gt;24')\u0026quot; -l 10 1 533 G C . 1 41342 T A 1,1 1 41791 G A 1 1 44449 T C . 1 44539 C T . 1 44571 G C 1,1,1 1 45162 C T 1 1 52066 T C 1,1 1 53534 G A 1 1 75891 T C 2  If you need to know which samples have these genotypes, you can use function samples() with the same condition.\n% vtools output variant chr pos ref alt \u0026quot;samples('BMI\u0026gt;24')\u0026quot; -l 10 1 533 G C . 1 41342 T A NA11918,NA12814 1 41791 G A NA11918 1 44449 T C . 1 44539 C T . 1 44571 G C NA12003,NA12287,NA12751 1 45162 C T NA12814 1 52066 T C NA12003,NA12751 1 53534 G A NA12287 1 75891 T C NA12814  Using strings inside the condition is bit tricky because you need to use backslash to pass condition sex='F' to the genotype function in the following example:\n% vtools output variant chr pos ref alt \u0026quot;genotype('sex=\\'F\\'')\u0026quot; -l 10 1 533 G C 1,1,1,1 1 41342 T A 1,1,1,1,1,1,1,1,2,1,1,1,1,1 1 41791 G A 1,1,1 1 44449 T C 1,1 1 44539 C T 1,1 1 44571 G C 1,1,1,1,1 1 45162 C T 1,2,1,1,2,1,1,1,1,1 1 52066 T C 1,1,1,1,1,1,1,1,1 1 53534 G A 1,1,1,1,1,1,1,1,1,1,1,1,1,1 1 75891 T C 2,1,2,1,2  Finally, if you would like to view values of other genotype info fields (c.f. vtools show genotypes), or using alternative delimiters, you can\n% vtools output variant chr pos ref alt \u0026quot;genotype('BMI\u0026gt;23', 'field=DP_geno\u0026amp;d=\\t\u0026amp;missing=.')\u0026quot; -l 10 1 533 G C . . . . . . . . . . 1 41342 T A . 1 4 3 . . . . 0 9 1 41791 G A . 2 . . . . . . . . 1 44449 T C . . . . . . . . . . 1 44539 C T . . . . . . . . . . 1 44571 G C . . . . 1 1 4 1 . . 1 45162 C T 4 . . . . . . . . 7 1 52066 T C . . 3 . 1 . . 1 . . 1 53534 G A 5 . . . . . 5 . . . 1 75891 T C . . . . . . . . . 6  \n Whereas the return value of genotype(sample_name) is an integer, the return value of genotype(sample_cond) is always a string, evern if only one sample is selected by the condition. You could match returned genotypes with samples by comparing the output of genotype(sample_cond) with the output of samples(sample_cond).  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/other_pipelines/illumina/",
	"title": "illumnina",
	"tags": [],
	"description": "",
	"content": " Pipelines to assist the analysis of illumina data Usage $ vtools show pipeline illumina A pipeline to handle illumina data prepared by CASAVA 1.8+. It imports variants from SNPs.vcf and Indel.vcf of multiple samples, separate maxgt and poly into different projects, calculate a few standard statistics and apply a few filters. All results are saved as variant tools snapshots. This pipeline uses command vtools so multi-processing is not supported. Available pipelines: load_data Pipeline \u0026quot;load_data\u0026quot;: This pipeline accepts a list of directories under which SNPs and Indels are listed in files Variations/SNPs.vcf and Variations/Indels.vcf. It reads all variants and save the project to a snapshot with raw data. It then removes MAXGT or POLY samples, rename samples, merge SNP and Indels remove variants without any genotype in all samples, create variant tables (all, SNVs and Indels) for each sample, and save results to two other snapshots for maxgt and poly data respectively. load_data_10: Load SNP and Indel variants from Variations/SNPs.vcf and Variations/Indels.vcf under specified directory. Save all inputted variants to the first snapshot file specified by --output load_data_20: Remove _POLY samples, merge SNPs and INDELs, remove genotypes that does not pass filter (filter != \u0026quot;PASS\u0026quot;), calculate genotype count of all variants, remove variants without any genotype, and save results to the second snapshot file specified by --output load_data_30: Remove _POLY samples, merge SNPs and INDELs, remove genotypes that does not pass filter (filter != \u0026quot;PASS\u0026quot;), calculate genotype count of all variants, remove variants without any genotype, and save results to the second snapshot file specified by --output Pipeline parameters: geno_info Genotype information fields imported from VCF files (default: filter qual DP_geno GQ_geno PL_geno) build Build of reference genome of the project. (default: hg19)  Details  Examples: Import illumina data\n$ vtools init test --force $ vtools execute illumina load_data --input /path/to/data/LP* \\ --output raw_data.tar maxgt_data.tar poly_data.tar  (:exampleend\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/genes/knowngene/",
	"title": "knownGene",
	"tags": [],
	"description": "",
	"content": " The knownGene database is based on the UCSC Genome Browser knownGene track. knownGene shows gene predictions based on data from RefSeq, Genbank, CCDS and UniProt. If you would like to annotate your variants to these genes, you can use the simpler knownGene database. If you would like to determine the exons that your variants are in, use the knownGene_exon database. See the available annotation fields for each database below.\nknownGene % vtools show annotation knownGene -v2 Annotation database knownGene (version hg19_20130904) Description: Gene predictions based on data from RefSeq, Genbank, CCDS and UniProt, from the UCSC KnownGene track. Database type: range Number of records: 82,960 Distinct ranges: 60,726 Reference genome hg19: chr, txStart, txEnd Field: name Type: string Comment: Name of gene such as uc001aaa.3 Missing entries: 0 Unique Entries: 82,960 Field: chr Type: string Missing entries: 0 Unique Entries: 60 Field: strand Type: string Comment: which DNA strand contains the observed alleles Missing entries: 0 Unique Entries: 2 Field: txStart Type: integer Comment: Transcription start position Missing entries: 0 Unique Entries: 48,720 Range: 1 - 249211537 Field: txEnd Type: integer Comment: Transcription end position Missing entries: 0 Unique Entries: 48,713 Range: 368 - 249213345 Field: cdsStart Type: integer Comment: Coding region start Missing entries: 0 Unique Entries: 51,789 Range: 1 - 249211537 Field: cdsEnd Type: integer Comment: Coding region end Missing entries: 0 Unique Entries: 51,745 Range: 0 - 249212562 Field: exonCount Type: integer Comment: Number of exons Missing entries: 0 Unique Entries: 119 Range: 1 - 5065  knownGene_exon % vtools show annotation knowGene_exon -v2 Annotation database knownGene_exon (version hg19_20130904) Description: Gene predictions based on data from RefSeq, Genbank, CCDS and UniProt, from the UCSC KnownGene track. This database contains all exome regions of the UCSC known gene database. Database type: range Number of records: 742,493 Distinct ranges: 289,953 Reference genome hg19: chr, exon_start, exon_end Field: chr Type: string Missing entries: 0 Unique Entries: 60 Field: strand Type: string Comment: which DNA strand contains the observed alleles Missing entries: 0 Unique Entries: 2 Field: txStart Type: integer Comment: Transcription start position Missing entries: 0 Unique Entries: 48,720 Range: 1 - 249211537 Field: txEnd Type: integer Comment: Transcription end position Missing entries: 0 Unique Entries: 48,713 Range: 368 - 249213345 Field: cdsStart Type: integer Comment: Coding region start Missing entries: 0 Unique Entries: 51,789 Range: 1 - 249211537 Field: cdsEnd Type: integer Comment: Coding region end Missing entries: 0 Unique Entries: 51,745 Range: 0 - 249212562 Field: exonCount Type: integer Comment: Number of exons Missing entries: 0 Unique Entries: 119 Range: 1 - 5065 Field: exon_start Type: integer Comment: exon start position Missing entries: 0 Unique Entries: 276,580 Range: 1 - 249211537 Field: exon_end Type: integer Comment: exon end position Missing entries: 0 Unique Entries: 276,718 Range: 368 - 249213345  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/variants/linkagephysicalmap/",
	"title": "linkage physical map",
	"tags": [],
	"description": "",
	"content": " The rutgersMap database was created from Rutgers Combined Linkage-Phsycal Map[^T. C. Matise, F. Chen, W. Chen, F. M. De La Vega, M. Hansen, C. He, F. C.L. Hyland, G. C. Kennedy, X. Kong, S. S. Murray, J. S. Ziegle, W. C.L. Stewart and S. Buyske (2007). A second-generation combined linkage physical map of the human genome. Genome Research^]. The current version contains interpolated genetic positions for variants from dbSNP build 134. It is also possible to provide a list of variants with physical positions to the Rutgers Map Interpolator and create your own annotation database using the rutgersMap format with --file option for vtools use command.\nDescription of the data from Rutgers Computational Genetics Lab:\nWe have constructed de novo a high-resolution genetic map that includes the largest set of polymorphic markers for which genotype data are publicly available: it combines genotype data from both the CEPH and deCODE pedigrees (for some markers), incorporates SNPs, also incorporates sequence-based positional information. The position of most markers on our map is corroborated by both genomic sequence and recombination-based data. This specific combination of features maximizes marker inclusion, coverage, and resolution, making this map uniquely suited as a comprehensive resource for determining genetic map information (order and distances) for any large set of polymorphic markers.\nrutgersMap % vtools show annotation rutgersMap -v2 Annotation database rutgersMap (version b134) Description: Rutgers Combined Linkage-Physical Map Database type: position Reference genome hg19: chr, position chr position one-based position in chromosome cm_avg map distance (cM), averaged cm_female map distance (cM), female cm_male map distance (cM), male  [^#^]\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_commands/phenotype/",
	"title": "phenotype",
	"tags": [],
	"description": "",
	"content": " Import and manipulate phenotypes 1. Usage % vtools phenotype -h usage: vtools phenotype [-h] [-f [INPUT_FILE [INPUT_FILE ...]]] [--set [EXPRESSION [EXPRESSION ...]]] [--from_stat [EXPRESSION [EXPRESSION ...]]] [--output [EXPRESSION [EXPRESSION ...]]] [-j N] [-g [COND [COND ...]]] [-s [COND [COND ...]]] [--header [HEADER [HEADER ...]]] [-d DELIMITER] [--na NA] [-l LIMIT] [-v {0,1,2}] Import phenotypes from a file, or set phenotypes to constants, or to summary statistics of sample genotype fields. optional arguments: -h, --help show this help message and exit -f [INPUT_FILE [INPUT_FILE ...]], --from_file [INPUT_FILE [INPUT_FILE ...]] Import phenotype from a tab or space delimited file, which can be standard input if a name - is specified. Samples are determined by sample names in the first column, or jointly by sample name and filename if there is another column with header 'filename'. Names of phenotype fields are determined by header of the input file, or by names provided from option --header. Non-alphanumeric characters in input filed names will be replaced by '_'. If multiple samples in a project share the same names, they will shared the imported phenotypes. Optionally, a list of phenotypes (columns of the file) can be specified after filename, in which case only the specified phenotypes will be imported. Parameter --samples could be used to limit the samples for which phenotypes are imported. Values that match value of parameter --na and cannot be converted to the probed type of phenotype (e.g. '' in a column of numbers) are recorded as missing values. --set [EXPRESSION [EXPRESSION ...]] Set a phenotype to a constant (e.g. --set aff=1), or an expression using other existing phenotypes (e.g. --set ratio_qt=high_qt/all_qt (the ratio of the number of high quality variants to the number of all variants, where high_qt and all_qt are obtained from sample statistics using parameter --from_stat). Parameter --samples could be used to limit the samples for which genotypes will be set. --from_stat [EXPRESSION [EXPRESSION ...]] Set a phenotype to a summary statistics of a genotype field. For example, \u0026quot;num=count(*)\u0026quot; sets phenotype num to be the number of genotypes of a sample, \u0026quot;GD=avg(DP)\u0026quot; sets phenotype DP to be the average depth (if DP is one of the genotype fields) of the sample. Multiple fields (e.g. '--from_stat \u0026quot;num=count(*)\u0026quot; \u0026quot;GD=avg(DP)\u0026quot;') are also allowed. In addition to standard SQL aggregation functions, variant tools supports special functions #(GT), #(wtGT), #(mutGT), #(alt), #(hom), #(het) and #(other), which counts the number of genotypes (the same as count(*)), wildtype genotypes, mutant genotypes alternative alleles, homozygotes, heterozygotes, and genotypes with two different alternative alleles. Parameters --genotypes and --samples could be used to limit the genotypes to be considered and the samples for which genotypes will be set. --output [EXPRESSION [EXPRESSION ...]] A list of phenotype to be outputted. SQL-compatible expressions or functions such as \u0026quot;DP/DP_all\u0026quot; and \u0026quot;avg(DP)\u0026quot; are also allowed -j N, --jobs N Allow at most N concurrent jobs to obtain sample statistics for parameter --from_stat. -g [COND [COND ...]], --genotypes [COND [COND ...]] Limit the operation to genotypes that match specified conditions. Use 'vtools show genotypes' to list usable fields for each sample. -s [COND [COND ...]], --samples [COND [COND ...]] Update phenotype for samples that match specified conditions. Use 'vtools show samples' to list usable fields in the sample table. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1). Input/Output options: --header [HEADER [HEADER ...]] A list of header names for input file if used with option --from_file. Otherwise a complete header or a list of names that will be joined by a delimiter (parameter --delimiter), for option --output. If a special name - is specified, the header will be read from the standard input, which is the preferred way to specify large multi-line headers (e.g. cat myheader | vtools export --header -). If this parameter is given without parameter, a default header will be derived from field names. -d DELIMITER, --delimiter DELIMITER Delimiter, default to tab, a popular alternative is ',' for csv output --na NA Input or output string for missing value.. -l LIMIT, --limit LIMIT Number of record to display. Default to all record.  2. Details Unlike vtools import and vtools update, this command imports/adds properties to samples rather than to variants. These properties include:\n Extra phenotype information imported from a tab-delimited file, via --from_file FILE Some values calculated from other phenotype columns, via --set \u0026quot;EXPRESSION\u0026quot; Summary statistics of genotype info of the samples, via --from_stat \u0026quot;EXPRESSION\u0026quot;  Any properties of sample individuals are considered a phenotype in vtools phenotype, including sample genotype information such as genotype calls quality, genotype depth of coverage and homozygote/heterozygote counts, etc., which can be useful in data quality control processes.\nThe difference between --set and --from_stat is that --set uses expressions with existing phenotype (fields in vtools show samples), and --from_stat uses expressions with genotype information.\n2.1 Importing phenotypes from text files The vtools phenotype --from_file command identifies a sample by its name but it can also identify a sample by a combination of sample name and file name because not all samples have names. The basic form of this command imports phenotype by sample names from a tab or comma delimited file.\n Examples: Create a new project To illustrate the use of this command, let\u0026rsquo;s start a new project and import some variants/genotypes\n% vtools init test -f % vtools admin --load_snapshot vt_testData % vtools import CEU_hg38.vcf --build hg38 --var_info DP --geno_info DP INFO: Importing variants from CEU_hg38.vcf (1/1) CEU_hg38.vcf: 100% [======================================] 306 21.4K/s in 00:00:00 INFO: 292 new variants (292 SNVs) from 306 lines are imported. Importing genotypes: 100% [================================] 292 3.5K/s in 00:00:00  There are 60 samples without genotype\n% vtools show samples -l 10 sample_name filename NA06985 CEU_hg38.vcf NA06986 CEU_hg38.vcf NA06994 CEU_hg38.vcf NA07000 CEU_hg38.vcf NA07037 CEU_hg38.vcf NA07051 CEU_hg38.vcf NA07346 CEU_hg38.vcf NA07347 CEU_hg38.vcf NA07357 CEU_hg38.vcf NA10847 CEU_hg38.vcf (50 records omitted)  \n Examples: Import phenotype from a file\n% head -10 phenotype.txt sample_name aff sex BMI NA06985 2 F 19.64 NA06986 1 M None NA06994 1 F 19.49 NA07000 2 F 21.52 NA07037 2 F 23.05 NA07051 1 F 21.01 NA07346 1 F 18.93 NA07347 2 M 19.2 NA07357 2 M 20.61  To import phenotypes from this file,\n% vtools phenotype --from_file phenotype.txt INFO: Adding phenotype aff of type INT INFO: Adding phenotype sex of type VARCHAR(1) INFO: Adding phenotype BMI of type FLOAT WARNING: Value \u0026quot;None\u0026quot; is treated as missing in phenotype BMI WARNING: 1 missing values are identified for phenotype BMI INFO: 3 field (3 new, 0 existing) phenotypes of 60 samples are updated.  This phenotype file now has 3 additional columns: affection status (1 or 2), gender (F or M) and BMI. The type of these columns are automatically determined, and the None value in the BMI column is treated as missing.\n% vtools show phenotypes -l 10 sample_name aff sex BMI NA06985 2 F 19.64 NA06986 1 M . NA06994 1 F 19.49 NA07000 2 F 21.52 NA07037 2 F 23.05 NA07051 1 F 21.01 NA07346 1 F 18.93 NA07347 2 M 19.2 NA07357 2 M 20.61 NA10847 2 M 14.6 (50 records omitted)  \nvariant tools automatically probe the type of phenotype. Values that match value specified by parameter --na or cannot be converted to probed type (e.g. '' or None in a column of numbers) will be treated as missing values.\nIf you have a large number of phenotypes and you only need to import some of them, you can specify a list of phenotypes after the filename.\n Examples: Import selected phenotypes from a file\nLet us first remove the phenotypes we just loaded:\n% vtools remove phenotypes aff sex BMI % vtools show phenotypes -l 10 sample_name NA06985 NA06986 NA06994 NA07000 NA07037 NA07051 NA07346 NA07347 NA07357 NA10847 (50 records omitted)  and only import the sex phenotype from the file:\n% vtools phenotype --from_file phenotype.txt sex INFO: Adding phenotype sex of type VARCHAR(1) INFO: 1 field (1 new, 0 existing) phenotypes of 60 samples are updated. % vtools show phenotypes -l 10 sample_name sex NA06985 F NA06986 M NA06994 F NA07000 F NA07037 F NA07051 F NA07346 F NA07347 M NA07357 M NA10847 M (50 records omitted)  \nOther features of this command include\n You can load phenotypes for only selected samples, which are specified by conditions such as --samples 'sample_name like \u0026quot;\u0026lt;span class='NB'\u0026gt;\u0026quot;'. The input file can be tab, comma, or space delimited. The command will automatically detect the delimiter used. The input file can have windows or Linux newlines, even the lengendary \\M newline that is still outputted by the MaxOSX version of Excel. The input file can be standard input if specify - as input filename. This allows you to use a pipe to send me phenotype file. variant tools automatically translate non-standard header names to a valid variant tools field name, by replacing non-alphanumeric characters with underscores ('_').  If your input file does not have any header, you can use option --header to specify a list of headers. This is helpful for importing plink .pfam file, using a command similar to vtools phenotype --from_file /tmp/test.tfam --header Family_ID sample_name Paternal_ID Maternal_ID Gender Status\n2.2 New columns based on other phenotypes vtools phenotype --set command allows users to create new columns in the phenotype table based on other phenotypes.\n Examples: Create a column race from CEU samples having race=1\n% vtools phenotype --set 'race=1' --samples 'filename like \u0026quot;%CEU%\u0026quot;' INFO: Adding phenotype race INFO: 60 values of 1 phenotypes (1 new, 0 existing) of 60 samples are updated. % vtools show samples -l -1 sample_name filename sex race NA06985 CEU_hg38.vcf F 1 NA06986 CEU_hg38.vcf M 1 NA06994 CEU_hg38.vcf F 1 NA07000 CEU_hg38.vcf F 1 NA07037 CEU_hg38.vcf F 1 NA07051 CEU_hg38.vcf F 1 ... ...  \nthe --samples option specify the subset of samples to which the new column value will be appended. Note above that None is assigned to samples that does not match the specified --samples condition. More examples on the --samples option are documented in vtools update, vtools select, etc.\n2.3 New columns based on sample genotype and genotype information With vtools show genotypes we know the total number of genotypes and available genotype information in the sample. vtools phenotype --from_stat further allows calculation of specific sample genotype properties.\n Examples: Phenotype from genotype statistics\n% vtools phenotype --from_stat \u0026quot;sample_total=#(GT)\u0026quot; % vtools phenotype --from_stat \u0026quot;sample_alt=#(alt)\u0026quot; % vtools phenotype --from_stat \u0026quot;sample_homo=#(hom)\u0026quot; % vtools phenotype --from_stat \u0026quot;sample_het=#(het)\u0026quot; % vtools phenotype --from_stat \u0026quot;sample_double_het=#(other)\u0026quot; % vtools show samples sample_name filename sex race sample_total sample_alt sample_homo sample_het sample_double_het NA06985 CEU_hg38.vcf F 1 292 110 40 30 0 NA06986 CEU_hg38.vcf M 1 292 126 31 64 0 NA06994 CEU_hg38.vcf F 1 292 131 37 57 0 ... ... NA12873 CEU_hg38.vcf F 1 288 137 37 63 0 NA12874 CEU_hg38.vcf M 1 292 101 30 41 0  gives statistic of different genotypes.\n Wild-type genotype can be directly calculated using vtools phenotype --set \u0026quot;sample_wt=sample_total-sample_homo-sample_het-sample_double_het\u0026quot;  \nAnother useful type of summary is the genotype information that usually summarizes genotype data quality. Notice that at the beginning of this example session we included genotype depth of coverage using option --geno_info. With this (and as many others as your vcf file provides) genotype information you can calculate summary statistics and append them to sample table. For example, DP_geno is the read depth for sample genotypes, a useful indicator of sample genotype quality. You may summarize DP_geno for each individual using the commands below:\n Examples: Phenotype calculated from statistics of genotype info fields\n% import_update jma7$ vtools phenotype --from_stat \u0026quot;meanDP=avg(DP)\u0026quot; \u0026quot;minDP=min(DP)\u0026quot; \u0026quot;maxDP=max(DP)\u0026quot; Calculating phenotype: 100% [===============================] 60 29.8/s in 00:00:02 INFO: 180 values of 3 phenotypes (0 new, 3 existing) of 60 samples are updated. % vtools show samples sample_name filename sex race sample_total sample_alt sample_homo sample_het sample_double_het meanDP minDP maxDP NA06985 CEU_hg38.vcf F 1 292 110 40 30 0 2.2705479452054793 0.0 12.0 NA06986 CEU_hg38.vcf M 1 292 126 31 64 0 10.736301369863014 0.0 29.0 NA06994 CEU_hg38.vcf F 1 292 131 37 57 0 5.815068493150685 0.0 16.0 ... ... NA12873 CEU_hg38.vcf F 1 288 137 37 63 0 3.952054794520548 0.0 16.0 NA12874 CEU_hg38.vcf M 1 292 101 30 41 0 3.886986301369863 0.0 14.0  \n2.4 Output selected phenotypes using option --output The basic form of vtools phenotype --output is very similar to command vtools show phenotypes. They can both display all or a specified subset of phenotypes.\n Examples: Output specified phenotypes % vtools phenotype \u0026ndash;from_file phenotype.txt BMI % vtools phenotype \u0026ndash;output sample_name BMI\nNA06985 19.64 NA06986 NA NA06994 19.49 NA07000 21.52 NA07037 23.05 ...  \nThe power of command vtools phenotype --output, similar to vtools output, is its ability to output summary statistics of phenotypes. For example, you can use item avg(meanDP) to display the average of the meanDP field. Because pehnotype meanDP records average depth of all genotypes each sample, avg(meanDP) displays average depth of all genotypes of all samples.\n Examples: Output summary statistics of phenotypes\nFor example, the following command outputs the wildtype genotype counts and BMI for each sample.\n% vtools phenotype --output \u0026quot;count(filename)\u0026quot; 60 % vtools phenotype --output \u0026quot;avg(meanDP)\u0026quot; 4.561244292237443  \n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/format/formats/rsname/",
	"title": "rsname",
	"tags": [],
	"description": "",
	"content": " Importing variants from a list of dbSNP iDs (rsnames) Format description % vtools show format rsname Import variants (chr, pos, ref, alt) that are queried from dbSNP database using provided rsnames Columns: None defined, cannot export to this format variant: chr Obtain chromosome from dbSNP by rsname pos Obtain position from dbSNP by rsname ref Obtain reference allele from dbSNP by rsname alt Obtain alternative allele from dbSNP by rsname Format parameters: sep delimiter used to separate input fields (default: ',') rsname_col Index for the column with rsname (default: 1) dbfile Name of an attached dbSNP database or path to the dbSNP database in sqlite format (default: dbSNP- hg19_138.DB)  Details This format retrieves variant information from dbSNP. To use this format, you should first download and decompress the dbSNP database\n% vtools init format rsname % vtools use dbSNP-hg19_138  You can then use the database to import variants from a list of rsnames:\n% vtools import variants.txt --format rsname --build hg19 INFO: Importing variants from variants.txt (1/1) variants.txt: 100% [==================================] 25,462 9.6K/s in 00:00:02 INFO: 25,944 new variants (25,885 SNVs, 50 insertions, 11 deletions) from 25,462 lines are imported. WARNING: Sample information is not recorded for a file without genotype and sample name. Importing genotypes: 0 0.0/s in 00:00:00 Copying samples: 0 0.0/s in 00:00:00  If a rsname corrsponds to multiple variants, all of them will be imported. For example, rs111688037 can import variants NM_004638.3:c.5085T\u0026gt;A and NM_004638.3:c.5085T\u0026gt;C (chr6:31602679).\nUse a different version of dbSNP If you are interested in using a different version of dbSNP, you will need to\n Use command vtools use dbSNP-VER to download and decompress another version of dbSNP Use option --dbfile dbSNP-VER.DB to use an alternative db file.  If your database file has different fields, please edit rsname.fmt to use the correct field names.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_report/sequence/",
	"title": "sequence",
	"tags": [],
	"description": "",
	"content": " Output DNA and protein sequence at specified chromosome regions Usage % vtools_report sequence -h usage: vtools_report sequence [-h] [--build [BUILD]] [--numbered [{left,right}]] [--char_per_line CHAR_PER_LINE] [--transcribe [GENE [GENE ...]]] [--translate [GENE [GENE ...]]] [--mark [MARK [MARK ...]]] [--mark_complement] [--mark_reverse] [--hide_unmatched] [-v {0,1,2,3}] regions [regions ...] positional arguments: regions One or more chromosome regions in the format of chr :start-end (e.g. chr21:33,031,597-33,041,570), Field:Value from a region-based annotation database (e.g. refGene.name2:TRIM2 or refGene_exon.name:NM_000947), or set options of several regions (\u0026amp;, |, -, and ^ for intersection, union, difference, and symmetric difference). Several regions will be printed if the name matches more than one regions. Chromosome positions are 1-based and are inclusive at both ends so the chromosome region has a length of end-start+1 bp. A reversed complementary sequence will be outputted if starting position is after the ending position. optional arguments: -h, --help show this help message and exit --build [BUILD] Output sequence at specified build of reference genome. The primary reference genome of the project will be used if by default. --numbered [{left,right}] If specified, add position of the first or last basepair of each line to the left or right of the line, and insert a space at every 10 basepair --char_per_line CHAR_PER_LINE Number of characters (excluding space and leading numbers) per line. Default to 70 in regular and 60 in numbered format. --transcribe [GENE [GENE ...]] Transcribe DNA sequence into RNA sequence. variant tools will look in the refGene database, find all genes that overlap with the region, locate exons and coding regions, transcribe the DNA sequence to RNA sequence (basically discard introns, and complement if on reverse strand). The complete mRNA sequence will be printed regardless of the bounaries of specified regions. If one or more names (refGene.name) are specified, only specified genes will be translated. --translate [GENE [GENE ...]] Translate DNA sequence into protein sequence. variant tools will look in the refGene database, find all genes that overlap with the region, locate exons and coding regions, transcribe and translate the DNA sequence to protein sequence. The complete protein sequence will be printed regardless of the boundaries of specified regions. If one or more names (refGene.name) are specified, only specified genes will be translated. --mark [MARK [MARK ...]] Mark a location (--mark chr pos), a variant (--mark chr pos ref alt), a region (e.g. refGene_exon.name:NM_000947), or a particular sequence (e.g. TCGGA) in red in the output. If a variant is specified, the changed nucleotide or amino acid will be printed. Currently only single nucleotide polymorphisms are supported. --mark_complement If set, also try to mark the complement of the specified sequence --mark_reverse If set, also try to mark the reverse sequence of the specified sequence. If both mark_complemnt and mark_reverse are set, four different sequences will be searched. --hide_unmatched If set, only display regions with marked variants or sequences -v {0,1,2,3}, --verbosity {0,1,2,3} Output error and warning (0), info (1), debug (2) and trace (3) information to standard output (default to 1).  Details Output DNA sequence at specified regions % vtools init test % vtools_report sequence chr6:123456-123743 --build hg19 \u0026gt;ref|hg19|chr6:123456-123743 TTCCTGGAGTATTTTTCCCCTGACAAATTACTTATCATCTATCATAATTCAGGTTAAATGGCACTAACTC AGGGAAGGCTTCCCTAACTGCCTCCCTTCTCCAACCAAATTAGGAACAATTATATGGCCACATAGTATCG AATCAAGTTTATAATTTTAAAATAATTGGGAGATTTTGTTGTTTAACACTTGTTTTCACTATAAGACTGT AATTACATGCAAGTAAGAACCATGCCTGTTTGTTCACTCCTGCCACAGTCAGAATAGTGCCTGGAATATG CAGTAAGG  Here we need to explicitly specify a reference genome because the project is empty and does not have a primary reference genome.\nYou can also output multiple sequences, or sequences in reverse order (on the - strand) if you specify a starting position that is larger than the ending position.\n% vtools_report sequence chr6:123456-123743 chr6:123743-123456 --build hg19 \u0026gt;ref|hg19|chr6:123456-123743 TTCCTGGAGTATTTTTCCCCTGACAAATTACTTATCATCTATCATAATTCAGGTTAAATGGCACTAACTC AGGGAAGGCTTCCCTAACTGCCTCCCTTCTCCAACCAAATTAGGAACAATTATATGGCCACATAGTATCG AATCAAGTTTATAATTTTAAAATAATTGGGAGATTTTGTTGTTTAACACTTGTTTTCACTATAAGACTGT AATTACATGCAAGTAAGAACCATGCCTGTTTGTTCACTCCTGCCACAGTCAGAATAGTGCCTGGAATATG CAGTAAGG \u0026gt;ref|hg19|chr6:123456-123743 (reversed) GGAATGACGTATAAGGTCCGTGATAAGACTGACACCGTCCTCACTTGTTTGTCCGTACCAAGAATGAACG TACATTAATGTCAGAATATCACTTTTGTTCACAATTTGTTGTTTTAGAGGGTTAATAAAATTTTAATATT TGAACTAAGCTATGATACACCGGTATATTAACAAGGATTAAACCAACCTCTTCCCTCCGTCAATCCCTTC GGAAGGGACTCAATCACGGTAAATTGGACTTAATACTATCTACTATTCATTAAACAGTCCCCTTTTTATG AGGTCCTT  A non-standard, but easier-to-read numbered format could be outputted using option --numbered:\n% vtools_report sequence chr6:123456-123743 chr6:123743-123456 --numbered --build hg19 \u0026gt;ref|hg19|chr6:123456-123743 123456 TTCCTGGAGT ATTTTTCCCC TGACAAATTA CTTATCATCT ATCATAATTC AGGTTAAATG 123516 GCACTAACTC AGGGAAGGCT TCCCTAACTG CCTCCCTTCT CCAACCAAAT TAGGAACAAT 123576 TATATGGCCA CATAGTATCG AATCAAGTTT ATAATTTTAA AATAATTGGG AGATTTTGTT 123636 GTTTAACACT TGTTTTCACT ATAAGACTGT AATTACATGC AAGTAAGAAC CATGCCTGTT 123696 TGTTCACTCC TGCCACAGTC AGAATAGTGC CTGGAATATG CAGTAAGG \u0026gt;ref|hg19|chr6:123456-123743 (reversed) 123743 GGAATGACGT ATAAGGTCCG TGATAAGACT GACACCGTCC TCACTTGTTT GTCCGTACCA 123683 AGAATGAACG TACATTAATG TCAGAATATC ACTTTTGTTC ACAATTTGTT GTTTTAGAGG 123623 GTTAATAAAA TTTTAATATT TGAACTAAGC TATGATACAC CGGTATATTA ACAAGGATTA 123563 AACCAACCTC TTCCCTCCGT CAATCCCTTC GGAAGGGACT CAATCACGGT AAATTGGACT 123503 TAATACTATC TACTATTCAT TAAACAGTCC CCTTTTTATG AGGTCCTT  The default value for parameter --numbered is left. You can also put the numbers to the right (referring to the 1-based position of the last base pair of each line) using option --numbered right,\n% vtools_report sequence chr6:123456-123743 chr6:123743-123456 --numbered right --build hg19 \u0026gt;ref|hg19|chr6:123456-123743 TTCCTGGAGT ATTTTTCCCC TGACAAATTA CTTATCATCT ATCATAATTC AGGTTAAATG 123515 GCACTAACTC AGGGAAGGCT TCCCTAACTG CCTCCCTTCT CCAACCAAAT TAGGAACAAT 123575 TATATGGCCA CATAGTATCG AATCAAGTTT ATAATTTTAA AATAATTGGG AGATTTTGTT 123635 GTTTAACACT TGTTTTCACT ATAAGACTGT AATTACATGC AAGTAAGAAC CATGCCTGTT 123695 TGTTCACTCC TGCCACAGTC AGAATAGTGC CTGGAATATG CAGTAAGG 123743 \u0026gt;ref|hg19|chr6:123456-123743 (reversed) GGAATGACGT ATAAGGTCCG TGATAAGACT GACACCGTCC TCACTTGTTT GTCCGTACCA 123684 AGAATGAACG TACATTAATG TCAGAATATC ACTTTTGTTC ACAATTTGTT GTTTTAGAGG 123624 GTTAATAAAA TTTTAATATT TGAACTAAGC TATGATACAC CGGTATATTA ACAAGGATTA 123564 AACCAACCTC TTCCCTCCGT CAATCCCTTC GGAAGGGACT CAATCACGGT AAATTGGACT 123504 TAATACTATC TACTATTCAT TAAACAGTCC CCTTTTTATG AGGTCCTT 123456  Specify regions by gene and other names The regions could also be specified using field_name:value of a linked annotation database. For example, if you have used annotation database refGene_exon in your project, you could list the sequence of all exons in a gene using command\n% vtools use refGene_exon % vtools_report sequence refGene_exon.name2:ABRA -v0 \u0026gt;ref|hg19|chr8:107773742-107771711 (refGene_exon.name2:ABRA 1) TACAAGAAAACATCTTTTATTCTTATGCTATTTGTCTTTAACATTTGGCGTAGGTTTCACTTGTAATAGA AGTGTGCATCTTACATGAAATCCTACTTAGAAATATTGGTCATTAACTTATAGCTTTATAAATACGGTAT GGAAACAAAATACGCATACTTTCTTAAGATACCAGAACCTTCAGTTTGAAAGAGACTCATACATGAAAAC AAATATAATTCTTATAGCAGTCTAATACCTATTATTTTGAGGTATCATATTTAGACATTAATTTTTACAT TTAACACCAAAGTGCTATACTATCAATGCATTTTAGTAATTTCATTGAATCCAGTAAGAATTGCAATCTC ACATTCCATTCCATTTGTTTTTAAGATCACATAGGCACATTAATGTCCAATGATTTTCTCCTTGCCATCA TCATTGTATATTTTTTACTTTGGCAGAACTAATATTGCAGTTTTATGACTTAAACATTTCATAAAGTTTT CTTTGTTACAGTATGAGGAACATTAAACTGTCTCAAATCTGTTTTTAATTCACCAATGATTCTATGGGAT TTTTCTAATACTGAACATTCCACTTCATAGATTTTCTGTATTTCTCCATTGTTGGAGAAATACATATCAT TGCATTGATGTTAATGCAAGCAGCTTGACTCGTTATATGCTGACATGTAATGAAACAATAAACTTCTCCA AGAAGTCCTACAAAGGCAAGTAAATCTGAATCTCTCACCTCTGCTCTACTTTTAGTGAGGGTGTGCCTTC CTTTGTTGGTACTAAGACAGGAAGTGTCTGTTTTTATGTGATTTGCTGAAATCAAACAAGAGGAAGGTGA ACTCTTACTGGAAACCTGTTAGAATCCAAGCCCACAGAGGAACTTCAACAATTTCAGCAACATCTTGACA ACTTTTTATATATGTGCTTGTTTTGTAAGTGATGCTATGATATAAACAATAATACAAAGTCAAGCTTCTG AAAAAATTTTAAGTTTAGTTTTACCAAACTTAATGGTATTTTCTTTTTTCCAAATAAAGACACATTATTA TATGTTCTACTGATATTTATCTCAAGTCAGCATTCTTCTTAGATGTAATGTTTAATTAAAAATCTATAGT AGTTTCTACAATGACTAGCTAAATATTTTGCCTAAAATATACAAGTGGCTGGGTGCTGTTGCTCATGCCT ATAATCCCAGCTACTTGGGAGGCTGAGGTGAGAGGATCACTTGAGGCCAGGAGTTAAAAGACCAGCTTTG GTGACATAAAGAGAATCTGTCTCAAAACAAAAACAAAAACACCCTGTGGAATTTCAACTATTAATACTAT TATTATACATTAACATTCTATGTGCTTTCTGAAATGCTTTGTGCCTTCTCAAAATCTCCAAAATTCCTCA TTCTAGATAGAAATAGAATGCCAGAAAGTCGTTTATGTAAAAATTGTTTAATATTTACTAACTTATTACA GAGAGTTTGCATTTTCATTTTACCTACATGAGCATTTAGCATTAAGACCATAGTGGGCCAAATTTGGCTT TTGTTTTTGAAGGTTCACTTGAGTAGCGTAATCACAACATGGTCATCTCGGCCTTGCCATAGCATCTCTC CTTCAAAGTCTACCAGTCCATGTTTCCTGGCACGCATGAGAATGCCCACTACTTTATCTGAAATACGAAC GTATCTGTCAAAGAGATCTCCAAAAGTAACCTGGATCTTGCCATCTCGTCTGTGGCGAGCCATTGTGCAG ATAATGAAGCACATGTCCATCATTTCCCTGTAGATGTGCTCCTCAGCACGCTTGGCCCTTTCAGCAGTTT TGGTTCCTTCTTTGGGGCGGCCATAGCCCTCATCTCCTTTGTGTAGGCGGGTGGACATGGCCAGCTCGTA ATCAAACTCTTCACTGAAAGGATTGAGCTTCTGGGATTGTATGTGTTCATCAGCCCACTGCTGCCATCTC CCTTTCAAGTTGCCCACTGGGCTATATTTCTGTTGGGCTTTGCAGTTGAGTTTCTCTGTAAATCTGTTTA CC \u0026gt;ref|hg19|chr8:107782472-107781751 (refGene_exon.name2:ABRA 2) TGGGAGGGCAAGGGGCGCTTGATCCTGACCACAGCCACCTGCACTCCATCCTGCTCGGGCCTCTCCTCAG CCTCTCCTCCATAGCCGCTGTCCTCTGTGTCTACGCTGTCACTCCTCCATGTGGGCTCCTCCTGCTCCAT CACTCTCCAGCCCTTGGTTAGCTCAGACACCAGGTTGGCACATTTTCTCCTCCGCGTTGGGGAGCCGTGG CTGTGGAGGATTCTGTCAATGTCATTCTCTGGCTGCCCAGGTTCAAGCACACCAGCATCCCTCTCGTACC TGTGGCTGAGGTGGCTCACGTCCCCTCCTCTCTCATAAGTCTTGCTGACCACCGTTTTGGACACCTCTTT CTTTTTGATGTGAGAAACCTCAGGGGCTTTCTCTGAGCTTTGTCCATCTCCATGTCCTTCTGGCAGGCGG GGTGGCGACTTTGGGGCACTCTGAGCTTTCTGGTGTGAAGTAGGGGGTGTGATTGGTTTAGGAGCTTGAG GTGAGTCCTGGGTCCCTCCCGGCAGCCAGCCTGTAGGCTCCTGGGCCTGCCTGATGCTGTTCTCATTCGC CCACTGCTGCCAACCTCGGGCCAAGCTGATGACCAGGGTGGCTGTGCGTATCTTCCGGAGGGCGCTCTTG GCTGGGCCCTCCCCGCTTTCCTTTTCGCCCGGAGCCATGCTGCCCACCTGTCTTTCTCTGCTGATAGCCT GGACACTGGCTAAAATGAGTGT  You can specify more complex regions using set options between regions (e.g. refGene.name2:ABRA \u0026amp; chr8:107782472-1077800). For example, the following command lists sequences of introns of gene BRCA1.\n% vtools use refGene % vtools use refGene_exon % vtools_report sequence 'refGene.name2:BRCA1-refGene_exon.name2:BRCA1' \u0026gt;ref|hg19|chr17:41197820-41199659 CTGGAGACAGAGAACACAAGCAGAGATTAGTGTCAATTCATTCTCCTGGACTAGGCTCTAATCAATCGAC TCCAGGGTCCTGGTTGTATGAGTTCTTAGGATTAATGAGGTAGAAGCTAATTTTTTTTTTTTTTTTTTGA GACGGAGTCTTGCTCTGTCGCCGAGGCTAGAGTGTGATGGCGCAATCTCGGCTCATTCAACCTCCGCCTC CTGGGTTCAAGCAATTCTCCTGTCTCTGCCTCCTGAGTAGCTGGAATTACAGGCACATGCCATCACACCC AGCTAATTTTTGTATTTTTAGTAGAGACGGGGGTTTCACAATGTTGGCCAGGCTGCTCTGGAACTCCTGA CCTCAGGTGATCCACCCACCTTGGCCTCCCAAAGTGCTGGGATTACAGGCGTGAGCCACTGCACCTGGCC TTTTTTTTTTTTTTTTTTTTTTTTTGAGACGGAGTCTTGCTCTTGTTGCTCAGCCTGGAATGCAATGGCA CGATCTCAGCTCACTGCAACCTCCACCTCCCGGGTTCAAGCAATTCTCCTGCCTCAGCCTCCCAAGTAGC AGGGATTACAGGTGCCTGCCACCATGCCAGGCTAATTGTTTTTTCTTTTTTTTCAGATGGAGTCTCACTC TGTCACTCAGGCTGGATTGTGATGGTGTGATCTCAGCTCACTGCAACCTCAACATCCTGGGTTCAAGCGA TTCTCCTGCCTCAGTCTCCCAAGTAGCTGGGACTACAAGTGCGTGCCACCATGCCTGGCTAATTTTTTTT AGTATTTTTAGTAGAGATGGGGTTTCGCCATATTGGCCAGGCTGGTCTCAAACTCCTGATGTCAGGTGAT CCGCCCTGAGGCTGAGGCAGGAGAATCATTTAAACCCAGGAGGCGGAGGTTGCAGTGAGCCAAGACTGGG CCACTGCACTCCAGCCTGCTAAGTGACAGAGTGAGACTCCACCTCAAAAAAAAAAAAAAAAGGCAATGCT TCAGGACATAAGGCCTTGCTCTGAAGAGGCCCTAGGAGTGACTCCTGGTGACAGTGAAAGCCCACAGCCT CTGGCAACTGTATTAACATGAACTTCAATCTGTTAAAGGAAAGCCACCAGGAAAACAGCACTGTAATTTA ACGATGTGGAAAAATGTATGTAATATCTTAAGGAAAAAAGCAAAACAGTGTAATTATGATCACATTTTAT AAAATACACGTGTATATATACGCACATATGCCTGGTGGAGTTTTATGGTGATCATCTCCAAGTGGTGGAA TTACTGGGATTATTTTATTGTTTTTGTGTAAATTTATACTTTCTTTTTTCTTTTTGAGACACGGTCTCGC TCTGTCGCCCAGGCTGGAGTACAGTGGTGTGATCGTGGCTCACTGAAGCATCAACCTCCTGAGCTCAAGT GATCCTCCCACCTCAGCTTCCCAAGTAGCTGCGACTACAGGCATCTGCCACCACACCCAGCTACTTTTTA AATTTGTTGTACAGATGAAGTCTCCTTATGTTGCCCAGGCTGGTCTCGAACTTCTAGGCTCCCACCTTGA CCTCCATCTTGACCTCCCAAAGTGCTGGAATTATAGGCATGAGCCACCATGCCCGGCCTTGATTTATGTT TTTGTGATGAACATTCATATCTTACTCCCACCCCATGGAAACAGTTCATGTATTACTTTTACAATATAAA ACAAATAACAATAAAAACATCAAAAAGACATTTTAGCCATTCATTCAACAAATATTTAAAATGTGCCAAG AACTGTGCTACTCAAGCACCAGGTAATGAGTGATAAACCAAACCCATGCAAAAGGACCCCATATAGCACA GGTACATGCAGGCACCTTAC \u0026gt;ref|hg19|chr17:41199721-41201137 CTGGATCCCCAGGAAGGAAAGAGCATTCAAAGTGTCAAAGTAGGACTACTGGAACTGTCACTTCATCATT TTTTTTGTTTGTTTTTGAGACAGGGTCTTGCTCTGTCACCCAGGCTGGAGTGCAGTGGTGTGATCTCAGC TCACTGCCACCTCTGCCTCCTGGGCTCAAGCAATCCTTCCATCTCAGCCTCCTAAGTAGCTGGAACTACA GACACGTACCACCACCCCTGGCTAATTTTTTTGTATTTTTGGTAGAGACAGGGTTTTGCCATGTTGCCCA GGCTGGTCTCAAACTCCTGGGCTCAACTTCACCCCCGGGATTATAGGCATGAGCCACCGCACCCAGCCTT GGCTAATTTTTAATAATTTTTTTGTAGACATGAGGTCCTACTGTATTGCCCAGGCTGGTCTTCAGCTCCC AGGCTCAAGCGATTCTCCCACCTTGGCCTCCCAGTGTTGTGATTACAGGGGTGGGGCACTGGCCCAGCCC ATCATTTCTCTCTCTCTCTTTTTTTTTGAGACGGAGTCTCGCTCTGTCGCCCGGGCTGGAGTGCAGTGGC GCGATCTTGGCTCACTGCAACCTCCGCCTCCGGGGTTCAAGCGATTCTCCTGCCCCAGCCCCTCAAGTAG CTGGGACTACAGGCGTGCGCCCCTACGCCCAGCTAATTTTTGTATTTTTAGTAGAGACGGGGTTTCGCCA TGTTGGTTGGCCAGGATGGTCTCGATCTCTTGACCTCGTGATCTGCCCACCTCAGCCTCCCAAAGTGCTG GGATTACAGGCGTGAGCCACCGCACCTAGCTTTTCTCTCTCTCTCTTTTTTTTTTTTTTTAGACAAAGTC TCACTCTGTCACCCAGTCTGGAGTGCAGTGGTGCAATCTTGGCTCACTGCAACCTCTGCCTCCCACGTTC AAGCGATGCTCACACCTCAACTTCCCAAATAGCTGGCATTACAGGCATGCTCCACCAGGCCTGGCTACTT TTTGTTTTTTTTTTTTTAGTACAGATGGGGTTTCACCATGTTGGCCAGGCTGGTCTCAAACTCCTGACAA GTGATCCACCTGCCTCGGCCTCCCAAAGTGCTGGGATTACAGACATGAGCCACCATGCCCAGCCTCCAGC CCATCATTTCTTGATGATTTGTTGAAACACAGTATGCTGGGGCAGTCACAGAGAGGAGGGGGAGGGACAT ATGGGAAAAAGAGTTAGAGGGAAAAAGTCTTCCCTCAGTATATTTAATATGTGCAGTTCTCAAATCCTTA CCCATCCCTTACAGATGGAGTCTTTTGGCACAGGTATGTGGGCAGAGAAGACTTCTGAGGCTACAGTAGG GGCATCCATAGGGACTGACAGGTGCCAGTCTTGCTCACAGGAGAGAATATTGTGTCCTCCCTCTCTGACA GGGCACCCAATACTTAC \u0026gt;ref|hg19|chr17:41201212-41203079 CTAAAATGGACATTTAGATGTAAAATCACTGCAGTAATCTGCATACTTAACCCAGGCCCTCTACCCTACA CTCTCCGGATGAAGGCTTATAGCAAGACCTCTCAATGGGAGAGTCTGTCTCTCTGCTCCAAAGGACAATG GTCTTAAAATAGTAGGGGTATGGATTTTAAGTCAATTTGCCACTGATATGCCATGTACTCTGGTTATCAG TCTCCATAAGGCCACTTGGTATAAGGTTTGATAGTCTCTCAAATAAAATGCTTGAAAGAAAAAAAAATCA AAGATCTAATTTCCATTAATTTGCTAAATTGCTGGCTAAGACACTGTGTGAAAAAACACCCACCTTCCTT ...  Here you can see that from the 5\u0026rsquo; to 3\u0026rsquo;, each intron starts with CT and ends with AC, which corresponds to the GU\u0026ndash;\u0026gt;AG signature of introns of RNA.\nOutput RNA sequences of genes overlap with the specified region The vtools_report sequence command can also be used to output mRNA sequences of genes that overlap with the specified regions. Because mRNA consists pieces of regions (coding sequences in exons) and only complete mRNA sequence could be translated, this option outputs complete RNA sequence of the genes (isoforms, as in field refGene.name). The coding regions will be listed after the sequence name.\nFor example, you can print output the RNA sequence of gene ABRA using command\n% vtools_report sequence refGene.name2:ABRA --transcribe --numbered \u0026gt;mRNA|NM_139166|chr8:107782418-107781751,107773742-107773265 (1146 bp on reverse strand) 1 ATGGCTCCGG GCGAAAAGGA AAGCGGGGAG GGCCCAGCCA AGAGCGCCCT CCGGAAGATA 61 CGCACAGCCA CCCTGGTCAT CAGCTTGGCC CGAGGTTGGC AGCAGTGGGC GAATGAGAAC 121 AGCATCAGGC AGGCCCAGGA GCCTACAGGC TGGCTGCCGG GAGGGACCCA GGACTCACCT 181 CAAGCTCCTA AACCAATCAC ACCCCCTACT TCACACCAGA AAGCTCAGAG TGCCCCAAAG 241 TCGCCACCCC GCCTGCCAGA AGGACATGGA GATGGACAAA GCTCAGAGAA AGCCCCTGAG 301 GTTTCTCACA TCAAAAAGAA AGAGGTGTCC AAAACGGTGG TCAGCAAGAC TTATGAGAGA 361 GGAGGGGACG TGAGCCACCT CAGCCACAGG TACGAGAGGG ATGCTGGTGT GCTTGAACCT 421 GGGCAGCCAG AGAATGACAT TGACAGAATC CTCCACAGCC ACGGCTCCCC AACGCGGAGG 481 AGAAAATGTG CCAACCTGGT GTCTGAGCTA ACCAAGGGCT GGAGAGTGAT GGAGCAGGAG 541 GAGCCCACAT GGAGGAGTGA CAGCGTAGAC ACAGAGGACA GCGGCTATGG AGGAGAGGCT 601 GAGGAGAGGC CCGAGCAGGA TGGAGTGCAG GTGGCTGTGG TCAGGATCAA GCGCCCCTTG 661 CCCTCCCAGG TAAACAGATT TACAGAGAAA CTCAACTGCA AAGCCCAACA GAAATATAGC 721 CCAGTGGGCA ACTTGAAAGG GAGATGGCAG CAGTGGGCTG ATGAACACAT ACAATCCCAG 781 AAGCTCAATC CTTTCAGTGA AGAGTTTGAT TACGAGCTGG CCATGTCCAC CCGCCTACAC 841 AAAGGAGATG AGGGCTATGG CCGCCCCAAA GAAGGAACCA AAACTGCTGA AAGGGCCAAG 901 CGTGCTGAGG AGCACATCTA CAGGGAAATG ATGGACATGT GCTTCATTAT CTGCACAATG 961 GCTCGCCACA GACGAGATGG CAAGATCCAG GTTACTTTTG GAGATCTCTT TGACAGATAC 1021 GTTCGTATTT CAGATAAAGT AGTGGGCATT CTCATGCGTG CCAGGAAACA TGGACTGGTA 1081 GACTTTGAAG GAGAGATGCT ATGGCAAGGC CGAGATGACC ATGTTGTGAT TACGCTACTC 1141 AAGTGA  Output protein sequences of genes overlap with the specified region The vtools_report sequence command can also be used to output protein sequences of genes that overlap with the specified regions. Because mRNA consists pieces of regions (coding sequences in exons) and only complete mRNA sequence could be translated, this option outputs complete protein sequence of the genes (isoforms, as in field refGene.name). The coding regions will be listed after the sequence name.\nFor example, you can print output the protein sequence of gene ABRA using command\n% vtools_report sequence refGene.name2:ABRA --translate --numbered \u0026gt;protein|NM_139166|chr8:107773265-107773742,107781751-107782418 (1146 bp) 1 MAPGEKESGE GPAKSALRKI RTATLVISLA RGWQQWANEN SIRQAQEPTG WLPGGTQDSP 61 QAPKPITPPT SHQKAQSAPK SPPRLPEGHG DGQSSEKAPE VSHIKKKEVS KTVVSKTYER 121 GGDVSHLSHR YERDAGVLEP GQPENDIDRI LHSHGSPTRR RKCANLVSEL TKGWRVMEQE 181 EPTWRSDSVD TEDSGYGGEA EERPEQDGVQ VAVVRIKRPL PSQVNRFTEK LNCKAQQKYS 241 PVGNLKGRWQ QWADEHIQSQ KLNPFSEEFD YELAMSTRLH KGDEGYGRPK EGTKTAERAK 301 RAEEHIYREM MDMCFIICTM ARHRRDGKIQ VTFGDLFDRY VRISDKVVGI LMRARKHGLV 361 DFEGEMLWQG RDDHVVITLL K*  A gene can have multiple isoforms. The --translate option will print out protein sequences of all isoforms, unless you list the isoforms of interest after parameter --translate. For example,\n% vtools_report sequence refGene.name2:BRCA1 --number --translate NM_007300 NM_007299 \u0026gt;protein|NM_007299|chr17:41276113-41276034,41267796-41267743,41258550-41258473,41256973-41256885,41256278-41256139,41251897-41251792,41249306-41249261,41247939-41247863,41246877-41246761,41243049-41242961,41234592-41234421,41228628-41228505,41226538-41226348,41223255-41222945,41219712-41219625,41215968-41215891,41215390-41215350,41209152-41209069,41203134-41203080,41199720-41199660,41197819-41197801 (2100 bp on reverse strand) 1 MDLSALRVEE VQNVINAMQK ILECPICLEL IKEPVSTKCD HIFCKFCMLK LLNQKKGPSQ 61 CPLCKNDITK RSLQESTRFS QLVEELLKII CAFQLDTGLE YANSYNFAKK ENNSPEHLKD 121 EVSIIQSMGY RNRAKRLLQS EPENPSLQET SLSVQLSNLG TVRTLRTKQR IQPQKTSVYI 181 ELGSDSSEDT VNKATYCSVG DQELLQITPQ GTRDEISLDS AKKAACEFSE TDVTNTEHHQ 241 PSNNDLNTTE KRAAERHPEK YQGEAASGCE SETSVSEDCS GLSSQSDILT TQQRDTMQHN 301 LIKLQQEMAE LEAVLEQHGS QPSNSYPSII SDSSALEDLR NPEQSTSEKV LTSQKSSEYP 361 ISQNPEGLSA DKFEVSADSS TSKNKEPGVE RSSPSKCPSL DDRWYMHSCS GSLQNRNYPS 421 QEELIKVVDV EEQQLEESGP HDLTETSYLP RQDLEGTPYL ESGISLFSDD PESDPSEDRA 481 PESARVGNIP SSTSALKVPQ LKVAESAQSP AAAHTTDTAG YNAMEESVSR EKPELTASTE 541 RVNKRMSMVV SGLTPEEFML VYKFARKHHI TLTNLITEET THVVMKTDAE FVCERTLKYF 601 LGIAGGKWVV SYFWVTQSIK ERKMLNEHDF EVRGDVVNGR NHQGPKRARE SQDRKIFRGL 661 EICCYGPFTN MPTGCPPNCG CAARCLDRGQ WLPCNWADV* \u0026gt;protein|NM_007300|chr17:41276113-41276034,41267796-41267743,41258550-41258473,41256973-41256885,41256278-41256139,41251897-41251792,41249306-41249261,41247939-41247863,41246877-41243452,41243049-41242961,41234592-41234421,41231416-41231351,41228628-41228505,41226538-41226348,41223255-41222945,41219712-41219625,41215968-41215891,41215390-41215350,41209152-41209069,41203134-41203080,41201211-41201138,41199720-41199660,41197819-41197695 (5655 bp on reverse strand) 1 MDLSALRVEE VQNVINAMQK ILECPICLEL IKEPVSTKCD HIFCKFCMLK LLNQKKGPSQ 61 CPLCKNDITK RSLQESTRFS QLVEELLKII CAFQLDTGLE YANSYNFAKK ENNSPEHLKD 121 EVSIIQSMGY RNRAKRLLQS EPENPSLQET SLSVQLSNLG TVRTLRTKQR IQPQKTSVYI 181 ELGSDSSEDT VNKATYCSVG DQELLQITPQ GTRDEISLDS AKKAACEFSE TDVTNTEHHQ 241 PSNNDLNTTE KRAAERHPEK YQGSSVSNLH VEPCGTNTHA SSLQHENSSL LLTKDRMNVE 301 KAEFCNKSKQ PGLARSQHNR WAGSKETCND RRTPSTEKKV DLNADPLCER KEWNKQKLPC 361 SENPRDTEDV PWITLNSSIQ KVNEWFSRSD ELLGSDDSHD GESESNAKVA DVLDVLNEVD 421 EYSGSSEKID LLASDPHEAL ICKSERVHSK SVESNIEDKI FGKTYRKKAS LPNLSHVTEN 481 LIIGAFVTEP QIIQERPLTN KLKRKRRPTS GLHPEDFIKK ADLAVQKTPE MINQGTNQTE 541 QNGQVMNITN SGHENKTKGD SIQNEKNPNP IESLEKESAF KTKAEPISSS ISNMELELNI 601 HNSKAPKKNR LRRKSSTRHI HALELVVSRN LSPPNCTELQ IDSCSSSEEI KKKKYNQMPV 661 RHSRNLQLME GKEPATGAKK SNKPNEQTSK RHDSDTFPEL KLTNAPGSFT KCSNTSELKE 721 FVNPSLPREE KEEKLETVKV SNNAEDPKDL MLSGERVLQT ERSVESSSIS LVPGTDYGTQ 781 ESISLLEVST LGKAKTEPNK CVSQCAAFEN PKGLIHGCSK DNRNDTEGFK YPLGHEVNHS 841 RETSIEMEES ELDAQYLQNT FKVSKRQSFA PFSNPGNAEE ECATFSAHSG SLKKQSPKVT 901 FECEQKEENQ GKNESNIKPV QTVNITAGFP VVGQKDKPVD NAKCSIKGGS RFCLSSQFRG 961 NETGLITPNK HGLLQNPYRI PPLFPIKSFV KTKCKKNLLE ENFEEHSMSP EREMGNENIP 1021 STVSTISRNN IRENVFKEAS SSNINEVGSS TNEVGSSINE IGSSDENIQA ELGRNRGPKL 1081 NAMLRLGVLQ PEVYKQSLPG SNCKHPEIKK QEYEEVVQTV NTDFSPYLIS DNLEQPMGSS 1141 HASQVCSETP DDLLDDGEIK EDTSFAENDI KESSAVFSKS VQKGELSRSP SPFTHTHLAQ 1201 GYRRGAKKLE SSEENLSSED EELPCFQHLL FGKVNNIPSQ STRHSTVATE CLSKNTEENL 1261 LSLKNSLNDC SNQVILAKAS QEHHLSEETK CSASLFSSQC SELEDLTANT NTQDPFLIGS 1321 SKQMRHQSES QGVGLSDKEL VSDDEERGTG LEENNQEEQS MDSNLGEAAS GCESETSVSE 1381 DCSGLSSQSD ILTTQQRDTM QHNLIKLQQE MAELEAVLEQ HGSQPSNSYP SIISDSSALE 1441 DLRNPEQSTS EKDSHIHGQR NNSMFSKRPR EHISVLTSQK SSEYPISQNP EGLSADKFEV 1501 SADSSTSKNK EPGVERSSPS KCPSLDDRWY MHSCSGSLQN RNYPSQEELI KVVDVEEQQL 1561 EESGPHDLTE TSYLPRQDLE GTPYLESGIS LFSDDPESDP SEDRAPESAR VGNIPSSTSA 1621 LKVPQLKVAE SAQSPAAAHT TDTAGYNAME ESVSREKPEL TASTERVNKR MSMVVSGLTP 1681 EEFMLVYKFA RKHHITLTNL ITEETTHVVM KTDAEFVCER TLKYFLGIAG GKWVVSYFWV 1741 TQSIKERKML NEHDFEVRGD VVNGRNHQGP KRARESQDRK IFRGLEICCY GPFTNMPTDQ 1801 LEWMVQLCGA SVVKELSSFT LGTGVHPIVV VQPDAWTEDN GFHAIGQMCE APVVTREWVL 1861 DSVALYQCQE LDTYLIPQIP HSHY*  Mark a location, regions, variant, or a sequence The output of command vtools_report sequence can be long and it could be difficult for you to locate a particular location or region that is of interest. If this is the case, you can use option --mark to mark them in the output.\nThe mark parameter accept three types of inputs\n A position such as chr12 12345 or 12 12345. A variant such as chr 12 12345 C T. In this case the alternative nucleotide or the translated amino acid will be marked and printed. The function does not yet support the translation of DNA sequences affected by indels so only SNVs are allowed in this option. One or more regions such as chr12:12345-12355 or refGene_exon.name2:WIF1.  For example, if you are interested in the location of a variant in the protein sequence,\nvtools_report sequence refGene.name2:WIF1 --build hg19 --translate --numbered --mark 12 65449852 \u0026gt;protein|NM_007191|chr12:65514971-65514824,65514336-65514197,65471634-65471526,65462684-65462544,65461570-65461475,65460516-65460421,65456356-65456261,65449906-65449811,65448993-65448898,65445250-65445129 (1140 bp on reverse strand) 1 MARRSAFPAA ALWLWSILLC LLALRAEAGP PQEESLYLWI DAHQARVLIG FEEDILIVSE 61 GKMAPFTHDF RKAQQRMPAI PVNIHSMNFT WQAAGQAEYF YEFLSLRSLD KGIMADPTVN 121 VPLLGTVPHK ASVVQVGFPC LGKQDGVAAF EVDVIVMNSE GNTILQTPQN AIFFKTCQQA 181 ECPGGCRNGG FCNERRICEC PDGFHGPHCE KALCTPRCMN GGLCVTPGFC ICPPGFYGVN  241 CDKANCSTTC FNGGTCFYPG KCICPPGLEG EQCEISKCPQ PCRNGGKCIG KSKCKCSKGY 301 QGDLCSKPVC EPGCGAHGTC HEPNKCQCQE GWHGRHCNKR YEASLIHALR PAGAQLRQHT\nIf you are interested in the change of amino acid, you can specify reference and alternative alleles,\nvtools_report sequence refGene.name2:WIF1 --build hg19 --translate --numbered --mark 12 65449852 C A \u0026gt;protein|NM_007191|chr12:65514971-65514824,65514336-65514197,65471634-65471526,65462684-65462544,65461570-65461475,65460516-65460421,65456356-65456261,65449906-65449811,65448993-65448898,65445250-65445129 (1140 bp on reverse strand) 1 MARRSAFPAA ALWLWSILLC LLALRAEAGP PQEESLYLWI DAHQARVLIG FEEDILIVSE 61 GKMAPFTHDF RKAQQRMPAI PVNIHSMNFT WQAAGQAEYF YEFLSLRSLD KGIMADPTVN 121 VPLLGTVPHK ASVVQVGFPC LGKQDGVAAF EVDVIVMNSE GNTILQTPQN AIFFKTCQQA 181 ECPGGCRNGG FCNERRICEC PDGFHGPHCE KALCTPRCMN GGLCVTPGFC ICPPGFYGVN  241 CDKANCSTTC FNGGTCFYPG KCICPPGLEG EQCEISKCPQ PCRNGGKCIG KSKFKCSKGY 301 QGDLCSKPVC EPGCGAHGTC HEPNKCQCQE GWHGRHCNKR YEASLIHALR PAGAQLRQHT\nIf you would like to mark the exon regions of this gene, you can do\nvtools_report sequence refGene.name2:WIF1 --build hg19 --numbered --mark refGene_exon.name2:WIF1  \u0026gt;ref|hg19|chr12:65444404-65515346 (refGene.name2 1)\n65444404 \u0026lt;span style='color: red;'\u0026gt;GCTCAGAAAA CTAAAGCAGC ACCTTTATTT TATACATACA AACAGTATAA AATGTTTATT\u0026lt;/span\u0026gt;\n65444464 \u0026lt;span style='color: red;'\u0026gt;AGGTAAGAGC TGTGTTTTGT TTACAATATA TTATATTGCT TCAAGCCAAT GCAAAAAGTT\u0026lt;/span\u0026gt;\n65444524 \u0026lt;span style='color: red;'\u0026gt;CATACATTAT ATTCCCTATT TCATTGTGTT TAGAATATAT TATATTGTTT AAATGCCACT\u0026lt;/span\u0026gt;\n65444584 \u0026lt;span style='color: red;'\u0026gt;ACCACAGTGT AATTTTTTTT TTTTTAATAC TGAATCTCTG GAATAATGGT AAGGTCAAAA\u0026lt;/span\u0026gt;\n65444644 \u0026lt;span style='color: red;'\u0026gt;TATATTGTAT TGAGAGTTTA AAAATTAAGA GCAATTTTTA AAAATGTAAC AAACATCTAA\u0026lt;/span\u0026gt;\n65444704 \u0026lt;span style='color: red;'\u0026gt;ATATCTGACA ATAAAATCTG AAATGCTGTA ACTTCAACAT TAACTGCACC ATCCAAATTC\u0026lt;/span\u0026gt;\n65444764 \u0026lt;span style='color: red;'\u0026gt;TTGTGACTTA CGCATTTTTG CCCAATTTAA CCTTTCTGAT GTTCCCCTGC CCCCAGACAC\u0026lt;/span\u0026gt;\n65444824 \u0026lt;span style='color: red;'\u0026gt;CATAAATGCA TTGTAATTTT GAAAATATCT GCCAACTACA CACTGAAAAT TTTAACCTGA\u0026lt;/span\u0026gt;\n65444884 \u0026lt;span style='color: red;'\u0026gt;TCAATTGACA TAATATAAAA TCTGTCCCAA AGCACTGAAA CAAGAAAATC TATACCATCA\u0026lt;/span\u0026gt;\n65444944 \u0026lt;span style='color: red;'\u0026gt;TGCTACAGAC GTACTTAGAA AACTTAAAAG GAAGAGTAAA TATCAGCTCA GTGATTTATA\u0026lt;/span\u0026gt;\n65445004 \u0026lt;span style='color: red;'\u0026gt;ATGAAGCTAA TAAAATTCAG GCCAGTATTC TTAAGTGTAA TGAACATTAT TTGAACATTC\u0026lt;/span\u0026gt;\n65445064 \u0026lt;span style='color: red;'\u0026gt;AACACATGAA AGGTTAACAA AGGCTATGAA CTTGGTGTAA CTTAAAACGT TTCAGATGTC\u0026lt;/span\u0026gt;\n65445124 \u0026lt;span style='color: red;'\u0026gt;GGAGTTCACC AGATGTAATT GGATTCAGGT GGATCCCGCC GCTCCTCGGC CTTTTTAAGT\u0026lt;/span\u0026gt;\n65445184 \u0026lt;span style='color: red;'\u0026gt;GAAGGCGTGT GCTGCCTGAG CTGGGCGCCT GCTGGCCTCA GGGCATGTAT GAGGCTGGCT\u0026lt;/span\u0026gt;\n65445244 \u0026lt;span style='color: red;'\u0026gt;TCG\u0026lt;/span\u0026gt;TACCCTG CAAAATTATT CACAGCTTAA AAGGAAAGAA ACTACAAAAC CAGGCTCTTC\n65445304 AGATTCATTA TTAACCATTC AAATGAAATC CATTTTTGCC TTTTCAATCC AGAATGAAAA\n....\n65514844 \u0026lt;span style='color: red;'\u0026gt;TGAGCATCGA TCCATAGGTA CAGGCTCTCC TCCTGCGGCG GCCCGGCCTC CGCCCGCAGT\u0026lt;/span\u0026gt;\n65514904 \u0026lt;span style='color: red;'\u0026gt;GCCAGCAGGC ACAGGAGGAT GCTCCAGAGC CAGAGCGCGG CGGCAGGGAA GGCGCTCCTC\u0026lt;/span\u0026gt;\n65514964 \u0026lt;span style='color: red;'\u0026gt;CGGGCCATGC TGCTCAGGAC CTCCTCGCTG CCGGGAAAAC TCCTCGTGCC GCACCTACGC\u0026lt;/span\u0026gt;\n65515024 \u0026lt;span style='color: red;'\u0026gt;AACCTGGCGC CGTCAGATAC TCTGCTGCGC TGCAGCTCCC TCAGCCAGGG CTGTTCCCGT\u0026lt;/span\u0026gt;\n65515084 \u0026lt;span style='color: red;'\u0026gt;TTAGACGGCT GGGCGCGTCG CCTCCCGGCC TGGGTGCCAA GGAGCCTGCG AGAGCAGGAG\u0026lt;/span\u0026gt;\n65515144 \u0026lt;span style='color: red;'\u0026gt;GAGGGGGCAG GCAGGACGCG GGAGGAGGAG GGGGGGACCA GCGGGCGCGA GTCGCGCAAG\u0026lt;/span\u0026gt;\n65515204 \u0026lt;span style='color: red;'\u0026gt;AAGATGGGGC GCGGGCGGGA GTGGGGGCGG CAGAGACGTA AGACTGGCAA AGCTGGCGAG\u0026lt;/span\u0026gt;\n65515264 \u0026lt;span style='color: red;'\u0026gt;GCCAGCAGTC AGCGGGGCAA ATAGAGCGAG AACAGAAGAG CGGGAAGGGC TGGCGCGAGC\u0026lt;/span\u0026gt;\n65515324 \u0026lt;span style='color: red;'\u0026gt;GAGGTGCGAG CGAGGAGTGG GGC\u0026lt;/span\u0026gt;\nFinally, if you are looking for a particular sub-sequence of the output, you can try to mark the sequence\n% vtools_report sequence refGene.name2:ABRA --transcribe --numbered --build hg19 --mark CTGCAC \u0026gt;mRNA|NM_139166|chr8:107782418-107781751,107773742-107773265 (1146 bp on reverse strand) 1 ATGGCTCCGG GCGAAAAGGA AAGCGGGGAG GGCCCAGCCA AGAGCGCCCT CCGGAAGATA 61 CGCACAGCCA CCCTGGTCAT CAGCTTGGCC CGAGGTTGGC AGCAGTGGGC GAATGAGAAC 121 AGCATCAGGC AGGCCCAGGA GCCTACAGGC TGGCTGCCGG GAGGGACCCA GGACTCACCT 181 CAAGCTCCTA AACCAATCAC ACCCCCTACT TCACACCAGA AAGCTCAGAG TGCCCCAAAG 241 TCGCCACCCC GCCTGCCAGA AGGACATGGA GATGGACAAA GCTCAGAGAA AGCCCCTGAG 301 GTTTCTCACA TCAAAAAGAA AGAGGTGTCC AAAACGGTGG TCAGCAAGAC TTATGAGAGA 361 GGAGGGGACG TGAGCCACCT CAGCCACAGG TACGAGAGGG ATGCTGGTGT GCTTGAACCT 421 GGGCAGCCAG AGAATGACAT TGACAGAATC CTCCACAGCC ACGGCTCCCC AACGCGGAGG 481 AGAAAATGTG CCAACCTGGT GTCTGAGCTA ACCAAGGGCT GGAGAGTGAT GGAGCAGGAG 541 GAGCCCACAT GGAGGAGTGA CAGCGTAGAC ACAGAGGACA GCGGCTATGG AGGAGAGGCT 601 GAGGAGAGGC CCGAGCAGGA TGGAGTGCAG GTGGCTGTGG TCAGGATCAA GCGCCCCTTG 661 CCCTCCCAGG TAAACAGATT TACAGAGAAA CTCAACTGCA AAGCCCAACA GAAATATAGC 721 CCAGTGGGCA ACTTGAAAGG GAGATGGCAG CAGTGGGCTG ATGAACACAT ACAATCCCAG 781 AAGCTCAATC CTTTCAGTGA AGAGTTTGAT TACGAGCTGG CCATGTCCAC CCGCCTACAC 841 AAAGGAGATG AGGGCTATGG CCGCCCCAAA GAAGGAACCA AAACTGCTGA AAGGGCCAAG  901 CGTGCTGAGG AGCACATCTA CAGGGAAATG ATGGACATGT GCTTCATTAT \u0026lt;span style='color: red;'\u0026gt;CTGCAC\u0026lt;/span\u0026gt;AATG\n961 GCTCGCCACA GACGAGATGG CAAGATCCAG GTTACTTTTG GAGATCTCTT TGACAGATAC 1021 GTTCGTATTT CAGATAAAGT AGTGGGCATT CTCATGCGTG CCAGGAAACA TGGACTGGTA 1081 GACTTTGAAG GAGAGATGCT ATGGCAAGGC CGAGATGACC ATGTTGTGAT TACGCTACTC 1141 AAGTGA  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/joint_conditional/variable-thresholds/",
	"title": "variable thresholds",
	"tags": [],
	"description": "",
	"content": " Varible Thresholds Methods for Disease and Quantitative Traits Introduction This implements the variable thresholds version of aggregation methods?. Similar to the VT? method, the VariableThresholdsBt and VariableThresholdsQt tests use a variable thresholds definition for the rare variants being considered such that multiple test statistics are calculated for an aggregation unit. The final statistic is taken as the one that gives the best result. Type I error is controlled due to the use of permutation testing.\nResults from variable thresholds methods have one additional column, i.e., an MAF column reporting the statistic of VT at which it is derived.\nDetails Command interface vtools show test VariableThresholdsBt Name: VariableThresholdsBt Description: Variable thresholds method for disease traits, in the spirit of Price et al 2010 usage: vtools associate --method VariableThresholdsBt [-h] [--name NAME] [-q1 MAFUPPER] [-q2 MAFLOWER] [--alternative TAILED] [-p N] [--permute_by XY] [--adaptive C] [--NA_adjust] [--moi {additive,dominant,recessive}] Variable thresholds in burden test for disease traits (in the spirit of Price et al 2010). The burden test statistic of a group of variants will be maximized over subsets of variants defined by applying different minor allele frequency thresholds. Significance of the statistic obtained is evaluated via permutation optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. -q1 MAFUPPER, --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 1.0 -q2 MAFLOWER, --maflower MAFLOWER Minor allele frequency lower limit. All variants having sample MAF\u0026gt;m2 will be included in analysis. Default set to 0.0 --alternative TAILED Alternative hypothesis is one-sided (\u0026quot;1\u0026quot;) or two-sided (\u0026quot;2\u0026quot;). Default set to 1 -p N, --permutations N Number of permutations --permute_by XY Permute phenotypes (\u0026quot;Y\u0026quot;) or genotypes (\u0026quot;X\u0026quot;). Default is \u0026quot;Y\u0026quot; --adaptive C Adaptive permutation using Edwin Wilson 95 percent confidence interval for binomial distribution. The program will compute a p-value every 1000 permutations and compare the lower bound of the 95 percent CI of p-value against \u0026quot;C\u0026quot;, and quit permutations with the p-value if it is larger than \u0026quot;C\u0026quot;. It is recommended to specify a \u0026quot;C\u0026quot; that is slightly larger than the significance level for the study. To disable the adaptive procedure, set C=1. Default is C=0.1 --NA_adjust This option, if evoked, will replace missing genotype values with a score relative to sample allele frequencies. The association test will be adjusted to incorporate the information. This is an effective approach to control for type I error due to differential degrees of missing genotypes among samples. --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive model. Default set to additive vtools show test VariableThresholdsQt Name: VariableThresholdsQt Description: Variable thresholds method for quantitative traits, in the spirit of Price et al 2010 usage: vtools associate --method VariableThresholdsQt [-h] [--name NAME] [-q1 MAFUPPER] [-q2 MAFLOWER] [--alternative TAILED] [-p N] [--permute_by XY] [--adaptive C] [--NA_adjust] [--moi {additive,dominant,recessive}] Variable thresholds in burden test for quantitative traits (in the spirit of Price et al 2010). The burden test statistic of a group of variants will be maximized over subsets of variants defined by applying different minor allele frequency thresholds. Significance of the statistic obtained is evaluated via permutation optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. -q1 MAFUPPER, --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 1.0 -q2 MAFLOWER, --maflower MAFLOWER Minor allele frequency lower limit. All variants having sample MAF\u0026gt;m2 will be included in analysis. Default set to 0.0 --alternative TAILED Alternative hypothesis is one-sided (\u0026quot;1\u0026quot;) or two-sided (\u0026quot;2\u0026quot;). Default set to 1 -p N, --permutations N Number of permutations --permute_by XY Permute phenotypes (\u0026quot;Y\u0026quot;) or genotypes (\u0026quot;X\u0026quot;). Default is \u0026quot;Y\u0026quot; --adaptive C Adaptive permutation using Edwin Wilson 95 percent confidence interval for binomial distribution. The program will compute a p-value every 1000 permutations and compare the lower bound of the 95 percent CI of p-value against \u0026quot;C\u0026quot;, and quit permutations with the p-value if it is larger than \u0026quot;C\u0026quot;. It is recommended to specify a \u0026quot;C\u0026quot; that is slightly larger than the significance level for the study. To disable the adaptive procedure, set C=1. Default is C=0.1 --NA_adjust This option, if evoked, will replace missing genotype values with a score relative to sample allele frequencies. The association test will be adjusted to incorporate the information. This is an effective approach to control for type I error due to differential degrees of missing genotypes among samples. --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive mode. Default set to additive  Application  Example using snapshot vt_ExomeAssociation\nvtools associate rare status --covariates age gender bmi exposure -m \u0026quot;VariableThresholdsBt \\ --name VariableThresholdsBt --alternative 2 -p 5000 --permute_by X --adaptive 0.05\u0026quot; --group\\ _by name2 --to_db variablethresholdsBt -j8 \u0026gt; variablethresholdsBt.txt vtools show fields | grep variablethresholdsBt.txt head variablethresholdsBt.txt vtools associate rare bmi --covariates age gender exposure -m \u0026quot;VariableThresholdsQt --name \\ VariableThresholdsQt --alternative 2 -p 5000 --permute_by X --adaptive 0.05\u0026quot; --group_by nam\\ e2 --to_db variablethresholdsQt -j8 \u0026gt; variablethresholdsQt.txt INFO: 3180 samples are found INFO: 2632 groups are found INFO: Starting 8 processes to load genotypes Loading genotypes: 100% [=========================================================================================================================================] 3,180 34.2/s in 00:01:33 Testing for association: 100% [================================================================================================================================] 2,632/147 2.8/s in 00:15:35 INFO: Association tests on 2632 groups have completed. 147 failed. INFO: Using annotation DB variablethresholdsQt in project test. INFO: Annotation database used to record results of association tests. Created on Thu, 31 Jan 2013 22:54:27 vtools show fields | grep variablethresholdsQt.txt variablethresholdsQt.name2 name2 variablethresholdsQt.sample_size_VariableThresholdsQt sample size variablethresholdsQt.num_variants_VariableThresholdsQt number of variants in each group (adjusted for specified MAF upper/lower bounds) variablethresholdsQt.total_mac_VariableThresholdsQt total minor allele counts in a group (adjusted for MOI) variablethresholdsQt.beta_x_VariableThresholdsQt test statistic. In the context of regression this is estimate of effect size for x variablethresholdsQt.pvalue_VariableThresholdsQt p-value variablethresholdsQt.std_error_VariableThresholdsQt Empirical estimate of the standard deviation of statistic under the null variablethresholdsQt.num_permutations_VariableThresholdsQt number of permutations at which p-value is evaluated variablethresholdsQt.MAF_threshold_VariableThresholdsQt The minor allele frequency at which the test statistic is maximized head variablethresholdsQt.txt name2 sample_size_VariableThresholdsQt num_variants_VariableThresholdsQt total_mac_VariableThresholdsQt beta_x_VariableThresholdsQt pvalue_VariableThresholdsQt std_error_VariableThresholdsQt num_permutations_VariableThresholdsQt MAF_threshold_VariableThresholdsQt ABCB10 3180 6 122 5.93777 0.247752 3.68504 1000 0.000157233 ABCD3 3180 3 42 -1.48612 0.301698 0.740477 1000 0.00267296 AADACL4 3180 5 138 -1.70538 0.151848 0.927952 1000 0.00157233 AAMP 3180 3 35 2.352 0.0666445 0.923285 3000 0.00220126 ABCB6 3180 7 151 1.98423 0.655345 3.83344 1000 0.000157233 ABI2 3180 1 25 0 0.993007 0 1000 0.00393082 ABHD1 3180 5 29 -1.81424 0.257742 1.19045 1000 0.000314465 ABCG8 3180 12 152 -3.48381 0.143856 1.26176 1000 0.000786164 ACAP3 3180 3 17 2.70541 0.281718 2.01218 1000 0.000314465  \n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/other_pipelines/annovar/",
	"title": "ANNOVAR",
	"tags": [],
	"description": "",
	"content": " Gene-based annotation through ANNOVAR Usage % vtools show pipeline ANNOVAR Pipeline to call ANNOVAR and import results as variant info fields. Available pipelines: geneanno Pipeline \u0026quot;geneanno\u0026quot;: This pipeline exports variants in specified variant table (parameter --var_table, default to variant), executes ANNOVAR's gene- based annotation (annotate_variantion.pl --geneanno), and imports specified fields from output of the command. Four fields (two for all variants and two for exonic variants) will be imported unless you disable some of them using parameters --variant_info and --exonic_info. No input or output file is required for this pipeline, but a snapshot could be specified, in which case the snapshot will be loaded (and overwrite the present project). geneanno_0: Load specified snapshot if a snapshot is specified. Otherwise use the existing project. geneanno_10: Check the existence of ANNOVAR's annotate_variation.pl command. geneanno_11: Determine the humandb path of ANNOVAR geneanno_14: Download gene database geneanno_20: Export variants in ANNOVAR format geneanno_30: Execute ANNOVAR annotate_variation.pl --geneanno geneanno_40: Importing results from ANNOVAR output .variant_function if --variant_info is specified geneanno_50: Importing results from ANNOVAR output .exonic_variant_function if --exonic_info is specified Pipeline parameters: var_table Variant table for the variants to be analyzed. (default: variant) annovar_path Path to a directory that contains annotate_variation.pl, if the script is not in the default $PATH. dbtype --dbtype parameter that will be passed to annotate_variation.pl --dbtype. The default value if refGene, but you can also use knownGene, ensGene. (default: refGene) variant_info Fields to import from the first two columns of .variant_function output of ANNOVAR. (default: region_type, region_name) exonic_info Fields to import from the .exonic_variant_function output of ANNOVAR. It has to be zero, one or more of mut_type and function. (default: mut_type, function)  Details This pipeline makes it easier to use (a small portion of) ANNOVAR\u0026rsquo;s gene-based annotation features to annotate variants, and update the variant tools project with the outputs. To use this pipeline, you should first download and install ANNOVAR somewhere, then execute a command similar to\n% vtools execute ANNOVAR geneanno --annovar_path ~/bin/annovar INFO: Executing step geneanno_0 of pipeline ANNOVAR: Load specified snapshot if a snapshot is specified. Otherwise use the existing project. INFO: Executing step geneanno_10 of pipeline ANNOVAR: Check the existence of ANNOVAR's annotate_variation.pl command. INFO: Command /Users/bpeng/bin/annovar/annotate_variation.pl is located. INFO: Executing step geneanno_11 of pipeline ANNOVAR: Determine the humandb path of ANNOVAR INFO: Running which /Users/bpeng/bin/annovar/annotate_variation.pl \u0026gt; cache/annovar.path INFO: Command \u0026quot;which /Users/bpeng/bin/annovar/annotate_variation.pl \u0026gt; cache/annovar.path\u0026quot; completed successfully in 00:00:01 INFO: Executing step geneanno_14 of pipeline ANNOVAR: Download gene database INFO: Running /Users/bpeng/bin/annovar/annotate_variation.pl --buildver hg19 -downdb refGene /Users/bpeng/bin/annovar/humandb INFO: Command \u0026quot;/Users/bpeng/bin/annovar/annotate_variation.pl --buildver hg19 -downdb refGene /Users/bpeng/bin/annovar/humandb\u0026quot; completed successfully in 00:00:23 INFO: Executing step geneanno_20 of pipeline ANNOVAR: Export variants in ANNOVAR format WARNING: Ignoring older existing output file cache/annovar_input. INFO: Running vtools export variant --format ANNOVAR --output cache/annovar_input INFO: Command \u0026quot;vtools export variant --format ANNOVAR --output cache/annovar_input\u0026quot; completed successfully in 00:00:01 INFO: Executing step geneanno_30 of pipeline ANNOVAR: Execute ANNOVAR annotate_variation.pl --geneanno INFO: Running /Users/bpeng/bin/annovar/annotate_variation.pl --geneanno --dbtype refGene --buildver hg19 cache/annovar_input /Users/bpeng/bin/annovar/humandb INFO: Command \u0026quot;/Users/bpeng/bin/annovar/annotate_variation.pl --geneanno --dbtype refGene --buildver hg19 cache/annovar_input /Users/bpeng/bin/annovar/humandb\u0026quot; completed successfully in 00:00:12 INFO: Executing step geneanno_40 of pipeline ANNOVAR: Importing results from ANNOVAR output .variant_function if --variant_info is specified INFO: Executing step geneanno_50 of pipeline ANNOVAR: Importing results from ANNOVAR output .exonic_variant_function if --exonic_info is specified INFO: Running vtools update variant --from_file cache/annovar_input.exonic_variant_function --format ANNOVAR_exonic_variant_function --var_info mut_type, function INFO: Using primary reference genome hg19 of the project. Getting existing variants: 100% [============================================] 1,611 175.7K/s in 00:00:00 INFO: Updating variants from cache/annovar_input.exonic_variant_function (1/1) annovar_input.exonic_variant_function: 100% [=====================================] 55 9.4K/s in 00:00:00 INFO: Fields mut_type, function of 55 variants are updated INFO: Command \u0026quot;vtools update variant --from_file cache/annovar_input.exonic_variant_function --format ANNOVAR_exonic_variant_function --var_info mut_type, function\u0026quot; completed successfully in 00:00:01  The options of this pipelines include\n annovar_path path to directory with annotate_variation.pl if the script is not in $PATH. var_table variant table whose variants will be exported and annotated. It is generally a bad idea to annotate millions of variants from a whole-genome sequencing project though. dbtype gene database to be used for the annotation, which can be refGene (default), knownGene, or ensGene. The pipeline will automatically download the required database for the analysis. variant_info: fields to be imported from the .variant_info output of ANNOVAR, which can be region_type and/or region_name. If you specify variant_info without value, no field will be imported from this file. The example above uses this trick to stop updating variant info from the .variant_info output. exonict_info: fields to be imported from the .exonic_variant_info output of ANNOVAR, which can be mut_type and/or function. If you specify exonic_info without value, no field will be imported from this file.  After the execution of the pipeline, two variant info fields are added to the project. Not all variants are updated because mut_type and function are only added forexonic variants.\n% vtools select variant 'mut_type is not NULL' --output chr pos ref alt mut_type function -l 10 1 900505 G C synonymous SNV KLHL17:NM_198317:exon12:c.G1863C:p.V621V, 1 1686040 G T nonsynonymous SNV NADK:NM_001198993:exon8:c.C786A:p.N262K,NADK:NM_023018:exon8:c.C786A:p.N262K,NADK:NM_001198995:exon6:c.C690A:p.N230K,NADK:NM_001198994:exon10:c.C1221A:p.N407K, 1 9034421 G A nonsynonymous SNV CA6:NM_001270500:exon8:c.G860A:p.G287E, 1 9030964 C T synonymous SNV CA6:NM_001270500:exon7:c.C768T:p.N256N,CA6:NM_001215:exon7:c.C768T:p.N256N,CA6:NM_001270502:exon5:c.C384T:p.N128N,CA6:NM_001270501:exon6:c.C588T:p.N196N, 1 16893752 T G unknown UNKNOWN 1 16913579 A G unknown UNKNOWN 1 16918486 C T unknown UNKNOWN 1 17085564 A G nonsynonymous SNV MST1L:NM_001271733:exon9:c.T1157C:p.L386P, 1 17083782 A C nonsynonymous SNV MST1L:NM_001271733:exon15:c.T2015G:p.F672C, 1 17087530 C T synonymous SNV MST1L:NM_001271733:exon2:c.G135A:p.A45A,  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/administration/",
	"title": "Administration",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/basic_data_statistics/",
	"title": "Basic data statistics",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/compare/",
	"title": "Compare",
	"tags": [],
	"description": "",
	"content": " Compare variants for the same samples called by complete genomics and illumina 1. Data Samples from two patients were sent to Complete Genomics and Illumina for whole-genome sequencing analysis. The variants are called by Complete Genomics using Complete Genomics Anslysis (CGA) package, and CASAVA 1.8 by Illumina. Before we do any further analysis, we are interested in knowing whether or not these two platforms yield comparable results.\nAs always, we need to find an empty directory and create a new project:\n% vtools init comparison  2. Loading data from two platforms 2.1 Loading data from Complete Genomics data For each sample, the variants are saved in a single file ASM/masterVarBeta-$ID-ASM.tsv.bz2, which can be imported directly using format CGA.\n% vtools import --format CGA /path/to/ASM/masterVarBeta-CG1-ASM.tsv.bz2 \\ -j2 --sample_name CG1 --build hg19 % vtools import --format CGA /path/to/ASM/masterVarBeta-CG2-ASM.tsv.bz2 \\ -j2 --sample_name CG2  2.2 Loading data from Illumina SNVs and INDELs are called separately and are saved by chromosomes. They can be imported using format CASAVA18_snp and CASAVA_indel.\n% vtools import --format CASAVA18_snp /path/to/S1/Variations/snps/chr*.txt \\ --sample_name Illumina1 % vtools import --format CASAVA18_snp /path/to/S2/Variations/snps/chr*.txt \\ --sample_name Illumina2 % vtools import --format CASAVA18_indel /path/to/S1/Variations/indels/chr*.txt \\ --sample_name Illumina1 % vtools import --format CASAVA18_indel /path/to/S2/Variations/indels/chr*.txt \\ --sample_name Illumina2  Although each genotypes from each sample consist of multiple samples (in variant tools term), they can be identified by their names.\nUse command vtools show samples to see samples and their phenotypes.\n 2.3 Separate variants into their own variant tables All samples are imported to the master variant table so we need to separate them into separate variant tables according their sample names. This can be done using commands\n% vtools select variant --samples 'sample_name=\u0026quot;CG1\u0026quot;' -t CG1 % vtools select variant --samples 'sample_name=\u0026quot;CG2\u0026quot;' -t CG2 % vtools select variant --samples 'sample_name=\u0026quot;Illumina1\u0026quot;' -t Illumina1 % vtools select variant --samples 'sample_name=\u0026quot;Illumina2\u0026quot;' -t Illumina2  We can use vtools_report variant_stat to calculate number of different types of variants in each table, or we can do that explicitly using commands\n% for table in CG1 CG2 Illumina1 Illumina2 % do vtools select $table 'alt!=\u0026quot;-\u0026quot;' 'ref!=\u0026quot;-\u0026quot;' 'length(alt)=1' 'length(ref)=1' -c vtools select $table 'ref=\u0026quot;-\u0026quot;' -c vtools select $table 'alt=\u0026quot;-\u0026quot;' -c vtools select $table 'alt!=\u0026quot;-\u0026quot;' 'ref!=\u0026quot;-\u0026quot;' 'length(alt) \u0026gt; 1 OR length(ref) \u0026gt; 1' -c % done  Of course, for the total number of variants in each table, you can simply call\n% vtools show tables  3. Compare variants To find common sets of variants, we can use command vtools compare to compare tables:\n% vtools compare CG1 CG2 -c % vtools compare Illumina1 Ilumina2 -c % vtools compare CG1 Illumina1 -c % vtools compare CG2 Illumina2 -c  The first two commands compare two samples called using the same platform, the latter two commands compare variants from the same sample, called by different platforms. If you would like to know the exact differences, you can run commands such as\n% vtools compare CG1 Illumina1 --difference CG_not_illumina % vtools compare Illumina1 CG1 --difference Illumina_not_CG  to get lists of variants differentially called by two platforms.\n4. Quality of variants Different quality scores are used for different platforms and variant types. The following command calculates the average quality scores per-sample, and adds six phenotypes to the sample table.\n% vtools phenotype --from_stat 'mean_Q_indel=avg(Q_indel)' 'mean_Q_snv=avg(Q_max_gt)' \\ 'mean_VAF1=avg(allele1VarScoreVAF)' 'mean_VAF2=avg(allele2VarScoreVAF)' \\ 'mean_EAF1=avg(allele1VarScoreEAF)' 'mean_EAF2=avg(allele2VarScoreEAF)'  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/functions/",
	"title": "Functions",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/single_gene/rbt-test/",
	"title": "RBT test",
	"tags": [],
	"description": "",
	"content": " Replication Based Test for Protective Variants Introduction This is implementation for the replication base test in Ionita-Laza et al 2011[^Iuliana Ionita-Laza, Joseph D. Buxbaum, Nan M. Laird and Christoph Lange (2011) A New Testing Strategy to Identify Rare Variants with Either Risk or Protective Effect on Disease. PLoS Genetics doi:10.1371/journal.pgen.1001289. http://dx.plos.org/10.1371/journal.pgen.1001289^]. The key of this method is replication, i.e., in the two-sided test of RBT it computes evidences to reject each of the two hypothesis\n Deleterious rare variants are enriched in cases Protective rare variants are enriched in controls  The final statistic is based on the stronger of the two evidences, adjusted for multiple testing. To increase the power of this approach a weighting theme is applied to variant counts in case or control group using a transformation of the probability of observing such counts under a Poisson model.\nImplementation of RBT in this program has both one-sided and two-sided versions via the --alternative parameter. The one-sided testing strategy tests for the presence of variants conferring risk to disease by focusing on variants that have higher observed frequency in cases compared with controls. Permutation procedure is used in both one-sided and two-sided tests to obtain valid {$p$} value.\nDetails Command interface vtools show test RBT Name: RBT Description: Replication Based Test for protective and deleterious variants, Ionita-Laza et al 2011 usage: vtools associate --method RBT [-h] [--name NAME] [-q1 MAFUPPER] [-q2 MAFLOWER] [--alternative TAILED] [-p N] [--adaptive C] [--moi {additive,dominant,recessive}] Replication Based Test for protective and deleterious variants, Ionita-Laza et al 2011. Variant sites are scored based on -log transformation of probability of having more than observed variants in cases/ctrls; the RBT statistic is defined as sum of the variant sites scores. One-sided RBT is implemented in addition to the two-sided statistic described in the RBT paper. p-value is estimated via permutation test. optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. -q1 MAFUPPER, --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 0.01 -q2 MAFLOWER, --maflower MAFLOWER Minor allele frequency lower limit. All variants having sample MAF\u0026gt;m2 will be included in analysis. Default set to 0.0 --alternative TAILED Alternative hypothesis is one-sided (\u0026quot;1\u0026quot;) or two-sided (\u0026quot;2\u0026quot;). Default set to 1 -p N, --permutations N Number of permutations --adaptive C Adaptive permutation using Edwin Wilson 95 percent confidence interval for binomial distribution. The program will compute a p-value every 1000 permutations and compare the lower bound of the 95 percent CI of p-value against \u0026quot;C\u0026quot;, and quit permutations with the p-value if it is larger than \u0026quot;C\u0026quot;. It is recommended to specify a \u0026quot;C\u0026quot; that is slightly larger than the significance level for the study. To disable the adaptive procedure, set C=1. Default is C=0.1 --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive model. Default set to additive  Application  Example using snapshot vt_ExomeAssociation\nvtools associate rare status -m \u0026quot;RBT --name RBT -p 5000\u0026quot; --group_by name2 --to_db rbt -j8 \u0026gt;\\ rbt.txt INFO: 3180 samples are found INFO: 2632 groups are found INFO: Starting 8 processes to load genotypes Loading genotypes: 100% [===========================] 3,180 34.0/s in 00:01:33 Testing for association: 100% [===================================] 2,632/591 14.3/s in 00:03:03 INFO: Association tests on 2632 groups have completed. 591 failed. INFO: Using annotation DB rbt in project test. INFO: Annotation database used to record results of association tests. Created on Wed, 30 Jan 2013 05:32:45 vtools show fields | grep RBT rbt.sample_size_RBT sample size rbt.num_variants_RBT number of variants in each group (adjusted for specified MAF rbt.total_mac_RBT total minor allele counts in a group (adjusted for MOI) rbt.statistic_RBT test statistic. rbt.pvalue_RBT p-value rbt.std_error_RBT Empirical estimate of the standard deviation of statistic rbt.num_permutations_RBT number of permutations at which p-value is evaluated head rbt.txt name2 sample_size_RBT num_variants_RBT total_mac_RBT statistic_RBT pvalue_RBT std_error_RBT num_permutations_RBT AADACL4 3180 5 138 1.37261 0.898102 2.99763 1000 ABCB6 3180 7 151 4.94419 0.665335 3.29949 1000 ABCG5 3180 6 87 5.1935 0.413586 2.98032 1000 ABCG8 3180 12 152 4.96566 0.769231 4.03695 1000 ABL2 3180 4 41 2.67589 0.456543 2.29237 1000 ACADL 3180 5 65 2.18841 0.696304 2.64459 1000 ACADM 3180 4 103 2.04935 0.678322 2.58183 1000 ACAP3 3180 3 17 2.32431 0.422577 1.95933 1000 ABCD3 3180 3 42 1.10394 0.797203 2.16152 1000  \n[^#^]\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/joint_conditional/skat-test/",
	"title": "SKAT test",
	"tags": [],
	"description": "",
	"content": " SNP-set (Sequence) Kernel Association Test Method Introduction Details Command interface vtools show test SKAT Name: SKAT Description: SKAT (Wu et al 2011) wrapper of its original R implementation usage: vtools associate --method SKAT [-h] [--name NAME] [-k {linear,linear.weighted,IBS,IBS.weighted,quadratic,2wayIX}] [--beta_param BETA_PARAM BETA_PARAM] [-m {davies,liu,liu.mod,optimal}] [-i {fixed,random}] [--logistic_weights PARAM PARAM] [-r [CORR [CORR ...]]] [--missing_cutoff MISSING_CUTOFF] [--resampling N] [--small_sample] [--resampling_kurtosis N] {quantitative,disease} SNP-set (Sequence) Kernel Association Test (Wu et al 2011). This is a wrapper for the R package \u0026quot;SKAT\u0026quot; implemented \u0026amp; maintained by Dr. Seunggeun Lee, with a similar interface and minimal descriptions based on the SKAT package documentation (May 11, 2012). Please refer to http://http://cran.r-project.org/web/packages/SKAT/ for details of usage. To use this test you should have R installed with SKAT v0.75 or higher. The SKAT commands applied to the data will be recorded and saved in the project log file. positional arguments: {quantitative,disease} Phenotype is quantitative trait or disease trait (0/1 coding). Default set to \u0026quot;quantitative\u0026quot; optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. -k {linear,linear.weighted,IBS,IBS.weighted,quadratic,2wayIX}, --kernel {linear,linear.weighted,IBS,IBS.weighted,quadratic,2wayIX} A type of kernel. Default set to \u0026quot;linear.weighted\u0026quot;. Please refer to SKAT documentation for details. --beta_param BETA_PARAM BETA_PARAM Parameters for beta weights. It is only used with weighted kernels. Default set to (1,25). Please refer to SKAT documentation for details. -m {davies,liu,liu.mod,optimal}, --method {davies,liu,liu.mod,optimal} A method to compute the p-value. Default set to \u0026quot;davies\u0026quot;. Please refer to SKAT documentation for details. -i {fixed,random}, --impute {fixed,random} A method to impute missing genotypes. Default set to \u0026quot;fixed\u0026quot;. Please refer to SKAT documentation for details. --logistic_weights PARAM PARAM This option, if specified, will get the logistic weights from genotype matrix Z and apply this weight to SKAT. It requires two input parameters par1 and par2. To use the SKAT default setting, type `--logistic_weights 0.07 150'. Please refer to SKAT documentation for details. -r [CORR [CORR ...]], --corr [CORR [CORR ...]] The pho parameter of SKAT test. Default is 0. Please refer to SKAT documentation for details. --missing_cutoff MISSING_CUTOFF a cutoff of the missing rates of SNPs. Any SNPs with missing rates higher than cutoff will be excluded from the analysis. Default set to 0.15 --resampling N Number of resampling using bootstrap method. Set it to '0' if you do not want to apply resampling. --small_sample This option, if evoked, will apply small sample adjustment \u0026quot;SKAT_Null_Model_MomentAdjust\u0026quot; for small sample size and binary trait. Please refer to SKAT documentation for details. --resampling_kurtosis N Number of resampling to estimate kurtosis, for small sample size adjustment. Set it to '0' if you do not wnat to apply the adjustment. The SKAT default setting is 10000. Please refer to SKAT documentation for details.  Application  Example using snapshot vt_ExomeAssociation\nvtools associate rare status -m \u0026quot;SKAT --name skat quantitative\u0026quot; --group_by refGene.name2 --\\ to_db skat -j8 \u0026gt; skat.txt INFO: 3180 samples are found INFO: 2632 groups are found INFO: Starting 8 processes to load genotypes Loading genotypes: 100% [=========================================================================================================================================] 3,180 32.8/s in 00:01:36 Testing for association: 100% [================================================================================================================================] 2,632/147 8.9/s in 00:04:56 INFO: Association tests on 2632 groups have completed. 147 failed. INFO: Using annotation DB skat in project test. INFO: Annotation database used to record results of association tests. Created on Wed, 30 Jan 2013 21:34:23 vtools show fields | grep skat skat.refGene_name2 refGene_name2 skat.sample_size_skat Sample size skat.Q_stats_skat Test statistic for SKAT, \u0026quot;Q\u0026quot; skat.pvalue_skat p-value head skat.txt refGene_name2 sample_size_skat Q_stats_skat pvalue_skat AADACL4 3180 33707.7 0.379148 ABCD3 3180 1178.25 0.961708 AAMP 3180 5905.71 0.612598 ABCB10 3180 55121.9 0.109206 ABCB6 3180 16500.2 0.812062 ABCG5 3180 9829.17 0.76832 ABI2 3180 42491.9 0.0100467 ABHD1 3180 1315.49 0.880286 ABL2 3180 794.385 0.963097  (:exampleend\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/variants/",
	"title": "Variants",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/format/formats/new/",
	"title": "cumtomized",
	"tags": [],
	"description": "",
	"content": " Specification of external file formats Roles of format specification in variant tools: Variant tools can import and export text files (or gzipped text files) in delimiter-separated format, namely records that are separated into columns by delimiters such as tab, space or comma. The file format must be variant-oriented (storing one or more variants by line), with the exception of sample-based PLINK format which is preprocessed internally into variant-oriented form for import. We use terms\n column for columns (text) in a delimiter-separated file, and field for fields (with types) in tables in a database, with  variant fields for fields that define variants (chr, pos, ref, alt), variant info for fields that annotate variants (e.g. membership to dbSNP), genotype fields for fields to store genotypes of samples, and genotype info for fields that annotate genotypes (e.g. quality score of each genotype)   A format specification defines how to extract fields from columns and how to write columns from fields, to\n Insert new variants to the project using command vtools import. The text file should provide at least four fields for chromosome, position, reference and alternative alleles. In addition to variant and variant info, an input file can contain genotype and genotype info for one or more samples.  The four fields could, but not necessarily have to, be in four columns because a field could be synthesized from multiple columns, even not from any existing column. For example, if all variants are from dbSNP, ref and alt fields could be looked up from a dbSNP annotation database.\n Update existing variants with additional info using command vtools update. The text files can have\n full variant information (chr, pos, ref and alt) to update matching variants and related genotypes and their info, or\n chromosomal positions (chr and pos) to update all variants at specified locations, or\n range (chr, start, end) to update variants in specified regions\n  Export samples and their variants using command vtools export. The file format should be organized by variant (not by sample). Although each line of the output file usually present a variant (chr, pos, ref, alt), it can contain multiple variants at a locus (chr, pos, ref, mutliple alternative alleles), or only locus-specific information (chr, pos).\n  The format specification file (.fmt file) A .fmt file describes the format of an external file so that it can be handled by variant tools. An format specification file follows an extended .ini format with section and key/value pairs. Details of this format can be found at this link because it is parsed by a Python ConfigParser object. This file should have at least a [format description] section and a few field sections. A format specification could be used to import and export files but you can ignore import or export specifications if you are only interested in exporting or importing.\nSection [format description] This section should have keys\n description: a description of the format, with preferably a URL to the documentation of the format.\n encoding (optional): encoding of the input file. If you see errors such as \u0026quot;codec can't decode byte 0xe7 in position 21480\u0026quot;, you should perhaps add encoding=ISO-8859-1 to your .fmt file.\n delimiter (optional): delimiter to define columns in the input file. Default to tab (delimiter='\\t'). If your input can be either tab or space delimited, use delimiter=None if your input does not have any missing field because '\\t\\t' or ' ' will be treated as a single delimiter. Quotations around other delimiters can be ignored (e.g. , instead of ',').\n header (optional): variant tools by default treats lines with a leading # as header and skip them during data importing. The header will also be used to probe sample names for some formats (e.g. .vcf). If your input file does not use such a header, you can override this behavior by specifying the number of lines to skip (header=1), or a pattern by which headers are matched (e.g. use header=^%.* for header lines starting with %, see documents of the Python re package for details).\n preprocessor (optional): a functor to pre-process input data into some intermediate format that can be readily imported by variant tools (e.g., PlinkConverter())\n export_by (optional, for export only): How variants at the same locus are exported. By default, variant tools exports one line for each variant. If fields specified by export_by (e.g. chr, pos) cannot uniquely identify variants so multiple variants will be outputted in one line, values at extra records will be ignored, or be collapsed to the first record if supported by column specification.\n sort_output_by (optional, for export only): How variants are ordered. This option is ignored if export_by is defined.\n  THIS OPTION IS CURRENTLY NOT USED\n merge_by (optional, for import only): If genotype at different homozygous copies (ploidy) is recorded in separate lines, this option has to be used to specify the columns to uniquely identify a variant. These columns will be passed to the processor without modification, values at all other columns are merged (separated by \u0026lsquo;,\u0026rsquo;).\n One of\n variant: fields for chr, pos, ref, and alt. Such input files have complete variant information and can be used to add new variants or add or update info of existing variants.\n position: fields for chr and pos for chromosomal positions.\n range: fields for chr, start and end positions of regions.\n   input files of the latter two types can only be used to update matching variants with additional variant_info.\n variant_info (optional): Additional fields that will be inserted to specified variant table.\n genotype (optional): name of a field that will be imported into the sample variant table. Using a slice-index syntax, this field can process genotypes for multiple samples (e.g. index=8: will produce genotypes from columns 8, 9, \u0026hellip;). The return value of this field must be value 1 for heterozygote, 2 for homozygote, and -1 for double heterozygote (alt1, alt2).\n genotype_info (optional): Fields such as quality score that will be appended to genotype of each sample. They should either generate a single value for all samples (regular index), or a different value for each sample (slice-index).\n  General speaking, genotype info fields are sample specific so different samples can have different values for the same variant. Variant info fields are supposed to be properties of variants and are shared by all (or part of the) samples. It is up to the user (and file format) to decide how to handle particular fields from input files.\nSection [DEFAULT] (define parameters of a format) The default section defines values that exist, conceptually, in all sections. It is used to define parameters used for import or export. These parameters could be overriden using corresponding command line option. For example, in the following .fmt file (partial)\n[format description] description=Output from ANNOVAR, generated from command \u0026quot;path/to/annovar/annotate_variation.pl annovar.txt path/to/annovar/humandb/\u0026quot;. This format imports chr, pos, ref, alt and ANNOVAR annotations. For details please refer to http://www.openbioinformatics.org/annovar/annovar_gene.html variant=chr, pos, ref, alt variant_info=%(var_info)s [DEFAULT] var_info=mut_type var_info_comment=Fields to be outputted, can be one or both of mut_type and function  The key var_info has a help message defined by parameter var_info_comment, and a default value mut_type. If you query the details of this format using command\n% vtools show format ANNOVAR_output  you will see at the end of the output the following description:\nOther fields (usable through parameters): function the gene name, the transcript identifier and the sequence change in the corresponding transcript Format parameters: var_info Fields to be outputted, can be one or both of mut_type and function. (default: mut_type)  This means you can pass an alternative value of var_info to this format using parameters such as --var_info function to change the variant information field to be imported or updated. For example, you can use command\n% vtools update variant input_file --format ANNOVAR_output --var_info mut_type function  to update two fields mut_type and function instead of the default one (mut_type).\nName of a variable cannot be any keyword (e.g. field, comment, adj, type) or start with fmt_.\nField sections (import: how to extract fields from input file) Import fields sections describe the fields that can be imported if they appear in one of variant, position, range, variant_info, genotype and genotype_info. Because the value of these fields could be overridden using corresponding parameters of command vtools import, a .fmt file might define additional or alternative fields to provide alternative ways to import data in this format.\nEach field section can have the following keys:\n index: index(es) of field, which can be\n A 1-based index of the column in the input file. The value at this column will be used for this field.\n A tuple syntax with multiple indexes separated by ',', for example 5,7. A list of values at specified columns will be passed to an adjust function to produce values of the field.\n A \u0026lsquo;slice\u0026rsquo; syntax to specify multiple fields. This syntax will only be used for genotype and genotype information fields. For example, index=8: will produce multiple fields from columns 8, 9, ... till end of the columns. Other examples include index=8::2 for 8, 10, 12, ..., index=5,8: for (5,8), (5,9), \u0026hellip;, and index=8::2,9::2 for (8,9), (10,11), etc\n  type: can be any SQL allowed types such as \u0026ldquo;INTEGER\u0026rdquo;, \u0026ldquo;FLOAT\u0026rdquo;, \u0026ldquo;INTEGER NOT NULL\u0026rdquo;, or \u0026ldquo;DECIMAL(7,6) NOT NULL\u0026rdquo;\n comment (optional) a description of the field\n adj (optional): Functions or functors to extract or modify one or more values from the field value. variant tools provides a number of functors to help the processing of different fields. For example,\n IncreaseBy(inc=1) (increase value by inc). This is usually used to adjust 0-based position to 1-based position that is used by variant tools.\n MapValue(map) (map value to another). This function is used to map input value to another one, for example, MapValue({'het': '1', 'hom': '2'}) maps value \u0026lsquo;het\u0026rsquo; to \u0026lsquo;1\u0026rsquo; and \u0026lsquo;hom\u0026rsquo; to \u0026lsquo;2\u0026rsquo;. Note that the mapped values should be strings or None.\n Nullify(val) (treat value as NULL). This is usually used to adjust input NA values to NULL in the database.\n RemoveLeading(val) (remove leading characters). This is usually used to remove leading chr from inputs with chromosomes such as chr1, chr2, because variant tools only stores 1, 2, etc.\n ExtractField(index, sep=';', default=None) (field of a column): Split the item by sep and return the index-th field (1-based). Return default if there are less than index fields. For example, ExtractField(2, ':') extracts 20 from 10:20:30.\n  Multiple functors/functions can be used sequentially. For example, ExtractValue('CEU:'), ExtractField(1, '/') extracts value 12 from YRI:20/222;CEU:12/45 (the first extractor gets 12/45, the second extractor gets 12), and ExtractValue('CEU:'), SplitField('/') extracts values 12 and 45 from YRI:20/222;CEU:12/45.\n If none of the provided extractors can be used, you can define your own function. For example, lambda x: x[6:].replace(\u0026quot;,\u0026quot;, \u0026quot;\u0026quot;) extracts 24000 from COUNT=24,000. You can also mix function with variant tools provided extractor ExtractValue(\u0026quot;COUNT=\u0026quot;), lambda x: x.replace(\u0026quot;,\u0026quot;, \u0026quot;\u0026quot;)]) to extract 24000 from values such as ASD;COUNT=24,000;MAF=0.5.\n If the return value of at least one of the fields is a tuple of more than one values (e.g. result from functor SplitField), multiple records will be generated from this line. Non-tuple values of other fields will be copied automatically. For example, if three fields have values A1, (B1,), (C1, C2), they will produce two records of A1, B1, C1 and A1, None, C2.\n If you would like to exclude certain records, you can use adj to produce invalid records that will be excluded during importing. For example, a record with None alternative allele, or a field with NOT NULL type will be ignored, or a genotype with None mutation type will be ignored.\n  Section [Field formatter] (export: how to format fields for output) This section specifies how to format fields when they are outputted to a file. Fields that are not listed in this section will be converted to string directly, unless a special wildcast formatter fmt_* is specified. This section should look like\n[Field formatter] fmt_chr=Prepend('chr') fmt_freq=Formatter('{.3f}') fmt_id=ValueOfNull('.') fmt_other=lambda x: something  The name of the formatter should be field name prepended by fmt_. Formatter for each field should be a functor or a function. Their return value must be a string. More interestingly, multiple fields could be formatted altogether so it is possible to specify\nfmt_PL1,fmt_PL2,fmt_PL3=lambda x: x[0] + x[1] + x[2]  to create a single string from multiple fields.\nColumn sections (export: how to organize fields into columns of output file) Export reverses the import process. Instead of extracting fields from one or more columns, it generates columns from one or more fields. Column sections have title col_# where # is the index of column. They are specified in a similar way to fields. File formats without column specification cannot be used to export variants and samples.\nEach column section can have the following keys:\n field: name of field or fields that will be used to create a column. The fields are usually defined in this .fmt file. If a field specifies genotype or genotype information of more than one sample using a slice syntax, multiple columns will be generated. If multiple records are collapsed into a single record(c.f. export_by), a tuple of values will be passed to the adj function/functor if it is defined. Otherwise, only the first record will be exported.\n adj: function or functor that accepts values at one or more fields and produce a single value at this column.\n comment (optional) a description of the column\n  The basic steps of outputting a file is to collect values of all fields, apply formatters to each field (or groups of fields) if available, and collect results to columns. Note that\n Although fields of columns are usually the ones that are defined in a .fmt file, arbitrary fields could be outputted if fields of a column are configurable through parameters.\n A column is considered as a genotype column if it contains field GT. Multiple columns will be exported if genotypes of multiple samples are outputted.\n A field can generate multiple columns by using a formatter that returns, for example, \u0026lsquo;1,2\u0026rsquo; for a comma-separated format.\n  Import and test After a file is created, you can use command\nvtools import --format /path/to/fmt_file input_file --build specified_build  to import your file, and use command\nvtools show table variant -l -1  to check if variants are correctly imported. If you believe that your format is commonly used, please send the .fmt file to our mailinglist. We will post the file to the repository so that others can make use of it.\nExamples You can learn from the system format files on how to define a format:\n A basic example of a format with variant fields: ANNOVAR format. An example of using lambda functions to extract information from multiple columns: snps.txt created by CASAVA 1.8.  You can have a look at system format files using\nvtools show formats vtools show format SOME_FORMAT more cache/SOME_FORMAT.fmt  The first command gets a list of supported formats. The second command gets details of a specific format, and the third command lets you view the format file because all used formats are stored in a temporary directory named cache under your project folder.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/variants/databaseof/",
	"title": "database",
	"tags": [],
	"description": "",
	"content": " s\nDatabase of Genomic Variants Database of genomic variants is a curated catalogue of human genomic structural variation. It is a range-based database that shows the range of such variants.\n% vtools show annotation DGV -v2 Annotation database DGV (version hg19_20130723) Description: Database of Genomic Variants, a curated catalogue of human genomic structural variation. Database type: range Number of records: 202,430 Distinct ranges: 199,827 Reference genome hg19: chr, start, end Field: variantaccession Type: string Missing entries: 0 Unique Entries: 202,430 Field: chr Type: string Missing entries: 0 Unique Entries: 24 Field: start Type: integer Missing entries: 0 Unique Entries: 189,925 Range: 1 - 249205967 Field: end Type: integer Missing entries: 0 Unique Entries: 189,604 Range: 16629 - 249206446 Field: varianttype Type: string Missing entries: 0 Unique Entries: 2 Field: variantsubtype Type: string Missing entries: 0 Unique Entries: 9 Field: reference Type: string Missing entries: 0 Unique Entries: 55 Field: pubmedid Type: integer Missing entries: 0 Unique Entries: 55 Range: 12058347 - 23290073 Field: method Type: string Missing entries: 0 Unique Entries: 31 Field: platform Type: string Missing entries: 0 Unique Entries: 49 Field: mergedvariants Type: string Missing entries: 0 Unique Entries: 1 Field: supportingvariants Type: string Missing entries: 0 Unique Entries: 198,642 Field: mergedorsample Type: string Missing entries: 0 Unique Entries: 2 Field: frequency Type: string Missing entries: 0 Unique Entries: 65 Field: samplesize Type: integer Missing entries: 0 Unique Entries: 37 Range: 0 - 6533 Field: observedgains Type: integer Missing entries: 0 Unique Entries: 188 Range: 0 - Field: observedlosses Type: integer Missing entries: 0 Unique Entries: 825 Range: 0 - Field: cohortdescription Type: string Missing entries: 0 Unique Entries: 6 Field: genes Type: string Missing entries: 0 Unique Entries: 25,687 Field: samples Type: string Missing entries: 0 Unique Entries: 67,200  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_commands/liftover/",
	"title": "lifttover",
	"tags": [],
	"description": "",
	"content": " Adding coordinates from an alternative reference genome 1. Usage % vtools liftover -h usage: vtools liftover [-h] [--flip] [-v STD[LOG]] build Convert coordinates of existing variants to alternative coordinates in an alternative reference genome. The UCSC liftover tool will be automatically downloaded if it is not available. positional arguments: build Name of the alternative reference genome optional arguments: -h, --help show this help message and exit --flip Flip primary and alternative reference genomes so that the specified build will become the primary reference genome of the project. -v STD[LOG], --verbosity STD[LOG] Output error and warning (0), info (1) and debug (2) information to standard output (default to 1), and to a logfile (default to 2).  2. Details Vtools provides a command which is based on the tool of USCS liftOver to map the variants from existing reference genome to an alternative build. After executing of this command, The fields of chromosome, position reference and alternative of the variant in current and previous reference genomes are all in the master variant table.\nAn illustration of the liftover process\n An illustration of the liftover process  -- \n This command adds alt_chr and alt_pos columns to the master variants table. Annotation databases that use the alternative reference genome can now be used. vtools output and vtools export can output alternative coordinates using parameter --build.   This feature is unavailable under windows because UCSC liftOver tool does not support windows. Because the UCSC liftover tools does not guarantee complete translation, variants that failed to map will have missing alternative coordinates.   Liftover from hg19 to hg38 The following example demonstrates how to liftOver a project from hg18 to hg19. Note that the UCSC liftOver tool and needed chain files are automatically downloaded if they are not available.\n% vtools init -f liftover % vtools import V1-3_hg19_combine.vcf --build hg19 % vtools liftover hg38 INFO: Downloading liftOver chain file from UCSC INFO: Exporting variants in BED format Exporting variants: 100% [===============================] 288 110.5K/s in 00:00:00 INFO: Running UCSC liftOver tool Updating table variant: 100% [============================] 288 780.0/s in 00:00:00  After the liftOver operation, three more fields are added to the master variant table (alt_bin, alt_chr, alt_pos)\n% vtools show table variant Name: variant Description: Master variant table Creation date: May29 Command: Fields: variant_id, bin, chr, pos, ref, alt, alt_bin, alt_chr, alt_pos Number of variants: 1611 variant_id, bin, chr, pos, ref, alt, DP, alt_bin, alt_chr, alt_pos 52,586,1,230047,A,T,586,1,260296 53,586,1,230058,T,G,586,1,260307 54,586,1,231480,G,C,586,1,261729 55,586,1,231504,G,A,586,1,261753 56,586,1,231526,C,T,586,1,261775 57,586,1,232223,C,T,587,1,262472 58,586,1,234301,T,C,587,1,264550 59,586,1,234308,A,G,587,1,264557 ... ...  \n Flipping primary and alternative reference genome\n% vtools show Project name: test Primary reference genome: hg19 Secondary reference genome: hg38 Storage method: hdf5 Variant tables: variant Annotation databases: % vtools liftover hg38 --flip INFO: Downloading liftOver chain file from UCSC INFO: Exporting variants in BED format Exporting variants: 100% [===============================] 288 116.2K/s in 00:00:00 INFO: Running UCSC liftOver tool INFO: Flipping primary and alternative reference genome Updating table variant: 100% [============================] 288 612.1/s in 00:00:00  Interruption of the flipping process will leave the project unusable because of mixed coordinates.\n% vtools show Project name: test Primary reference genome: hg38 Secondary reference genome: hg19 Storage method: hdf5 Variant tables: variant Annotation databases: % vtools show table variant variant_id, bin, chr, pos, ref, alt, DP, alt_bin, alt_chr, alt_pos 52,586,1,260296,A,T,586,1,230047 53,586,1,260307,T,G,586,1,230058 54,586,1,261729,G,C,586,1,231480 55,586,1,261753,G,A,586,1,231504 56,586,1,261775,C,T,586,1,231526 57,587,1,262472,C,T,586,1,232223 58,587,1,264550,T,C,586,1,234301 59,587,1,264557,A,G,586,1,234308 ... ...  \n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/genes/refgene/",
	"title": "refGene",
	"tags": [],
	"description": "",
	"content": " The RefGene database was created from the UCSC database. RefGene specifies known human protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq). If you would like to annotate your variants to genes, you can use the simpler refGene database. If you would like to determine the exons that your variants are in, use the refGene_exon database. See the available annotation fields for each database below.\nDescription of the database from NCBI:\nRefSeqGene, a subset of NCBI\u0026rsquo;s Reference Sequence (RefSeq) project, defines genomic sequences to be used as reference standards for well-characterized genes. These sequences, labeled with the keyword RefSeqGene in NCBI\u0026rsquo;s nucleotide database, serve as a stable foundation for reporting mutations, for establishing conventions for numbering exons and introns, and for defining the coordinates of other variations. RefSeq mRNA and protein sequences have long been used for this purpose, but have the obvious weakness of not providing explicit coordinates for flanking or intronic sequence. RefSeq chromosome sequences do provide explicit coordinates no matter the relationship to any gene annotation, but have awkwardly large coordinate values that will change when the sequence is updated because of a re-assembly. Sequences of the RefSeqGene project counter both of these drawbacks by providing more stable gene-specific genomic sequence for each gene, as well as including upstream and downstream flanking regions. If modifications must be made to any RefSeqGene sequence, it will be versioned and tools will be provided to facilitate conversion of coordinates. The RefSeqGene sequences are aligned to reference chromosomes, and current and previous chromosome coordinates are available because of that re-alignment. The Clinical Remap tool make that conversion easy.\nAlthough the majority of UCSC Known Genes (KG) are identical to RefSeq genes, there are some significant differences according to this post:\n Not every RefSeq is a KG. Some RefSeqs were filtered out because they did not pass our gene-check processing step (e.g. RefSeqs with no start or stop codons, or bad reading frames are filtered out). If there is a UniProt protein which maps well to a GenBank mRNA, and it passes the gene-check filter and there is no equal or better corresponding RefSeq, the mRNA/UniProt pair will be added to the KG data set. UCSC KG is updated once in a few months. Our RefSeq track is updated nightly. So the refGene table may contains some latest RefSeq updates that came after the last KG build.  refGene % vtools show annotation refGene -v2 Annotation database refGene (version hg19_20130904) Description: Known human protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq). Database type: range Number of records: 45,749 Distinct ranges: 32,293 Reference genome hg19: chr, txStart, txEnd Field: name Type: string Comment: Gene name Missing entries: 0 Unique Entries: 42,286 Field: chr Type: string Missing entries: 0 Unique Entries: 49 Field: strand Type: string Comment: which DNA strand contains the observed alleles Missing entries: 0 Unique Entries: 2 Field: txStart Type: integer Comment: Transcription start position Missing entries: 0 Unique Entries: 28,789 Range: 6011 - 249200442 Field: txEnd Type: integer Comment: Transcription end position Missing entries: 0 Unique Entries: 28,737 Range: 14409 - 249213345 Field: cdsStart Type: integer Comment: Coding region start Missing entries: 0 Unique Entries: 30,038 Range: 6011 - 249211537 Field: cdsEnd Type: integer Comment: Coding region end Missing entries: 0 Unique Entries: 30,147 Range: 14409 - 249212562 Field: exonCount Type: integer Comment: Number of exons Missing entries: 0 Unique Entries: 113 Range: 1 - 363 Field: score Type: integer Comment: Score Missing entries: 0 Unique Entries: 1 Range: 0 - 0 Field: name2 Type: string Comment: Alternative name Missing entries: 0 Unique Entries: 23,953 Field: cdsStartStat Type: string Comment: cds start stat, can be 'non', 'unk', 'incompl', and 'cmp1' Missing entries: 0 Unique Entries: 3 Field: cdsEndStat Type: string Comment: cds end stat, can be 'non', 'unk', 'incompl', and 'cmp1' Missing entries: 0 Unique Entries: 3  refGene_exon % vtools show annotation refGene_exon -v2 Annotation database refGene_exon (version hg19_20130904) Description: RefGene specifies known human protein-coding and non- protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq). This database contains all exome regions of the refSeq genes. Database type: range Number of records: 443,218 Distinct ranges: 240,821 Reference genome hg19: chr, exon_start, exon_end Field: name Type: string Comment: Gene name Missing entries: 0 Unique Entries: 42,286 Field: chr Type: string Missing entries: 0 Unique Entries: 49 Field: strand Type: string Comment: which DNA strand contains the observed alleles Missing entries: 0 Unique Entries: 2 Field: txStart Type: integer Comment: Transcription start position Missing entries: 0 Unique Entries: 28,789 Range: 6011 - 249200442 Field: txEnd Type: integer Comment: Transcription end position Missing entries: 0 Unique Entries: 28,737 Range: 14409 - 249213345 Field: cdsStart Type: integer Comment: Coding region start Missing entries: 0 Unique Entries: 30,038 Range: 6011 - 249211537 Field: cdsEnd Type: integer Comment: Coding region end Missing entries: 0 Unique Entries: 30,147 Range: 14409 - 249212562 Field: exonCount Type: integer Comment: Number of exons Missing entries: 0 Unique Entries: 113 Range: 1 - 363 Field: exon_start Type: integer Comment: exon start position Missing entries: 0 Unique Entries: 235,886 Range: 6011 - 249211478 Field: exon_end Type: integer Comment: exon end position Missing entries: 0 Unique Entries: 236,105 Range: 6168 - 249213345 Field: score Type: integer Comment: Score Missing entries: 0 Unique Entries: 1 Range: 0 - 0 Field: name2 Type: string Comment: Alternative name Missing entries: 0 Unique Entries: 23,953 Field: cdsStartStat Type: string Comment: cds start stat, can be 'non', 'unk', 'incompl', and 'cmp1' Missing entries: 0 Unique Entries: 3 Field: cdsEndStat Type: string Comment: cds end stat, can be 'non', 'unk', 'incompl', and 'cmp1' Missing entries: 0 Unique Entries: 3  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/functions/samples/",
	"title": "samples",
	"tags": [],
	"description": "",
	"content": " Samples that harbor the variant Usage This function is only supported when STOREMODE is set to sqlite. The samples function is similar to genotype but it returns name of samples that contain the variant. When you use the function in command vtools output var_table samples(), this function will be evaluated for each variant in the variant table var_table. In its basic form,\nsamples()  returns a list of comma-separated names of samples that contain the variant, regardless the type of variant (homozygote etc).\nThis function returns all samples that contain the variant, so it will return samples without genotype info (no GT column, and samples with homozygote wildtype allele (genotype with GT=0) as long as the variant is included in the sample.\nDetails The samples function accepts an optional parameter with \u0026amp; separated KEY=VAL pairs. Supported KEY include\n sample_filter. A condition to select samples, using sample names of phenotype (e.g. aff=1). (c.f. command vtools show samples or vtools show phenotypes) geno_filter. Select samples by type of variant in the sample, using genotype type (GT) or genotype info fields (e.g. DP_geno). (c.f. command vtools show genotypes). For example, if you use condition GT=2, only samples with homozygote alternative alleles will be returned. delimiter. Delimiter to seprate sample names, default to ,. You can set it to \\t to output tab separated lists.  For example, command\nsamples() samples('sample_filter=aff=1') samples('geno_filter=GT=1')  returns the\n name of samples that contains the variant, name of samples with phenotype aff=1 (cases) that contains the variant name of samples that contains heterzygote genotype of the variant. You can use condition GT!=0 to output samples with only non-wildtype genotypes.   Examples: Use samples function to get samples that contain the variant Continue to use the project from the previous example, let us see which samples that contain the variants\n% vtools admin --load_snapshot vt_simple % vtools admin --rename_samples \u0026quot;filename='V2.vcf'\u0026quot; SAMP2 % vtools admin --rename_samples \u0026quot;filename='V3.vcf'\u0026quot; SAMP3 % vtools output variant chr pos ref alt \u0026quot;samples()\u0026quot; -l 10 1 4540 G A SAMP1,SAMP3 1 5683 G T SAMP1 1 5966 T G SAMP1,SAMP2,SAMP3 1 6241 T C SAMP1,SAMP3 1 9992 C T SAMP1,SAMP3 1 9993 G A SAMP1,SAMP3 1 10007 G A SAMP1,SAMP2,SAMP3 1 10098 G A SAMP1 1 14775 G A SAMP1,SAMP3 1 16862 A G SAMP1,SAMP3  Just to show the results from genotype() and samples() match each other:\n% vtools output variant chr pos ref alt \u0026quot;genotype('SAMP1')\u0026quot; \u0026quot;genotype('SAMP2')\u0026quot; \\ \u0026quot;genotype('SAMP3')\u0026quot; \u0026quot;samples()\u0026quot; -l 10 1 4540 G A 1 . 1 SAMP1,SAMP3 1 5683 G T 1 . . SAMP1 1 5966 T G 1 1 1 SAMP1,SAMP2,SAMP3 1 6241 T C 1 . 1 SAMP1,SAMP3 1 9992 C T 1 . 1 SAMP1,SAMP3 1 9993 G A 1 . 1 SAMP1,SAMP3 1 10007 G A 1 1 1 SAMP1,SAMP2,SAMP3 1 10098 G A 2 . . SAMP1 1 14775 G A 2 . 2 SAMP1,SAMP3 1 16862 A G 2 . 2 SAMP1,SAMP3  You can limit the samples to those with a particular type of genotype\n% vtools output variant chr pos ref alt \u0026quot;genotype('SAMP1')\u0026quot; \u0026quot;genotype('SAMP2')\u0026quot; \\ \u0026quot;genotype('SAMP3')\u0026quot; \u0026quot;samples('geno_filter=GT=2')\u0026quot; -l 10 1 4540 G A 1 . 1 . 1 5683 G T 1 . . . 1 5966 T G 1 1 1 . 1 6241 T C 1 . 1 . 1 9992 C T 1 . 1 . 1 9993 G A 1 . 1 . 1 10007 G A 1 1 1 . 1 10098 G A 2 . . SAMP1 1 14775 G A 2 . 2 SAMP1,SAMP3 1 16862 A G 2 . 2 SAMP1,SAMP3  \nBecause this function needs to scan the whole genotype tables of samples for each variant, it is expected to be much slower than batch operations that process all genotypes. For example, it would be much faster to export genotypes in batch (e.g. using command vtools export to export variants and genotypes in csv or vcf formats) if you need to list genotypes of a large number of variants.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_report/trans_ratio/",
	"title": "trans_ratio",
	"tags": [],
	"description": "",
	"content": " Transition-transversion Ratio About `vtools_report trans_ratio This command counts the number of transition and transversion variants and calculates its ratio. The expected ratio is 2 in human pseudo-genes (after the exclusion of transitions at CpG sites).\nUsage % vtools_report trans_ratio -h usage: vtools_report trans_ratio [-h] -n NUM_FIELD [--group_by [GROUP_BY [GROUP_BY ...]]] [-v {0,1,2}] table This command counts the number of transition (A\u0026lt;-\u0026gt;G and C\u0026lt;-\u0026gt;T) and transversion variants (others) and calculate its ratio. A ratio of 2 is expected from a normal sample. If option '--by_count' is specified, it will calculate this ratio for variants with different sample allele frequency (count). This commands requires a field that stores the sample count for each variant, which should be prepared using command 'vtools update table --from_stat \u0026quot;num=#(alt)\u0026quot;'. positional arguments: table Variant table for which transversion/transversion mutants are counted. optional arguments: -h, --help show this help message and exit -n NUM_FIELD, --num_field NUM_FIELD Name of the field that holds sample variant count, which is the field name for command 'vtools update table --from_stat \u0026quot;num=#(alt)\u0026quot;'. --group_by [GROUP_BY [GROUP_BY ...]] Output transition/transversion rate for groups of variants. e.g. --group_by num for each sample variant frequency group. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information of vtools and vtools_report. Debug information are always recorded in project and vtools_report log files.  Example % vtools_report trans_ratio variant -n num num_of_transition num_of_transversion ratio 4891 2562 1.909 % vtools_report trans_ratio variant -n num --group_by num sample_count num_of_transition num_of_transversion ratio 1 375 170 2.206 2 105 68 1.544 3 17 8 2.125 4 44 25 1.760 5 15 3 5.000 6 10 11 0.909 7 9 6 1.500 8 12 7 1.714 9 8 7 1.143 10 4 6 0.667 ... ...  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/genes/cancergenecensus/",
	"title": "CancerGeneCensus",
	"tags": [],
	"description": "",
	"content": " Data source This database contains variants from the Cancer Genome Project. It is \u0026ldquo;an ongoing effort to catalogue those genes for which mutations have been causally implicated in cancer. The original census and analysis was published in Nature Reviews Cancer and supplemental analysis information related to the paper is also available. Currently, more than 1% of all human genes are implicated via mutation in cancer. Of these, approximately 90% have somatic mutations in cancer, 20% bear germline mutations that predispose to cancer and 10% show both somatic and germline mutations.\u0026rdquo; {1}\nNot all genes are available in the knownGene or refGene database so you will lose a few genes if you try to find all variants within these cancer genes through location information of knownGene or refGene. The latest version of Cancer Gene Census lists the following genes that are not available in refGene.name2: AMER1, C12orf9, CDKN2a, FAM22B, H3F3AP4, IGH, IGK@, IGL@, KMT2A, KMT2B, KMT2C, NUTM1, NUTM2A, TCRB, TRA, TRD.\nUsage This database should be linked to a field of common gene name, e.g. refGene.name2. You can use load it by\nvtools use refGene vtools use CancerGeneCensus --linked_by refGene.name2 NFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/CancerGeneCensus-20130711.DB.gz INFO: Using annotation DB CancerGeneCensus in project ra. INFO: This database contains variants from the Cancer Genome Project. It is an ongoing effort to catalogue those genes for which mutations have been causally implicated in cancer. The original census and analysis was published in Nature Reviews Cancer and supplemental analysis information related to the paper is also available. Currently, more than 1% of all human genes are implicated via mutation in cancer. Of these, approximately 90% have somatic mutations in cancer, 20% bear germline mutations that predispose to cancer and 10% show both somatic and germline mutations. INFO: 471 out of 23242 refgene.name2 are annotated through annotation database CancerGeneCensus WARNING: 16 out of 487 values in annotation database CancerGeneCensus are not linked to the project.  If you would like to use the knownGene database, you will have to link through knownGene.name. The command to use would be\nvtools use knownGene vtools use CancerGeneCensus --linked_by knownGene.name --linked_field kgID INFO: Using annotation DB CancerGeneCensus in project ra. INFO: This database contains variants from the Cancer Genome Project. It is an ongoing effort to catalogue those genes for which mutations have been causally implicated in cancer. The original census and analysis was published in Nature Reviews Cancer and supplemental analysis information related to the paper is also available. Currently, more than 1% of all human genes are implicated via mutation in cancer. Of these, approximately 90% have somatic mutations in cancer, 20% bear germline mutations that predispose to cancer and 10% show both somatic and germline mutations. INFO: 433 out of 80922 knowngene.name are annotated through annotation database CancerGeneCensus WARNING: 54 out of 487 values in annotation database CancerGeneCensus are not linked to the project.  Fields Description: Cancer Genome Project Database type: field Number of records: 487 Number of distinct entries: 485 Reference genome *: ['kgID'] Field: GeneSymbol Type: string Missing entries: 0 Unique Entries: 484 Field: kgID Type: string Missing entries: 0 Unique Entries: 485 Field: Name Type: string Missing entries: 0 Unique Entries: 487 Field: GeneID Type: string Missing entries: 0 Unique Entries: 485 Field: Chr Type: string Missing entries: 0 Unique Entries: 24 Field: ChrBand Type: string Missing entries: 0 Unique Entries: 343 Field: CancerSomaticMut Type: string Missing entries: 0 Unique Entries: 2 Field: CancerGermlineMut Type: string Missing entries: 0 Unique Entries: 3 Field: TumourTypesSomatic Type: string Missing entries: 0 Unique Entries: 230 Field: TumourTypesGermline Type: string Missing entries: 0 Unique Entries: 59 Field: CancerSyndrome Type: string Missing entries: 0 Unique Entries: 66 Field: TissueType Type: string Missing entries: 0 Unique Entries: 26 Field: CancerMolecularGenetics Type: string Missing entries: 0 Unique Entries: 9 Field: MutationType Type: string Missing entries: 0 Unique Entries: 77 Field: TranslocationPartner Type: string Missing entries: 0 Unique Entries: 159 Field: OtherGermlineMut Type: string Missing entries: 0 Unique Entries: 3 Field: OtherSyndromeOrDisease Type: string Missing entries: 0 Unique Entries: 33  Abbreviations Abbreviation Term A amplification AEL acute eosinophilic leukemia AL acute leukemia ALCL anaplastic large-cell lymphoma ALL acute lymphocytic leukemia AML acute myelogenous leukemia AML* acute myelogenous leukemia (primarily treatment associated) APL acute promyelocytic leukemia B-ALL B-cell acute lymphocytic leukaemia B-CLL B-cell Lymphocytic leukemia B-NHL B-cell Non-Hodgkin Lymphoma CLL chronic lymphatic leukemia CML chronic myeloid leukemia CMML chronic myelomonocytic leukemia CNS central nervous system D large deletion DFSP dermatofibrosarcoma protuberans DLBCL diffuse large B-cell lymphoma DLCL diffuse large-cell lymphoma Dom dominant E epithelial F frameshift GIST gastrointestinal stromal tumour JMML juvenile myelomonocytic leukemia L leukaemia/lymphoma M mesenchymal MALT mucosa-associated lymphoid tissue lymphoma MDS myelodysplastic syndrome Mis Missense MLCLS mediastinal large cell lymphoma with sclerosis MM multiple myeloma MPD Myeloproliferative disorder N nonsense NHL non-Hodgkin lymphoma NK/T natural killer T cell NSCLC non small cell lung cancer O other PMBL primary mediastinal B-cell lymphoma pre-B All pre-B-cell acute lymphoblastic leukaemia Rec reccesive S splice site T translocation T-ALL T-cell acute lymphoblastic leukemia T-CLL T-cell chronic lymphocytic leukaemia TGCT testicular germ cell tumour T-PLL T cell prolymphocytic leukaemia  Examples Find variants belong to one of the cancer genes vtools use CancerGeneCensus --linked_by refGene.name2 vtools select variant 'GeneSymbol is not NULL' -t CancerVariants  Find variants that are in 5kb up and downstream of some cancer genes. If you are interested in only some of the cancer genes, but would like to get variants not only within the genes, but also up and downstream of these genes, you will first have to get a list of genes.\nFor example, you can run\nvtools execute select GeneSymbol from CancerGeneCensus  to get a list of cancer genes.\nThen, to locate variants in a different region as the default range of the refGene database (from txStart to txEnd), you will need to re-use the refGene database using command\nvtools use refGene --linked_fields chr 'txStart-5000', 'txEnd+5000'  Then, you can use the following commands to create tables of variants for each gene:\nfor gene in GENE1 GENE2 GENE3 do vtools select variant \u0026quot;refGene.name2='${gene}'\u0026quot; -t ${gene}_ext done  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/variants/esp/",
	"title": "ESP",
	"tags": [],
	"description": "",
	"content": " Variants from the Exome Sequencing Project (ESP) The EVS annotation source contains exome sequencing variants retrieved from the Exome Variant Server (EVS) for the NHLBI Exome Sequencing Project (ESP). The evs annotation data was generated from approximately 2500 exomes and evs_5400 from approximately 5400 exomes. (7500 exomes are the next milestone for this project in the next couple of months - see their website for project details: http://evs.gs.washington.edu/EVS/). Currently minor allele frequencies are given for European American and African American populations - see below for additional fields that you can use for variant selection and annotation.\nThe data in evs annotation source was retrieved from the project website on November 7, 2011, and evs_5400 was retrieved on December 15, 2011. If you find this data useful please cite their project:\n*Exome Variant Server, NHLBI Exome Sequencing Project (ESP), Seattle, WA (URL: http://evs.gs.washington.edu/EVS/) [December 15, 2011] (or [November 7, 2011] for the 2500 exome version)*\nAvailable databases You should run the following command to see the availability of most recent version of the evs database:\n% vtools show annotations evs ESP ESP-6500SI-V2-SSA137 NHLBI GO Exome Sequencing Project (Exome Variant Server, NHLBI Exome Sequencing Project (ESP), Seattle, WA (URL: http://evs.gs.washington.edu/EVS/) [6500 samples, February, 2013].) ESP NHLBI GO Exome Sequencing Project (Exome Variant Server, NHLBI Exome Sequencing Project (ESP), Seattle, WA (URL: http://evs.gs.washington.edu/EVS/) [6500 samples, February, 2013].) evs-6500 NHLBI GO Exome Sequencing Project (Exome Variant Server, NHLBI Exome Sequencing Project (ESP), Seattle, WA (URL: http://evs.gs.washington.edu/EVS/) [6500 samples, February, 2013].) evs-hg19_20111107 NHLBI GO Exome Sequencing Project (Exome Variant Server, NHLBI Exome Sequencing Project (ESP), Seattle, WA (URL: http://evs.gs.washington.edu/EVS/) [November, 2011].) evs NHLBI GO Exome Sequencing Project (Exome Variant Server, NHLBI Exome Sequencing Project (ESP), Seattle, WA (URL: http://evs.gs.washington.edu/EVS/) [6500 samples, February, 2013].) evs_5400 NHLBI GO Exome Sequencing Project (Exome Variant Server, NHLBI Exome Sequencing Project (ESP), Seattle, WA (URL: http://evs.gs.washington.edu/EVS/) [5400 samples, December, 2011].) % vtools show annotation ESP Description: NHLBI GO Exome Sequencing Project (Exome Variant Server, NHLBI Exome Sequencing Project (ESP), Seattle, WA (URL: http://evs.gs.washington.edu/EVS/) [6500 samples, February, 2013].) Database type: variant Number of records: 1,998,204 Distinct variants: 1,998,173 Reference genome hg19: chr, pos, ref, alt Field: chr Type: string Comment: Chromosome that the variant was found in. Missing entries: 0 Unique Entries: 24 Field: pos Type: integer Comment: Location on the chromosome (NCBI 37 or hg19), 1-based. Missing entries: 0 Unique Entries: 1,979,319 Range: 5994 - 249212579 Field: rs_id Type: string Comment: dbSNP reference SNP identifier (if available) Missing entries: 1,068,352 (53.5% of 1,998,204 records) Unique Entries: 921,262 Field: ref Type: string Comment: Variant alternate allele. Missing entries: 0 Unique Entries: 8,026 Field: alt Type: string Comment: Reference allele. Missing entries: 0 Unique Entries: 2,084 Field: dbSNPVersion Type: string Comment: dbSNP version which established the rs_id Missing entries: 0 Unique Entries: 57 Field: EuropeanAmericanAltCount Type: integer Comment: The observed ref allele counts for the European American population. Allele counts only include genotypes with quality \u0026gt;= 30 and read depth \u0026gt;= 10. Missing entries: 0 Unique Entries: 8,517 Range: 0 - 8600 Field: EuropeanAmericanRefCount Type: integer Comment: The observed ref allele counts for the European American population. Allele counts only include genotypes with quality \u0026gt;= 30 and read depth \u0026gt;= 10. Missing entries: 0 Unique Entries: 8,599 Range: 0 - 8600 Field: AfricanAmericanAltCount Type: integer Comment: The observed alt allele counts for the African American population. Allele counts only include genotypes with quality \u0026gt;= 30 and read depth \u0026gt;= 10. Missing entries: 0 Unique Entries: 4,406 Range: 0 - 4406 Field: AfricanAmericanRefCount Type: integer Comment: The observed ref allele counts for the African American population. Allele counts only include genotypes with quality \u0026gt;= 30 and read depth \u0026gt;= 10. Missing entries: 0 Unique Entries: 4,407 Range: 0 - 4406 Field: AllAltCount Type: integer Comment: The observed alt allele counts for all populations. Allele counts only include genotypes with quality \u0026gt;= 30 and read depth \u0026gt;= 10. Missing entries: 0 Unique Entries: 12,543 Range: 0 - 13005 Field: AllRefCount Type: integer Comment: The observed ref allele counts for all populations. Allele counts only include genotypes with quality \u0026gt;= 30 and read depth \u0026gt;= 10. Missing entries: 0 Unique Entries: 12,971 Range: 0 - 13005 Field: EuropeanAmericanMaf Type: float Comment: The European American minor-allele frequency in percent. Missing entries: 0 Unique Entries: 67,810 Range: 0 - 0.650641 Field: AfricanAmericanMaf Type: float Comment: The African American minor-allele frequency in percent. Missing entries: 0 Unique Entries: 75,477 Range: 0 - 0.652047 Field: AllMaf Type: float Comment: The minor-allele frequency in percent for all populations. Missing entries: 0 Unique Entries: 85,231 Range: 7.7e-05 - 0.652174 Field: AvgSampleReadDepth Type: integer Comment: The average sample read depth. Missing entries: 0 Unique Entries: 795 Range: 1 - 2855 Field: Genes Type: string Comment: One or more genes for which the SNP is in the coding region (CCDS). Missing entries: 0 Unique Entries: 19,395 Field: GeneAccession Type: string Comment: NCBI mRNA transcripts accession number. Missing entries: 1,998,204 (100.0% of 1,998,204 records) Field: FunctionGvs Type: string Comment: The GVS functions are calculated by the Exome Variant Server; they are based on the alleles for all populations and individuals; the bases in the coding region are divided into codons (if a multiple of 3), and the resulting amino acids are examined. Missing entries: 0 Unique Entries: 157,919 Field: AminoAcidChange Type: string Comment: The corresponding amino acid change for a SNP. Missing entries: 1,998,204 (100.0% of 1,998,204 records) Field: ProteinPos Type: string Comment: The coresponding amino acid postion in a protein relative to the whole protein length. Missing entries: 1,998,204 (100.0% of 1,998,204 records) Field: cDNAPos Type: integer Comment: The coresponding cDNA postion for a SNP. Missing entries: 1,998,204 (100.0% of 1,998,204 records) Field: ConservationScorePhastCons Type: float Comment: A number between 0 and 1 that describes the degree of sequence conservation among 17 vertebrate species; these numbers are downloaded from the UCSC Genome site and are defined as the \u0026quot;posterior probability that the corresponding alignment column was generated by the conserved state of the phylo-HMM, given the model parameters and the multiple alignment\u0026quot; (see UCSC description). Missing entries: 0 Unique Entries: 12 Range: 0 - . Field: ConservationScoreGERP Type: float Comment: The rejected-substitution score from the program GERP, a number between -11.6 and 5.82 that describes the degree of sequence conservation among 34 mammalian species, with 5.82 being the most conserved; these scores were provided by Gregory M. Cooper of the University of Washington Department of Genome Sciences to the EVS project. Missing entries: 0 Unique Entries: 187 Range: -12.3 - . Field: GranthamScore Type: integer Comment: Grantham Scores categorize codon replacements into classes of increasing chemical dissimilarity based on the publication by Granthan R.in 1974, Amino acid difference formula to help explain protein evolution. Science 1974 185:862-864. Missing entries: 0 Unique Entries: 9,363 Range: 5 - 99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99,99 Field: PolyPhenPrediction Type: string Comment: Prediction of possible impact of an amino acid substitution on protein structure and function based on Polymorphism Phenotyping (PolyPhen) program. Missing entries: 0 Unique Entries: 23,374 Field: ChimpAllele Type: string Comment: Chimp alleles are acquired from UCSC human/chimp alignment files. If the variation does not fall within an alignment block, or if it is an indel, the chimp allele is listed as \u0026quot;unknown\u0026quot;. If the variation falls within a gap in the alignment, it is listed as \u0026quot;-\u0026quot;. Missing entries: 0 Unique Entries: 6 Field: ClinicalLink Type: string Comment: The potential clinical implications associated with a SNP (limited). Missing entries: 0 Unique Entries: 5,918 Field: ExomeChip Type: string Comment: Whether a SNP is on the Illumina HumanExome Chip Missing entries: 0 Unique Entries: 2 Field: FilterStatus Type: string Comment: A machine-learning technique called support vector machine (SVM) classification was applied for variant filtering. After the initial SNP calls were generated, we re-examined the BAM files to collect additional information about each variant site. Based on the information, variants are initially filtered by individual thresholds. For example, variants with posterior probability \u0026lt;99% (glfMultiples SNP quality \u0026lt;20), were \u0026lt;5bp away from an indel detected in the 1000 Genomes Pilot Project, had total depth across samples of \u0026lt;5,379 or \u0026gt;5,379,000 reads (~1-1000 reads per sample), having \u0026gt;65% of reads as heterozygotes carrying the variant allele or where the absolute squared correlation between allele (variant or reference) and strand (forward or reverse) was \u0026gt;0.15 were marked as problematic SNPs. Sites failed 3 or more criteria are used as negative examples to train SVM classifier. HapMap3 and OMNI polymorphic sites were used as positive examples. The SVM classifier produces scores for each site, and we marked ~8.5% of sites at threshold 0.3 as SVM filter-failed. The unfiltered set had Ti/Tv = 2.63, and the filtered set had Ti/Tv =2.78. Missing entries: 0 Unique Entries: 1  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/faq/",
	"title": "FAQ",
	"tags": [],
	"description": "",
	"content": " 1. Import data 1.1 Some of my samples occur in multiple vcf files but their genotype calls may be different. How can I identify them after they are imported? Because a file might contain genotype for multiple samples (.vcf), and genotype for a sample can be spread into several files (your case), a sample in variant tools is uniquely identified by filename and sample_name in the output of \u0026ldquo;vtools show sample\u0026rdquo;. However\n Samples usually come with pre-specified names (the header line of vcf or other text files). But you may customize sample names by option --sample_name in vtools import for different data sources when you import data. The customized names will overwrite the original names. Then your sample can be identified by option --samples 'sample_name = \u0026quot;name\u0026quot;' in vtools select command.\n If there are too many to customize, you could still identify your sample by filename + sample_name (e.g. --samples 'filename like \u0026quot;FILE_1%\u0026quot;' 'sample_name = \u0026quot;NA07000\u0026quot;').\n You can also add a column of customized sample names to the sample table using command vtools phenotype. You can then refer to the samples using the new names. For example you append an additional column sampleID to the sample table, where you customize sample names from different sources, then use --samples 'sampleID=\u0026quot;name\u0026quot;' to identify samples.\n  2. My filtering commands are running slowly With SQLite and MySQL, you can \u0026ldquo;analyze\u0026rdquo; tables or create indexes on table columns to help speed up queries. Creating indexes though does increase the size of the database and can slow down import speeds. Indexes based on genomic positions are automatically created by vtools.\n2.1 Can I rename sample\u0026rsquo;s name 2.2 Is there a way to merge a sample from the different sources 2.3 How to update the sample information, inclusing geno, and phenotype information 2.4 What kind formats can be imported using vtools 2.5 What kind of formats of the results can be outputed using vtools 2.6 Can I use the different versions of human genome assembled 2.7 How to create sub-project 2.8 Can I exclude some specific samples 2.9 How to remove the tables I created 2.10 how to create connection between my samples and the annotation database 2.11 Can I use more than 1 annotation databases 2.12 vtools execute 'analyze variant'\nvtools execute 'create index my_index on variant(some_field)'\nFor more help see:\n http://www.sqlite.org/lang_analyze.html http://www.sqlite.org/lang_createindex.html  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/joint_conditional/metaskat-analysis/",
	"title": "MetaSKAT analysis",
	"tags": [],
	"description": "",
	"content": " Association Analysis with the Meta SKAT R Program The R extension for RTest is available HERE. For details on the format of this script please refer to the RTest method documentation.\nExample We analyze association with a binary trait named X6 conditioning on 3 covariates X8, X9, X10. Group information is provided by race. For each testing group, data is first cleaned by removing samples missing greater than 50% calls, then by removing variants missing 50% calls.\nBasic command The following command uses the default parameter settings in the R script:\nvtools associate variant X6 --covariates X8 X9 X10 race \\ -m \u0026quot;RTest ~/MetaSKAT.VAT.R --name MetaSKAT --out_type 'D' --group_colname 'race' \u0026quot; \\ --discard_samples '%(NA)\u0026gt;0.5' --discard_variants '%(NA)\u0026gt;0.5' \\ --group_by 'refGene.name2' -j8 --to_db MetaSKAT \u0026gt; MetaSKAT.txt INFO: Loading R script '/home/gw/MetaSKAT.VAT.R' INFO: 252 samples are found INFO: 131 groups are found INFO: Starting 8 processes to load genotypes Loading genotypes: 100% [===================================] 252 72.5/s in 00:00:03 Testing for association: 100% [==============================] 131/122 10.4/s in 00:00:12 INFO: Association tests on 131 groups have completed. 122 failed. INFO: Using annotation DB MetaSKAT in project mskat. INFO: Annotation database used to record results of association tests. Created on Tue, 16 Apr 2013 01:40:03 INFO: 131 out of 23242 refgene.name2 are annotated through annotation database MetaSKAT  Note that with such stringent cleaning criteria only 9 out of 131 groups are analyzed. In the R program we throw an error on having no samples, only one variant, or only one study group. Please take a look at the *.log file for details of the errors.\nrefGene_name2 pvalue_MetaSKAT n_pop1_MetaSKAT n_pop2_MetaSKAT n_pop3_MetaSKAT gene1 0.686969 79 84 NAN gene2 0.0697923 84 68 NAN gene3 0.0684316 81 83 NAN gene4 0.426611 63 84 NAN gene5 0.591128 70 77 NAN gene6 0.00586012 84 81 NAN gene7 0.306343 77 84 NAN gene8 0.0951658 81 84 NAN gene9 0.0988938 84 84 84  Use other parameters From the way MetaSKAT.VAT.R is written we known out_type and group_colname are required. They have to be explicitly specified at all times. Other parameters have default values, which can be altered by passing them like, for example:\n... -m \u0026quot;RTest ~/MetaSKAT.VAT.R --name MetaSKAT \\ --out_type 'D' --group_colname 'race' --pval.method 'davies' \u0026quot; ...  [^#^]\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/single_gene/rarecover-test/",
	"title": "RareCover test",
	"tags": [],
	"description": "",
	"content": " A \u0026ldquo;Covering Algorithm\u0026rdquo; for Rare and Low Frequency Variants Introduction The RareCover test in Bhatia et al 2010[^Gaurav Bhatia, Vikas Bansal, Olivier Harismendy, Nicholas J. Schork, Eric J. Topol, Kelly Frazer and Vineet Bafna (2010) A Covering Method for Detecting Genetic Associations between Rare Variants and Common Phenotypes. PLoS Computational Biology doi:10.1371/journal.pcbi.1000954. http://dx.plos.org/10.1371/journal.pcbi.1000954^] is an efficient heuristic greedy algorithm to find an optimized combination of variants in a loci with the strongest association signal. It uses the same collapsing strategy and test statistic as in Li and Leal, 2008[^Bingshan Li and Suzanne M. Leal (2008) Methods for Detecting Associations with Rare Variants for Common Diseases: Application to Analysis of Sequence Data. The American Journal of Human Genetics doi:10.1016/j.ajhg.2008.06.024. http://linkinghub.elsevier.com/retrieve/pii/S0002929708004084^] but scans over the loci, adding at each iteration the variants that contributes most to the statistic.\nRareCover is related to the Variable Thresholds test? yet differs in the sequence by which rare variants are incorporated into the test. Variable thresholds test assumes a fixed yet unknown MAF boundary of rare causal variants, while RareCover does not have the assumption. Still, it does not mean that RareCover would perform exhaustive search for all combinations of variants in a loci region. The \u0026ldquo;coverage\u0026rdquo; of RareCover method depends on the convergence cut-off {$Q$}.\nRareCover method is implemented in this program as a two-sided test with the tuning parameter {$Q=0.5$}, as recommanded by the original paper.\nDetails Command interface vtools show test RareCover Name: RareCover Description: A \u0026quot;covering\u0026quot; method for detecting rare variants association, Bhatia et al 2010. usage: vtools associate --method RareCover [-h] [--name NAME] [-q1 MAFUPPER] [-q2 MAFLOWER] [-p N] [--adaptive C] [--moi {additive,dominant,recessive}] A \u0026quot;covering\u0026quot; method for detecting rare variants association, Bhatia et al 2010. The algorithm combines a disparate collection of rare variants and maximize the association signal over the collection using a heuristic adaptive approach, which can be computationally intensive. Different from VT method, it does not require rare variants evaluated being adjacent in minor allele frequency ranking. RareCover test is a two-tailed test. optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. -q1 MAFUPPER, --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 0.01 -q2 MAFLOWER, --maflower MAFLOWER Minor allele frequency lower limit. All variants having sample MAF\u0026gt;m2 will be included in analysis. Default set to 0.0 -p N, --permutations N Number of permutations --adaptive C Adaptive permutation using Edwin Wilson 95 percent confidence interval for binomial distribution. The program will compute a p-value every 1000 permutations and compare the lower bound of the 95 percent CI of p-value against \u0026quot;C\u0026quot;, and quit permutations with the p-value if it is larger than \u0026quot;C\u0026quot;. It is recommended to specify a \u0026quot;C\u0026quot; that is slightly larger than the significance level for the study. To disable the adaptive procedure, set C=1. Default is C=0.1 --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive model. Default set to additive  Application  Example using snapshot vt_ExomeAssociation\nvtools associate rare status -m \u0026quot;RareCover --name RareCover -p 5000\u0026quot; --group_by name2 --to_\\ db rarecover -j8 \u0026gt; rarecover.txt INFO: 3180 samples are found INFO: 2632 groups are found INFO: Starting 8 processes to load genotypes Loading genotypes: 100% [=============================] 3,180 32.8/s in 00:01:36 Testing for association: 100% [===============================] 2,632/591 6.0/s in 00:07:17 INFO: Association tests on 2632 groups have completed. 591 failed. INFO: Using annotation DB rarecover in project test. INFO: Annotation database used to record results of association tests. Created on Wed, 30 Jan 2013 05:40:44 vtools show fields | grep RareCover rarecover.sample_size_RareCover sample size rarecover.num_variants_RareCover number of variants in each group (adjusted for specified MAF rarecover.total_mac_RareCover total minor allele counts in a group (adjusted for MOI) rarecover.statistic_RareCover test statistic. rarecover.pvalue_RareCover p-value rarecover.std_error_RareCover Empirical estimate of the standard deviation of statistic under the rarecover.num_permutations_RareCover number of permutations at which p-value is evaluated head rarecover.txt name2 sample_size_RareCover num_variants_RareCover total_mac_RareCover statistic_RareCover pvalue_RareCover std_error_RareCover num_permutations_RareCover ABCG5 3180 6 87 0.991364 0.911089 3.32099 1000 ABCB10 3180 6 122 5.54768 0.28971 3.25502 1000 ABHD1 3180 5 29 0.262705 0.901099 3.76918 1000 AAMP 3180 3 35 1.3233 0.667333 2.09356 1000 ABCD3 3180 3 42 0.394182 0.949051 2.33258 1000 AADACL4 3180 5 138 4.82996 0.200799 2.82611 1000 ABCB6 3180 7 151 1.26936 0.895105 3.0108 1000 ABL2 3180 4 41 0.344182 0.947053 3.3311 1000 ACAP3 3180 3 17 2.87639 0.277722 2.90011 1000  QQ-plot Attach:rarecover.jpg\n\n[^#^]\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/regions/",
	"title": "Regions",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/select/",
	"title": "Select",
	"tags": [],
	"description": "",
	"content": " Selecting variants belong to specified genes 1. Data We have whole genome sequencing data for more than 18M variants. After some initial analysis, three genes geneA, geneB, and geneC caught our eyes and we would like to further investigate these genes. We assume that we already have a project with all the variants imported\n2. Find variants that belong to the genes We first need to get a list of genes\n% vtools use refGene  From the output\n% vtools show annotation refGene  we can see that it has locations of each gene, gene ID (NM_XXX) and a more common name name2. To select variants that belong to these genes, we can do\n% vtools select variant 'refGene.name2 in (\u0026quot;geneA\u0026quot;, \u0026quot;geneB\u0026quot;, \u0026quot;geneC\u0026quot;)' -t gene_ABC  Or, if you prefer separating the tables, you can use commands\n% for gene in geneA geneB geneC % do vtools select variant \u0026quot;refGene.name2='$gene'\u0026quot; -t $gene % done  to create three tables. To create another table with variants in these three tables, you could do\n% vtools compare geneA geneB --A_or_B gene_AB % vtools compare gene_AB geneC --A_or_B gene_ABC % vtools remove tables gene_AB  The last command remove the intermediate table gene_AB.\n3. Find variants that belong to a long list of genes To subset a dataset to variants within a group of hundreds of genes, you need to create a small annotation database to link the gene list to the project, via, e.g., the refGene database. Suppose your list of genes are formatted like:\n% NEBL NM_213569 % NEBL NM_213569 % NEBL NM_213569 % NEBL NM_213569 % LINC00167 NR_024233 % PGAP2 NR_027016 % PGAP2 NR_027016 ...  where the columns are gene name and (or) transcript name. You can create an annotation file for the gene list, e.g.,\n[linked fields] *=gene_name [data sources] description=My gene selection for xxx project version=20130419 anno_type=field source_type=txt [gene_name] index=1 type=VARCHAR(255) comment=Gene name [transcript_name] index=2 type=VARCHAR(255) comment=Transcript name  and the annotation database\n% vtools use MyGenes.ann -f my_gene_list.txt --linked_by refGene.name2  Note that the default linked field is \u0026ldquo;gene_name\u0026rdquo;, the gene names. Alternatively you can choose to link by transcript name, e.g.\n% vtools use MyGenes.ann -f my_gene_list.txt --linked_by refGene.name --linked_fields transcript_name  Finally select the variants belonging to this list of gene\n% vtools select some_table \u0026quot;MyGenes.gene_name is not NULL\u0026quot; -t my_genes  4. Find variants that belong to exonic regions of the genes Annotation database refGene_exon lists all exonic regions of each gene. To use this annotation database, you can download and use the latest version of this database using command\n% vtools use refGene_exon  Then select variants that belong to the exonic regions of the genes using command\n% vtools select variant 'refGene_exon.name2 in (\u0026quot;geneA\u0026quot;, \u0026quot;geneB\u0026quot;, \u0026quot;geneC\u0026quot;)' -t gene_ABC  Or separately for each gene:\n% for gene in geneA geneB geneC % do vtools select variant \u0026quot;refGene_exon.name2='$gene'\u0026quot; -t ${gene}_exon % done  4.1 Finding variants around a gene (e.g. promotor regions) If you would like to find all variants that are in vicinity of genes (e.g. 2k basepair in the upstream and downstream of the gene), you will have to know the position of the genes. You could get such information from UCSC database, or from the refGene database using commands such as\n% vtools execute 'SELECT chr, txStart, txEnd FROM refGene.refGene WHERE refGene.name2=\u0026quot;geneA\u0026quot;'  This query is database dependent. You could use command sqlite3 annotation.DB .schame to get the structure of database if you would like to know the structure of another annotation database and submit a similar query.\n After you get the starting and ending locations of the genes, you could select a variants using commands such as\n% vtools select variant 'chr=\u0026quot;5\u0026quot;' 'pos\u0026gt;=7152445' 'pos\u0026lt;=7158882' -t geneA_ext  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/single_variant/",
	"title": "Single variant analysis",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/under-development/",
	"title": "Under development",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_report/",
	"title": "Vtools report",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/functions/in_table/",
	"title": "in_table",
	"tags": [],
	"description": "",
	"content": " Test membership of variants in variant tables Usage The in_table function is a simple function used to test is a variant is in a specified variant table. It accepts the name of a variant table and returns 1 if the variant belong to this table, and 0 otherwise.\nin_table('table_name')  Details For example, command\n% vtools admin --load_snapshot vt_simple % vtools show tables  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_commands/show/",
	"title": "show",
	"tags": [],
	"description": "",
	"content": " Display project and system information 1. Usage % vtools show -h usage: vtools show [-h] [-l N] [-v {0,1,2,3}] [{project,tables,table,samples,phenotypes,genotypes,fields,annotations,annotation,track,formats,format,tests,test,runtime_options,runtime_option,snapshot,snapshots}] [items [items ...]] Output information of all system and project related items such as variant tables, samples, phenotypes, annotation databases and fields. positional arguments: {project,tables,table,samples,phenotypes,genotypes,fields,annotations,annotation,track,formats,format,tests,test,runtime_options,runtime_option,snapshot,snapshots} Type of information to display, which can be 'project' for summary of a project, 'tables' for all variant tables (or all tables if --verbosity=2), 'table TBL' for details of a specific table TBL, 'samples [COND]' for sample name, files from which samples are imported, and associated phenotypes (can be supressed by option --verbosity 0) of all or selected samples, 'phenotypes [P1 P2...]' for all or specified phenotypes of samples, 'fields' for fields from variant tables and all used annotation databases, 'annotations' for a list of all available annotation databases, 'annotation ANN' for details about annotation database ANN, 'track' for information of a track file in tabixed vcf, bigWig, or bigBed format, 'formats' for all supported import and export formats, 'format FMT' for details of format FMT, 'tests' for a list of all association tests, and 'test TST' for details of an association test TST, 'runtime_options' for a list of runtime options and their descriptions, 'runtime_option OPT' for value of specified runtime option OPT, 'snapshot' for a particular snapshot by name or filename, 'snapshots' for a list of publicly available snapshots, and snapshots of the current project saved by command 'vtools admin --save_snapshots'. The default parameter of this command is 'project'. items Items to display, which can be, for example, name of table for type 'table', conditions to select samples for type 'samples', a list of phenotypes for type 'phenotypes', name of an annotation database for type 'annotation', a pattern to selected annotation databases for type 'annotations', name of a format for type 'format', and name of an association test for type 'test'. optional arguments: -h, --help show this help message and exit -l N, --limit N Limit output to the first N records. -v {0,1,2,3}, --verbosity {0,1,2,3} Output error and warning (0), info (1), debug (2) and trace (3) information to standard output (default to 1).  2. Details Command `vtools show displays various project and system information. It accepts type of item to display as its first parameter, followed by names of items if information about particular items are needed. Generally speaking:\n plural form of output type (e.g. tables, tests) lists all available items. Options are usually available to limit the items to display. single form of output type (e.g. table, test) list details of a single item. The verbosity level can be used to adjust output. For example, -v0 can usually be used to suppress description of items, and -v2 can be used to show more information.  2.1 Show project (project) Command `vtools show without parameter and `vtools show project displays general information about a project, including project name, reference genome, existing variant tables, and used annotation databases.\n Examples: Show summary of a downloaded project\nLet us load a fairly large project from an online snapshot vt_ExomeAssociation,\n% vtools init show % vtools admin --load_snapshot vt_ExomeAssociation Downloading snapshot vt_ExomeAssociation.tar.gz from online INFO: Load genotypes INFO: Snapshot vt_ExomeAssociation has been loaded % vtools show Project name: show Primary reference genome: hg19 Secondary reference genome: None Runtime options: verbosity=1 Variant tables: rare variant Annotation databases:  The project has 2 variant tables, the master variant table and another variant tables rare. It uses the hg19 reference genome, and has not been connected to any annotation database.\n\n2.2 Show variant and other tables (tables and table) Command vtools show tables lists all variant tables, their creation dates and comments (if available). This command does not accept any additional parameter.\n Examples: Show all variant tables \n% vtools show tables table #variants date message rare 19,785 Jan24 rare variants variant 26,797  \nvtools show tables lists all variant tables of a project, with creation date and comment. If you only need to know information about a particular variant table, it is easier and faster to use command vtools show table TABLE. This command lists date of creation, a short description, number of variants and fields (only the master variant table has multiple fields). Perhaps more interestingly, it shows the command that has been used to create this variant table, which usually contain import information regarding from which table this table is drawn, and what criteria has been used.\n Examples: Show details of a variant table Show details of a table rare, note that you can specify multiple tables after command vtools show table.\n% vtools show table rare Name: rare Type: variant Description: rare variants Creation date: Jan24 Command: vtools select variant 'af\u0026lt;0.01 OR af\u0026gt;0.99' -t rare 'rare variants' Fields: variant_id Number of variants: 19785  \n2.3 Show samples (samples) Command vtools show samples lists samples, files from which samples are imported, and phenotypes associated with each samples. The command by default lists all samples and phenotypes, but you can list part of the information by\n Option --limit limit the output to the first few records Option --samples can limit the samples to those that match specified criteria Option -v 0 (--verbosity 0) supress phenotypes. This is useful when there are a large number of phenotypes Option -v 2 lists full filenames. The default output lists part of the filenames if they are too long. Increasing verbosity level will show complete information.   Examples: Show all or selected samples, with or without phenotype Show all samples:\n% vtools show samples -l 10 sample_name filename gender age bmi status exposure SAMP10 assoctest.dat 1 44 27.93818994 0 0 SAMP100 assoctest.dat 1 47 33.47268746 0 0 SAMP1000 assoctest.dat 1 50 26.4845 0 0 SAMP1001 assoctest.dat 2 59 24.02405 0 1 SAMP1002 assoctest.dat 2 61 26.32636 0 0 SAMP1003 assoctest.dat 1 49 24.4131 0 1 SAMP1004 assoctest.dat 1 57 30.57549 0 0 SAMP1005 assoctest.dat 2 57 28.40909 0 1 SAMP1006 assoctest.dat 2 48 28.7642 0 0 SAMP1007 assoctest.dat 1 65 24.14179 0 0 (3170 records omitted)  Show only male samples using condition gender=1 to select samples\n% vtools show samples 'gender=1' -l 10 sample_name filename gender age bmi status exposure SAMP10 assoctest.dat 1 44 27.93818994 0 0 SAMP100 assoctest.dat 1 47 33.47268746 0 0 SAMP1000 assoctest.dat 1 50 26.4845 0 0 SAMP1003 assoctest.dat 1 49 24.4131 0 1 SAMP1004 assoctest.dat 1 57 30.57549 0 0 SAMP1007 assoctest.dat 1 65 24.14179 0 0 SAMP1008 assoctest.dat 1 48 28.20037 0 1 SAMP1010 assoctest.dat 1 56 23.67424 0 1 SAMP1014 assoctest.dat 1 47 23.54056 0 0 SAMP1016 assoctest.dat 1 60 23.8961 0 0 (3170 records omitted)  Suppressing phenotypes and only show basic sample information\n% vtools show samples -l 10 -v0 sample_name filename SAMP10 assoctest.dat SAMP100 assoctest.dat SAMP1000 assoctest.dat SAMP1001 assoctest.dat SAMP1002 assoctest.dat SAMP1003 assoctest.dat SAMP1004 assoctest.dat SAMP1005 assoctest.dat SAMP1006 assoctest.dat SAMP1007 assoctest.dat (3170 records omitted)  \n2.4 Show all or selected phenotypes (phenotypes) Command vtools show phenotypes is similar to vtools show samples but it does not show filename information and can display only specified phenotypes.\n Examples: Show all or selected phenotypes Show all phenotypes\n% vtools show phenotypes -l 10 sample_name gender age bmi status exposure SAMP10 1 44 27.93818994 0 0 SAMP100 1 47 33.47268746 0 0 SAMP1000 1 50 26.4845 0 0 SAMP1001 2 59 24.02405 0 1 SAMP1002 2 61 26.32636 0 0 SAMP1003 1 49 24.4131 0 1 SAMP1004 1 57 30.57549 0 0 SAMP1005 2 57 28.40909 0 1 SAMP1006 2 48 28.7642 0 0 SAMP1007 1 65 24.14179 0 0 (3170 records omitted)  Show values of specified phenotypes\n% vtools show phenotypes exposure -l 10 sample_name exposure SAMP10 0 SAMP100 0 SAMP1000 0 SAMP1001 1 SAMP1002 0 SAMP1003 1 SAMP1004 0 SAMP1005 1 SAMP1006 0 SAMP1007 0 (3170 records omitted)  \nAnother command vtools phenotype --output can also output selected phenotypes. It is more powerful in that it has better control of the format of output, and more importantly, allow output of summary statistics of phenotypes.\n2.5 Show genotype information for each sample (genotypes) Command vtools show genotypes shows the number of genotypes and names of genotype info fields of each sample. Such information are useful for the calculation of summary statistics of genotypes (e.g. depth of coverage) using commandsvtools phenotype \u0026ndash;from_stat(statistics for each sample) andvtools update \u0026ndash;from_stat@@ (statistics for each variant).\n Examples: Show details of genotypes\n% vtools show genotypes -l 10 sample_name filename num_genotypes sample_genotype_fields SAMP2 assoctest.dat 26612 GT SAMP3 assoctest.dat 26613 GT SAMP4 assoctest.dat 26600 GT SAMP5 assoctest.dat 26600 GT SAMP6 assoctest.dat 26603 GT SAMP7 assoctest.dat 26584 GT SAMP8 assoctest.dat 26612 GT SAMP9 assoctest.dat 26585 GT SAMP10 assoctest.dat 26613 GT SAMP11 assoctest.dat 26588 GT (3170 records omitted)  \n2.6 Show variant info and annotation fields (fields) Command vtools show fields) lists all variant info fields (fields in the master variant table) and annotation fields (fields provided by annotation databases). Although these fields are from different sources, they can be used in the same manner to identify and filter variants (c.f. vtools select). If you only need to see a list of available fields, you can use option -v0 to suppress comments.\n Examples: Show all variant info and annotation fields This project uses annotation database knownGene so all fields from that database are available in the project:\n% vtools show fields variant.chr (char) Chromosome name (VARCHAR) variant.pos (int) Position (INT, 1-based) variant.ref (char) Reference allele (VARCHAR, - for missing allele of an insertion) variant.alt (char) Alternative allele (VARCHAR, - for missing allele of an deletion) variant.cnt (int) variant.hom (int) variant.het (int) variant.other (int) variant.num (int) variant.missing (int) variant.wtGT (int) variant.mutGT (int) variant.af (float)  You can use option -v0 to suppress comments (which can be long):\n% vtools show fields -v0 variant.chr variant.pos variant.ref variant.alt variant.cnt variant.hom variant.het variant.other variant.num variant.missing variant.wtGT variant.mutGT variant.af  \n2.7 Show annotation databases (annotations and annotation) Command vtools show annotations displays all available annotation databases with their descriptions. Because of the growing number of annotation databases, the output of this command can be very long. You can however\n Limit the databases by specifying a number of patterns. A database is eligible if its name contains any of the patterns. Use option --limit to limit the number of annotation database displayed, or Use option -v 0 to suppress descriptions of databases.   Examples: Show all annotation databases Show all annotation databases. With this command, variant tools connects to its ftp server and list all available annotation databases.\n% vtools show annotations | head -50 CancerGeneCensus-20111215 Cancer Genome Project CancerGeneCensus-20120315 Cancer Genome Project CancerGeneCensus Cancer Genome Project CosmicCodingMuts-v61_260912 Cosmic coding mutation database. This data contains mutations affecting 10 or less nucleotides in REF. The mutation data was obtained from the Sanger Institute Catalogue Of Somatic Mutations In Cancer web site, http://www.sanger.ac.uk/cosmic. Bamford et al (2004). The COSMIC (Catalogue of Somatic Mutations in Cancer) database and website. Br J Cancer, 91,355-358. CosmicCodingMuts Cosmic coding mutation database. This data contains mutations affecting 10 or less nucleotides in REF. The mutation data was obtained from the Sanger Institute Catalogue Of Somatic Mutations In Cancer web site, http://www.sanger.ac.uk/cosmic. Bamford et al (2004). The COSMIC (Catalogue of Somatic Mutations in Cancer) database and website. Br J Cancer, 91,355-358. CosmicMutantExport-v61_260912 Cosmic mutant export. This data contains all coding point mutations. The mutation data was obtained from the Sanger Institute Catalogue Of Somatic Mutations In Cancer web site, http://www.sanger.ac.uk/cosmic. Bamford et al (2004). The COSMIC (Catalogue of Somatic Mutations in Cancer) database and website. Br J Cancer, 91,355-358. CosmicMutantExport Cosmic mutant export. This data contains all coding point mutations. The mutation data was obtained from the Sanger Institute Catalogue Of Somatic Mutations In Cancer web site, http://www.sanger.ac.uk/cosmic. Bamford et al (2004). The COSMIC (Catalogue of Somatic Mutations in Cancer) database and website. Br J Cancer, 91,355-358. CosmicNonCodingVariants-v61_260912 Cosmic non-coding mutation database. This data contains mutations affecting 10 or less nucleotides in REF. The mutation data was obtained from the Sanger Institute Catalogue Of Somatic Mutations In Cancer web site, http://www.sanger.ac.uk/cosmic. Bamford et al (2004). The COSMIC (Catalogue of Somatic Mutations in Cancer) database and website. Br J Cancer, 91,355-358. CosmicNonCodingVariants Cosmic non-coding mutation database. This data contains mutations affecting 10 or less nucleotides in REF. The mutation data was obtained from the Sanger Institute Catalogue Of Somatic Mutations In Cancer web site, http://www.sanger.ac.uk/cosmic. Bamford et al (2004). The COSMIC (Catalogue of Somatic Mutations in Cancer) database and website. Br J Cancer, 91,355-358. ccdsGene-hg19_20110909 CCDS Genes ccdsGene-hg19_20111206 CCDS Genes ccdsGene CCDS Genes ccdsGene_exon-hg19_20110909 CCDS exons  You can list a subset of annotation databases by specifying one or more patterns:\n% vtools show annotations thousand ccds ccdsGene-hg19_20110909 CCDS Genes ccdsGene-hg19_20111206 CCDS Genes ccdsGene-hg19_20130904 High-confidence human gene annotations from the Consensus Coding Sequence (CCDS) project. ccdsGene-hg38_20171008 High-confidence human gene annotations from the Consensus Coding Sequence (CCDS) project. ccdsGene_exon-hg19_20110909 CCDS exons ccdsGene_exon-hg19_20111206 CCDS exons ccdsGene_exon-hg19_20130904 High-confidence human gene annotations from the Consensus Coding Sequence (CCDS) project. This database contains all exon regions of the CCDS genes. ccdsGene_exon-hg38_20171008 CCDS exons ccdsGene_exon_hg19-20111206 CCDS exons ccdsGene_hg19-20111206 CCDS Genes thousandGenomes-hg19_20130502 Phase 3 data of the thousand genomes project, created from ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/release/20130502/ALL.wgs.p hase3_shapeit2_mvncall_integrated_v5a.20130502.sites.vcf.gz thousandGenomes-hg19_v3_20101123 1000 Genomes VCF file analyzed in March 2012 from data generated from phase 1 of the project (available from: ftp://ftp.1000ge nomes.ebi.ac.uk/vol1/ftp/release/20110521/ALL.wgs.phase1_release_v3.201 01123.snps_indels_sv.sites.vcf.gz). thousandGenomes-hg19_v5b_20130502 1000 Genomes VCF file analyzed in February 2015 from data generated from phase 1 of the project (available from: ftp://ftp.1000ge nomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.wgs.phase3_shapeit2_mvnca ll_integrated_v5b.20130502.sites.vcf.gz.)  If you only need to see a list annotation databases without description, you can pass the -v0 option,\n% vtools show annotations gene -v0 CancerGeneCensus-20111215 CancerGeneCensus-20120315 CancerGeneCensus-20130711 CancerGeneCensus-20170912 EntrezGene-20131028 EntrezGene-20170919 EntrezGene2RefSeq-20131028 EntrezGene2RefSeq-20170919 ccdsGene-hg19_20110909 ccdsGene-hg19_20111206 ccdsGene-hg19_20130904 ccdsGene-hg38_20171008 ccdsGene_exon-hg19_20110909 ccdsGene_exon-hg19_20111206 ccdsGene_exon-hg19_20130904 ccdsGene_exon-hg38_20171008 ccdsGene_exon_hg19-20111206 ccdsGene_hg19-20111206 dbNSFP_gene-2_0 dbNSFP_gene-2_1 dbNSFP_gene-2_3 dbNSFP_gene-2_4 dbNSFP_gene-2_7 dbNSFP_gene-3_5a knownGene-hg18_20110909 knownGene-hg18_20121219 knownGene-hg19_20110909 knownGene-hg19_20121219 knownGene-hg19_20130904 knownGene-hg38_20160328 knownGene_exon-hg18_20110909 knownGene_exon-hg19_20110909 knownGene_exon-hg19_20130904 knownGene_exon-hg38_20160328 refGene-hg18_20110909 refGene-hg19_20110909 refGene-hg19_20130904 refGene-hg38_20170201 refGene-mm10_20141201 refGene_coding-hg19_20130904 refGene_exon-hg18_20110909 refGene_exon-hg19_20110909 refGene_exon-hg19_20130904 refGene_exon-mm10_20141201 refGene_exon-mm10_20171008  \nAfter using an annotation database with command vtools use, you can view the details of the annotation database using command vtools show annotation ANNODB. By default, this command displays basic information of the annotation database (type, number of records etc), and name and comment of each annotation field. If an -v 2 option is specified, it will also list the details of each fields, including range, unique values, and number of missing values.\n Examples: Show details of an annotation database\n% vtools show annotation knownGene Annotation database knownGene (version hg19_20121219) Description: UCSC Known Genes Database type: range Reference genome hg19: chr, txStart, txEnd name Name of gene such as uc001aaa.3 chr strand which DNA strand contains the observed alleles txStart Transcription start position txEnd Transcription end position cdsStart Coding region start cdsEnd Coding region end exonCount Number of exons % vtools show annotation knownGene -v2 DEBUG: DEBUG: vtools show annotation knownGene -v2 DEBUG: Using temporary directory /var/folders/5b/4qkyrb3519qgn77s62853xrh0000gn/T/tmp3kkA40 DEBUG: Opening project show.proj DEBUG: Loading annotation database ~/.variant_tools/annoDB/knownGene-hg19_20121219.DB Annotation database knownGene (version hg19_20121219) Description: UCSC Known Genes Database type: range Number of records: 80,922 Distinct ranges: 59,942 Reference genome hg19: chr, txStart, txEnd Field: name Type: string Comment: Name of gene such as uc001aaa.3 Missing entries: 0 Unique Entries: 80,922 Field: chr Type: string Missing entries: 0 Unique Entries: 60 Field: strand Type: string Comment: which DNA strand contains the observed alleles Missing entries: 0 Unique Entries: 2 Field: txStart Type: integer Comment: Transcription start position Missing entries: 0 Unique Entries: 48,076 Range: 1 - 249211537 Field: txEnd Type: integer Comment: Transcription end position Missing entries: 0 Unique Entries: 48,025 Range: 368 - 249213345 Field: cdsStart Type: integer Comment: Coding region start Missing entries: 0 Unique Entries: 50,891 Range: 1 - 249211537 Field: cdsEnd Type: integer Comment: Coding region end Missing entries: 0 Unique Entries: 50,876 Range: 0 - 249212562 Field: exonCount Type: integer Comment: Number of exons Missing entries: 0 Unique Entries: 115 Range: 1 - 4461  \n2.8 Show details of annotation tracks (track) variant tools supports the use of annotation tracks to annotate and select variants. These tracks can be in tabix-indexed vcf files, indexed BAM file, bigBed and bigWig format and provides differnt fields through the second parameter of function track(filename, field). Command vtools show track is provided to display the details of each track file.\n Examples: show details of a local vcf track  Show details of a local vcf track file:\n% vtools show track CEU.vcf.gz | head -30 Version VCF v4.0 Number of fields: 69 Header: (exclude INFO and FORMAT lines) ##reference=human_b36_both.fasta ##rsIDs=dbSNP b129 mapped to NCBI 36.3, August 10, 2009 Available columns (with default type VARCHAR): 0 (INTEGER) 1 if matched chr (1, chrom) chromosome pos (2 for INTEGER) position (1-based) name (3) name of variant ref (4) reference allele alt (5) alternative alleles qual (6) qual filter (7) filter info (8, default) variant info fields info.DP Total Depth info.HM2 HapMap2 membership info.HM3 HapMap3 membership info.AA Ancestral Allele, ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/technical/reference/ancestral_alignments/README info.AC Allele count in genotypes info.AN Total number of alleles in called genotypes format (9) genotype format NA06985 (10) genotype for sample NA06985 NA06985.GT Genotype for sample NA06985 NA06985.DP Read Depth for sample NA06985 NA06985.CB Called by S(Sanger), M(UMich), B(BI) for sample NA06985 NA06986 (11) genotype for sample NA06986 NA06986.GT Genotype for sample NA06986  \nAlthough cannot be used as track files, vtools show track can display information of plain vcf file (not compressed, with extension .vcf), which can be used to show useful information of the header of such files.\n Examples: show details of an online vcf track \n% vtools show track http://ftp-trace.ncbi.nih.gov/1000genomes/ftp/release/20110521/ALL.chr1.phase1_release_v3.20101123.snps_indels_svs.genotypes.vcf.gz | head -30 Version VCF v4.1 Number of fields: 1101 Header: (exclude INFO and FORMAT lines) ##ALT=\u0026lt;ID=DEL,Description=\u0026quot;Deletion\u0026quot;\u0026gt; ##reference=GRCh37 ##reference=GRCh37 Available columns (with default type VARCHAR): 0 (INTEGER) 1 if matched chr (1, chrom) chromosome pos (2 for INTEGER) position (1-based) name (3) name of variant ref (4) reference allele alt (5) alternative alleles qual (6) qual filter (7) filter info (8, default) variant info fields info.LDAF MLE Allele Frequency Accounting for LD info.AVGPOST Average posterior probability from MaCH/Thunder info.RSQ Genotype imputation quality from MaCH/Thunder info.ERATE Per-marker Mutation rate from MaCH/Thunder info.THETA Per-marker Transition rate from MaCH/Thunder info.CIEND Confidence interval around END for imprecise variants info.CIPOS Confidence interval around POS for imprecise variants info.END End position of the variant described in this record info.HOMLEN Length of base pair identical micro-homology at event breakpoints info.HOMSEQ Sequence of base pair identical micro-homology at event breakpoints info.SVLEN Difference in length between REF and ALT alleles info.SVTYPE Type of structural variant  \n Examples: show details of a bigBed track \n% vtools show track wgEncodeDukeDnase8988T.fdr01peaks.hg19.bb Version: 4 Item count: 196180 Primary data size: 1806867 Zoom levels: 8 Chrom count: 23 Chrom size: chr1 249250621 chr10 135534747 chr11 135006516 chr12 133851895 chr13 115169878 chr14 107349540 chr15 102531392 chr16 90354753 chr17 81195210 chr18 78077248 chr19 59128983 chr2 243199373 chr20 63025520 chr21 48129895 chr22 51304566 chr3 198022430 chr4 191154276 chr5 180915260 chr6 171115067 chr7 159138663 chr8 146364022 chr9 141213431 chrX 155270560 Bases covered 29405430 Mean depth: 1.000734 Min depth: 1.000000 Max depth: 2.000000 Std of depth: 0.027074 Number of fields: 10 Available columns (with default type VARCHAR): chrom (1) Name of the chromosome (or contig, scaffold, etc.). chromStart (2 as INTEGER) The starting position of the feature in the chromosome or scaffold. The first base in a chromosome is numbered 0. chromEnd (3 as INTEGER) The ending position of the feature in the chromosome or scaffold. The chromEnd base is not included in the display of the feature. For example, the first 100 bases of a chromosome are defined as chromStart=0, chromEnd=100, and span the bases numbered 0-99. name (4) Name given to a region (preferably unique). Use '.' if no name is assigned. score (5 as INTEGER) Indicates how dark the peak will be displayed in the browser (0-1000). If all scores were '0' when the data were submitted to the DCC, the DCC assigned scores 1-1000 based on signal value. Ideally the average signalValue per base spread is between 100-1000. strand (6) +/- to denote strand or orientation (whenever applicable). Use '.' if no orientation is assigned. signalValue (7 as FLOAT) Measurement of overall (usually, average) enrichment for the region pValue (8 as FLOAT) Measurement of statistical significance (-log10, -1 if no pValue is assigned) qValue (9 as FLOAT) Measurement of statistical significance using false discovery rate (-log10, -1 if no qValue is assigned) peak (10 as INTEGER) Point-source called for this peak; 0-based offset from chromStart (-1 if no point-source called)  \n Examples: show details of a bigWig track \n% vtools show track ~/vtools/wgEncodeGisRnaSeqH1hescCellPapPlusRawRep1.bigWig Version: 4 Primary data size 226114375 Zoom levels: 10 Chrom count: 25 Chrom size: chr1 249250621 chr10 135534747 chr11 135006516 chr12 133851895 chr13 115169878 chr14 107349540 chr15 102531392 chr16 90354753 chr17 81195210 chr18 78077248 chr19 59128983 chr2 243199373 chr20 63025520 chr21 48129895 chr22 51304566 chr3 198022430 chr4 191154276 chr5 180915260 chr6 171115067 chr7 159138663 chr8 146364022 chr9 141213431 chrM 16571 chrX 155270560 chrY 59373566 Bases covered: 84281746 Mean: 10.253978 Min: 1.000000 Max: 46751.000000 std: 119.977095 Number of fields: 4 Available columns (with default type VARCHAR): 0 (INTEGER) 1 if matched chrom (1) chromosome chromStart (2 as INTEGER) start position (0-based) chromEnd (3 as INTEGER) end position (1-based) value (4 as FLOAT) value  \n Examples: show details of an online BAM track  For indexed BAM file, this command lists the header of the BAM file, size of chromosomes, and available fields:\n% vtools show track ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data/HG00096/alignment/HG00096.chrom11.ILLUMINA.bwa.GBR.low_coverage.20120522.bam [bam_index_load] attempting to download the remote index file. [bam_index_load] attempting to download the remote index file. Header: @HD VN:1.0 SO:coordinate @SQ SN:1 LN:249250621 M5:1b22b98cdeb4a9304cb5d48026a85128 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:2 LN:243199373 M5:a0d9851da00400dec1098a9255ac712e UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:3 LN:198022430 M5:fdfd811849cc2fadebc929bb925902e5 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:4 LN:191154276 M5:23dccd106897542ad87d2765d28a19a1 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:5 LN:180915260 M5:0740173db9ffd264d728f32784845cd7 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:6 LN:171115067 M5:1d3a93a248d92a729ee764823acbbc6b UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:7 LN:159138663 M5:618366e953d6aaad97dbe4777c29375e UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:8 LN:146364022 M5:96f514a9929e410c6651697bded59aec UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:9 LN:141213431 M5:3e273117f15e0a400f01055d9f393768 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:10 LN:135534747 M5:988c28e000e84c26d552359af1ea2e1d UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:11 LN:135006516 M5:98c59049a2df285c76ffb1c6db8f8b96 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:12 LN:133851895 M5:51851ac0e1a115847ad36449b0015864 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:13 LN:115169878 M5:283f8d7892baa81b510a015719ca7b0b UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:14 LN:107349540 M5:98f3cae32b2a2e9524bc19813927542e UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:15 LN:102531392 M5:e5645a794a8238215b2cd77acb95a078 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:16 LN:90354753 M5:fc9b1a7b42b97a864f56b348b06095e6 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:17 LN:81195210 M5:351f64d4f4f9ddd45b35336ad97aa6de UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:18 LN:78077248 M5:b15d4b2d29dde9d3e4f93d1d0f2cbc9c UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:19 LN:59128983 M5:1aacd71f30db8e561810913e0b72636d UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:20 LN:63025520 M5:0dec9660ec1efaaf33281c0d5ea2560f UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:21 LN:48129895 M5:2979a6085bfe28e3ad6f552f361ed74d UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:22 LN:51304566 M5:a718acaa6135fdca8357d5bfe94211dd UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:X LN:155270560 M5:7e0e2e580297b7764e31dbc80c2540dd UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:Y LN:59373566 M5:1fa3474750af0948bdf97d5a0ee52e51 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:MT LN:16569 M5:c68f52674c9fb33aef52dcf399755519 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000207.1 LN:4262 M5:f3814841f1939d3ca19072d9e89f3fd7 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000226.1 LN:15008 M5:1c1b2cd1fccbc0a99b6a447fa24d1504 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000229.1 LN:19913 M5:d0f40ec87de311d8e715b52e4c7062e1 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000231.1 LN:27386 M5:ba8882ce3a1efa2080e5d29b956568a4 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000210.1 LN:27682 M5:851106a74238044126131ce2a8e5847c UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000239.1 LN:33824 M5:99795f15702caec4fa1c4e15f8a29c07 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000235.1 LN:34474 M5:118a25ca210cfbcdfb6c2ebb249f9680 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000201.1 LN:36148 M5:dfb7e7ec60ffdcb85cb359ea28454ee9 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000247.1 LN:36422 M5:7de00226bb7df1c57276ca6baabafd15 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000245.1 LN:36651 M5:89bc61960f37d94abf0df2d481ada0ec UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000197.1 LN:37175 M5:6f5efdd36643a9b8c8ccad6f2f1edc7b UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000203.1 LN:37498 M5:96358c325fe0e70bee73436e8bb14dbd UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000246.1 LN:38154 M5:e4afcd31912af9d9c2546acf1cb23af2 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000249.1 LN:38502 M5:1d78abec37c15fe29a275eb08d5af236 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000196.1 LN:38914 M5:d92206d1bb4c3b4019c43c0875c06dc0 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000248.1 LN:39786 M5:5a8e43bec9be36c7b49c84d585107776 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000244.1 LN:39929 M5:0996b4475f353ca98bacb756ac479140 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000238.1 LN:39939 M5:131b1efc3270cc838686b54e7c34b17b UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000202.1 LN:40103 M5:06cbf126247d89664a4faebad130fe9c UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000234.1 LN:40531 M5:93f998536b61a56fd0ff47322a911d4b UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000232.1 LN:40652 M5:3e06b6741061ad93a8587531307057d8 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000206.1 LN:41001 M5:43f69e423533e948bfae5ce1d45bd3f1 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000240.1 LN:41933 M5:445a86173da9f237d7bcf41c6cb8cc62 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000236.1 LN:41934 M5:fdcd739913efa1fdc64b6c0cd7016779 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000241.1 LN:42152 M5:ef4258cdc5a45c206cea8fc3e1d858cf UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000243.1 LN:43341 M5:cc34279a7e353136741c9fce79bc4396 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000242.1 LN:43523 M5:2f8694fc47576bc81b5fe9e7de0ba49e UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000230.1 LN:43691 M5:b4eb71ee878d3706246b7c1dbef69299 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000237.1 LN:45867 M5:e0c82e7751df73f4f6d0ed30cdc853c0 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000233.1 LN:45941 M5:7fed60298a8d62ff808b74b6ce820001 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000204.1 LN:81310 M5:efc49c871536fa8d79cb0a06fa739722 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000198.1 LN:90085 M5:868e7784040da90d900d2d1b667a1383 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000208.1 LN:92689 M5:aa81be49bf3fe63a79bdc6a6f279abf6 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000191.1 LN:106433 M5:d75b436f50a8214ee9c2a51d30b2c2cc UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000227.1 LN:128374 M5:a4aead23f8053f2655e468bcc6ecdceb UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000228.1 LN:129120 M5:c5a17c97e2c1a0b6a9cc5a6b064b714f UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000214.1 LN:137718 M5:46c2032c37f2ed899eb41c0473319a69 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000221.1 LN:155397 M5:3238fb74ea87ae857f9c7508d315babb UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000209.1 LN:159169 M5:f40598e2a5a6b26e84a3775e0d1e2c81 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000218.1 LN:161147 M5:1d708b54644c26c7e01c2dad5426d38c UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000220.1 LN:161802 M5:fc35de963c57bf7648429e6454f1c9db UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000213.1 LN:164239 M5:9d424fdcc98866650b58f004080a992a UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000211.1 LN:166566 M5:7daaa45c66b288847b9b32b964e623d3 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000199.1 LN:169874 M5:569af3b73522fab4b40995ae4944e78e UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000217.1 LN:172149 M5:6d243e18dea1945fb7f2517615b8f52e UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000216.1 LN:172294 M5:642a232d91c486ac339263820aef7fe0 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000215.1 LN:172545 M5:5eb3b418480ae67a997957c909375a73 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000205.1 LN:174588 M5:d22441398d99caf673e9afb9a1908ec5 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000219.1 LN:179198 M5:f977edd13bac459cb2ed4a5457dba1b3 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000224.1 LN:179693 M5:d5b2fc04f6b41b212a4198a07f450e20 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000223.1 LN:180455 M5:399dfa03bf32022ab52a846f7ca35b30 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000195.1 LN:182896 M5:5d9ec007868d517e73543b005ba48535 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000212.1 LN:186858 M5:563531689f3dbd691331fd6c5730a88b UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000222.1 LN:186861 M5:6fe9abac455169f50470f5a6b01d0f59 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000200.1 LN:187035 M5:75e4c8d17cd4addf3917d1703cacaf25 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000193.1 LN:189789 M5:dbb6e8ece0b5de29da56601613007c2a UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000194.1 LN:191469 M5:6ac8f815bf8e845bb3031b73f812c012 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000225.1 LN:211173 M5:63945c3e6962f28ffd469719a747e73c UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:GL000192.1 LN:547496 M5:325ba9e808f669dfeee210fdd7b470ac UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:NC_007605 LN:171823 M5:6743bd63b3ff2b5b8985d8933c53290a UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @SQ SN:hs37d5 LN:35477943 M5:5b6a4b3a81a2d3c134b7d14bf6ad39f1 UR:ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz AS:NCBI37 SP:Human @RG ID:SRR062634 LB:2845856850 SM:HG00096 PI:206 CN:WUGSC PL:ILLUMINA DS:SRP001294 @RG ID:SRR062635 LB:2845856850 SM:HG00096 PI:206 CN:WUGSC PL:ILLUMINA DS:SRP001294 @RG ID:SRR062641 LB:2845856850 SM:HG00096 PI:206 CN:WUGSC PL:ILLUMINA DS:SRP001294 @PG ID:bwa_index PN:bwa VN:0.5.9-r16 CL:bwa index -a bwtsw $reference_fasta @PG ID:bwa_aln_fastq PN:bwa PP:bwa_index VN:0.5.9-r16 CL:bwa aln -q 15 -f $sai_file $reference_fasta $fastq_file @PG ID:bwa_sam PN:bwa PP:bwa_aln_fastq VN:0.5.9-r16 CL:bwa sampe -a 618 -r $rg_line -f $sam_file $reference_fasta $sai_file(s) $fastq_file(s) @PG ID:sam_to_fixed_bam PN:samtools PP:bwa_sam VN:0.1.17 (r973:277) CL:samtools view -bSu $sam_file | samtools sort -n -o - samtools_nsort_tmp | samtools fixmate /dev/stdin /dev/stdout | samtools sort -o - samtools_csort_tmp | samtools fillmd -u - $reference_fasta \u0026gt; $fixed_bam_file @PG ID:gatk_target_interval_creator PN:GenomeAnalysisTK PP:sam_to_fixed_bam VN:1.2-29-g0acaf2d CL:java $jvm_args -jar GenomeAnalysisTK.jar -T RealignerTargetCreator -R $reference_fasta -o $intervals_file -known $known_indels_file(s) @PG ID:bam_realignment_around_known_indels PN:GenomeAnalysisTK PP:gatk_target_interval_creator VN:1.2-29-g0acaf2d CL:java $jvm_args -jar GenomeAnalysisTK.jar -T IndelRealigner -R $reference_fasta -I $bam_file -o $realigned_bam_file -targetIntervals $intervals_file -known $known_indels_file(s) -LOD 0.4 -model KNOWNS_ONLY -compress 0 --disable_bam_indexing @PG ID:bam_count_covariates PN:GenomeAnalysisTK PP:bam_realignment_around_known_indels VN:1.2-29-g0acaf2d CL:java $jvm_args -jar GenomeAnalysisTK.jar -T CountCovariates -R $reference_fasta -I $bam_file -recalFile $bam_file.recal_data.csv -knownSites $known_sites_file(s) -l INFO -L '1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18;19;20;21;22;X;Y;MT' -cov ReadGroupCovariate -cov QualityScoreCovariate -cov CycleCovariate -cov DinucCovariate @PG ID:bam_recalibrate_quality_scores PN:GenomeAnalysisTK PP:bam_count_covariates VN:1.2-29-g0acaf2d CL:java $jvm_args -jar GenomeAnalysisTK.jar -T TableRecalibration -R $reference_fasta -recalFile $bam_file.recal_data.csv -I $bam_file -o $recalibrated_bam_file -l INFO -compress 0 --disable_bam_indexing @PG ID:bam_calculate_bq PN:samtools PP:bam_recalibrate_quality_scores VN:0.1.17 (r973:277) CL:samtools calmd -Erb $bam_file $reference_fasta \u0026gt; $bq_bam_file @PG ID:bam_merge PN:picard PP:bam_calculate_bq VN:1.53 CL:java $jvm_args -jar MergeSamFiles.jar INPUT=$bam_file(s) OUTPUT=$merged_bam VALIDATION_STRINGENCY=SILENT @PG ID:bam_mark_duplicates PN:picard PP:bam_merge VN:1.53 CL:java $jvm_args -jar MarkDuplicates.jar INPUT=$bam_file OUTPUT=$markdup_bam_file ASSUME_SORTED=TRUE METRICS_FILE=/dev/null VALIDATION_STRINGENCY=SILENT @PG ID:bam_merge.1 PN:picard PP:bam_mark_duplicates VN:1.53 CL:java $jvm_args -jar MergeSamFiles.jar INPUT=$bam_file(s) OUTPUT=$merged_bam VALIDATION_STRINGENCY=SILENT @CO $known_indels_file(s) = ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_mapping_resources/ALL.wgs.indels_mills_devine_hg19_leftAligned_collapsed_double_hit.indels.sites.vcf.gz @CO $known_indels_file(s) .= ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_mapping_resources/ALL.wgs.low_coverage_vqsr.20101123.indels.sites.vcf.gz @CO $known_sites_file(s) = ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_mapping_resources/ALL.wgs.dbsnp.build135.snps.sites.vcf.gz Chrom size: 86 1 249250621 2 243199373 3 198022430 4 191154276 5 180915260 6 171115067 7 159138663 8 146364022 9 141213431 10 135534747 11 135006516 12 133851895 13 115169878 14 107349540 15 102531392 16 90354753 17 81195210 18 78077248 19 59128983 20 63025520 21 48129895 22 51304566 X 155270560 Y 59373566 MT 16569 GL000207.1 4262 GL000226.1 15008 GL000229.1 19913 GL000231.1 27386 GL000210.1 27682 GL000239.1 33824 GL000235.1 34474 GL000201.1 36148 GL000247.1 36422 GL000245.1 36651 GL000197.1 37175 GL000203.1 37498 GL000246.1 38154 GL000249.1 38502 GL000196.1 38914 GL000248.1 39786 GL000244.1 39929 GL000238.1 39939 GL000202.1 40103 GL000234.1 40531 GL000232.1 40652 GL000206.1 41001 GL000240.1 41933 GL000236.1 41934 GL000241.1 42152 GL000243.1 43341 GL000242.1 43523 GL000230.1 43691 GL000237.1 45867 GL000233.1 45941 GL000204.1 81310 GL000198.1 90085 GL000208.1 92689 GL000191.1 106433 GL000227.1 128374 GL000228.1 129120 GL000214.1 137718 GL000221.1 155397 GL000209.1 159169 GL000218.1 161147 GL000220.1 161802 GL000213.1 164239 GL000211.1 166566 GL000199.1 169874 GL000217.1 172149 GL000216.1 172294 GL000215.1 172545 GL000205.1 174588 GL000219.1 179198 GL000224.1 179693 GL000223.1 180455 GL000195.1 182896 GL000212.1 186858 GL000222.1 186861 GL000200.1 187035 GL000193.1 189789 GL000194.1 191469 GL000225.1 211173 GL000192.1 547496 NC_007605 171823 hs37d5 35477943 Tags that can be outputed or used in filters, with values from the 1st record: X0 c (int8) : 10 X1 c (int8) : 0 MD Z (string) : 0A99 RG Z (string) : SRR062634 AM c (int8) : 0 NM c (int8) : 1 SM c (int8) : 0 MQ c (int8) : 0 XT A (char) : R BQ Z (string) : C[Y@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ Parameters min_qual, min_mapq and TAG=VAL can be used to limit the reads to the ones with mapq and qual scores that exceed the specified value, and with specified TAG.  \nThe header of BAM track provides many important information about the bam file. You should consult the SAM format specification for the meaning of them, but briefly:\n HD - header: VN is for file format version, SO for sort order, which can be unsorted, queryname or coordinate. SQ - Sequence dictionary: SN is sequence name, @LNis sequence length. This might repeat the chromome length information listed below.ASreference genome used for assembly,SP@@ for species. RG - Read group: ID for read group identifier, SM for sample, LB for library, DS for description, PU for platform unit, DT for date the run was produced, PL for platform (e.g. illumina). PG - Program: ID for program name, VN for program version, CL for command line. CO - Comment  The tags are also important if you need to filter reads by tag values. For example, RG can be used to differentiate reads that belong to different samples if the bam file contains reads from multiple samples.\n2.9 Show supported input and output file formats (formats and format) variant tools repository has a number of file format description files .fmt that defines a formats of files that can be used for commands vtools import, vtools update --from_file, and vtools export. To get a complete list of supported file formats, you can use command vtools show formats. Options -v0 and --limit are supported to suppress comment and limit number of formats to display, respectively.\n Examples: Show a list of supported input/output file formats Command vtools show formats display a long list of file formats that are supported by variant tools:\n% vtools show formats | head -50 CASAVA18_snps Input format illumina snps.txt file, created by CASAVA version 1.8 (http://www.illumina.com/support/documentation.ilmn). This format imports chr, pos, ref, alt of most likely genotype, and a Q score for the most likely genotype. plink Input format for PLINK dataset. Currently only PLINK binary PED file format is supported (*.bed, *.bim \u0026amp; *.fam) ANNOVAR Input format of ANNOVAR. No genotype is defined. pileup_indel Input format for samtools pileup indel caller. This format imports chr, pos, ref, alt and genotype. ANNOVAR_exonic_variant_function Output from ANNOVAR, generated from command \u0026quot;path/to/annovar/annotate_variation.pl annovar.txt path/to/annovar/humandb/\u0026quot;. This format imports chr, pos, ref, alt and ANNOVAR annotations. For details please refer to http://www.openbioinformatics.org/anno var/annovar_gene.html ANNOVAR_variant_function Output from ANNOVAR for files of type \u0026quot;*.variant_function\u0026quot;, generated from command \u0026quot;path/to/annovar/annotate_variation.pl annovar.txt path/to/annovar/humandb/\u0026quot;. This format imports chr, pos, ref, alt and ANNOVAR annotations. For details please refer to http://www.openbioinformatics.org/anno var/annovar_gene.html CGA Input format from Complete Genomics Variant file masterVarBeta-[ASM-ID].tsv.bz2, created by Complete Genomcis Analysis Tools (GSA Tools 1.5 or eariler, http://www.completegenomics.com/sequence- data/cgatools/, http://media.completegenomics.com/docu ments/DataFileFormats+Standard+Pipeline+2.0.pdf). This format imports chr, pos, ref, alt of only variants that have been fully called and are not equals to ref. (E.g. records with zygosity equal to no-call and half, and varType equal to ref are discarded.) map This input format imports variants from files in MAP format (with columns chr, name gen_dist, pos), or any delimiter-separated format with columns chr and pos. Because these input files do not contain reference and alternative alleles of variants, this format queries such information from the dbSNP database using chr and pos. Records that does not exist in dbSNP will be discarded. Records with multiple alternative alleles will lead to multiple records. polyphen2 To be used to export variants in a format that is acceptable by the polyphen2 server http://genetics.bwh.harvard.edu/pph2/bgi.shtml, and to import the FULL report returned by this server. basic A basic variant input format with four columns: chr, pos, ref, alt. vcf Import vcf  Comments can be suppressed using option -v0,\n% vtools show formats -v0 CASAVA18_snps plink ANNOVAR pileup_indel ANNOVAR_exonic_variant_function ANNOVAR_variant_function CGA map polyphen2 basic vcf CASAVA18_indels csv tped  \nYou can use command vtools show format FMT to list the details of a format. Note that\n Columns are used to direct output. If no column is specified, the format cannot be used for command vtools export. A input file format can have type variant, position, and range. Command vtools import can only import data from variant-based files (because it imports variants). In comparison, command vtools update can update existing variant using all three types of input files. Format options can be used to customized how to import/export data using the format.   Examples: Show details of a format If you would like to know the details of one specific format, you can use command vtools show format FORMAT,\n% vtools show format map Format: map Description: This input format imports variants from files in MAP format (with columns chr, name gen_dist, pos), or any delimiter-separated format with columns chr and pos. Because these input files do not contain reference and alternative alleles of variants, this format queries such information from the dbSNP database using chr and pos. Records that does not exist in dbSNP will be discarded. Records with multiple alternative alleles will lead to multiple records. Columns: None defined, cannot export to this format variant: chr Chromosome pos 1-based position ref Reference allele, '-' for insertion. alt Alternative allele obtained from another database Format parameters: db_file (default: dbSNP.DB) pos_idx Index of column for pyhysical location in the map file, should be 4 for a standard map file with chr, pos, gen_dist, pos. (default: 4) ref_field Name of ref field from the annotation database, used to retrieve reference allele at specified location. (default: refNCBI) alt_field Name of alt field from the annotation database, used to retrieve alternative allele at specified location. (default: alt) chr_field Name of chr field from the annotation database, used to locate variants from the dbSNP database. (default: chr) pos_field Name of pos field from the annotation database, used to locate variants from the dbSNP database. (default: start) separator Separator of the input file, default to space or tab. (default: None)  \n2.10 Show association tests (tests and test) Command vtools show tests shows a list of association tests that can be used in command vtools associate. Similar to other commands, option -v0 and --limit can be used to suppress description of tests and limit the number of tests to display.\n Examples: Show a list of supported association tests List all available association tests.\n% vtools show tests BurdenBt Burden test for disease traits, Morris \u0026amp; Zeggini 2009 BurdenQt Burden test for quantitative traits, Morris \u0026amp; Zeggini 2009 CFisher Fisher's exact test on collapsed variant loci, Li \u0026amp; Leal 2008 Calpha c-alpha test for unusual distribution of variants between cases and controls, Neale et al 2011 CollapseBt Collapsing method for disease traits, Li \u0026amp; Leal 2008 CollapseQt Collapsing method for quantitative traits, Li \u0026amp; Leal 2008 GroupStat Calculates basic statistics for each testing group GroupWrite Write data to disk for each testing group KBAC Kernel Based Adaptive Clustering method, Liu \u0026amp; Leal 2010 LinRegBurden A versatile framework of association tests for quantitative traits LogitRegBurden A versatile framework of association tests for disease traits RBT Replication Based Test for protective and deleterious variants, Ionita-Laza et al 2011 RTest A general framework for association analysis using R programs RareCover A \u0026quot;covering\u0026quot; method for detecting rare variants association, Bhatia et al 2010. SKAT SKAT (Wu et al 2011) and SKAT-O (Lee et al 2012) SSeq_common Score statistic / SCORE-Seq software (Tang \u0026amp; Lin 2011), for common variants analysis SSeq_rare Score statistic / SCORE-Seq software (Tang \u0026amp; Lin 2011), for rare variants analysis VTtest VT statistic for disease traits, Price et al 2010 VariableThresholdsBt Variable thresholds method for disease traits, in the spirit of Price et al 2010 VariableThresholdsQt Variable thresholds method for quantitative traits, in the spirit of Price et al 2010 WSSRankTest Weighted sum method using rank test statistic, Madsen \u0026amp; Browning 2009 WeightedBurdenBt Weighted genotype burden tests for disease traits, using one or many arbitrary external weights as well as one of 4 internal weighting themes WeightedBurdenQt Weighted genotype burden tests for quantitative traits, using one or many arbitrary external weights as well as one of 4 internal weighting themes aSum Adaptive Sum score test for protective and deleterious variants, Han \u0026amp; Pan 2010  Display only the first 5 tests without description:\n% vtools show tests -v0 -l 5 BurdenBt BurdenQt CFisher Calpha CollapseBt (19 records omitted)  \nIf you are interested in more details of a particular test, you can use command vtools show test TEST. This should give you a detailed description of the test, and all the options the test accept.\n Examples: Show details of an association test\n% vtools show test LogitRegBurden Name: LogitRegBurden Description: A versatile framework of association tests for disease traits usage: vtools associate --method LogitRegBurden [-h] [--name NAME] [-q1 MAFUPPER] [-q2 MAFLOWER] [--alternative TAILED] [--use_indicator] [-p N] [--permute_by XY] [--adaptive C] [--variable_thresholds] [--extern_weight [EXTERN_WEIGHT [EXTERN_WEIGHT ...]]] [--weight {Browning_all,Browning,KBAC,RBT}] [--NA_adjust] [--moi {additive,dominant,recessive}] Logistic regression test. p-value is based on the significance level of the regression coefficient for genotypes. If --group_by option is specified, it will collapse the variants within a group into a generic genotype score optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. -q1 MAFUPPER, --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 1.0 -q2 MAFLOWER, --maflower MAFLOWER Minor allele frequency lower limit. All variants having sample MAF\u0026gt;m2 will be included in analysis. Default set to 0.0 --alternative TAILED Alternative hypothesis is one-sided (\u0026quot;1\u0026quot;) or two-sided (\u0026quot;2\u0026quot;). Default set to 1 --use_indicator This option, if evoked, will apply binary coding to genotype groups (coding will be \u0026quot;1\u0026quot; if ANY locus in the group has the alternative allele, \u0026quot;0\u0026quot; otherwise) -p N, --permutations N Number of permutations --permute_by XY Permute phenotypes (\u0026quot;Y\u0026quot;) or genotypes (\u0026quot;X\u0026quot;). Default is \u0026quot;Y\u0026quot; --adaptive C Adaptive permutation using Edwin Wilson 95 percent confidence interval for binomial distribution. The program will compute a p-value every 1000 permutations and compare the lower bound of the 95 percent CI of p-value against \u0026quot;C\u0026quot;, and quit permutations with the p-value if it is larger than \u0026quot;C\u0026quot;. It is recommended to specify a \u0026quot;C\u0026quot; that is slightly larger than the significance level for the study. To disable the adaptive procedure, set C=1. Default is C=0.1 --variable_thresholds This option, if evoked, will apply variable thresholds method to the permutation routine in burden test on aggregated variant loci --extern_weight [EXTERN_WEIGHT [EXTERN_WEIGHT ...]] External weights that will be directly applied to genotype coding. Names of these weights should be in one of '--var_info' or '--geno_info'. If multiple weights are specified, they will be applied to genotypes sequentially. Note that all weights will be masked if --use_indicator is evoked. --weight {Browning_all,Browning,KBAC,RBT} Internal weighting themes inspired by various association methods. Valid choices are: 'Browning_all', 'Browning', 'KBAC' and 'RBT'. Except for 'Browning_all' weighting, tests using all other weighting themes has to calculate p-value via permutation. For details of the weighting themes, please refer to the online documentation. --NA_adjust This option, if evoked, will replace missing genotype values with a score relative to sample allele frequencies. The association test will be adjusted to incorporate the information. This is an effective approach to control for type I error due to differential degrees of missing genotypes among samples. --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive mode. Default set to additive  \n2.11 Show currently available snapshots (snapshots and snapshot) You can save snapshots of the current project and revert to them later. This allows you to recover a project when it is damaged by wrong operations or system failure, and more importantly, allows you to explore different processing pipelines with a saved baseline stage. The command vtools show snapshots lists information about all snapshots. Names starting with vt_ are online snapshots that will be downloaded automatically using command vtools admin --load_snapshot NAME. These snapshots contain sample projects and data and are ideal for learning variant tools.\nNote that:\n Project-specific snapshots are stored under the project cache directory and are listed by command vtools show snapshots. Snapshots saved locally (use a filename with vtools admin --save_snapshot) can be saved in any directory and will not be listed by command vtools show snapshots. Command vtools show snapshot FILENAME can be used to show details of such snapshots.   Examples: Show a list of local and online snapshots\n% vtools show snapshots vt_qc snapshot for QC tutorial, exome data of 1000 genomes project with simulated GD and GQ scores (online snapshot) vt_ExomeAssociation Data with ~26k variants from chr1 and 2, ~3k samples, 3 phenotypes, ready for association testing. (online snapshot) vt_quickStartGuide A simple project with variants from the CEU and JPT pilot data of the 1000 genome project (online snapshot) vt_illuminaTestData Test data with 1M paired reads (online snapshot) vt_simple A simple project with variants imported from three vcf files (online snapshot) vt_testData An empty project with some test datasets (online snapshot)  If we create a snapshot,\n% vtools admin --save_snapshot test1 'a test snapshot' INFO: Copying genotypes INFO: Snapshot test1 has been saved  It will be displayed in the list\n% vtools show snapshots test1 a test snapshot (created: Jul12 16:37:00) vt_ExomeAssociation Data with ~26k variants from chr1 and 2, ~3k samples, 3 phenotypes, ready for association testing. (created: Jul12 03:35:50) vt_qc snapshot for QC tutorial, exome data of 1000 genomes project with simulated GD and GQ scores (online snapshot) vt_ExomeAssociation Data with ~26k variants from chr1 and 2, ~3k samples, 3 phenotypes, ready for association testing. (online snapshot) vt_quickStartGuide A simple project with variants from the CEU and JPT pilot data of the 1000 genome project (online snapshot) vt_illuminaTestData Test data with 1M paired reads (online snapshot) vt_simple A simple project with variants imported from three vcf files (online snapshot) vt_testData An empty project with some test datasets (online snapshot)  Such local snapshots are stored in the project cache directory and are listed automatically. However, if you create a local snapshot by specifying a filename (with suffix .tar or .tar.gz), such snapshots will not be displayed.\n% vtools admin --save_snapshot local_snapshot.tar 'a local snapshot' INFO: Copying genotypes INFO: Snapshot local_snapshot.tar has been saved % vtools show snapshots -l 2 -v0 test1 vt_ExomeAssociation  You can show the details of such snapshots using command vtools show snapshot NAME though.\n% vtools show snapshot local_snapshot.tar Name: local_snapshot.tar Source: local Creation date: Jul12 16:39:24 Description: a local snapshot  \n2.12 Show a list of runtime options (runtime_options and runtime_option) variant tools provides a number of runtime options that can be used to fine-tune the behavior of commands. You can use command vtools show runtime_options to get the name and description of these options. If you simply need to see a list of options, you can pass option -v0 to suppress descriptions. Please see command vtools admin --set_runtime_option for details.\n Examples: Show a list of runtime options\n% vtools show runtime_options | head -50 associate_num_of_readers None (default) Use specified number of processes to read genotype data for association tests. The default value is the minimum of value of option --jobs and 8. Note that a large number of reading processes might lead to degraded performance or errors due to disk access limits. association_timeout None (default) Cancel associate test and return special values when a test lasts more than specified time (in seconds). The default value of this option is None, which stands for no time limit. import_num_of_readers 2 (default) variant tools by default uses two processes to read from input files during multi-process importing (--jobs \u0026gt; 0). You can want to set it to zero if a single process provides better performance or reduces disk traffic. local_resource ~/.variant_tools (default) A directory to store variant tools related resources such as reference genomes and annotation database. Files under this directory is usually downloaded automatically upon use, but can also be synchronized directly from http://vtools.houstonbioinformatics.org/. logfile_verbosity 2 (default) Verbosity level of the log file, can be 0 for warning and error only, 1 for general information, or 2 for general and debug information. search_path .;http://vtools.houstonbioinformatics.org/ (default) A ;-separated list of directories and URLs that are used to locate annotation database (.ann, .DB), file format (.fmt) and other files. Reset this option allows alternative local or online storage of such files. variant tools will append trailing directories such as annoDB for certain types of data so only root directories should be listed in this search path. sqlite_pragma (default) pragmas for sqlite database that can be used to optimize the performance of database operations. temp_dir None (default) Use the specified temporary directory to store temporary files to improve performance (use separate disks for project and temp files), or avoid problems due to insufficient disk space. treat_missing_as_wildtype False (default) Treat missing values as wildtype alleles for association tests. This option is used when samples are called individuals or in batch so genotypes for some samples are ignored and treated as missing if  to see a list of runtime options, use command\n% vtools show runtime_options -v0 associate_num_of_readers association_timeout import_num_of_readers local_resource logfile_verbosity search_path sqlite_pragma temp_dir treat_missing_as_wildtype verbosity  Furthermore, if you only need to check the exiting value of a runtime option, you can use command vtools show runtime_option OPT,\n% vtools show runtime_option local_resource ~/.variant_tools  \n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/other_pipelines/snpeff/",
	"title": "snpEff",
	"tags": [],
	"description": "",
	"content": " Variant effect provided by snpEFF Usage This pipeline exports variants in VCF format, call snpEff to predict its effect, and import the result as an variant info field EFF.\n% vtools show pipeline snpEff A pipeline to call snpEff to annotate variants. Available pipelines: eff Pipeline \u0026quot;eff\u0026quot;: This pipeline export variants in VCF format, call snpEff to annotate it, and import the EFF info as an information field. This pipeline will automatically download appropriate snpEff database (e.g. hg19). eff_0: Load specified snapshot if a snapshot is specified. Otherwise use the existing project. eff_10: Check the existence of command java eff_11: Check if snpEff is installed and executable eff_12: Check the data storage location in snpEff.config file. eff_14: Download reference database for the project reference genome eff_20: Export variants in VCF format eff_30: Execute snpEff eff to annotate variants eff_40: Importing results from snpEff Pipeline parameters: var_table Variant table for the variants to be analyzed. (default: variant) java path to java. Default to 'java' (use $PATH to determine actual path) (default: java) opt_java Option to java program. -Djava.io.tmpdir is frequently used to set java temporary directory if system temporary partition is not big enough. (default: -Xmx4g -XX:-UseGCOverheadLimit) snpeff_path Path to directory that contains snpEff.jar. (default: ./) eff_fields Fields that will be imported to the project from the output of snpEff. The default value is EFF, which is the whole EFF info. You can also specify one or more off EFF_Type, EFF_Impact and Eff_Functional_Class, which are from extracted from the Effect(Effct_impact|Functional_Class... field. (default: EFF)  Details This pipeline calls snpEff to estimate the effect of variants so you first need to download and install snpEff.\n% vtools execute snpEff eff --snpeff_path ~/bin/snpEff/ INFO: Executing step eff_0 of pipeline snpEff: Load specified snapshot if a snapshot is specified. Otherwise use the existing project. INFO: Executing step eff_10 of pipeline snpEff: Check the existence of command java INFO: Command java is located. INFO: Executing step eff_11 of pipeline snpEff: Check if snpEff is installed and executable INFO: Executing step eff_12 of pipeline snpEff: Check the data storage location in snpEff.config file. INFO: Running cat /Users/bpeng/bin/snpEff//snpEff.config | grep \u0026quot;data_dir =\u0026quot; | cut -d= -f2 \u0026gt; cache/snpEff.data_dir INFO: Command \u0026quot;cat /Users/bpeng/bin/snpEff//snpEff.config | grep \u0026quot;data_dir =\u0026quot; | cut -d= -f2 \u0026gt; cache/snpEff.data_dir\u0026quot; completed successfully in 00:00:01 INFO: Executing step eff_14 of pipeline snpEff: Download reference database for the project reference genome INFO: Reuse existing files /Users/bpeng/snpEff/data//hg19/snpEffectPredictor.bin INFO: Executing step eff_20 of pipeline snpEff: Export variants in VCF format INFO: Running vtools export variant --format vcf --output cache/snpEff_input.vcf INFO: Command \u0026quot;vtools export variant --format vcf --output cache/snpEff_input.vcf\u0026quot; completed successfully in 00:00:01 INFO: Executing step eff_30 of pipeline snpEff: Execute snpEff eff to annotate variants INFO: Running java -jar /Users/bpeng/bin/snpEff//snpEff.jar -c /Users/bpeng/bin/snpEff//snpEff.config -v hg19 cache/snpEff_input.vcf \u0026gt; cache/snpEff_output.vcf INFO: Command \u0026quot;java -jar /Users/bpeng/bin/snpEff//snpEff.jar -c /Users/bpeng/bin/snpEff//snpEff.config -v hg19 cache/snpEff_input.vcf \u0026gt; cache/snpEff_output.vcf\u0026quot; completed successfully in 00:00:34 INFO: Executing step eff_40 of pipeline snpEff: Importing results from snpEff INFO: Running vtools update variant --from_file cache/snpEff_output.vcf --var_info EFF INFO: Using primary reference genome hg19 of the project. Getting existing variants: 100% [===========================================] 1,611 181.8K/s in 00:00:00 INFO: Updating variants from cache/snpEff_output.vcf (1/1) snpEff_output.vcf: 100% [====================================================] 1,610 12.3K/s in 00:00:00 INFO: Field EFF of 1,611 variants are updated INFO: Command \u0026quot;vtools update variant --from_file cache/snpEff_output.vcf --var_info EFF\u0026quot; completed successfully in 00:00:01  The field EFF is added to (or updated if it already exists) the project,\n% vtools output variant chr pos ref alt EFF -l 10 6 32797167 A G INTRON(MODIFIER||||653|TAP2||CODING|NM_018833.2.8|11|1),INTRON(MODIFIER||||703|TAP2||CODING|NM_000544.3.8|11|1) 6 32369594 A G INTRON(MODIFIER||||455|BTNL2||CODING|NM_019602.1.8|3|1) 6 32797947 A G INTRON(MODIFIER||||653|TAP2||CODING|NM_018833.2.8|9|1),INTRON(MODIFIER||||703|TAP2||CODING|NM_000544.3.8|9|1) 6 32797168 A G INTRON(MODIFIER||||653|TAP2||CODING|NM_018833.2.8|11|1),INTRON(MODIFIER||||703|TAP2||CODING|NM_000544.3.8|11|1) 6 31380276 A G INTRON(MODIFIER||||332|MICA||CODING|NM_001177519.1.4|5|1),INTRON(MODIFIER||||383|MICA||CODING|NM_000247.1.5|6|1),INTRON(MODIFIER|||||MICA||CODING|NR_036523.1.5|5|1),INTRON(MODIFIER|||||MICA||CODING|NR_036524.1.4|5|1) 6 32369554 A G INTRON(MODIFIER||||455|BTNL2||CODING|NM_019602.1.8|4|1) 6 32369596 A G INTRON(MODIFIER||||455|BTNL2||CODING|NM_019602.1.8|3|1) 6 32369597 A G INTRON(MODIFIER||||455|BTNL2||CODING|NM_019602.1.8|3|1) 6 32369515 A G INTRON(MODIFIER||||455|BTNL2||CODING|NM_019602.1.8|4|1) 6 31380278 A G INTRON(MODIFIER||||332|MICA||CODING|NM_001177519.1.4|5|1),INTRON(MODIFIER||||383|MICA||CODING|NM_000247.1.5|6|1),INTRON(MODIFIER|||||MICA||CODING|NR_036523.1.5|5|1),INTRON(MODIFIER|||||MICA||CODING|NR_036524.1.4|5|1)  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/format/formats/tped/",
	"title": "tped",
	"tags": [],
	"description": "",
	"content": " PLINK/TPED format About TPED format Many software applications for linkage and association studies (e.g. plink, merlin) accept PED/MAP format. The map file records basic information about markers, the Ped file contains sample genotype. Whereas variant tools can easily export in MAP format, it is difficult to export in PED format because this format is not variant oriented (output by variant).\nFortunately, PLINK accepts a transposed PED format (TPED) that is variant oriented. variant tools can export variants in this format using format tped.\nFormat tped cannot import from TPED files because this format does not specify reference and alternative alleles. To import PLINK TPED data please use format plink?\nThe TPED/TFAM bundle To make the exported TPED file compatible with other software applications that handles PLINK input, a TFAM file containing individual names is generated. Unlike a standard TFAM file which is the first six columns of a PED file, i.e., Family ID, Individual ID, Paternal ID, Maternal ID, Sex and Phenotype, the TFAM file exported here only has valid individual ID, with other columns being placeholders. However it is straightforward to create a TFAM file with information for other columns using vtools phenotype --output command.\nFormat specification vtools show format tped Format: tped Description: Output to TPED format with the first four columns chr name gen_pos pos, and the rest for genotypes. Variant tools cannot import from this format because it does not contain information about reference genome. Columns: 1 chromosome (without leading chr) 2 Locus name 3 Genetic distance, left empty 4 Physical position 5 genotype Formatters are provided for fields: gt variant: chr Chromosome pos 1-based position ref alt Format parameters: name (export) Field for name of variants, can be dbSNP.name if dbSNP is available (default: ) style (export) Style of genotype format, can be 'genotype' for genotype separated by tab (e.g. A C), or 'numeric' for 0, 1, or 2 for number of alternative alleles. (default: genotype) tfamfile (export) Name of the tfam file to be outputed. Filename that does not ends with .tfam will be ignored. (default: $table.tfam)  By default, the corresponding TFAM file is named after the variant table from which variants/samples are exported. You can specify the TFAM file name by passing an additional parameter with specified filename: --tfamfile FILENAME.tfam. Note that the extension .tfam is required.\nExample Output some variants. The genotypes for selected samples are ordered alphabetically by sample name (and the selected samples are recorded in the log file).\nvtools export variant --format tped --samples 'sample_name like \u0026quot;NA069%\u0026quot;' -v0 1 . . 10533 G G G G G G 1 . . 51479 T T T A T A 1 . . 51928 G G G G G G 1 . . 54586 T T T T T T 1 . . 54676 C C C C C C 1 . . 54708 G G G G G G 1 . . 55299 C C C C C C 1 . . 62203 T T T T T T 1 . . 63671 G G G A G A 1 . . 86028 T T T T T T 1 . . 86065 G G G G G G 1 . . 86331 A A A A A A 1 . . 87190 G G G A G G 1 . . 88316 G G G G G G 1 . . 88338 G G G A G G 1 . . 91536 G G T T G G 1 . . 108310 C C T C T C 1 . . 233473 C C C C C G 1 . . 234760 A A A A A A  Export in numeric style. This will recode the tped file to a numeric format using additive coding, equivalent to applying the PLINK --recodeA command to the data:\nvtools export variant --format tped --samples 'sample_name like \u0026quot;NA069%\u0026quot;' --style numeric -v0 1 . . 10533 0 0 0 1 . . 51479 0 1 1 1 . . 51928 0 0 0 1 . . 54586 0 0 0 1 . . 54676 0 0 0 1 . . 54708 0 0 0 1 . . 55299 0 0 0 1 . . 62203 0 0 0 1 . . 63671 0 1 1 1 . . 86028 0 0 0 1 . . 86065 0 0 0 1 . . 86331 0 0 0 1 . . 87190 0 1 0 1 . . 88316 0 0 0 1 . . 88338 0 1 0 1 . . 91536 0 2 0 1 . . 108310 2 1 1 1 . . 233473 0 0 1 1 . . 234760 0 0 0  The name field of the output is empty. If you would like to use an annotation database to assign variants a name, you can do\nvtools use dbSNP vtools export variant --format tped --samples 'sample_name like \u0026quot;NA069%\u0026quot;' --name dbSNP.name -v0 1 rs114315702 . 10533 G G G G G G 1 rs116400033 . 51479 T T T A T A 1 rs78732933 . 51928 G G G G G G 1 rs79600414 . 54586 T T T T T T 1 rs2462492 . 54676 C C C C C C 1 rs115797567 . 54708 G G G G G G 1 rs10399749 . 55299 C C C C C C 1 rs28402963 . 62203 T T T T T T 1 rs80011619 . 63671 G G G A G A 1 rs114608975 . 86028 T T T T T T 1 rs116504101 . 86065 G G G G G G 1 rs115209712 . 86331 A A A A A A 1 rs1524602 . 87190 G G G A G G 1 rs113759966 . 88316 G G G G G G 1 rs55700207 . 88338 G G G A G G 1 rs6702460 . 91536 G G T T G G 1 rs74747225 . 108310 C C T C T C 1 rs112455420 . 233473 C C C C C G 1 rs7548182 . 234760 A A A A A A  In case there are multiple entries for a variant in the dbSNP database, only the first name will be used, which does not have to be the most commonly used name for the variant.\nA TFAM file is also generated,\n0 NA06985 0 0 0 -9 1 NA06986 0 0 0 -9 2 NA06994 0 0 0 -9 3 NA06985 0 0 0 -9 4 NA06986 0 0 0 -9 5 NA06994 0 0 0 -9 6 NA06985 0 0 0 -9 7 NA06986 0 0 0 -9 8 NA06994 0 0 0 -9  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_report/variant_stat/",
	"title": "variant_stat",
	"tags": [],
	"description": "",
	"content": " Counting variants of different types, optionally by samples Usage % vtools_report variant_stat -h usage: vtools_report variant_stat [-h] [-s [SAMPLES [SAMPLES ...]]] [-g [GROUP_BY [GROUP_BY ...]]] [-v {0,1,2}] table Command 'vtools variant_stat' calculates the number of snps, insertions, deletions and substitutions for groups of samples with some size metrics to characterize the indels. The statistics can be calculated for all samples (effectively for the master variant table when parameters --samples and --group_by are ignored), a subset of samples (e.g. --samples aff=1), grouped by samples (e.g. --group_by aff), or for each sample separately (e.g. --group_by filename sample_name, because those two fields in the sample table uniquely identify each sample. positional arguments: table Variant table for which variant metrics are calculated. optional arguments: -h, --help show this help message and exit -s [SAMPLES [SAMPLES ...]], --samples [SAMPLES [SAMPLES ...]] Limiting variants from samples that match conditions that use columns shown in command 'vtools show sample' (e.g. 'aff=1', 'filename like \u0026quot;MG%\u0026quot;'). If this parameter is specified without a value, variants belonging to any of the samples will be counted. If this parameter is left unspecified, all variants, including those that do not belong to any samples will be counted. -g [GROUP_BY [GROUP_BY ...]], --group_by [GROUP_BY [GROUP_BY ...]] Group samples by certain conditions such as 'aff=1'. A common usage is to group variants by 'filename' and 'sample_name' so that variant statistics are outputted for each sample. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information of vtools and vtools_report. Debug information are always recorded in project and vtools_report log files.  Details This command calculates the number of snps, insertions, deletions and substitutions for groups of samples with some size metrics to characterize the indels. You can use parameters --samples to limit variants to specified samples, and --group_by to output statistics for each sample groups. For example, the statistics can be calculated\n all variants in the specified variant table (default if parameters --samples and --group_by are ignored), a subset of samples (e.g. --samples aff=1), grouped by samples (e.g. --group_by aff), or for each sample separately (e.g. --group_by filename sample_name, because those two fields in the sample table uniquely identify each sample.\n% vtools_report variant_stat VTABLE % vtools_report variant_stat VTABLE \u0026ndash;samples 1 % vtools_report variant_stat VTABLE \u0026ndash;group_by aff\n  might give different total variant count because the first command counts all variants in the VTABLE, the second and third commands count all variants in specified samples (all samples for condition 1). Because some variants might not appear in any of the samples, the number of reported variants of the first command might be larger than the others.\nYou you would like to generate output for selected variants (e.g. variants on chromosome 1), you should use command vtools select -t table to generate a variant table and use this command to summarize them.\n% vtools_report variant_stat variant --group_by filename filename num_sample num_snps num_insertions num_deletions num_substitutions min_insertion_size avg_insertion_size max_insertion_size min_deletion_size avg_deletion_size max_deletion_size case1.vcf 1 21504 322 75 0 1 2.64906832298 23 1 1.28 11 case10.vcf 1 21069 317 77 0 1 2.64353312303 21 1 1.25974025974 6 case11.vcf 1 20995 315 70 0 1 2.65396825397 23 1 1.08571428571 3 case12.vcf 1 22195 340 68 0 1 2.91176470588 26 1 1.23529411765 10 ... ...  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/",
	"title": "Customization",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/analysis/",
	"title": "Detailed analysis",
	"tags": [],
	"description": "",
	"content": " Analysis of one genetic variant 1. Data After some preliminary analysis, we find one particular variant (179248034 on chromosome 5) in gene SQSTM1 that is likely to be associated with a phenotype. Let us try to find more information about this variant, which is in a variant table named MyVar in our project.\n2. Gene and mRNA We first would like to download and use the ref gene database to our project. To learn what fields are available in this annotation database, we can use command vtools show annotation to print the details of it.\n% vtools use refGene % vtools show annotation refGene  The following command output the corresponding records in refGene database for this variant:\n% vtools output myVar chr pos ref alt refGene.name txStart txEnd cdsStart cdsEnd exonCount name2 5 179248034 C T NM_001142298 179233388 179265077 179250005 179263593 9 SQSTM1 5 179248034 C T NM_001142299 179234003 179265077 179250005 179263593 9 SQSTM1 5 179248034 C T NM_003900 179247842 179265077 179247937 179263593 8 SQSTM1  If we use the ccdsGene database, we would get:\n% vtools use ccdsGene % vtools output myVar chr pos ref alt ccdsGene.name ccdsGene.txStart ccdsGene.txEnd ccdsGene.cdsStart ccdsGene.cdsEnd ccdsGene.exonCount ccdsGene.name2 5 179248034 C T CCDS34317.1 179247937 179263593 179247937 179263593 8  We had to use full name ccdsGene.txStart etc to avoid ambiguity because these fields also exist in the refGene database.\nThe results show that\n This variant locates in consensus CDS gene CCDS34317.1, with common name SQSTM1.  This gene encodes a multifunctional protein that binds ubiquitin and regulates activation of the nuclear factor kappa-B (NF-kB) signaling pathway. The protein functions as a scaffolding/adaptor protein in concert with TNF receptor-associated factor 6 to mediate activation of NF-kB in response to upstream signals. Alternatively spliced transcript variants encoding either the same or different isoforms have been identified for this gene. Mutations in this gene result in sporadic and familial Paget disease of bone.\n This gene can transcribed two three mRNAs NM_001142298, NM_00142299 and NM_003900, which corresponds to CCDS id CCDS4735.1 (first two), and CCDS34317.1. Searching in CCDS gene only displays CCDS34317.1 because this variant falls out of the coding region of CCDS4735.1.  3. Which exon? Now we know that this variant is within the coding region of CCDS34317.1, is it in one of the exon region? We can use the ccdsGene_exon database to find this out.\n% vtools use ccdsGene_exon % vtools output MyVar chr pos ref alt ccdsGene_exon.exon_start ccdsGene_exon.exon_end 5 179248034 C T 179247937 179248141  So we know this variant stays in an exon starting from 179247937, according to here, this is the first exon of this gene.\n4. Potential of damaging? Because this variant belongs to one of the CCDS genes, we can find the SIFT score and PolyPhen2 (and other scores) of this variant from the dbNSFP database.\n% vtools use dbNSFP % vtools output MyVar chr pos ref alt SIFT_score polyphen2_score 5 179248034 C T 0.49 0.893  This database also tells you how this mutation changes the aminoacid:\n% vtools output MyVar chr pos ref alt aaref aaalt refcodon codonpos aapos 5 179248034 C T A V GCG 2 33  So this variant mutates C in GCG to T, and changes aminoacid A (GCG) to V (GTG).\nNow, let us get the aminoacid sequence from the CCDS gene page, and send it to the PolyPhen 2 website, we need to fill in\n Protein identifier: leave blank or use name NP_003891.1 Protein sequence: copy and paste with leading line \u0026gt;NP_003891.1 or leave blank Position: 33 From A -\u0026gt; V  Note that we can use either protein name or sequence, but not both.\nThe results show that\nRecName: Full=Sequestosome-1; AltName: Full=EBI3-associated protein of 60 kDa; Short=EBIAP; Short=p60; AltName: Full=Phosphotyrosine-independent ligand for the Lck SH2 domain of 62 kDa; AltName: Full=Ubiquitin-binding protein p62; LENGTH: 440 AA HumDiv: (preferred model of evaluating rare alleles, dense mapping and analysis of natural selection) This mutation is predicted to be POSSIBLY DAMAGING with a score of 0.915 (sensitivity: 0.81; specificity: 0.94) HumVar: (preferred model for diagnostics of Mendelian disease) This mutation is predicted to be BENIGN with a score of 0.399 (sensitivity: 0.84; specificity: 0.78)  The PolyPhen2 score obtained from PolyPhen2 website differs from what is reported by dbNSFP, which used a previous version of PolyPhen2 to generate scores for these variants.\n "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/format/",
	"title": "Format",
	"tags": [],
	"description": "",
	"content": " Specification of external file formats Roles of format specification in variant tools: Variant tools can import and export text files (or gzipped text files) in delimiter-separated format, namely records that are separated into columns by delimiters such as tab, space or comma. The file format must be variant-oriented (storing one or more variants by line), with the exception of sample-based PLINK format which is preprocessed internally into variant-oriented form for import. We use terms\n column for columns (text) in a delimiter-separated file, and field for fields (with types) in tables in a database, with  variant fields for fields that define variants (chr, pos, ref, alt), variant info for fields that annotate variants (e.g. membership to dbSNP), genotype fields for fields to store genotypes of samples, and genotype info for fields that annotate genotypes (e.g. quality score of each genotype)   A format specification defines how to extract fields from columns and how to write columns from fields, to\n Insert new variants to the project using command vtools import. The text file should provide at least four fields for chromosome, position, reference and alternative alleles. In addition to variant and variant info, an input file can contain genotype and genotype info for one or more samples.  The four fields could, but not necessarily have to, be in four columns because a field could be synthesized from multiple columns, even not from any existing column. For example, if all variants are from dbSNP, ref and alt fields could be looked up from a dbSNP annotation database.\n Update existing variants with additional info using command vtools update. The text files can have\n full variant information (chr, pos, ref and alt) to update matching variants and related genotypes and their info, or\n chromosomal positions (chr and pos) to update all variants at specified locations, or\n range (chr, start, end) to update variants in specified regions\n  Export samples and their variants using command vtools export. The file format should be organized by variant (not by sample). Although each line of the output file usually present a variant (chr, pos, ref, alt), it can contain multiple variants at a locus (chr, pos, ref, mutliple alternative alleles), or only locus-specific information (chr, pos).\n  The format specification file (.fmt file) A .fmt file describes the format of an external file so that it can be handled by variant tools. An format specification file follows an extended .ini format with section and key/value pairs. Details of this format can be found at this link because it is parsed by a Python ConfigParser object. This file should have at least a [format description] section and a few field sections. A format specification could be used to import and export files but you can ignore import or export specifications if you are only interested in exporting or importing.\nSection [format description] This section should have keys\n description: a description of the format, with preferably a URL to the documentation of the format.\n encoding (optional): encoding of the input file. If you see errors such as \u0026quot;codec can't decode byte 0xe7 in position 21480\u0026quot;, you should perhaps add encoding=ISO-8859-1 to your .fmt file.\n delimiter (optional): delimiter to define columns in the input file. Default to tab (delimiter='\\t'). If your input can be either tab or space delimited, use delimiter=None if your input does not have any missing field because '\\t\\t' or ' ' will be treated as a single delimiter. Quotations around other delimiters can be ignored (e.g. , instead of ',').\n header (optional): variant tools by default treats lines with a leading # as header and skip them during data importing. The header will also be used to probe sample names for some formats (e.g. .vcf). If your input file does not use such a header, you can override this behavior by specifying the number of lines to skip (header=1), or a pattern by which headers are matched (e.g. use header=^%.* for header lines starting with %, see documents of the Python re package for details).\n preprocessor (optional): a functor to pre-process input data into some intermediate format that can be readily imported by variant tools (e.g., PlinkConverter())\n export_by (optional, for export only): How variants at the same locus are exported. By default, variant tools exports one line for each variant. If fields specified by export_by (e.g. chr, pos) cannot uniquely identify variants so multiple variants will be outputted in one line, values at extra records will be ignored, or be collapsed to the first record if supported by column specification.\n sort_output_by (optional, for export only): How variants are ordered. This option is ignored if export_by is defined.\n  THIS OPTION IS CURRENTLY NOT USED\n merge_by (optional, for import only): If genotype at different homozygous copies (ploidy) is recorded in separate lines, this option has to be used to specify the columns to uniquely identify a variant. These columns will be passed to the processor without modification, values at all other columns are merged (separated by \u0026lsquo;,\u0026rsquo;).\n One of\n variant: fields for chr, pos, ref, and alt. Such input files have complete variant information and can be used to add new variants or add or update info of existing variants.\n position: fields for chr and pos for chromosomal positions.\n range: fields for chr, start and end positions of regions.\n   input files of the latter two types can only be used to update matching variants with additional variant_info.\n variant_info (optional): Additional fields that will be inserted to specified variant table.\n genotype (optional): name of a field that will be imported into the sample variant table. Using a slice-index syntax, this field can process genotypes for multiple samples (e.g. index=8: will produce genotypes from columns 8, 9, \u0026hellip;). The return value of this field must be value 1 for heterozygote, 2 for homozygote, and -1 for double heterozygote (alt1, alt2).\n genotype_info (optional): Fields such as quality score that will be appended to genotype of each sample. They should either generate a single value for all samples (regular index), or a different value for each sample (slice-index).\n  General speaking, genotype info fields are sample specific so different samples can have different values for the same variant. Variant info fields are supposed to be properties of variants and are shared by all (or part of the) samples. It is up to the user (and file format) to decide how to handle particular fields from input files.\nSection [DEFAULT] (define parameters of a format) The default section defines values that exist, conceptually, in all sections. It is used to define parameters used for import or export. These parameters could be overriden using corresponding command line option. For example, in the following .fmt file (partial)\n[format description] description=Output from ANNOVAR, generated from command \u0026quot;path/to/annovar/annotate_variation.pl annovar.txt path/to/annovar/humandb/\u0026quot;. This format imports chr, pos, ref, alt and ANNOVAR annotations. For details please refer to http://www.openbioinformatics.org/annovar/annovar_gene.html variant=chr, pos, ref, alt variant_info=%(var_info)s [DEFAULT] var_info=mut_type var_info_comment=Fields to be outputted, can be one or both of mut_type and function  The key var_info has a help message defined by parameter var_info_comment, and a default value mut_type. If you query the details of this format using command\n% vtools show format ANNOVAR_output  you will see at the end of the output the following description:\nOther fields (usable through parameters): function the gene name, the transcript identifier and the sequence change in the corresponding transcript Format parameters: var_info Fields to be outputted, can be one or both of mut_type and function. (default: mut_type)  This means you can pass an alternative value of var_info to this format using parameters such as --var_info function to change the variant information field to be imported or updated. For example, you can use command\n% vtools update variant input_file --format ANNOVAR_output --var_info mut_type function  to update two fields mut_type and function instead of the default one (mut_type).\nName of a variable cannot be any keyword (e.g. field, comment, adj, type) or start with fmt_.\nField sections (import: how to extract fields from input file) Import fields sections describe the fields that can be imported if they appear in one of variant, position, range, variant_info, genotype and genotype_info. Because the value of these fields could be overridden using corresponding parameters of command vtools import, a .fmt file might define additional or alternative fields to provide alternative ways to import data in this format.\nEach field section can have the following keys:\n index: index(es) of field, which can be\n A 1-based index of the column in the input file. The value at this column will be used for this field.\n A tuple syntax with multiple indexes separated by ',', for example 5,7. A list of values at specified columns will be passed to an adjust function to produce values of the field.\n A \u0026lsquo;slice\u0026rsquo; syntax to specify multiple fields. This syntax will only be used for genotype and genotype information fields. For example, index=8: will produce multiple fields from columns 8, 9, ... till end of the columns. Other examples include index=8::2 for 8, 10, 12, ..., index=5,8: for (5,8), (5,9), \u0026hellip;, and index=8::2,9::2 for (8,9), (10,11), etc\n  type: can be any SQL allowed types such as \u0026ldquo;INTEGER\u0026rdquo;, \u0026ldquo;FLOAT\u0026rdquo;, \u0026ldquo;INTEGER NOT NULL\u0026rdquo;, or \u0026ldquo;DECIMAL(7,6) NOT NULL\u0026rdquo;\n comment (optional) a description of the field\n adj (optional): Functions or functors to extract or modify one or more values from the field value. variant tools provides a number of functors to help the processing of different fields. For example,\n IncreaseBy(inc=1) (increase value by inc). This is usually used to adjust 0-based position to 1-based position that is used by variant tools.\n MapValue(map) (map value to another). This function is used to map input value to another one, for example, MapValue({'het': '1', 'hom': '2'}) maps value \u0026lsquo;het\u0026rsquo; to \u0026lsquo;1\u0026rsquo; and \u0026lsquo;hom\u0026rsquo; to \u0026lsquo;2\u0026rsquo;. Note that the mapped values should be strings or None.\n Nullify(val) (treat value as NULL). This is usually used to adjust input NA values to NULL in the database.\n RemoveLeading(val) (remove leading characters). This is usually used to remove leading chr from inputs with chromosomes such as chr1, chr2, because variant tools only stores 1, 2, etc.\n ExtractField(index, sep=';', default=None) (field of a column): Split the item by sep and return the index-th field (1-based). Return default if there are less than index fields. For example, ExtractField(2, ':') extracts 20 from 10:20:30.\n  Multiple functors/functions can be used sequentially. For example, ExtractValue('CEU:'), ExtractField(1, '/') extracts value 12 from YRI:20/222;CEU:12/45 (the first extractor gets 12/45, the second extractor gets 12), and ExtractValue('CEU:'), SplitField('/') extracts values 12 and 45 from YRI:20/222;CEU:12/45.\n If none of the provided extractors can be used, you can define your own function. For example, lambda x: x[6:].replace(\u0026quot;,\u0026quot;, \u0026quot;\u0026quot;) extracts 24000 from COUNT=24,000. You can also mix function with variant tools provided extractor ExtractValue(\u0026quot;COUNT=\u0026quot;), lambda x: x.replace(\u0026quot;,\u0026quot;, \u0026quot;\u0026quot;)]) to extract 24000 from values such as ASD;COUNT=24,000;MAF=0.5.\n If the return value of at least one of the fields is a tuple of more than one values (e.g. result from functor SplitField), multiple records will be generated from this line. Non-tuple values of other fields will be copied automatically. For example, if three fields have values A1, (B1,), (C1, C2), they will produce two records of A1, B1, C1 and A1, None, C2.\n If you would like to exclude certain records, you can use adj to produce invalid records that will be excluded during importing. For example, a record with None alternative allele, or a field with NOT NULL type will be ignored, or a genotype with None mutation type will be ignored.\n  Section [Field formatter] (export: how to format fields for output) This section specifies how to format fields when they are outputted to a file. Fields that are not listed in this section will be converted to string directly, unless a special wildcast formatter fmt_* is specified. This section should look like\n[Field formatter] fmt_chr=Prepend('chr') fmt_freq=Formatter('{.3f}') fmt_id=ValueOfNull('.') fmt_other=lambda x: something  The name of the formatter should be field name prepended by fmt_. Formatter for each field should be a functor or a function. Their return value must be a string. More interestingly, multiple fields could be formatted altogether so it is possible to specify\nfmt_PL1,fmt_PL2,fmt_PL3=lambda x: x[0] + x[1] + x[2]  to create a single string from multiple fields.\nColumn sections (export: how to organize fields into columns of output file) Export reverses the import process. Instead of extracting fields from one or more columns, it generates columns from one or more fields. Column sections have title col_# where # is the index of column. They are specified in a similar way to fields. File formats without column specification cannot be used to export variants and samples.\nEach column section can have the following keys:\n field: name of field or fields that will be used to create a column. The fields are usually defined in this .fmt file. If a field specifies genotype or genotype information of more than one sample using a slice syntax, multiple columns will be generated. If multiple records are collapsed into a single record(c.f. export_by), a tuple of values will be passed to the adj function/functor if it is defined. Otherwise, only the first record will be exported.\n adj: function or functor that accepts values at one or more fields and produce a single value at this column.\n comment (optional) a description of the column\n  The basic steps of outputting a file is to collect values of all fields, apply formatters to each field (or groups of fields) if available, and collect results to columns. Note that\n Although fields of columns are usually the ones that are defined in a .fmt file, arbitrary fields could be outputted if fields of a column are configurable through parameters.\n A column is considered as a genotype column if it contains field GT. Multiple columns will be exported if genotypes of multiple samples are outputted.\n A field can generate multiple columns by using a formatter that returns, for example, \u0026lsquo;1,2\u0026rsquo; for a comma-separated format.\n  Import and test After a file is created, you can use command\nvtools import --format /path/to/fmt_file input_file --build specified_build  to import your file, and use command\nvtools show table variant -l -1  to check if variants are correctly imported. If you believe that your format is commonly used, please send the .fmt file to our mailinglist. We will post the file to the repository so that others can make use of it.\nExamples You can learn from the system format files on how to define a format:\n A basic example of a format with variant fields: ANNOVAR format. An example of using lambda functions to extract information from multiple columns: snps.txt created by CASAVA 1.8.  You can have a look at system format files using\nvtools show formats vtools show format SOME_FORMAT more cache/SOME_FORMAT.fmt  The first command gets a list of supported formats. The second command gets details of a specific format, and the third command lets you view the format file because all used formats are stored in a temporary directory named cache under your project folder.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/other_pipelines/king/",
	"title": "KING",
	"tags": [],
	"description": "",
	"content": " Global ancestry and kinship inference Usage % vtools show pipeline KING Pipeline to call KING to perform global ancestry and kinship inference, and import ancestry analysis results as phenotypes into sample table. Available pipelines: king Pipeline \u0026quot;king\u0026quot;: This pipeline exports genotypes in specified variant table (parameter --var_table, default to variant) for specified samples (parameter --samples, default to all samples), executes PLINK's LD pruning, (R^2\u0026lt;0.5) and analysis selected variants using KING's population ancestry and kingship analysis. Specified number of MDS components for global ancestry analysis will be imported to sample table (parameter --num_comp, default to 5). A report of relatedness between pairs of samples will be written to file \u0026lt;jobname\u0026gt;.relatedness.txt (parameter --jobname, default to \u0026quot;KING\u0026quot;). No input or output file is required for this pipeline, but a snapshot could be specified, in which case the snapshot will be loaded (and overwrite the present project). king_0: Load specified snapshot if a snapshot is specified. Otherwise use the existing project. king_10: Check the existence of KING and PLINK command. king_20: Write selected variant and samples in tped format king_21: Rename tfam file to match tped file king_30: Calculate LD pruning candidate list with a cutoff of R^2=0.5 king_31: LD pruning from pre-calculated list king_41: Global ancestry inference king_42: Kinship inference king_51: Extract MDS result for vtools phenotype import king_52: Import phenotype from global ancestry analysis king_61: Save global ancestry inference result to plot king_62: Save kinship analysis result to text file Pipeline parameters: var_table Variant table for the variants to be analyzed. (default: variant) samples Samples to be analyzed. (default: 1) reported_ancestry Field name for self-reported ancestry. This is the name of the column of population group information in \u0026quot;vtools show samples\u0026quot; command. If specified, the global ancestry inference will be reported on a graph with colored dots indicating sample's self-reported ancestry group. king_path Path to a directory that contains the \u0026quot;king\u0026quot; program, if it is not in the default $PATH. plink_path Path to a directory that contains the \u0026quot;plink\u0026quot; program, if it is not in the default $PATH. num_comp number of MDS components in global ancestry analysis that will be imported to sample table. (default: 5) maf Minor Allele Frequency cutoff. Variants having MAF smaller than this value will be dropped from analysis. (default: 0.01) jobname A jobname, an identifier that will be part of filenames and field names generated during the execution of this pipeline. Please ONLY use combination of letters and underscore (\u0026quot;_\u0026quot;) for job name. (default: KING)  Details This pipeline integrates global ancestry analysis (MDS method) and kinship analysis. It updates sample phenotypes with calculated MDS components and generate graphic report for ancestry analysis, and text report for kinship analysis. project with the outputs. To use this pipeline, you should first download and install KING and PLINK to your $PATH or somewhere, then execute a command similar to\n% vtools execute KING --jobname kin --var_table kin --reported_ancestry Population  After the execution of the pipeline, MDS analysis results are updated to phenotype fields\n% vtools phenotype --output sample_name Population kin_mds1 kin_mds2 -l 10 HG00096 GBR -0.0372 0.0185 HG00097 GBR -0.0369 -0.0768 HG00099 GBR -0.0338 -0.0608 HG00100 GBR -0.0361 0.0284 HG00101 GBR -0.0336 0.0254 HG00102 GBR -0.0332 0.02 HG00103 GBR -0.0334 0.0241 HG00104 GBR -0.0337 -0.0572 HG00106 GBR -0.0347 -0.0794 HG00108 GBR -0.035 0.0431  and a graph kin.mds.pdf is generated for the same information. Additionally a summary of kinship analysis is available to identify related individuals\n% cat kin.RelatedIndividuals.txt ID1 ID2 HetHet IBS0 Kinship Relationship HG00116 HG00120 0.116 0.0358 0.0781 3rd-degree HG00119 HG00124 0.131 0.0201 0.1558 2nd-degree HG00134 HG00142 0.122 0.0346 0.0849 3rd-degree HG00238 HG00240 0.125 0.0372 0.0868 3rd-degree NA11931 NA11933 0.119 0.0422 0.0540 3rd-degree NA11932 NA12383 0.118 0.0430 0.0530 3rd-degree  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/misc/",
	"title": "Misc",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/single_gene/",
	"title": "Single gene association methods",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/single_gene/vt-test/",
	"title": "VT test",
	"tags": [],
	"description": "",
	"content": " Variable Thresholds Test for Case Control Data Analysis Introduction The variable thresholds method (VT, Price et al 2010[^Alkes L. Price, Gregory V. Kryukov, Paul I.W. de Bakker, Shaun M. Purcell, Jeff Staples, Lee-Jen Wei and Shamil R. Sunyaev (2010) Pooled Association Tests for Rare Variants in Exon-Resequencing Studies. The American Journal of Human Genetics doi:10.1016/j.ajhg.2010.04.005. http://linkinghub.elsevier.com/retrieve/pii/S0002929710002077^]) tests for association between phenotypic values (case control or quantitative traits) with individuals\u0026rsquo; genotype \u0026ldquo;score\u0026rdquo; subject to a variable MAF threshold. It assumes that there exists a fixed yet unknown MAF threshold on a given genetic region which is related to the cutoff for the causality of variants on that loci. In testing the association for the genetic region, for each possible MAF threshold a genotype score is computed based on given collapsing theme, and is tested for association between the phenotype of interest; the final MAF threshold is chosen such that the association signal is strongest. Permutation procedure has to be used to control for type I error due to multiple testing.\nThe VT strategy creates a very flexible framework that can be applied to many association tests, including the use of external information such as weight theme by annotation scores, as the VT paper suggested. The VTtest method implements the test for case control phenotype using the CMC coding theme and Fisher\u0026rsquo;s exact test, in addition to the original VT statistic. Permutation procedure is optimized due to the use of Fisher\u0026rsquo;s exact test: the minimum {$p$} value resulted from Fisher\u0026rsquo;s exact test on the original dataset have to exceed the expected significance level in order to enter the permutation test procedure; otherwise it will be reported as it is. This trick reduces the computation time the original VT test would require.\nPlease refer to VariableThresholdsBt and VariableThresholdsQt for more versatile versions of VT method, which tests for both case control and quantitative traits, with/without presence of phenotype co-variates, and is capable of incorporating functional information.\nDetails Command interface vtools show test VTtest Name: VTtest Description: VT statistic for disease traits, Price et al 2010 usage: vtools associate --method VTtest [-h] [--name NAME] [-q1 MAFUPPER] [-q2 MAFLOWER] [--alternative TAILED] [-p N] [--adaptive C] [--cfisher] [--midp] [--moi {additive,dominant,recessive}] Variable thresholds test for disease traits, Price et al 2010. The burden test statistic of a group of variants will be maximized over subsets of variants defined by applying different minor allele frequency thresholds. This implementation provides two different statistics: the original VT statistics in Price et al 2010 (default) and an adaptive VT statistic combining the CFisher method (via \u0026quot;--cfisher\u0026quot; option). p-value is estimated by permutation test. The adaptive VT statistic will not generate uniformly distributed p-value. For a more generalized version of VT test, type \u0026quot;vtools show test VariableThresholdsBt / VariableThresholdsQt\u0026quot;. optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. -q1 MAFUPPER, --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 1.0 -q2 MAFLOWER, --maflower MAFLOWER Minor allele frequency lower limit. All variants having sample MAF\u0026gt;m2 will be included in analysis. Default set to 0.0 --alternative TAILED Alternative hypothesis is one-sided (\u0026quot;1\u0026quot;) or two-sided (\u0026quot;2\u0026quot;). Two sided test is only valid with \u0026quot;--cfisher\u0026quot; option evoked (please use \u0026quot;VariableThresholdsBt\u0026quot; otherwise). Default set to 1 -p N, --permutations N Number of permutations --adaptive C Adaptive permutation using Edwin Wilson 95 percent confidence interval for binomial distribution. The program will compute a p-value every 1000 permutations and compare the lower bound of the 95 percent CI of p-value against \u0026quot;C\u0026quot;, and quit permutations with the p-value if it is larger than \u0026quot;C\u0026quot;. It is recommended to specify a \u0026quot;C\u0026quot; that is slightly larger than the significance level for the study. To disable the adaptive procedure, set C=1. Default is C=0.1 --cfisher This option, if evoked, will use an adaptive VT test via Fisher's exact statistic. For more details, please refer to the online documentation. --midp This option, if evoked, will use mid-p value correction for one-sided Fisher's exact test. It is only applicatable to one sided test with \u0026quot;--cfisher\u0026quot; option. --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive model. Default set to additive  Application  Example using snapshot vt_ExomeAssociation\nvtools associate rare status -m \u0026quot;VTtest --name vt -p 5000\u0026quot; --group_by name2 --to_db vt -j8 \\ \u0026gt; vt.txt INFO: 3180 samples are found INFO: 2632 groups are found INFO: Starting 8 processes to load genotypes Loading genotypes: 100% [=========================================================================================================================================] 3,180 14.6/s in 00:03:37 Testing for association: 100% [================================================================================================================================] 2,632/591 5.4/s in 00:08:04 INFO: Association tests on 2632 groups have completed. 591 failed. INFO: Using annotation DB vt in project test. INFO: Annotation database used to record results of association tests. Created on Thu, 31 Jan 2013 20:48:50 vtools show fields | grep vt vt.name2 name2 vt.sample_size_vt sample size vt.num_variants_vt number of variants in each group (adjusted for specified MAF vt.total_mac_vt total minor allele counts in a group (adjusted for MOI) vt.statistic_vt test statistic. vt.pvalue_vt p-value vt.std_error_vt Empirical estimate of the standard deviation of statistic vt.num_permutations_vt number of permutations at which p-value is evaluated head vt.txt name2 sample_size_vt num_variants_vt total_mac_vt statistic_vt pvalue_vt std_error_vt num_permutations_vt ABCD3 3180 3 42 -0.0717229 0.753247 0.316505 1000 ABCB10 3180 6 122 0.37788 0.396603 0.339246 1000 ABCG5 3180 6 87 0.204207 0.58042 0.337788 1000 ABCB6 3180 7 151 0.180786 0.609391 0.328099 1000 AADACL4 3180 5 138 -0.284233 0.986014 0.302561 1000 AAMP 3180 3 35 0.158666 0.474525 0.306232 1000 ABHD1 3180 5 29 -0.0677963 0.771229 0.343744 1000 ABL2 3180 4 41 0.0378648 0.593407 0.34231 1000 ABCG8 3180 12 152 0.187745 0.612388 0.310029 1000 vtools associate rare status -m \u0026quot;VTtest --name vtfisher --cfisher --midp -p 5000\u0026quot; --group_b\\ y name2 --to_db vtfisher -j8 \u0026gt; vtfisher.txt vtools show fields | grep vtfisher head vtfisher.txt  \n[^#^]\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/variants/gwas/",
	"title": "gwasCatalog",
	"tags": [],
	"description": "",
	"content": " The gwasCatalog is NHGRI\u0026rsquo;s collection of Genome-Wide Association (GWA) Studies SNPs. We downloaded the data for this annotation source from the UCSC Genome Browser database (http://genome.ucsc.edu/cgi-bin/hgTables?command=start). You can use this annotation source as a position, range or field-based annotation source. Examples for usage as a range-based and field-based annotation source are given on this page. (By default the usage for this annotation source is a position-based annotation source).\nUsage Here are the available gwasCatalog fields for annotation and filtering.\nvtools show annotation gwasCatalog -v2 Annotation database gwasCatalog (version hg19_20140112) Description: This database contains single nucleotide polymorphisms (SNPs) identified by published Genome-Wide Association Studies (GWAS), collected in the Catalog of Published Genome-Wide Association Studies at the National Human Genome Research Institute (NHGRI). From http://www.genome.gov/gwastudies/: Database type: position Number of records: 18,027 Distinct positions: 13,980 Reference genome hg19: chr, position Field: chr Type: string Missing entries: 0 Unique Entries: 36 Field: position Type: integer Comment: one-based position in chromosome Missing entries: 0 Unique Entries: 13,974 Range: 5641 - 249168436 Field: name Type: string Comment: ID of SNP associated with trait Missing entries: 0 Unique Entries: 12,003 Field: pubMedId Type: integer Comment: PubMed ID of publication of the study Missing entries: 0 Unique Entries: 1,488 Range: 15761122 - 23894747 Field: author Type: string Comment: First author of publication Missing entries: 0 Unique Entries: 1,129 Field: pubDate Type: string Comment: Date of publication Missing entries: 0 Unique Entries: 899 Field: journal Type: string Comment: Journal of publication Missing entries: 0 Unique Entries: 204 Field: title Type: string Comment: Title of publication Missing entries: 0 Unique Entries: 1,488 Field: trait Type: string Comment: Disease or trait assessed in study Missing entries: 0 Unique Entries: 865 Field: initSample Type: string Comment: Initial sample size Missing entries: 0 Unique Entries: 1,579 Field: replSample Type: string Comment: Replication sample size Missing entries: 0 Unique Entries: 1,064 Field: region Type: string Comment: Chromosome band / region of SNP Missing entries: 0 Unique Entries: 871 Field: genes Type: string Comment: Reported gene(s) Missing entries: 0 Unique Entries: 6,521 Field: riskAllele Type: string Comment: Strongest snp-risk allele Missing entries: 0 Unique Entries: 12,631 Field: riskAlFreq Type: string Comment: risk allele frequency Missing entries: 0 Unique Entries: 1,661 Field: pValue Type: float Comment: p-Value Missing entries: 0 Unique Entries: 623 Range: 0 - NS Field: pValueDesc Type: string Comment: p-Value description Missing entries: 0 Unique Entries: 1,563 Field: orOrBeta Type: string Comment: Odds ratio or beta Missing entries: 0 Unique Entries: 863 Field: ci95 Type: string Comment: 95% confidence interval Missing entries: 0 Unique Entries: 5,604 Field: platform Type: string Comment: Platform and [SNPs passing QC] Missing entries: 0 Unique Entries: 1,279 Field: cnv Type: string Comment: Y if copy number variant Missing entries: 0 Unique Entries: 1  Details gwasCatalog: usage as a position-based annotation source (default) To check if your variants contain any gwas hits, you can\nvtools use gwasCatalog vtools select variant \u0026quot;gwasCatalog.chr is not NULL\u0026quot; -t gwasHits  However, because GWA studies use tagging SNPs to identify associated (hopefully) causal variants, your dataset might not contain the exact SNP that is reported in gwas catalog. It might contains the casual variant or other associations that are in vicinity (in LD) with the reported gwas hits. Therefore, it make more sense to find variants that are close to the reported gwas hits.\ngwasCatalog: usage as a range-based annotation source The most flexible way to use this annotation source is to link your variants to GWA hits with a position range. The following links your variant positions to GWA hits using variant chromosomal locations that are +/- 5000bp within the GWA hit.\nvtools use gwasCatalog --anno_type range --linked_fields chr position-5000 position+5000  Then you can generate a useful report showing what known gwas hits are near your variants. The following command generates a report showing Type 2 diabetes hits near your variants.\nvtools select variant \u0026quot;gwasCatalog.trait == 'Type 2 diabetes'\u0026quot; -o variant.chr variant.pos variant.ref variant.alt gwasCatalog.trait gwasCatalog.name gwasCatalog.position gwasCatalog.pValue gwasCatalog.journal gwasCatalog.title \u0026gt; variants_near_diabetes_gwas_hits.txt 1 207653395 C A Type 2 diabetes rs17045328 207652176 7e-06 PLoS Genet Transferability of type 2 diabetes implicated loci in multi-ethnic cohorts from Southeast Asia. 11 17408630 C T Type 2 diabetes rs5215 17408630 4e-07 Nat Genet Meta-analysis of genome-wide association data and large-scale replication identifies additional susceptibility loci for type 2 diabetes. 11 17408630 C T Type 2 diabetes rs5215 17408630 5e-11 Science Replication of genome-wide association signals in UK samples reveals risk loci for type 2 diabetes. 11 17408630 C T Type 2 diabetes rs5219 17409572 1e-07 Science Genome-wide association analysis identifies loci for type 2 diabetes and triglyceride levels. 11 17408630 C T Type 2 diabetes rs5219 17409572 1e-09 Diabetes Adiposity-related heterogeneity in patterns of type 2 diabetes susceptibility observed in genome-wide association data. 11 17408630 C T Type 2 diabetes rs5219 17409572 5e-07 Diabetes Adiposity-related heterogeneity in patterns of type 2 diabetes susceptibility observed in genome-wide association data. 11 17408630 C T Type 2 diabetes rs5219 17409572 7e-11 Science A genome-wide association study of type 2 diabetes in Finns detects multiple susceptibility variants. 11 17409069 G A Type 2 diabetes rs5215 17408630 4e-07 Nat Genet Meta-analysis of genome-wide association data and large-scale replication identifies additional susceptibility loci for type 2 diabetes. 11 17409069 G A Type 2 diabetes rs5215 17408630 5e-11 Science Replication of genome-wide association signals in UK samples reveals risk loci for type 2 diabetes. 11 17409069 G A Type 2 diabetes rs5219 17409572 1e-07 Science Genome-wide association analysis identifies loci for type 2 diabetes and triglyceride levels. 11 17409069 G A Type 2 diabetes rs5219 17409572 1e-09 Diabetes Adiposity-related heterogeneity in patterns of type 2 diabetes susceptibility observed in genome-wide association data. 11 17409069 G A Type 2 diabetes rs5219 17409572 5e-07 Diabetes Adiposity-related heterogeneity in patterns of type 2 diabetes susceptibility observed in genome-wide association data. 11 17409069 G A Type 2 diabetes rs5219 17409572 7e-11 Science A genome-wide association study of type 2 diabetes in Finns detects multiple susceptibility variants. 11 17409572 T C Type 2 diabetes rs5215 17408630 4e-07 Nat Genet Meta-analysis of genome-wide association data and large-scale replication identifies additional susceptibility loci for type 2 diabetes. 11 17409572 T C Type 2 diabetes rs5215 17408630 5e-11 Science Replication of genome-wide association signals in UK samples reveals risk loci for type 2 diabetes. 11 17409572 T C Type 2 diabetes rs5219 17409572 1e-07 Science Genome-wide association analysis identifies loci for type 2 diabetes and triglyceride levels. 11 17409572 T C Type 2 diabetes rs5219 17409572 1e-09 Diabetes Adiposity-related heterogeneity in patterns of type 2 diabetes susceptibility observed in genome-wide association data. 11 17409572 T C Type 2 diabetes rs5219 17409572 5e-07 Diabetes Adiposity-related heterogeneity in patterns of type 2 diabetes susceptibility observed in genome-wide association data. 11 17409572 T C Type 2 diabetes rs5219 17409572 7e-11 Science A genome-wide association study of type 2 diabetes in Finns detects multiple susceptibility variants. 12 51354803 C T Type 2 diabetes rs12304921 51357542 7e-06 Nature Genome-wide association study of 14,000 cases of seven common diseases and 3,000 shared controls. 15 91524841 G T Type 2 diabetes rs8042680 91521337 2e-10 Nat Genet Twelve type 2 diabetes susceptibility loci identified through large-scale association analysis. 15 91525197 C T Type 2 diabetes rs8042680 91521337 2e-10 Nat Genet Twelve type 2 diabetes susceptibility loci identified through large-scale association analysis. 4 6302519 G A Type 2 diabetes rs1801214 6303022 3e-08 Nat Genet Twelve type 2 diabetes susceptibility loci identified through large-scale association analysis. 4 6302707 C T Type 2 diabetes rs1801214 6303022 3e-08 Nat Genet Twelve type 2 diabetes susceptibility loci identified through large-scale association analysis. 4 6303022 C T Type 2 diabetes rs1801214 6303022 3e-08 Nat Genet Twelve type 2 diabetes susceptibility loci identified through large-scale association analysis. 4 6303354 G A Type 2 diabetes rs1801214 6303022 3e-08 Nat Genet Twelve type 2 diabetes susceptibility loci identified through large-scale association analysis. 4 6303955 G A Type 2 diabetes rs1801214 6303022 3e-08 Nat Genet Twelve type 2 diabetes susceptibility loci identified through large-scale association analysis. .....  gwasCatalog: usage as a field-based annotation source In this usage, you can annotate your variants with published GWA hits that are in the same cytoband as your project variants. You can link your variants to the cytoBand annotation source and then annotate your variant cytoBands to published GWA hits\nvtools use cytoBand vtools use gwasCatalog --anno_type field --linked_fields region --linked_by 'cytoBand.name'  Then you can generate a useful report showing what known gwas hits are in the same cytobands as your variants. Once again, the following command generates a report showing Type 2 diabetes hits near your variants - except this time \u0026ldquo;near\u0026rdquo; means GWA hits that are within the same cytoband as your variants.\nvtools select variant \u0026quot;gwasCatalog.trait == 'Type 2 diabetes'\u0026quot; -o variant.chr variant.pos variant.ref variant.alt gwasCatalog.trait gwasCatalog.name gwasCatalog.position gwasCatalog.pValue gwasCatalog.journal gwasCatalog.title \u0026gt; variants_near_diabetes_gwas_hits.txt 1 117841245 C T Height rs17038182 118868405 5e-07 Nat Genet A large-scale genome-wide association study of Asian populations uncovers genetic factors influencing eight quantitative traits. 1 117841245 C T Height rs12735613 118883973 4e-11 Nat Genet Genome-wide association analysis identifies 20 loci that influence adult height. 1 117841245 C T Waist-hip ratio rs984222 119503843 9e-25 Nat Genet Meta-analysis identifies 13 new loci associated with waist-hip ratio and reveals sexual dimorphism in the genetic basis of fat distribution. 1 117841245 C T Type 2 diabetes rs10923931 120517959 4e-08 Nat Genet Meta-analysis of genome-wide association data and large-scale replication identifies additional susceptibility loci for type 2 diabetes. 1 117847270 A G Height rs17038182 118868405 5e-07 Nat Genet A large-scale genome-wide association study of Asian populations uncovers genetic factors influencing eight quantitative traits. 1 117847270 A G Height rs12735613 118883973 4e-11 Nat Genet Genome-wide association analysis identifies 20 loci that influence adult height. 1 117847270 A G Waist-hip ratio rs984222 119503843 9e-25 Nat Genet Meta-analysis identifies 13 new loci associated with waist-hip ratio and reveals sexual dimorphism in the genetic basis of fat distribution. 1 117847270 A G Type 2 diabetes rs10923931 120517959 4e-08 Nat Genet Meta-analysis of genome-wide association data and large-scale replication identifies additional susceptibility loci for type 2 diabetes. .....  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_report/inbreeding_coefficient/",
	"title": "inbreeding_coefficient",
	"tags": [],
	"description": "",
	"content": " Calculation inbreeding coefficient for individual samples vtools_report inbreeding_coefficient calculates the {$F$} statistic at single individual sample level from genotype data. It measures the reduction in heterozygosity for given genomic region of samples, compare to expected heterozygosity level under Hardy-Weinberg Equilibrium. For a two allelic locus, {$$P(AA)=p^2(1-F)+pF$$} {$$P(aa)=q^2(1-F)+qF$$} {$$P(Aa)=2pq(1-F)$$} We compute estimate for {$F$} as {$\\hat{F}=1-\\frac{#observed(Aa)}{#expected(Aa)}$}\nVariants included for calculation of {$F$} must be under HWE and be bi-allelic. Tri-allelic loci are automatically excluded from calculation.\nEstimate of MAF using given samples should be computed prior to calculation of {$F$}, via vtools update TABLE --from_stat \u0026lt;em\u0026gt;maf=maf()\u0026lt;/em\u0026gt;.\nDetails Interface vtools_report inbreeding_coefficient -h usage: vtools_report inbreeding_coefficient [-h] [--samples [SAMPLES [SAMPLES ...]]] --maf_field MAF_FIELD [-v {0,1,2}] table Report F statistic which describe the expected degree of a reduction in heterozygosity when compared to Hardy-Weinberg expectation. In simple two allele system with inbreeding, P(AA) = p^2(1-F)+pF, P(aa) = q^2(1-F)+qF and P(HET) = 2pq(1-F). For an individual F is estimated by F = 1 - #observed(HET) / #expected(HET). Tri-allelic loci, if identified, are excluded from calculation. positional arguments: table Variants based on which individual inbreeding coefficients are evaluated. optional arguments: -h, --help show this help message and exit --samples [SAMPLES [SAMPLES ...]] Conditions based on which samples are selected to have inbreeding coefficients calculated. Default to all samples. --maf_field MAF_FIELD Name of the field that holds minor allele frequency for sample variants, which is the field name for command 'vtools update table --from_stat \u0026quot;maf_field=maf()\u0026quot; --samples ...'. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information of vtools and vtools_report. Debug information are always recorded in project and vtools_report log files.  Example Compute MAF for given samples\nvtools update variant --from_stat 'mafEUR=maf()' --samples \u0026quot;super_pop='EUR'\u0026quot; -j8  We evaluate heterozygosity level on chromosome 1\nvtools select \u0026quot;chr='1'\u0026quot; -t chr1  Inbreeding coefficients are computed and saved to file chr1.inbreeding.txt\nvtools_report inbreeding_coef chr1 --maf_field mafEUR --samples \u0026quot;super_pop='EUR'\u0026quot; \\ \u0026gt; chr1.inbreeding.txt head chr1.inbreeding.txt HG00118 0.00599944241381 HG00119 0.00206096581669 HG00120 0.0114070032711 HG00121 0.0461496321201 HG00122 0.0127749763012 HG00123 0.00582167049467 HG00124 0.0129693670104 ...  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/format/formats/map/",
	"title": "map",
	"tags": [],
	"description": "",
	"content": " Import variants from file without ref and alt alleles Introduction From time to time, you might get a list of variants in map format, or as a list with only chromosome and position information. Reference and alternative alleles are not specified because the variants are from GWA studies with well-defined reference and alternative alleles. In this case, you can use format map, which automatically retrieve reference and alternative alleles from a specified dbSNP database.\nFormat specification vtools show format format/map.fmt Format: map Description: This input format imports variants from files in MAP format (with columns chr, name gen_dist, pos), or any delimiter-separated format with columns chr and pos. Because these input files do not contain reference and alternative alleles of variants, this format queries such information from the dbSNP database using chr and pos. Records that does not exist in dbSNP will be discarded. Records with multiple alternative alleles will lead to multiple records. Columns: None defined, cannot export to this format variant: chr Chromosome pos 1-based position ref Reference allele, '-' for insertion. alt Alternative allele obtained from another database Format parameters: db_file (default: dbSNP.DB) pos_idx Index of column for pyhysical location in the map file, should be 4 for a standard map file with chr, pos, gen_dist, pos. (default: 4) ref_field Name of ref field from the annotation database, used to retrieve reference allele at specified location. (default: refNCBI) alt_field Name of alt field from the annotation database, used to retrieve alternative allele at specified location. (default: alt) chr_field Name of chr field from the annotation database, used to locate variants from the dbSNP database. (default: chr) pos_field Name of pos field from the annotation database, used to locate variants from the dbSNP database. (default: start) separator Separator of the input file, default to space or tab. (default: None)  Examples You are given a list of variants with chromosome as the first column, and physical position as the third column:\nCHR SNP BP A1 12 rs11054701 12180423 C 12 rs2075241 12182746 C 12 rs2160521 12184905 T 12 rs10590349 12223570 G 12 rs10492120 12224619 C 12 rs3825258 12170662 C 12 rs11054697 12163740 C 12 rs16907786 12205869 A 12 rs11054665 12113442 G  Download dbSNP The first step is to get the right version of dbSNP. Because the variants are in hg18, you cannot use the default version of dbSNP, which uses hg19. Instead, you should run\nvtools show annotations vtools use dbSNP-hg18_130  The first command lists all available annotation databases, and the second command will download dbSNP and put a database such as dbSNP-hg18_130.DB under your project directory.\nImport and filter variants The default column for the position column is 4, but the input file has it at the third column, so you will need to use parameter --pos_idx 3. You do not have to set other parameters (fields) if you are using dbSNP database provided by variant tools.\nTo import the data, you can run command\nvtools import gwas_result.txt --format map --db_file dbSNP-hg18_130.DB \\ --pos_idx 3 --build hg18  This format will import multiple variants if there are multiple variants (usually SNV and indels) at the same location at dbSNP. For example, you can get one SNV and two deletions at position 12223570 of chromosome 12 in the following example.\nvtools output variant chr pos dbSNP.name ref alt 12 12180423 rs11054701 T C 12 12182746 rs2075241 G C 12 12184905 rs2160521 C T 12 12223570 rs7974059 G T 12 12223570 rs10590349 GATA - 12 12223570 rs56097732 GA - 12 12224619 rs10492120 C T 12 12170662 rs3825258 T C 12 12163740 rs11054697 T C 12 12205869 rs16907786 G A 12 12113442 rs11054665 T G  If you believe that all your variants are SNVs, you can run\nvtools select variant 'ref != \u0026quot;-\u0026quot;' 'alt != \u0026quot;-\u0026quot;' -t SNV  to put all SNVs into a separate table, or run\nvtools select variant 'ref = \u0026quot;-\u0026quot; OR alt = \u0026quot;-\u0026quot;' -t indels vtools remove variants indels  to remove all indels.\nThis format will ignore all variants that are not in dbSNP. If you would like to keep them, you can modify map.fmt, and add parameter default='-' to DatabaseQuerier.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/functions/otherfunctions/",
	"title": "other functions",
	"tags": [],
	"description": "",
	"content": " Other customized SQL functions vcf_variant: Output variants in vcf format with padding alleles Function vcf_variant(chr, pos, ref, alt, name=\u0026quot;.\u0026quot;) returns a string that represent variants in vcf format. If the variant is a SNV, the output merely connects input by tab (\u0026rsquo;\\t\u0026rsquo;). If the variant is an indel, it will pad reference (for insertion) or alternative (for deletion) allele with the allele before variant, adjust position, and generate an output that is acceptable by vcf. For example, if the variant is\n1 9468278 G - 1 9468279 - GA  Function vcf_variant(chr, pos, ref, alt, dbSNP.name) will produce\n1 9468277 rs111651373 GG G 1 9468278 rs111651373 G GGA  for these variants. Here dbSNP.name is used to add rsname to the output. You can use a contant \u0026quot;.\u0026quot; if dbSNP is not available. If no name is specified, the output will have only four columns.\n Examples: output indels with padding alleles Because the SNV case is simple, let us import some indels from an online snapshot\n% vtools init test -f % vtools admin --load_snapshot vt_testData % vtools import indels.vcf --build hg19 INFO: Importing variants from indels.vcf (1/1) indels.vcf: 100% [======================================================================] 184 15.4K/s in 00:00:00 INFO: 137 new variants (1 SNVs, 77 insertions, 58 deletions, 7 complex variants) from 184 lines are imported. Importing genotypes: 0 0.0/s in 00:00:00 Copying samples: 0 0.0/s in 00:00:00  The variants in vcf files are\n% sort indels.vcf -n -k2 | tail -5 | cut -f1-5 1 819516 rs71315270 A AT 1 819612 rs34487673 TC T 1 819612 rs71315271 TC T 1 819703 rs111948412 TC T,TCTATGTGTC 1 819703 rs77305433 TCTATGTGTCT T,TCTATGTGTC  If we output the variants, we can see that the padding alleles are removed, the positions have been adjusted, duplicates are removed (even if they have different rsnames) and variants are separated:\n% vtools output variant chr pos ref alt --order_by chr pos | tail -6 1 819517 - T 1 819613 C - 1 819704 CTATGTGTCT - 1 819704 C - 1 819705 - TATGTGTC 1 819713 T -  We can output the variants in vcf format using function vcf_variant,\n% vtools output variant 'vcf_variant(chr, pos, ref, alt)' --order_by chr pos | tail -6 1 819516 A AT 1 819612 TC T 1 819703 TCTATGTGTCT T 1 819703 TC T 1 819704 C CTATGTGTC 1 819712 CT C  The result does not match lines in the vcf exactly, because variants at different positions are not combined, and a padding of length 1 is used.\nAnyway, to produce vcf-like output, a name is needed. We can use a default value \u0026quot;.\u0026quot;,\n% vtools output variant 'vcf_variant(chr, pos, ref, alt, \u0026quot;.\u0026quot;)' --order_by chr pos | tail -6 1 819516 . A AT 1 819612 . TC T 1 819703 . TCTATGTGTCT T 1 819703 . TC T 1 819704 . C CTATGTGTC 1 819712 . CT C  or name from dbSNP\n% vtools use dbSNP % vtools output variant 'vcf_variant(chr, pos, ref, alt, dbSNP.name)' --order_by chr pos | tail -6 1 819516 rs71315270 A AT 1 819612 rs34487673 TC T 1 819703 rs77305433 TCTATGTGTCT T 1 819703 rs148493754 TC T 1 819704 rs148493754 C CTATGTGTC 1 819712 rs77305433 CT C  For variants with multiple entries in the dbSNP database, we can use option --all to output all of them\n% vtools output variant 'vcf_variant(chr, pos, ref, alt, dbSNP.name)' --order_by chr pos --all | tail -8 1 819516 rs71315270 A AT 1 819612 rs34487673 TC T 1 819703 rs77305433 TCTATGTGTCT T 1 819703 rs111948412 TC T 1 819703 rs148493754 TC T 1 819704 rs111948412 C CTATGTGTC 1 819704 rs148493754 C CTATGTGTC 1 819712 rs77305433 CT C  \nleast_not_null: a version of min(x,y) that ignores NULL This function is similar to min(x,y,...) but it ignores NULL values so least(2, NULL, 4) returns 2.\nHWE_exact: exact Tests of Hardy-Weinberg Equilibrium Special function HWE_exact implements a bi-allelic HWE exact test based on equation 2 of this paper. It requires 3 fields as input:\n total: total number of genotypes het: number of heterozygote (genotype 0/1 or 0/2) hom: number of homozygote (genotype 1\u0026frasl;1 or 2\u0026frasl;2)  and an optional field:\n other: number of heterozygote with two alternative alleles (genotype 1\u0026frasl;2, which is rarely observed in sequencing data)  If the optional field other is specified, then genotype 1\u0026frasl;2 will be collapsed with genotype 1\u0026frasl;1 or 2\u0026frasl;2 to maintain a bi-allelic system. Otherwise it will be ignored (treated as homozygote wildtype). The resulting field is p-value of the test.\n Examples: test of Hardy-Weinberg Equilibrium We can calculate HWE p-value based on existing fields total, het, and hom,\n% vtools update variant --set \u0026quot;hwe=HWE_exact(total, het, hom)\u0026quot; INFO: Adding field hwe  Because of the small sample size, there are not many choices for p-values:\n% vtools output variant chr pos ref alt hwe -l5 1 4540 G A 1.0 1 5683 G T 1.0 1 5966 T G 0.4 1 6241 T C 1.0 1 9992 C T 1.0  \nFisher_exact: Fisher\u0026rsquo;s exact test for case/ctrl associaiton The function Fisher_exact(num_var_alleles_case, num_var_alleles_ctrl, 2*num_gt_case, 2*num_gt_ctrl) tests for association of an alternate allele with a phenotype (i.e., case or control) status. Given a variant site to be tested, the function takes in the following 4 parameters, that are obtainable through vtools functions:\n num_var_alleles_case: number of alternative alleles for the case samples num_var_alleles_ctrl: number of alternative alleles for the control samples num_gt_case: total number of genotypes for the case samples, so twice of the number is total number of alleles for case samples num_gt_ctrl: total number of genotypes for the control samples, so twice of the number is total number of alleles for ctrl samples   Examples: Fisher\u0026rsquo;s exact test for case/ctrl association To perform Fisher\u0026rsquo;s exact test for case/ctrl association we can try to separate them into cases and controls and calculate statistics separately:\n% vtools update variant a --from_stat 'num_gt_case=#(GT)' 'num_var_alleles_case=#(alt)' --samples \u0026quot;phen1=1\u0026quot; INFO: 1000 samples are selected Counting variants: 100% [=======================================] 1,000 11.1K/s in 00:00:00 INFO: Adding field num_var_alleles_case INFO: Adding field num_gt_case Updating variant: 100% [=======================================] 27 38.3K/s in 00:00:00 INFO: 26 records are updated % vtools update variant a --from_stat 'num_gt_ctrl=#(GT)' 'num_var_alleles_ctrl=#(alt)' --samples \u0026quot;phen1=0\u0026quot; INFO: 1000 samples are selected Counting variants: 100% [=====================================] 1,000 11.4K/s in 00:00:00 INFO: Adding field num_var_alleles_ctrl INFO: Adding field num_gt_ctrl Updating variant: 100% [======================================] 27 38.8K/s in 00:00:00 INFO: 26 records are updated  And calculate p-value for the Fisher\u0026rsquo;s exact test:\n% vtools update variant --set \u0026quot;prop_pval=Fisher_exact(num_var_alleles_case, num_var_alleles_ctrl, 2*num_gt_case, 2*num_gt_ctrl)\u0026quot; INFO: Adding field prop_pval  Again, there are not many possible p-values due to small sample size \u0026hellip;\n% vtools output variant chr pos ref alt prop_pval | sort -k5 | head -5 22 49522870 G C 0.148032884657 22 49529883 C T 0.236820419247 1 742456 T G 0.249812453115 22 49534747 G C 0.265775831399 22 49534781 C T 0.337597625574  (:exampleend\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_commands/use/",
	"title": "use",
	"tags": [],
	"description": "",
	"content": " Use an annotation database 1. Usage % vtools use -h usage: vtools use [-h] [--as NAME] [-l [LINKED_BY [LINKED_BY ...]]] [--anno_type {variant,position,range,field}] [--linked_fields [LINKED_FIELDS [LINKED_FIELDS ...]]] [-f [FILES [FILES ...]]] [--rebuild] [-j N] [-v {0,1,2}] source Link an annotation database to the project, download it from the variant tools website or build it from source if needed. positional arguments: source Use an annotation database ($source.DB or $source.DB.gz) if it is available, download or build the database if a description file ($source.ann) is available. Otherwise, this command will download a description file and the corresponding database from web (c.f. runtime variable $search_path) and the latest version of the datavase). If all means fail, this command will try to download the source of the annotation database (or use source files provided by option --files). optional arguments: -h, --help show this help message and exit -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1). Basic link options: --as NAME An alternative name for the linked database. This option allows the use of shorter field names (e.g. tg.chr instead of thousandGenomes.chr) and the use of multiple versions of the same database. -l [LINKED_BY [LINKED_BY ...]], --linked_by [LINKED_BY [LINKED_BY ...]] A list of fields that are used to link the annotation database to tables in the existing project. This parameter is required only for 'field' type of annotation databases that link to fields of existing tables. Advanced link options: --anno_type {variant,position,range,field} This option overrides type of an existing annotation database when it is attached to a project. It corresponds to key anno_type of the data sources section of an annotation file (with suffix .ann) but does not affect the .ann file or the database built from it. --linked_fields [LINKED_FIELDS [LINKED_FIELDS ...]] An alternative set of fields that are used to link the annotation database to the master variant table. It should have four, two, and three values for database of type variant, position, and range. Similar to anno_type, this option does not affect the .ann file or the database built from it. Build database from source: -f [FILES [FILES ...]], --files [FILES [FILES ...]] A list of source files. If specified, vtools will not try to download and select source files. These source files will be compiled into a local annotation database. This is used only when no local annotation database is specified. --rebuild If set, variant tools will always rebuild the annotation database from source, ignoring existing local and online database. In addition to $name.DB, variant tools will also create $name-$version.DB.gz that can be readily distributed. -j N, --jobs N If need to build database from source, maximum number of processes to use.  2. Details Command vtools use attaches an annotation database to the project, effectively making one or more attributes available to variants in the project. Four types of annotation databases can be used with variant tools:\n A variant annotation database is linked directly to the project by linking chromosome, position, reference and alternative allele to fields chr, pos, ref, and alt of the project. It provides variant-level annotation. A position annotation database is linked to the project using fields chr and pos. It provides annotation information for nucleotide locations. If there are more than one variants at a locus, the annotation information are used for all of them. A range annotation database is linked to the project by comparing fields chr and pos to chromosome, starting and ending positions of each range. It provides annotation information for all variants in chromosomal regions. A field annotation database can be linked to any existing variant info or annotation fields and provide annotation information for these fields. For example, a gene annotation table might provide description for some genes, which can be linked to the project through field refGene.name2 that is provided by database refGene. Because attribute annotation databases are anchored to a project through existing attributes, one or more fields must be specified to link the database to the project using parameter --linked_by.  2.1 Basic usages of system-provided annotation databases It is easy to use system-provided annotation databases. Generally speaking, you should\n Use command vtools show annotations to see a list of annotation databases, and identify annotation databases that match the reference genome of your project. Use command vtools show annotation ANNODB to check the details of an annotation database. Use command vtools use ANNODB to download (if needed) and link the database to your project. variant tools will automatically link the project to the database using appropriate fields.  Position-aware annotation databases (variant, position, and range) are ref-genome dependent. Most such annotation databases are built for a particular build of reference genome, but some of them support multiple reference genomes.\n Newer databases usually contain more updated annotation information and usually use more recent build of reference genome. If you are using hg18 and would like to use annotation databases that use build hg19 of the reference genome, you can liftover your project to add hg19 as an alternative reference genome.\n  Examples: Use system-provided annotation databases Let us get a project\n% vtools import V1-3_hg19_combine.vcf --build hg19  This project uses build hg19 of the reference genome, as shown in the output of command vtools show\n% vtools show Verifying variants: 100% [=========================================] 1,611 105.8K/s in 00:00:00 INFO: 0 variants are updated Project name: use Primary reference genome: hg19 Secondary reference genome: Storage method: hdf5 Variant tables: variant Annotation databases:  We then use command vtools show annotations to check all available databases, using option -v0 to suppress descriptions of databases:\n% vtools show annotations -v0 CancerGeneCensus-20111215 CancerGeneCensus-20120315 CancerGeneCensus-20130711 CancerGeneCensus-20170912 CosmicCodingMuts-v61_260912 CosmicCodingMuts-v67_20131024 CosmicCodingMuts-v82_20170801 CosmicMutantExport-v61_260912 CosmicMutantExport-v67_241013 CosmicMutantExport-v82_20170803 CosmicNonCodingVariants-v61_260912 CosmicNonCodingVariants-v67_241013 CosmicNonCodingVariants-v82_20170801 DGV-hg18_20130723 DGV-hg19_20130723 DGV-hg38_20160831 ESP-6500SI-V2-SSA137 EntrezGene-20131028 EntrezGene-20170919 EntrezGene2RefSeq-20131028 EntrezGene2RefSeq-20170919 ExAC-hg19_r0.2 HGNC-20131029 HGNC-20170920 Illumina_NRCE-20130307 LCR-hg19_20090320 ccdsGene-hg19_20110909 ccdsGene-hg19_20111206 ccdsGene-hg19_20130904 ccdsGene-hg38_20171008 ccdsGene_exon-hg19_20110909 ccdsGene_exon-hg19_20111206 ccdsGene_exon-hg19_20130904 ccdsGene_exon-hg38_20171008 ccdsGene_exon_hg19-20111206 ccdsGene_hg19-20111206 clinvar-20150804 clinvar-20150929 clinvar-20171002 cytoBand-hg18_20111216 cytoBand-hg19_20111216 cytoBand-hg38_20140810 dbNSFP-hg18_hg19_1.1_2 dbNSFP-hg18_hg19_1_3 dbNSFP-hg18_hg19_2_0 dbNSFP-hg18_hg19_2_0b4 dbNSFP-hg18_hg19_2_1 dbNSFP-hg18_hg19_2_3 dbNSFP-hg18_hg19_2_4 dbNSFP-hg18_hg19_2_7 dbNSFP-hg18_hg19_2_9 dbNSFP-hg38_3_5a dbNSFP_gene-2_0 dbNSFP_gene-2_1 dbNSFP_gene-2_3 dbNSFP_gene-2_4 dbNSFP_gene-2_7 dbNSFP_gene-3_5a dbNSFP_light-hg18_hg19_1.0_0 dbNSFP_light-hg18_hg19_1_3 dbSNP-hg18_129 dbSNP-hg18_130 dbSNP-hg19_131 dbSNP-hg19_132 dbSNP-hg19_135-1 dbSNP-hg19_135 dbSNP-hg19_137 dbSNP-hg19_138 dbSNP-hg19_141 dbSNP-hg38_143 dbscSNV-hg19_20141120 evs-6500 evs-hg19_20111107 genomicSuperDups-hg19_20130626 genomicSuperDups-hg38_20141018 gwasCatalog-hg19_20111220 gwasCatalog-hg19_20140112 gwasCatalog-hg38_20171004 hapmap_ASW_freq-hg18_20100817 hapmap_CEU_freq-hg18_20100817 hapmap_CHB_freq-hg18_20100817 hapmap_CHD_freq-hg18_20100817 hapmap_GIH_freq-hg18_20100817 hapmap_JPT_freq-hg18_20100817 hapmap_LWK_freq-hg18_20100817 hapmap_MEX_freq-hg18_20100817 hapmap_MKK_freq-hg18_20100817 hapmap_TSI_freq-hg18_20100817 hapmap_YRI_freq-hg18_20100817 keggPathway-20110823 knownGene-hg18_20110909 knownGene-hg18_20121219 knownGene-hg19_20110909 knownGene-hg19_20121219 knownGene-hg19_20130904 knownGene-hg38_20160328 knownGene_exon-hg18_20110909 knownGene_exon-hg19_20110909 knownGene_exon-hg19_20130904 knownGene_exon-hg38_20160328 phastCons-hg19_20110909 phastCons-hg19_20130322 phastCons-hg38_20150913 phastConsElements-hg19_20130622 phastConsElements-hg38_20150913 refGene-hg18_20110909 refGene-hg19_20110909 refGene-hg19_20130904 refGene-hg38_20170201 refGene-mm10_20141201 refGene_coding-hg19_20130904 refGene_exon-hg18_20110909 refGene_exon-hg19_20110909 refGene_exon-hg19_20130904 refGene_exon-mm10_20141201 refGene_exon-mm10_20171008 rutgersMap-b134 thousandGenomes-hg19_20130502 thousandGenomes-hg19_v3_20101123 thousandGenomes-hg19_v5b_20130502  Some databases uses hg19, but most uses hg38. You can use most databases as simple as\n% vtools use refGene INFO: Choosing version refGene-hg19_20130904 from 5 available databases. INFO: Downloading annotation database annoDB/refGene-hg19_20130904.ann INFO: Using annotation DB refGene as refGene in project use. INFO: Known human protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq). % vtools use refGene_exon INFO: Choosing version refGene_exon-hg19_20130904 from 5 available databases. INFO: Downloading annotation database annoDB/refGene_exon-hg19_20130904.ann INFO: Using annotation DB refGene_exon as refGene_exon in project use. INFO: RefGene specifies known human protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq). This database contains all exome regions of the refSeq genes. % vtools use dbNSFP INFO: Downloading annotation database from annoDB/dbNSFP.ann INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/dbNSFP-hg18_hg19_2_0b4.DB.gz INFO: Using annotation DB dbNSFP in project test. INFO: dbNSFP version 2.0b4, maintained by Xiaoming Liu from UTSPH. Please cite \u0026quot;Liu X, Jian X, and Boerwinkle E. 2011. dbNSFP: a lightweight database of human non-synonymous SNPs and their functional predictions. Human Mutation. 32:894-899\u0026quot; if you find this database useful. % vtools use thousandGenomes INFO: Choosing version thousandGenomes-hg19_v5b_20130502 from 3 available databases. INFO: Downloading annotation database annoDB/thousandGenomes-hg19_v5b_20130502.ann INFO: Downloading annotation database from annoDB/thousandGenomes-hg19_v5b_20130502.DB.gz INFO: Using annotation DB thousandGenomes in project test. INFO: 1000 Genomes VCF file (available from: ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606/VCF/v4.0/00-All.vcf.gz).  The CancerGeneCensus database is a bit difficult to use because it is a field database that annotate gene names so you need to link it to refGene.name2,\n% vtools use CancerGeneCensus --linked_by refGene.name2 INFO: Choosing version CancerGeneCensus-20170912 from 4 available databases. INFO: Downloading annotation database annoDB/CancerGeneCensus-20170912.ann INFO: Downloading annotation database from annoDB/CancerGeneCensus-20170912.DB.gz INFO: This database contains variants from the Cancer Genome Project. It is an ongoing effort to catalogue those genes for which mutations have been causally implicated in cancer. The original census and analysis was published in Nature Reviews Cancer and supplemental analysis information related to the paper is also available. Currently, more than 1% of all human genes are implicated via mutation in cancer. Of these, approximately 90% have somatic mutations in cancer, 20% bear germline mutations that predispose to cancer and 10% show both somatic and germline mutations. INFO: 454 out of 25360 refGene.refGene.name2 are annotated through annotation database CancerGeneCensus WARNING: 72 out of 526 values in annotation database CancerGeneCensus are not linked to the project.  After you use these databases, you could get the details of them using command vtools show annotation ANNODB,\n% vtools show annotation refGene Annotation database refGene (version hg19_20130904) Description: Known human protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq). Database type: range Reference genome hg19: chr, txStart, txEnd name (char) Gene name chr (char) strand (char) which DNA strand contains the observed alleles txStart (int) Transcription start position (1-based) txEnd (int) Transcription end position cdsStart (int) Coding region start (1-based) cdsEnd (int) Coding region end exonCount (int) Number of exons exonStarts (char) Starting point of exons (adjusted to 1-based positions) exonEnds (char) Ending point of exons score (int) Score name2 (char) Alternative name cdsStartStat (char) cds start stat, can be 'non', 'unk', 'incompl', and 'cmp1' cdsEndStat (char) cds end stat, can be 'non', 'unk', 'incompl', and 'cmp1'   More detailed information such as statistics for each field are available if you specify option -v2 to the vtools show annotation command If you need to see a list of available fields, use command vtools show fields.  \nAbout multiple versions of the same database: The default database without version name always refers to the latest version. For example, dbSNP could be dbSNP-hg19_135, and then dbSNP-hg19_138 after version 138 becomes available.\n You can use a specific version of a database by specifying its full name. The database will appear without version name in your project (e.g. as dbSNP).\n You can use the --as option to give databases different names if you would like to use different versions of the same database in the project.\n 2.2 Advanced usages of annotation databases Each database provide a number of fields and one or more default methods to link them to a project database. For example, if you look at the output of vtools show annotation refGene, you can see that this is a range-based database that is linked to a project using fields chr, txStart, and txEnd, which are chromosome name and start and ending of transcription region. The database, however, has other fields such as cdsStart and cdsEnd so you can link the database to a project using these two fields to identify variants in the coding regions of ref seq genes. You can even use regions such as txStart-5000, txEnd+5000 to extend each region by 5k to include variants that are in vicinity of ref seq genes.\n Examples: alternative ways to link range-based annotation databases There are 730 variants in the regular ref seq gene regions,\n% vtools import V*_hg38.vcf --build hg38 % vtools select variant 'refGene.chr is not NULL' -c Counting variants: 21 1.3K/s in 00:00:00 469  We can link to the refGene database using coding regions\n% vtools use refGene --linked_fields chr cdsStart cdsEnd INFO: Choosing version refGene-hg38_20170201 from 5 available databases. INFO: Downloading annotation database annoDB/refGene-hg38_20170201.ann Binning ranges: 100% [=================================] 74,385 70.4K/s in 00:00:01 INFO: Using annotation DB refGene as refGene in project use. INFO: Known human protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq).  only 253 variants are selected, that means most variants are not in the coding regions,\n% vtools select variant 'refGene.chr is not NULL' -c Counting variants: 19 1.2K/s in 00:00:00 253  You can also link the database by an expanded region of each transcription region (adding 5k before and after the region),\n% vtools use refGene --linked_fields chr 'txStart-5000' 'txEnd+5000' INFO: Choosing version refGene-hg38_20170201 from 5 available databases. INFO: Downloading annotation database annoDB/refGene-hg38_20170201.ann Binning ranges: 100% [=================================] 74,385 66.5K/s in 00:00:01 INFO: Using annotation DB refGene as refGene in project use. INFO: Known human protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq).  This time more variants are selected by the refGene database,\n% vtools select variant 'refGene.chr is not NULL' -c Counting variants: 22 1.0K/s in 00:00:00 938  \nIn addition to the fields used to link to the project, you can even change the type of annotation database by specifying the appropriate values to options --anno_type and --linked_fieleds. For example, the gawsCatalog database records is a position-based annotation database that records GWAS hits. Because of the uncertainty of the exact locations of these findings, you can link it to the project as a range-based database that find variants that are close to these GWAS hits.\n Examples: Link a position based database as a range-based database We would like to see if any of our variants has been identified by one of the Genome-wide association studies. gwasCatalog is a position-based database that records all identified variants by their positions.\n% vtools use gwasCatalog INFO: Choosing version gwasCatalog-hg38_20171004 from 3 available databases. INFO: Downloading annotation database annoDB/gwasCatalog-hg38_20171004.ann INFO: Using annotation DB gwasCatalog as gwasCatalog in project use. INFO: This database contains single nucleotide polymorphisms (SNPs) identified by published Genome-Wide Association Studies (GWAS), collected in the Catalog of Published Genome-Wide Association Studies at the National Human Genome Research Institute (NHGRI). From http://www.genome.gov/gwastudies/:  One matching variant is found in our project\n% vtools select variant 'gwasCatalog.chr is not null' -c Counting variants: 3 1.2K/s in 00:00:00 1  However, we can link the database as a range-based database to check if there is any variant that falls in the vicinity of any GWA hits.\n% vtools use gwasCatalog --anno_type range --linked_fields chr 'position - 10000' 'position + 10000' INFO: Choosing version gwasCatalog-hg38_20171004 from 3 available databases. INFO: Downloading annotation database annoDB/gwasCatalog-hg38_20171004.ann Binning ranges: 100% [=================================] 64,965 71.2K/s in 00:00:00 INFO: Using annotation DB gwasCatalog as gwasCatalog in project use. INFO: This database contains single nucleotide polymorphisms (SNPs) identified by published Genome-Wide Association Studies (GWAS), collected in the Catalog of Published Genome-Wide Association Studies at the National Human Genome Research Institute (NHGRI). From http://www.genome.gov/gwastudies/:  This time, 110 variants are identified as within 10k distance of one of the GWA hits.\n% vtools select variant 'gwasCatalog.chr is not null' -c Counting variants: 6 1.1K/s in 00:00:00 110  \nBecause field-based databases can link to arbitrary fields, you do not have to use the default linking fields. For example, the CancerGeneCensus database by default links to the refGene.name2 field by \u0026lsquo;gene name\u0026rsquo;. It can also be linked to a knownGene ID because the CancerGeneCensus database has this field.\n Examples: Linking a field database using an alternative field The CancerGeneCensus database by default links to the refGene.name2 field by \u0026lsquo;gene name\u0026rsquo;.\n% vtools use CancerGeneCensus --linked_by refGene.name2 INFO: Choosing version CancerGeneCensus-20170912 from 4 available databases. INFO: Downloading annotation database annoDB/CancerGeneCensus-20170912.ann INFO: Using annotation DB CancerGeneCensus as CancerGeneCensus in project use. INFO: This database contains variants from the Cancer Genome Project. It is an ongoing effort to catalogue those genes for which mutations have been causally implicated in cancer. The original census and analysis was published in Nature Reviews Cancer and supplemental analysis information related to the paper is also available. Currently, more than 1% of all human genes are implicated via mutation in cancer. Of these, approximately 90% have somatic mutations in cancer, 20% bear germline mutations that predispose to cancer and 10% show both somatic and germline mutations. INFO: 448 out of 28031 refGene.refGene.name2 are annotated through annotation database CancerGeneCensus WARNING: 78 out of 526 values in annotation database CancerGeneCensus are not linked to the project.  From the output of vtools show annotation CancerGeneCensus, you can see that this database also provides kgID for each record. This allows you to link the database to the project using kgID,\n% vtools use knownGene INFO: Choosing version knownGene-hg38_20160328 from 6 available databases. INFO: Downloading annotation database annoDB/knownGene-hg38_20160328.ann INFO: Using annotation DB knownGene as knownGene in project use. INFO: Gene predictions based on data from RefSeq, Genbank, CCDS and UniProt, from the UCSC KnownGene track. % vtools use CancerGeneCensus --linked_fields kgID --linked_by knownGene.name INFO: Downloading annotation database from annoDB/CancerGeneCensus.ann INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/CancerGeneCensus-20130711.DB.gz INFO: Using annotation DB CancerGeneCensus in project test. INFO: This database contains variants from the Cancer Genome Project. It is an ongoing effort to catalogue those genes for which mutations have been causally implicated in cancer. The original census and analysis was published in Nature Reviews Cancer and supplemental analysis information related to the paper is also available. Currently, more than 1% of all human genes are implicated via mutation in cancer. Of these, approximately 90% have somatic mutations in cancer, 20% bear germline mutations that predispose to cancer and 10% show both somatic and germline mutations. INFO: 433 out of 80922 knowngene.name are annotated through annotation database CancerGeneCensus WARNING: 54 out of 487 values in annotation database CancerGeneCensus are not linked to the project.  Note that you can link GeneSymbol (the default link-out field in the database) to knowGene.name because none of the names will match\n% vtools use CancerGeneCensus --linked_by knownGene.name INFO: Downloading annotation database from annoDB/CancerGeneCensus.ann INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/CancerGeneCensus-20130711.DB.gz INFO: Using annotation DB CancerGeneCensus in project test. INFO: 0 out of 80922 knowngene.name are annotated through annotation database CancerGeneCensus WARNING: 487 out of 487 values in annotation database CancerGeneCensus are not linked to the project.  \nThere is also nothing prevents you from using other annotation database as a field-based database. For example, the gwasCatalog database has a field region that records the cytoband of each GWAS signal belongs. If you link this field to database cytoBand, you can provide a list of GWAS hits within each cytoband.\n Examples: Use a position-based database as a field database to annotate cytoBand The gwasCatalog database has a field region that records the cytoband of each GWAS hit. If we first use cytoBand,\n% vtools use cytoBand INFO: Downloading annotation database from annoDB/cytoBand.ann INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/cytoBand-hg19_20111216.DB.gz INFO: Using annotation DB cytoBand in project test. INFO: Cyto Band  and link the gwasCatalog database (originally a position-based database) to it through field region,\n% vtools use gwasCatalog --anno_type field --linked_fields region --linked_by cytoBand.name INFO: Downloading annotation database from annoDB/gwasCatalog.ann INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/gwasCatalog-hg19_20111220.DB.gz INFO: Using annotation DB gwasCatalog in project test. INFO: GWAS Catalog INFO: 745 out of 862 cytoband.name are annotated through annotation database gwasCatalog WARNING: 1 out of 746 values in annotation database gwasCatalog are not linked to the project.  For each variant, we have cytoband information as cytoBand.name (as well as gwasCatalog.region), and all GWAS hits for that belong to that region,\n% vtools output variant chr pos cytoBand.name gwasCatalog.genes gwasCatalog.trait --all -l 10 1 4540 1p36.33 PRKCZ Reasoning 1 5683 1p36.33 PRKCZ Reasoning 1 5966 1p36.33 PRKCZ Reasoning 1 6241 1p36.33 PRKCZ Reasoning 1 9992 1p36.33 PRKCZ Reasoning 1 9993 1p36.33 PRKCZ Reasoning 1 10007 1p36.33 PRKCZ Reasoning 1 10098 1p36.33 PRKCZ Reasoning 1 14775 1p36.33 PRKCZ Reasoning 1 16862 1p36.33 PRKCZ Reasoning  Although in this case we should use option --all to list all GAWS hits\n% vtools output variant chr pos cytoBand.name gwasCatalog.genes gwasCatalog.trait --all -l 10 1 4540 1p36.33 NR Body mass index 1 4540 1p36.33 PRKCZ Height 1 4540 1p36.33 PRKCZ Reasoning 1 5683 1p36.33 NR Body mass index 1 5683 1p36.33 PRKCZ Height 1 5683 1p36.33 PRKCZ Reasoning 1 5966 1p36.33 NR Body mass index 1 5966 1p36.33 PRKCZ Height 1 5966 1p36.33 PRKCZ Reasoning 1 6241 1p36.33 NR Body mass index  Obviously, all variants belonging to the same cytoband will have the same gwas hits as annotations. \n2.3 Create your own annotation databases You may create your own annotation databases to annotate, prioritize, and filter variants in your project. For example if you have a huge amount of data and you do not want to import all of them into a project (to reduce size and improve performance of the main project database), you can create annotation databases from input data.\nThe general process to create an annotation database is\n Write a .ann file that describe your annotation source (http://varianttools.sourceforge.net/Annotation/New). You can usually start from one of the system .ann files under ~/.varianttools/annoDB. Use command vtools use NAME.ann to create an annotation database and use it in the project. You can specify source files using option --files. A option --rebuild will force the rebuild of database from source file and generate a versioned and compressed .DB.gz file.  The [anno_utils][1] pipelines provide a few pipelines that can help you create annotation databases from various resources. For example, if you have a project with variants from unaffected individuals, you can export the variants as an annotation database. This database can be used by other projects to filter variants.\n "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/1000genome/",
	"title": "1000 genomes",
	"tags": [],
	"description": "",
	"content": " Import all genotype data from the 1000 genome project The genotype data for all 60 samples from consists of 23 .vcf.gz files with a total of 142G. Because of the size of data, it can be slow to import all these files into variant tools. Depending on your computing environment, you can\n1. Import all files together The most straightforward method is to import all files together:\nmkdir p1000g_all cd p1000g_all vtools init p1000g_all vtools admin --set_runtime_option \u0026quot;temp_dir=/Volumes/AnotherDisk/tmp/p1000g_all\u0026quot; vtools admin --set_runtime_option 'sqlite_pragma=synchronous=OFF,journal_mode=MEMORY' vtools import /path/to/ALL.chr*.vcf.gz -j8 --build hg19 vtools admin --merge_samples  Command vtools admin --merge_samples is needed because genotypes for these samples are imported chromosome by chromosome, and appear as multiple samples with same names.\n2. Import data chromosome by chromosome into subprojects If you have a cluster system to spread the workload, you could create multiple projects and import genotypes chromosome by chromosome. That is to say, for chromosome 1, \u0026hellip;, 22 and X, you can create bash scripts such as\nchr=1 mkdir p1000g_$chr cd p1000g_$chr vtools init p1000g_$chr -f vtools admin --set_runtime_option \u0026quot;temp_dir=/Volumes/AnotherDisk/tmp/p1000g_$chr\u0026quot; vtools admin --set_runtime_option 'sqlite_pragma=synchronous=OFF,journal_mode=MEMORY' vtools import /path/to/ALL.chr${chr}.phase1_release_v3.20101123.snps_indels_svs.genotypes.vcf.gz -j4 --build hg19  After all jobs are completed, you can merge the projects using command. The project and sample merge steps can be slow (about 1 day), but this method leaves 23 subprojects, which are much smaller than the master project and can be useful if you are only interested in data on a particular chromosome.\nmkdir p1000g_merged cd p1000g_merged vtools init p1000g_merged --children ../p1000g_* -j8 vtools admin --merge_samples  3. Merge vcf files before importing To avoid merging samples, you could merge the vcf files using vcftools before importing them\nmkdir p1000g_single cd p1000g_single vcf-concat /path/to/ALL.chr*.vcf.gz \u0026gt; ALL.vcf vtools admin --set_runtime_option \u0026quot;temp_dir=/Volumes/AnotherDisk/tmp/p1000g_all\u0026quot; vtools admin --set_runtime_option 'sqlite_pragma=synchronous=OFF,journal_mode=MEMORY' vtools import ALL.vcf -j8 --build hg19  This appears to be the most efficient method to import this dataset.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/format/formats/annovar/",
	"title": "ANNNOVAR",
	"tags": [],
	"description": "",
	"content": " Importing ANNOVAR input file Format description http://www.openbioinformatics.org/annovar/annovar_input.html\n\u0026ldquo;ANNOVAR takes text-based input files, where each line corresponds to one variant. On each line, the first five space- or tab- delimited columns represent chromosome, start position, end position, the reference nucleotides and the observed nucleotides. Additional columns can be supplied and will be printed out in identical form. For convenience, users can use “0” to fill in the reference nucleotides, if this information is not readily available. Insertions, deletions or block substitutions can be readily represented by this simple file format, by using “–” to represent a null nucleotide. One example is given below (this example is included as ex1.human file in the ANNOVAR package), with extra columns that serve as comments on the variants. By default, 1-based coordinate system will be assumed; if \u0026ndash;zerostart argument is issued, a half-open zero-based coordinate system will be used in ANNOVAR instead.\u0026rdquo;\nSample input 1 161003087 161003087 C T comments: rs1000050, a SNP in Illumina SNP arrays 1 84647761 84647761 C T comments: rs6576700 or SNP_A-1780419, a SNP in Affymetrix SNP arrays 1 13133880 13133881 TC - comments: rs59770105, a 2-bp deletion 1 11326183 11326183 - AT comments: rs35561142, a 2-bp insertion 1 105293754 105293754 A ATAAA comments: rs10552169, a block substitution 1 67478546 67478546 G A comments: rs11209026 (R381Q), a SNP in IL23R associated with Crohn's disease 2 233848107 233848107 T C comments: rs2241880 (T300A), a SNP in the ATG16L1 associated with Crohn's disease 16 49303427 49303427 C T comments: rs2066844 (R702W), a non-synonymous SNP in NOD2 16 49314041 49314041 G C comments: rs2066845 (G908R), a non-synonymous SNP in NOD2 16 49321279 49321279 - C comments: rs2066847 (c.3016_3017insC), a frameshift SNP in NOD2 13 19661686 19661686 G - comments: rs1801002 (del35G), a frameshift mutation in GJB2, associated with hearing loss 13 19695176 20003944 0 - comments: a 342kb deletion encompassing GJB6, associated with hearing loss  How to import Saving the above example file as ex1.human, one can import it using command\nvtools import --format ANNOVAR ex1.human --build hg18 INFO: Importing genotype from ex1.human (1/1) ex1.human: 12 INFO: 0 new variants from 11 records are imported, with 0 SNVs, 0 insertions, 0 deletions, and 0 complex variants. 1 invalid records are ignored  The inputted variants can be displayed using\nvtools output variant chr pos ref alt 1 161003087 C T 1 84647761 C T 1 13133880 TC - 1 11326183 - AT 1 105293755 - TAAA 1 67478546 G A 2 233848107 T C 16 49303427 C T 16 49314041 G C 16 49321279 - C 13 19661686 G -  variant tools does not recognize missing reference allele in the last line of input (a large deletion) and only imports 11 variants from the input file.\nSee an export example.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/joint_conditional/",
	"title": "Joint/conditional association analysis",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/",
	"title": "Pipelines",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/single_gene/wss-test/",
	"title": "WSS test",
	"tags": [],
	"description": "",
	"content": " Weighted Sum Statistic via Rank Test Introduction The method proposed by Madsen and Browning 2009[^Bo Eskerod Madsen and Sharon R. Browning (2009) A Groupwise Association Test for Rare Mutations Using a Weighted Sum Statistic. PLoS Genetics doi:10.1371/journal.pgen.1000384. http://dx.plos.org/10.1371/journal.pgen.1000384^] first introduced the idea of assigning \u0026ldquo;weights\u0026rdquo; to rare variants within a genetic region before they are collapsed. In this case the variants having higher weights will have more substantial contribution to the collapsed variant score. In the Madsen \u0026amp; Browning paper the \u0026ldquo;weights\u0026rdquo; are defined as {$\\sqrt{n_iq_i(1-q_i)}$} with the assumption that the \u0026ldquo;rarer\u0026rdquo; the variant, the larger the risk effect it is to a phenotype. The {$q_i$} in the original paper was based on observed control sample, which might result in inflated type I error[^Mathieu Lemire (2011) Defining rare variants by their frequencies in controls may increase type I error. Nature Genetics doi:10.1038/ng.818. http://www.nature.com/doifinder/10.1038/ng.818^]. Implementation of the WSS statistic in the WSSRankTest method uses the same definition for {$q_i$} but the Mann-Whitney U test (definition and C++ implementation for this program) now relies on a full permutation procedure rather than normal approximation, such that the bias is correctly accounted for.\nAs with the Varible Thresholds strategy?, the idea of weighting can be applied to many other rare variant methods. The WeightedBurdenBt and WeightedBurdenQt methods implements the Madsen \u0026amp; Browning weighting based on controls (or samples with low quantitative phenotypic values) or the entire population, and tests for association for both case control and quantitative traits with/without presence of phenotype co-variates.\nDetails Command interface vtools show test WSSRankTest Name: WSSRankTest Description: Weighted sum method using rank test statistic, Madsen \u0026amp; Browning 2009 usage: vtools associate --method WSSRankTest [-h] [--name NAME] [-q1 MAFUPPER] [-q2 MAFLOWER] [--alternative TAILED] [-p N] [--adaptive C] [--moi {additive,dominant,recessive}] Weighted sum method using rank test statistic, Madsen \u0026amp; Browning 2009. p-value is based on the significance level of the Wilcoxon rank-sum test. Two methods are available for evaluating p-value: a semi-asymptotic p-value based on normal distribution, or permutation based p-value. Variants will be weighted by 1/sqrt(nP*(1-P)) and the weighted codings will be summed up for rank test. Two-sided test is available for the asymptotic version, which will calculate two p-values based on weights from controls and cases respectively, and use the smaller of them with multiple testing adjustment. For two-sided permutation based p-value please refer to \u0026quot;vtools show test WeightedBurdenBt\u0026quot; optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. -q1 MAFUPPER, --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 0.01 -q2 MAFLOWER, --maflower MAFLOWER Minor allele frequency lower limit. All variants having sample MAF\u0026gt;m2 will be included in analysis. Default set to 0.0 --alternative TAILED Alternative hypothesis is one-sided (\u0026quot;1\u0026quot;) or two-sided (\u0026quot;2\u0026quot;). Note that two-sided test is only available for asymptotic version of the test. Default set to 1 -p N, --permutations N Number of permutations. Set it to zero to use the asymptotic version. Default is zero --adaptive C Adaptive permutation using Edwin Wilson 95 percent confidence interval for binomial distribution. The program will compute a p-value every 1000 permutations and compare the lower bound of the 95 percent CI of p-value against \u0026quot;C\u0026quot;, and quit permutations with the p-value if it is larger than \u0026quot;C\u0026quot;. It is recommended to specify a \u0026quot;C\u0026quot; that is slightly larger than the significance level for the study. To disable the adaptive procedure, set C=1. Default is C=0.1 --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive model. Default set to additive  Application  Example using snapshot vt_ExomeAssociation\n% vtools associate rare status -m \u0026quot;WSSRankTest --name wss -p 5000\u0026quot; --group_by name2 --to_db w\\ ss -j8 \u0026gt; wss.txt INFO: 3180 samples are found INFO: 2632 groups are found INFO: Starting 8 processes to load genotypes Loading genotypes: 100% [=========================================] 3,180 33.7/s in 00:01:34 Testing for association: 100% [================================================] 2,632/591 10.7/s in 00:04:06 INFO: Association tests on 2632 groups have completed. 591 failed. INFO: Using annotation DB wss in project test. INFO: Annotation database used to record results of association tests. Created on Wed, 30 Jan 2013 16:18:43 % vtools show fields | grep wss wss.name2 name2 wss.sample_size_wss sample size wss.num_variants_wss number of variants in each group (adjusted for specified MAF wss.total_mac_wss total minor allele counts in a group (adjusted for MOI) wss.statistic_wss test statistic. wss.pvalue_wss p-value wss.std_error_wss Empirical estimate of the standard deviation of statistic wss.num_permutations_wss number of permutations at which p-value is evaluated % head wss.txt name2 sample_size_wss num_variants_wss total_mac_wss statistic_wss pvalue_wss std_error_wss num_permutations_wss AADACL4 3180 5 138 34206 0.911089 11215.6 1000 ABCD3 3180 3 42 12967 0.63037 6602.73 1000 ABCG5 3180 6 87 37794 0.248751 8912.03 1000 AAMP 3180 3 35 16160 0.290709 5777.64 1000 ABCB10 3180 6 122 56091 0.145854 10409.2 1000 ABHD1 3180 5 29 9825 0.605395 5363.56 1000 ABCB6 3180 7 151 49949 0.608392 11831.6 1000 ABL2 3180 4 41 16097 0.438561 6499.52 1000 ACADM 3180 4 103 19070 0.967033 9782.51 1000  \n[^#^]\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/pipelines/other_pipelines/filtering/",
	"title": "filtering",
	"tags": [],
	"description": "",
	"content": " Identification of recessive and de novo variants for family-based design Usage % vtools show pipeline filtering Pipelines to filter variants. Available pipelines: denovo, recessive Pipeline \u0026quot;denovo\u0026quot;: This pipeline identifies de novo mutations from a family of unaffected parents, affected offspring, and optional unaffected siblings. It can be applied either to the current project (no --input is specified), or a snapshot (--input) for which the snapshot will be loaded and overwrite the existing project. The parameter --samples is required to specify the name of samples in the order of offspring (proband), parents and sibling. Parameter --name is recommended to give all variant tables a prefix. This pipeline will produce tables $name_denovo (variants that are observed only in the proband), $name_denovo_by_site (variants that are observed in the proband with no variant in parents and sibling at this site). A table $name_denovo_SNP will be created with all SNP markers in table $name_denovo. And, depending on values of parameter --databases, it can produce tables $table_1kg for variants in 1000 genomes project, $table_dbSNP for variants in dbSNP project, and $table_refGene, $table_refGene_exon, $table_ccdsGene, $table_ccdsGene_exon, $table_CancerGenomeCensus, $table_COSMIC, $table_dbNSFP, $table_phastCons, $table_phastConsElements, $table_genomicSuperDups for tables in respective annotation databases. It is up to you to select variants based on these membership tables using the 'vtools compare' command. The project will be saved to a snapshot if a name (or filename with extension .tar or .tar.gz) is specified as the output. denovo_0: Load specified snapshot if a snapshot is specified. Otherwise use the existing project. denovo_5: Check the version of variant tools (version 2.2.1 and above is required to execute this pipeline) denovo_10: Select variants for each sample denovo_15: Import all annotation databases denovo_20: Locate de novo variants of the proband denovo_30: Locate de novo variants by site (no parental variants at the sites, even if the variants are different). This table contains a subset of table $name_denovo. denovo_50: Create variant tables according to their membership in different annotation databases denovo_100: Save the project to a snapshot if an output is specified. denovo_200: Summarize the results. Pipeline \u0026quot;recessive\u0026quot;: This pipeline identifies recessive mutations from a family of unaffected parents, affected offspring, and optional unaffected siblings. Recessive variant is defined as variants that are homozygous in the affected offspring (proband), heterozygous in both parents, and heterozygous or wildtype in a sibling (if available). The pipeline can be applied either to the current project (no --input is specified), or a snapshot (--input) for which the snapshot will be loaded and overwrite the existing project. The parameter --samples is required to specify the name of samples in the order of offspring (proband), parents, and sibling. Parameter --name is recommended to give all variant tables a prefix. This pipeline will produce tables $name_recessive (variants that are observed only in the proband), $name_recessive_by_site (variants that are observed in the proband with no variant in parents and sibling at this site). A table $name_denovo_SNP will be created with all SNP markers in table $name_denovo. And, depending on values of parameter --databases, it can produce tables $table_1kg for variants in 1000 genomes project, $table_dbSNP for variants in dbSNP project, and $table_refGene, $table_refGene_exon, $table_ccdsGene, $table_ccdsGene_exon, $table_CancerGenomeCensus, $table_COSMIC, $table_dbNSFP, $table_phastCons, $table_phastConsElements, $table_genomicSuperDups for tables in respective annotation databases. It is up to you to select variants based on these membership tables using the 'vtools compare' command. Two optional output files are allowed. The project will be saved to a snapshot if a name (or filename with extension .tar or .tar.gz) is specified as the output. recessive_0: Load specified snapshot if a snapshot is specified. Otherwise use the existing project. recessive_5: Check the version of variant tools (version 2.2.1 and above is required to execute this pipeline) recessive_10: Count the number of heterozygotes in parents, number of homozygotes in proband and his or her sibling, if available. recessive_15: Import all annotation databases recessive_20: Locate recessive variants of the proband (homozygous only in proband) and save variants in table $name_recessive recessive_50: Create variant tables according to their membership in different annotation databases recessive_100: Save the project to a snapshot if an output is specified. recessive_200: Summarize the results. Pipeline parameters: samples Name of samples for proband (affected offspring), his or her parents (unaffected) and sibling (unaffected, if available) for the denovo and recessive pipelines. name Name of the family. All generated tables will be prefixed with this name. (default: family) databases Databases for which membership tables will be produced. (default: thou sandGenomes,dbSNP,refGene,ccdsGene,refGene_exon,ccdsGene_exon,CosmicCo dingMuts,CosmicNonCodingVariants,dbNSFP,phastCons,phastConsElements,ge nomicSuperDups)  Details Identification of de novo variants in a family with affected offspring This pipeline executes a series of vtools commands to identify de novo variants in a family with affected offsprng, unaffected parents, and an optional unaffected sibling.\nThe pipeline either applies to the existing project, or load a snapshot if a snapshot is specified using parameter --input. For a project with two unaffected parents, affected offspring (proband), and an optional sibling, this pipeline\n identify variants for each sample identify variants that appear only in the affected offspring, save it to a variant table $name_denovo identify a subset of variants that have no other parental variants at the variant sites, save it to table $name_denovo_site identify variants that belong to a number of annotation databases and save them to their respective variant tables.  The pipeline writes a summary of tables created to the standard output, and save the project to a snapshot if a name or filename is assigned to parameter --output.\nFor example, the following command\n% vtools execute filtering denovo --input poly_data.tar \\ --samples WGS3_2 WGS3_3 WGS3_1 --output denovo.tar \\ \u0026gt; logfile  produces a log file\n% cat logfile SUMMARY: Identification of de novo variants for family family Members: WGS3_2 WGS3_3 (unaffected parents), WGS3_1 (affected offspring) Number of variants: family_WGS3_2 : 4367814 (variants from sample WGS3_2) family_WGS3_3 : 4455890 (variants from sample WGS3_3) family_WGS3_1 : 4343418 (variants from sample WGS3_1) de novo variants: family_denovo : 113553 (de novo variants for family family ) family_denovo_SNP: 63578 (de novo SNP variants for family family ) family_denovo_by_site: 95653 (de novo variants for family family (by site, namely no parental and sibling variant at the sites)) Database membership: family_denovo_in_thousandGenomes: 18330 (de novo variants in database thousandGenomes) family_denovo_in_dbSNP: 71921 (de novo variants in database dbSNP) family_denovo_in_refGene: 40037 (de novo variants in database refGene) family_denovo_in_ccdsGene: 28427 (de novo variants in database ccdsGene) family_denovo_in_refGene_exon: 1099 (de novo variants in database refGene_exon) family_denovo_in_ccdsGene_exon: 235 (de novo variants in database ccdsGene_exon) family_denovo_in_CosmicCodingMuts: 73 (de novo variants in database CosmicCodingMuts) family_denovo_in_CosmicNonCodingVariants: 111 (de novo variants in database CosmicNonCodingVariants) family_denovo_in_dbNSFP: 148 (de novo variants in database dbNSFP) family_denovo_in_phastCons: 101916 (de novo variants in database phastCons) family_denovo_in_phastConsElements: 3502 (de novo variants in database phastConsElements) family_denovo_in_genomicSuperDups: 24836 (de novo variants in database genomicSuperDups)  The order of sample names in parameter --samples is very important. It should be the name for parents, followed by affected offspring (proband), and optionally name of another unaffected offspring. Mixing up the order will certainly lead to erroneous results!\nIdentification of recessive variants in a family with affected offspring This pipeline works similarly to the denovo pipeline (with the same input, output and other options), but tried to identify variants that are recessive in the affected offspring, heterozygous in parents, and wildtype or heterozygous in the unaffected sibling, if available.\nVariants on sex chromosomes are handled in the same way as variants on autosomes. There must be some genotyping error if you observe recessive variants on chromosome Y. If you observe recessive variants on chromosome X, it means the variant is heterozygous for mother, and exists in father.\nWhat is next? The pipelines identify recessive or de novo variants and create a bunch of tables. You usually should filter the list more using combination of memberships, quality scores, and other information. For example, if you are looking for novel variants that are not in 1000 genomes, in exon regions, with high conservation score, not in genomic duplication regions, you can select the variants using command\n% vtools compare --expression 'mylist=family_denovo - family_denovo_in_thousandGenomes - \\ (family_denovo - (family_denovo_in_refGene_exon | family_denovo_phastConsElements)) - \\ family_denovo_genomicSuperDups'  and start looking closely at these variants, using commands such as\n% vtools output mylist chr pos ref alt 'ref_sequence(chr, pos, pos+20)' \u0026quot;track('mydata.bam', 'reads')\u0026quot;  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/variants/hapmap/",
	"title": "hapmap",
	"tags": [],
	"description": "",
	"content": " Usage Population-specific databases from the HapMap project. They provide population-specific variant count and frequences.\n% vtools show annotations hapmap -v0 hapmap_ASW_freq-hg18_20100817 hapmap_ASW_freq hapmap_CEU_freq-hg18_20100817 hapmap_CEU_freq hapmap_CHB_freq-hg18_20100817 hapmap_CHB_freq hapmap_CHD_freq-hg18_20100817 hapmap_CHD_freq hapmap_GIH_freq-hg18_20100817 hapmap_GIH_freq hapmap_JPT_freq-hg18_20100817 hapmap_JPT_freq hapmap_LWK_freq-hg18_20100817 hapmap_LWK_freq hapmap_MEX_freq-hg18_20100817 hapmap_MEX_freq hapmap_MKK_freq-hg18_20100817 hapmap_MKK_freq hapmap_TSI_freq-hg18_20100817 hapmap_TSI_freq hapmap_YRI_freq-hg18_20100817 hapmap_YRI_freq  Details % vtools show annotation hapmap_CEU_freq Annotation database hapmap_CEU_freq (version hg18_20100817) Description: Allele frequency information of SNP markers of the CEU population of phase II and III of the HAPMAP project. Database type: variant Reference genome hg18: chrom, pos, refallele, otherallele rsname rsname chrom chromosome pos 1-based position strand strand refallele reference allele CEU_refallele_freq frequency of reference allele CEU_refallele_count Count of reference allele otherallele Other allele CEU_otherallele_freq frequency of other allele CEU_otherallele_count Count of other allele CEU_totalcount Total allele count  For example, if you would like to know the allele count and frequencies in hapmap, ESP, and thousand genomes projects, you can\nvtools init freq vtools import mydata.vcf --build hg19 # import data vtools liftover hg18 # if your data is in hg19 vtools use dbSNP vtools use hapmap_ASW_freq vtools use hapmap_CEU_freq vtools use hapmap_CHB_freq vtools use hapmap_CHD_freq vtools use hapmap_GIH_freq vtools use hapmap_JPT_freq vtools use hapmap_LWK_freq vtools use hapmap_MEX_freq vtools use hapmap_MKK_freq vtools use hapmap_TSI_freq vtools use hapmap_YRI_freq vtools use ESP vtools use thousandGenomes vtools export variant --format csv --header \\ chr pos ref alt rsname \\ ASW_refallele_freq ASW_total_count \\ CEU_refallele_freq CEU_totalcount \\ CHB_refallele_freq CHB_totalcount \\ CHD_refallele_freq CHD_totalcount \\ GIH_refallele_freq GIH_totalcount \\ JPT_refallele_freq JPT_totalcount \\ LWK_refallele_freq LWK_totalcount \\ MEX_refallele_freq MEX_totalcount \\ MKK_refallele_freq MKK_totalcount \\ TSI_refallele_freq TSI_totalcount \\ YRI_refallele_freq YRI_totalcount \\ ESP_all_ref_freq ESP_totalcount \\ ESP_AfricanAmerican_RefFreq ESP_AfricanAmerican_totalcount \\ ESP_EuropeanAmerican_RefFreq EuropeanAmerican_totalcount \\ 1kg_REF_FREQ \\ --fields chr pos ref alt dbSNP.name \\ ASW_refallele_freq ASW_totalcount \\ CEU_refallele_freq CEU_totalcount \\ CHB_refallele_freq CHB_totalcount \\ CHD_refallele_freq CHD_totalcount \\ GIH_refallele_freq GIH_totalcount \\ JPT_refallele_freq JPT_totalcount \\ LWK_refallele_freq LWK_totalcount \\ MEX_refallele_freq MEX_totalcount \\ MKK_refallele_freq MKK_totalcount \\ TSI_refallele_freq TSI_totalcount \\ YRI_refallele_freq YRI_totalcount \\ \u0026quot;ESP.AllRefCount * 1.0 / (ESP.AllRefCount + ESP.AllAltCount)\u0026quot; \u0026quot;ESP.AllRefCount + ESP.AllAltCount\u0026quot; \\ \u0026quot;ESP.AfricanAmericanRefCount * 1.0 / (ESP.AfricanAmericanRefCount + ESP.AfricanAmericanAltCount)\u0026quot; \\ \u0026quot;ESP.AfricanAmericanRefCount + ESP.AfricanAmericanAltCount\u0026quot; \\ \u0026quot;ESP.EuropeanAmericanRefCount * 1.0 / (ESP.EuropeanAmericanRefCount + ESP.EuropeanAmericanAltCount)\u0026quot; \\ \u0026quot;ESP.EuropeanAmericanRefCount + ESP.EuropeanAmericanAltCount\u0026quot; \\ thousandGenomes.REF_FREQ_INFO \u0026gt; freq.csv  Or, if you would like to get the frequency across all hapmap populations, you can do\nvtools output variant chr pos ref alt dbSNP.name \\ ASW_refallele_freq ASW_totalcount \\ CEU_refallele_freq CEU_totalcount \\ CHB_refallele_freq CHB_totalcount \\ CHD_refallele_freq CHD_totalcount \\ GIH_refallele_freq GIH_totalcount \\ JPT_refallele_freq JPT_totalcount \\ LWK_refallele_freq LWK_totalcount \\ MEX_refallele_freq MEX_totalcount \\ MKK_refallele_freq MKK_totalcount \\ TSI_refallele_freq TSI_totalcount \\ YRI_refallele_freq YRI_totalcount \\ \u0026quot;(IFNULL(ASW_refallele_count, 0.) + \\ IFNULL(CEU_refallele_count, 0.) + \\ IFNULL(CHB_refallele_count, 0.) + \\ IFNULL(CHD_refallele_count, 0.) + \\ IFNULL(GIH_refallele_count, 0.) + \\ IFNULL(JPT_refallele_count, 0.) + \\ IFNULL(LWK_refallele_count, 0.) + \\ IFNULL(MEX_refallele_count, 0.) + \\ IFNULL(MKK_refallele_count, 0.) + \\ IFNULL(TSI_refallele_count, 0.) + \\ IFNULL(YRI_refallele_count, 0.)) * 1.0 / \\ (IFNULL(ASW_totalcount, 0) + \\ IFNULL(CEU_totalcount, 0) + \\ IFNULL(CHB_totalcount, 0) + \\ IFNULL(CHD_totalcount, 0) + \\ IFNULL(GIH_totalcount, 0) + \\ IFNULL(JPT_totalcount, 0) + \\ IFNULL(LWK_totalcount, 0) + \\ IFNULL(MEX_totalcount, 0) + \\ IFNULL(MKK_totalcount, 0) + \\ IFNULL(TSI_totalcount, 0) + \\ IFNULL(YRI_totalcount, 0))\u0026quot; -l 10  Here IFNULL is used to convert missing values to , and the result will be `NULL` if total count is (which leads to 0./0).\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_commands/select/",
	"title": "select",
	"tags": [],
	"description": "",
	"content": " Select variants from a variant table 1. Usage % vtools select -h usage: vtools select [-h] [-s [COND [COND ...]]] [-t [TABLE [DESC ...]]] [-c | -o [FIELDS [FIELDS ...]]] [--header [HEADER [HEADER ...]]] [-d DELIMITER] [--na NA] [-l N] [--build BUILD] [-g [FIELD [FIELD ...]]] [--all] [--order_by FIELD [FIELD ...]] [-v {0,1,2}] from_table [condition [condition ...]] Select variants according to properties (variant and annotation fields) and membership (samples) of variant. The result can be counted, outputted, or saved to a variant table. positional arguments: from_table Source variant table. condition Conditions by which variants are selected. Multiple arguments are automatically joined by 'AND' so 'OR' conditions should be provided by a single argument with conditions joined by 'OR'. If unspecified, all variants (except those excluded by parameter --samples) will be selected. optional arguments: -h, --help show this help message and exit -s [COND [COND ...]], --samples [COND [COND ...]] Limiting variants from samples that match conditions that use columns shown in command 'vtools show sample' (e.g. 'aff=1', 'filename like \u0026quot;MG%\u0026quot;'). -t [TABLE [DESC ...]], --to_table [TABLE [DESC ...]] Destination variant table. -c, --count Output number of variant, which is a shortcut to '-- output count(1)'. -o [FIELDS [FIELDS ...]], --output [FIELDS [FIELDS ...]] A list of fields that will be outputted. SQL- compatible expressions or functions such as \u0026quot;pos-1\u0026quot;, \u0026quot;count(1)\u0026quot; or \u0026quot;sum(num)\u0026quot; are also allowed. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1). Output options: --header [HEADER [HEADER ...]] A complete header or a list of names that will be joined by a delimiter (parameter --delimiter). If a special name - is specified, the header will be read from the standard input, which is the preferred way to specify large multi-line headers (e.g. cat myheader | vtools export --header -). If this parameter is given without parameter, a default header will be derived from field names. -d DELIMITER, --delimiter DELIMITER Delimiter use to separate columns of output. The default output uses multiple spaces to align columns of output. Use '-d,' for csv output, or -d'\\t' for tab-delimited output. --na NA Output string for missing value -l N, --limit N Limit output to the first N records. --build BUILD Output reference genome. If set to alternative build, chr and pos in the fields will be replaced by alt_chr and alt_pos -g [FIELD [FIELD ...]], --group_by [FIELD [FIELD ...]] Group output by fields. This option is useful for aggregation output where summary statistics are grouped by one or more fields. --all Variant tools by default output only one of the records if a variant matches multiple records in an annotation database. This option tells variant tools to output all matching records. --order_by FIELD [FIELD ...] Order output by specified fields in ascending order, or descending order if field name is followed by DESC (e.g. --order_by 'num DESC')  2. Details The basic form of command\nvtools select table condition action  selects from a variant table table a subset of variants satisfying given condition, and perform an action of\n creating a new variant table if --to_table is specified. counting the number of variants if --count is specified. outputting selected variants if --output is specified (as if command vtools output is used on it).  The condition should be a SQL expression using one or more fields in the project (shown in vtools show fields). If the condition argument is unspecified, then all variants in table will be selected. More details about the use of conditions could be found here. An optional condition --samples [condition] can also be used to limit selected variants to specified samples.\n2.1 Basic usages of the command  Examples: Load a sample project Let us load a sample project simple from online: % vtools init -f select % vtools import V*_hg38.vcf \u0026ndash;build hg38\nThe project has a master variant table with 1,611 variant,\n% vtools show tables table #variants date message variant 2,051  from two samples,\n% vtools show samples sample_name filename SAMP1 V1_hg38.vcf SAMP2 V2_hg38.vcf SAMP3 V3_hg38.vcf  \nVariant info fields provide annotation information for all variants in a project. They are usually imported from source data using command vtools import, and are listed as variant.NAME in the output of vtools show fields. You can use these fields to select variants from the master variant table, or another variant table.\n Examples: Select variants by variant info fields This project has the following fields\n% vtools show fields variant.chr (char) Chromosome name (VARCHAR) variant.pos (int) Position (INT, 1-based) variant.ref (char) Reference allele (VARCHAR, - for missing allele of an insertion) variant.alt (char) Alternative allele (VARCHAR, - for missing allele of an deletion)  This project does not have many interesting fields, but we can at least select variants by chromosome, position, reference or alternative allele.\n% vtools select variant 'pos \u0026lt; 200000' -t pos_20k 'variants with position \u0026lt; 20000' Running: 0 0.0/s in 00:00:00 INFO: 91 variants selected.  This command write selected variants to a table pos_20k. A message is optional but is highly recommended because it helps you remember what variants this table contains. The message will be displayed in the output ofvtools show tablesandvtools show table TBL@@,\n% vtools show tables table #variants date message pos_20k 91 May28 variants with position \u0026lt; 20000 variant 2,051 May28 Master variant table  You can use multiple conditions to select tables, as in\n% vtools select variant 'pos \u0026lt; 200000' 'ref=\u0026quot;T\u0026quot;' -t 'pos \u0026lt; 20k ref=T' \\ % 'Variants with position \u0026lt; 20000 and with reference allele T' Running: 0 0.0/s in 00:00:00 INFO: 22 variants selected.  The resulting table has a name with space and special characters \u0026lt; and =. Such names are allowed but should be properly quoted. If you need to specify OR condition, you can do\n% vtools select variant 'pos \u0026lt; 200000 OR ref=\u0026quot;T\u0026quot;' -t 'pos \u0026lt; 20k or ref=T' \\ % 'Variants with position \u0026lt; 20000 or with reference allele T' Running: 2 1.3K/s in 00:00:00 INFO: 521 variants selected.  \nName of variant tables can contain arbitrary characters so names such as 'TRA@' and 'AA=T' are acceptable. You should however properly quote such names to avoid accidental shell interpretation of these names (e.g. expansion of * and ?).\n Multiple conditions are allowed and are joined by 'AND'. You can use a single condition with OR to specify OR condition (e.g. DP \u0026gt; 10 OR pos\u0026lt;20000).\n Variant info fields can also be added by command vtools update. The --from_stat option of this command is most useful because it can calculate genotype statistics (e.g. number of genotypes, number of homozygotes etc) for each variant across all or selected samples. Such information can then be used to select variants that are, for example, singletons in the database.\n Examples: Select variant by genotype statistics We can add a field num to present the number of genotypes in three samples\n% vtools update variant --from_stat 'num=#(GT)' Counting variants: 100% [====================================] 3 25.9/s in 00:00:00 INFO: Adding variant info field num with type INT Updating variant: 100% [================================] 2,051 58.8K/s in 00:00:00 INFO: 2051 records are updated  The fields are now available to the project\n% vtools show fields variant.chr (char) Chromosome name (VARCHAR) variant.pos (int) Position (INT, 1-based) variant.ref (char) Reference allele (VARCHAR, - for missing allele of an insertion) variant.alt (char) Alternative allele (VARCHAR, - for missing allele of an deletion) variant.num (int) Created from stat \u0026quot;#(GT)\u0026quot; with type INT on May28 pos_20k.chr (char) Chromosome name (VARCHAR) pos \u0026lt; 20k ref=T.chr (char) Chromosome name (VARCHAR) pos \u0026lt; 20k or ref=T.chr (char) Chromosome name (VARCHAR)  and can be used to select variants. For example, the following command select variants that appear in all three samples,\n% vtools select variant 'num=3' -t inAllSamples 'variants that are in all three samples' Running: 1 592.0/s in 00:00:00 INFO: 646 variants selected.  \nYou do not have to select from the master variant table, and in case that you only need to saved the selected variants, you can use option --count to output the number of selected variants, or use option --output to output variants. The latter option is equivalent to saving selected variants to a table and outputting variants in that table using command vtools output. Please refer to command vtools output for details.\n Examples: Count or output selected variants For example, the following command count the number of variants that appear in all samples from variants in table pos \u0026lt; 20k or ref=T.\n% vtools select 'pos \u0026lt; 20k or ref=T' 'num=3' -c Counting variants: 0 0.0/s in 00:00:00 154  You can also have a look at these variants without saving them to a table\n% vtools select 'pos \u0026lt; 20k or ref=T' 'num=3' --output chr pos ref alt num -l 10 1 16103 T G 3 1 20144 G A 3 1 30860 G C 3 1 30923 G T 3 1 41842 A G 3 1 54380 T C 3 1 54490 G A 3 1 54676 C T 3 1 57999 G T 3 1 62203 T C 3  \n2.2 Select variants using annotation fields You can select variants from a variant table based on fields from external annotation databases. Although annotation databases have different types and are linked to the project in different ways (e.g. variant databases link to individual variants, and range databases annotate groups of variants), they appear the same from a user point of view.\nIn contrast to variant info fields that annotate all variants, annotation databases usually do not cover all variants in the project and variants that are not annotated have value NULL for these annotation fields. Because almost all annotation databases has a field chr, the most frequently used queries for these databases are probably the membership queies such as XXX.chr IS NOT NULL@, and @XXX.chr is NULL. The former identifies all variants that are in the database, and the latter identifies all variants that are not in the database.\n Examples: Select variants based on database membership Let us first link the project to the dbSNP database\n% vtools use dbSNP INFO: Choosing version dbSNP-hg38_143 from 10 available databases. INFO: Downloading annotation database annoDB/dbSNP-hg38_143.ann INFO: Using annotation DB dbSNP as dbSNP in project select. INFO: dbSNP version 143, created using vcf file downloaded from NCBI  then find out all the variants that are in the dbSNP database:\n% vtools select variant 'dbSNP.chr IS NOT NULL' -t inDbSNP 'variants in dbSNP version 130' Running: 6 97.9/s in 00:00:00 INFO: 1429 variants selected.  We can see the rsname of these variants\n% vtools output inDbSNP chr pos ref alt dbSNP.name --all 1 14677 G A rs201327123 1 15820 G T rs2691315 1 16103 T G rs78376469 ... ...  Here we use the --all option of command vtools output because a variant can have multiple rsnames, and this is indeed the case for mutation A-\u0026gt;G at chr1:746775.\nThe syntax is the same for range-based databases. For example, if we use the refGene database,\n% vtools use refGene INFO: Choosing version refGene-hg38_20170201 from 5 available databases. INFO: Downloading annotation database annoDB/refGene-hg38_20170201.ann INFO: Using annotation DB refGene as refGene in project select. INFO: Known human protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq).  we can find out all the variants that are not in dbSNP but in one of the ref seq genes,\n% vtools select variant 'dbSNP.chr IS NULL' 'refGene.chr IS NOT NULL' -t inRefGene 'variants that are in refGene but not dbSNP' Running: 7 567.6/s in 00:00:00 INFO: 32 variants selected.  \nYou of course do not have to limit yourself to the membership conditions because annotation databases provides many fields that can be used to select variants. For example, the dbNSFP database provides SIFT and PolyPhen2 scores for non-synonymous variants in CCDS genes, you can select variants that are probably damaging based on such information.\n Examples: Select variants by values of annotation fields Let us first link the dbNSFP database,\n% vtools use dbNSFP INFO: Downloading annotation database from annoDB/dbNSFP.ann INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/dbNSFP-hg18_hg19_2_0b4.DB.gz INFO: Using annotation DB dbNSFP in project select. INFO: dbNSFP version 2.0b4, maintained by Xiaoming Liu from UTSPH. Please cite \u0026quot;Liu X, Jian X, and Boerwinkle E. 2011. dbNSFP: a lightweight database of human non-synonymous SNPs and their functional predictions. Human Mutation. 32:894-899\u0026quot; if you find this database useful.  you can select variants that are in this database using the memebership query\n% vtools select variant 'dbNSFP.chr IS NOT NULL' -t ns 'non-synonymous variants in dbNSFP database' Running: 3 63.7/s in 00:00:00 INFO: 12 variants selected.  then select variants that are probably damaging according to SIFT scores\n% vtools select ns 'SIFT_score \u0026lt; 0.05' -t damaging 'probably damaging' Running: 0 0.0/s in 00:00:00 INFO: 5 variants selected.  You can check if the SIFT score - selected damaging variants are also damaging according to other criteria/scores,\n% vtools select ns 'SIFT_score \u0026lt; 0.05' --output chr pos ref alt SIFT_score \\ dbNSFP.MutationAssessor_pred PolyPhen2_HDIV_score PolyPhen2_HDIV_pred 1 879501 G C . medium . . 1 908247 G T 0.03 low 0.999;0.998;0.998 D;D;D 1 909364 G T 0.03 low 0.99;0.999;0.997 D;D;D 1 909861 A T 0.02 neutral 0.358;0.062;0.358 B;B;B 1 909873 A T 0.0 low 0.95;0.98;0.899 P;D;P  As you can see, one of the variants with small SIFT score is predicted to be benign according to polyphen2 HDIV prediction.\nBecause these scores do not agree with each other too well, we sometimes use them together and consider a variant to be damaging if it is declared so by one of the scores:\n% vtools select ns 'SIFT_score \u0026lt; 0.05 or PolyPhen2_HDIV_pred like \u0026quot;%D%\u0026quot;' -t damaging 'Damaging predicted by either SIFT or polyphen2' WARNING: Existing table damaging is renamed to damaging_Jul14_214229. Running: 0 0.0/s in 00:00:00 INFO: 6 variants selected. 6  Because a table damage has been created before, the existing table is renamed before a new table is created. If you do not need such backup tables, you can remove them using command vtools remove tables,\n% vtools remove tables '*Jul*' INFO: Removing table damaging_Jul14_214229  here a wildcard pattern is used to remove all backup tables created in July.\n\nOne of the common use of annotation databases is to identify variants that belong to certain genes, exonic regions of genes, or pathways. Databases that are useful for these operations are refGene, refGene_exon, knownGene, knownGene_exon, and keggPathway.\n Examples: Select variants by gene, exon regions and pathway membership Let us first load the keggPathway database. Because this database is a field database that annotates ccdsGene ID, it should be linked to a database that contains CCDS ID:\n% vtools use ccdsGene INFO: Choosing version ccdsGene-hg38_20171008 from 4 available databases. INFO: Downloading annotation database annoDB/ccdsGene-hg38_20171008.ann INFO: Using annotation DB ccdsGene as ccdsGene in project select. INFO: High-confidence human gene annotations from the Consensus Coding Sequence (CCDS) project. % vtools use keggPathway --linked_by ccdsGene.name INFO: Choosing version keggPathway-20110823 from 1 available databases. INFO: Downloading annotation database annoDB/keggPathway-20110823.ann INFO: Using annotation DB keggPathway as keggPathway in project select. INFO: kegg pathway for CCDS genes INFO: 6745 out of 32508 ccdsGene.ccdsGene.name are annotated through annotation database keggPathway WARNING: 204 out of 6949 values in annotation database keggPathway are not linked to the project.  As you can see from the above output, the KEGG pathway database contains 6881 CCDS genes, but also has 68 IDs that are not recognizable by the current version of the CCDS database.\nAnyway, the following command lists all CCDS genes and refGenes that contain one or more variants in the project,\n% vtools output variant ccdsGene.name refGene.name2 | sort | uniq . .  . AGRN . B3GALT6 . C1orf159 . FAM41C . FAM87B . ISG15 . KLHL17 . LINC00115 . LINC01128 . LINC01342 . LOC100130417 . LOC100288069 . LOC100288175 . LOC100288778 . MIR6723 . PERM1 . PLEKHN1 . RNF223 . SAMD11 . SDF4 . TTLL10 . UBE2J2 . WASH7P CCDS10.1 TNFRSF18 CCDS11.1 TNFRSF4 CCDS12.1 SDF4 CCDS14.1 UBE2J2 CCDS2.2 SAMD11 CCDS3.1 NOC2L CCDS30547.1 OR4F5 CCDS30550.1 KLHL17 CCDS30551.1 AGRN CCDS4.1 PLEKHN1 CCDS44036.1 TTLL10 CCDS6.1 ISG15 CCDS7.2 C1orf159 CCDS76083.1 PERM1 CCDS8.1 TTLL10\nAs you can see, CCDS genes are more conservative and do not contain some of the ref seq genes. If you need to find out all the variants that belong to a particular gene, you can use\n% vtools select variant 'refGene.name2 = \u0026quot;AGRN\u0026quot;' -t AGRN Running: 21 1.0K/s in 00:00:00 \u0026lt;/I\u0026gt;NFO: 111 variants selected  You can also output the pathway that this gene belong as follows:\n% vtools select variant 'refGene.name2 = \u0026quot;AGRN\u0026quot;' --output \\ chr pos ref alt refGene.name2 keggpathway.kgID keggPathway.kgDesc -l 10 --all 1 1021740 G C AGRN hsa04512 ECM-receptor interaction 1 1021740 G C AGRN hsa04512 ECM-receptor interaction 1 1022868 A G AGRN hsa04512 ECM-receptor interaction 1 1022868 A G AGRN hsa04512 ECM-receptor interaction 1 1023351 A G AGRN hsa04512 ECM-receptor interaction 1 1023351 A G AGRN hsa04512 ECM-receptor interaction 1 1023525 A G AGRN hsa04512 ECM-receptor interaction 1 1023525 A G AGRN hsa04512 ECM-receptor interaction 1 1023573 A G AGRN hsa04512 ECM-receptor interaction 1 1023573 A G AGRN hsa04512 ECM-receptor interaction  \nPlease read the description of fields from the output of vtools show fields carefully to avoid wrongful interpretation of annotation values. For example, SIFT_score provided by dbNSFP verion 1.0 are normalized (1-original score) so a higher score means higher probability of being damaging. It is no longer normalized in version 2.0 and latter so a smaller score (e.g. \u0026lt; 0.05) means more damaging.\n If you select variants based on some condition, and then its NOT condition, you might be surprised to find that some variants belong to both sets. This is because some variants match multiple records in the annotation database, and are selected by these seemingly contradicting conditions. For example, a variant can belong to multipe isoforms of a gene might be benign in one gene and damaging in another. The variant will be selected by both benigh and damaging conditions.\n 2.3 Select variants according to sample genotypes It is sometimes useful to select variants based on sample genotypes, to answer questions such as what variants are available in the affected individuals. Command vtools select accepts a parameter --samples and will select variants that belong to selected samples. This parameter accepts one or more conditions by which samples are selected. For example --samples 1 selects all samples (condition True), --samples 'sample_name = \u0026quot;CEU\u0026quot;' selects a sample with name CEU, and --samples 'filename like \u0026quot;\u0026lt;span class='CEU'\u0026gt;\u0026quot;' selects all samples that are imported from files with filename containing CEU. \n Examples: Select variants that belong to some or all samples Our project contains three samples with the same name SAMP1, which is not unusual for pipelines that produce .vcf files with a default name.\n% vtools show samples sample_name filename SAMP1 V1_hg38.vcf SAMP2 V2_hg38.vcf SAMP3 V3_hg38.vcf  We can rename samples using command vtools admin --rename_samples but we can also identify samples by filename here. For example, the following command selects all variants imported from V1.vcf to a table V1.\n% vtools select variant --samples 'filename = \u0026quot;V1.vcf\u0026quot;' -t V1 'variants imported from V1.vcf' INFO: 1 samples are selected by condition: filename = \u0026quot;V1.vcf\u0026quot; Running: 3 1.0K/s in 00:00:00 INFO: 1269 variants selected.  \nSamples without genotype information can be imported from data without genotype by specifying sample names. Such \u0026lsquo;samples\u0026rsquo; can help you identify the source of variants.\n Variants do not have to belong to any sample so it is not surprising that vtools select TABLE --sample 1 do not have to select all variants in TABLE.\n "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_report/transmission/",
	"title": "transmission",
	"tags": [],
	"description": "",
	"content": " Locate de novo, recessive and other variants that are transmitted from parents to offspring The inconsistent option of this command is not completed yet.\nUsage % vtools_report transmission -h usage: vtools_report transmission [-h] [--parents PARENTS PARENTS] [--offspring OFFSPRING [OFFSPRING ...]] [--denovo [DENOVO [DENOVO ...]]] [--recessive [RECESSIVE [RECESSIVE ...]]] [--inconsistent [INCONSISTENT [INCONSISTENT ...]]] [-v {0,1,2}] optional arguments: -h, --help show this help message and exit --parents PARENTS PARENTS Names of parents, which should uniquely identify two samples. --offspring OFFSPRING [OFFSPRING ...] Names of one or more offspring samples. --denovo [DENOVO [DENOVO ...]] A list of tables to store denovo variants for each offspring. DeNovo variants are defined as offspring variants that do not exist in any of the parents, including the cases when the offspring have different variants from what parents have at the same genomic locations. --recessive [RECESSIVE [RECESSIVE ...]] A list of tables to store recessive variants for each offspring. Recessive variants are defined as variants that are homozygous in offspring, and heterozygous in both parents. --inconsistent [INCONSISTENT [INCONSISTENT ...]] A list of tables to store variants for each offspring that demonstrate mendelian inconsistencies, namely variants that are not passed from parents to offspring in a Mendelian fashion. Examples of inconsistent variants include de novo variants, homozygous variants in offspring with only one parental carrier, wildtype offspring variants with a homozygous parent, heterozygous offspring variants with two homozygous parents, and more complicated cases when multiple variants appear at the same sites. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1).  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/annovar/",
	"title": "ANNOVAR",
	"tags": [],
	"description": "",
	"content": " Generating and importing ANNOVAR annotations for variants in vtools vtools supports the generation of an ANNOVAR input file through the ANNOVAR.fmt format. In addition, there are two ANNOVAR format files (ANNOVAR_variant_function.fmt and ANNOVAR_exonic_variant_function.fmt) that support the import of ANNOVAR generated annotations.\n1. Example of running annovar on variants in vtools and importing the resulting annotations # export all variants in the variant table to an annovar file (an input file for annovar) vtools export variant ANNOVAR.input --format ANNOVAR # run annovar to generate annotation files # see http://www.openbioinformatics.org/annovar/ for help perl annotate_variation.pl -geneanno ANNOVAR.input -buildver hg19 humandb/ # import annovar annotations using a separate format for each of the two annovar annotation files vtools update variant --format ANNOVAR_exonic_variant_function --from_file ANNOVAR.input.exonic_variant_function --var_info mut_type function genename vtools update variant --format ANNOVAR_variant_function --from_file ANNOVAR.input.variant_function --var_info region_type region_name  You now have the following fields: region_type, region_name, genename, mut_type, and function added as annotations to your variants in vtools.\nA description of the used annotation files are below.\n2. ANNOVAR.fmt vtools show format ANNOVAR Format: ANNOVAR Description: Input format of ANNOVAR. No genotype is defined. Columns: 1 chromosome 2 position (1-based) 3 end position 4 reference allele 5 alternative allele 6 optional column variant: chr Chromosome pos 1-based position ref Reference allele, '-' for insertion. alt Alternative allele, '-' for deletion. Format parameters: comment_string Output one or more fields to the optional comment column of this format. (default: )  3. ANNOVAR_variant_function.fmt vtools show format ANNOVAR_variant_function Format: ANNOVAR_variant_function Description: Output from ANNOVAR for files of type \u0026quot;*.variant_function\u0026quot;, generated from command \u0026quot;path/to/annovar/annotate_variation.pl annovar.txt path/to/annovar/humandb/\u0026quot;. This format imports chr, pos, ref, alt and ANNOVAR annotations. For details please refer to http://www.openbioinformatics.org/annovar/annovar_gene.html Columns: None defined, cannot export to this format variant: chr Chromosome pos 1-based position ref Reference allele, '-' for insertion. alt Alternative allele, '-' for deletion. Variant info: region_type The genomic region type (i.e., intergenic, ncRNA_intronic, etc) where this variant lies. Other fields (usable through parameters): region_name Genomic region name that corresponds to the region_type. If the variant lies in an intergenic region, this field will specify the closest known regions upstream and downstream of this variant. Format parameters: var_info Fields to be outputted, can be one or both of region_type and region_name. (default: region_type)  4. ANNOVAR_exonic_variant_function.fmt vtools show format ANNOVAR_exonic_variant_function Format: ANNOVAR_exonic_variant_function Description: Output from ANNOVAR, generated from command \u0026quot;path/to/annovar/annotate_variation.pl annovar.txt path/to/annovar/humandb/\u0026quot;. This format imports chr, pos, ref, alt and ANNOVAR annotations. For details please refer to http://www.openbioinformatics.org/annovar/annovar_gene.html Columns: None defined, cannot export to this format variant: chr Chromosome pos 1-based position ref Reference allele, '-' for insertion. alt Alternative allele, '-' for deletion. Variant info: mut_type the functional consequences of the variant. Other fields (usable through parameters): genename Gene name (for the first exon if the variant is in more than one exons, but usually the names for all exons are the same). function the gene name, the transcript identifier and the sequence change in the corresponding transcript Format parameters: var_info Fields to be outputted, can be one or both of mut_type and function. (default: mut_type)  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/format/formats/cga/",
	"title": "CGA",
	"tags": [],
	"description": "",
	"content": " HomePage Sample data ASSEMBLY_ID XXXX #CNV_WINDOW_WIDTH 2000 #COSMIC COSMIC v48 #DBSNP_BUILD dbSNP build 132 #DGV_VERSION 9 #FORMAT_VERSION 1.7 #GENERATED_AT XXX #GENERATED_BY cgatools #GENE_ANNOTATIONS NCBI build 37.2 #GENOME_REFERENCE NCBI build 37 #MIRBASE_VERSION miRBase version 16 #PFAM_DATE XXX #REPMASK_GENERATED_AT XXX #SAMPLE XXX #SEGDUP_GENERATED_AT XXX #SOFTWARE_VERSION 1.12.0.47 #TYPE VAR-OLPL \u0026gt;locus ploidy chromosome begin end zygosity varType reference allele1Seq allele2Seq allele1Score allele2Score allele1HapLink allele2HapLink xRef evidenceIntervalId allele1ReadCount allele2ReadCount referenceAlleleReadCount totalReadCount allele1Gene allele2Gene pfam miRBaseId repeatMasker segDupOverlap relativeCoverage calledPloidy 1 2 chr1 0 10000 no-call no-ref = ? ? 2 2 chr1 10000 11090 no-call complex = ? ? 1.13 N 3 2 chr1 11090 11105 hom ref = = = 1.13 N 4 2 chr1 11105 11170 no-call complex = ? ? 1.13 N 5 2 chr1 11170 11195 hom ref = = = 1.13 N 6 2 chr1 11195 11211 no-call complex = ? ? 1.13 N 7 2 chr1 11211 11227 hom ref = = = 1.13 N  Example vtools import --format CGA /path/to/masterVarBeta$ID.tsv.bz2 --build hg19  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/utilities/",
	"title": "Utilities",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/vat_stacking/",
	"title": "VAT stacking",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/single_gene/asum-test/",
	"title": "aSum test",
	"tags": [],
	"description": "",
	"content": " Data-adaptive Sum Test for Protective and Deleterious Variants Introduction The data-adaptive sum test (aSum) by Han and Pan 2010[^Fang Han and Wei Pan (2010) A Data-Adaptive Sum Test for Disease Association with Multiple Common or Rare Variants. Human Heredity doi:10.1159/000288704. http://www.karger.com/doi/10.1159/000288704^] is the first method that took into consideration the difference in direction of effects (protective or deleterious) of rare variants in the same genetic region analyzed by a rare variant association test. It is a two-stage approach. In the first stage the effect size of each rare variant is evaluated in a multivariate regression analysis, identifying the variants having significant \u0026ldquo;protective\u0026rdquo; effects, i.e., variants with a negative log odds ratio associated with a {$p$} value smaller than {$0.1$}. In the second stage, variants are collapsed across the genetic region similar to Morris and Zeggini 2010[^Andrew P. Morris and Eleftheria Zeggini (2010) An evaluation of statistical approaches to rare variant analysis in genetic association studies. Genetic Epidemiology doi:10.1002/gepi.20450. http://doi.wiley.com/10.1002/gepi.20450^] but with the coding for protective variants flipped. The test statistic is a score test for logistic regression for case control data.\nThe implementation of stage 1 in this program differs from the original paper. Instead of evaluating the effect size for each variant, it evaluates the difference in MAF of each variant between case and controls via an exact test to determine which variants are to be re-coded in stage 2. The same {$p\u0026lt;0.1$} criteria is used for stage 1, but in effect is more stringent than the original criteria for a multivariate logistic regression analysis.\nDetails Command interface vtools show test aSum Name: aSum Description: Adaptive Sum score test for protective and deleterious variants, Han \u0026amp; Pan 2010 usage: vtools associate --method aSum [-h] [--name NAME] [-q1 MAFUPPER] [-q2 MAFLOWER] [-p N] [--adaptive C] Adaptive Sum score test for protective and deleterious variants, Han \u0026amp; Pan 2010. In the first stage of the test, each variant site are evaluated for excess of minor alleles in controls and genotype codings are flipped, and the second stage performs a burden test similar to BRV (Morris \u0026amp; Zeggini 2009). This two-stage test is robust to a mixture of protective/risk variants within one gene, yet is computationally intensive. aSum test is a two-tailed test. optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. -q1 MAFUPPER, --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 0.01 -q2 MAFLOWER, --maflower MAFLOWER Minor allele frequency lower limit. All variants having sample MAF\u0026gt;m2 will be included in analysis. Default set to 0.0 -p N, --permutations N Number of permutations --adaptive C Adaptive permutation using Edwin Wilson 95 percent confidence interval for binomial distribution. The program will compute a p-value every 1000 permutations and compare the lower bound of the 95 percent CI of p-value against \u0026quot;C\u0026quot;, and quit permutations with the p-value if it is larger than \u0026quot;C\u0026quot;. It is recommended to specify a \u0026quot;C\u0026quot; that is slightly larger than the significance level for the study. To disable the adaptive procedure, set C=1. Default is C=0.1  Application  Example using snapshot vt_ExomeAssociation\nvtools associate rare status -m \u0026quot;aSum --name aSum -p 5000\u0026quot; --group_by name2 --to_db asum -j\\ 8 \u0026gt; asum.txt INFO: 3180 samples are found INFO: 2632 groups are found INFO: Starting 8 processes to load genotypes Loading genotypes: 100% [=================================] 3,180 32.6/s in 00:01:37 Testing for association: 100% [=========================================] 2,632/591 10.3/s in 00:04:14 INFO: Association tests on 2632 groups have completed. 591 failed. INFO: Using annotation DB asum in project test. INFO: Annotation database used to record results of association tests. Created on Wed, 30 Jan 2013 16:32:32 vtools show fields | grep asum asum.name2 name2 asum.sample_size_aSum sample size asum.num_variants_aSum number of variants in each group (adjusted for specified MAF asum.total_mac_aSum total minor allele counts in a group (adjusted for MOI) asum.statistic_aSum test statistic. asum.pvalue_aSum p-value asum.std_error_aSum Empirical estimate of the standard deviation of statistic asum.num_permutations_aSum number of permutations at which p-value is evaluated head asum.txt name2 sample_size_aSum num_variants_aSum total_mac_aSum statistic_aSum pvalue_aSum std_error_aSum num_permutations_aSum AADACL4 3180 5 138 2.59057 0.32967 3.85368 1000 ABCG5 3180 6 87 1.90472 0.335664 3.00098 1000 ABCD3 3180 3 42 -0.873585 0.635365 2.17424 1000 ABCB6 3180 7 151 -0.521698 0.632368 3.97958 1000 ABHD1 3180 5 29 -0.365094 0.548452 1.81627 1000 ABCG8 3180 12 152 -5.63774 0.95005 4.06417 1000 ABL2 3180 4 41 0.242453 0.565435 1.98108 1000 ACADL 3180 5 65 0.457547 0.58042 3.00258 1000 ACAP3 3180 3 17 0.0273585 0.404595 1.26823 1000  QQ-plot Attach:asum.jpg\n\n[^#^]\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_commands/exclude/",
	"title": "exclude",
	"tags": [],
	"description": "",
	"content": " Exclude variants that match certain criteria 1. Usage % vtools exclude -h usage: vtools exclude [-h] [-s [COND [COND ...]]] [-t [TABLE [DESC ...]]] [-c | -o [FIELDS [FIELDS ...]]] [--header [HEADER [HEADER ...]]] [-d DELIMITER] [--na NA] [-l N] [--build BUILD] [-g [FIELD [FIELD ...]]] [--order_by [FIELD [FIELD ...]]] [-u] [-v {0,1,2}] from_table [condition [condition ...]] Exclude variants according to properties (variant and annotation fields) and membership (samples) of variant. The result can be counted, outputted, or saved to a variant table. positional arguments: from_table Source variant table. condition Conditions by which variants are excluded. Multiple arguments are automatically joined by 'AND' so 'OR' conditions should be provided by a single argument with conditions joined by 'OR'. If unspecified, all variants (except those excluded by parameter --samples) will be excluded. optional arguments: -h, --help show this help message and exit -s [COND [COND ...]], --samples [COND [COND ...]] Limiting variants from samples that match conditions that use columns shown in command 'vtools show sample' (e.g. 'aff=1', 'filename like \u0026quot;MG%\u0026quot;'). -t [TABLE [DESC ...]], --to_table [TABLE [DESC ...]] Destination variant table. -c, --count Output number of variant, which is a shortcut to '-- output count(1)'. -o [FIELDS [FIELDS ...]], --output [FIELDS [FIELDS ...]] A list of fields that will be outputted. SQL- compatible expressions or functions such as \u0026quot;pos-1\u0026quot;, \u0026quot;count(1)\u0026quot; or \u0026quot;sum(num)\u0026quot; are also allowed. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1). Output options: --header [HEADER [HEADER ...]] A complete header or a list of names that will be joined by a delimiter (parameter --delimiter). If a special name - is specified, the header will be read from the standard input, which is the preferred way to specify large multi-line headers (e.g. cat myheader | vtools export --header -). If this parameter is given without parameter, a default header will be derived from field names. -d DELIMITER, --delimiter DELIMITER Delimiter, default to tab, a popular alternative is ',' for csv output --na NA Output string for missing value -l N, --limit N Limit output to the first N records. --build BUILD Output reference genome. If set to alternative build, chr and pos in the fields will be replaced by alt_chr and alt_pos -g [FIELD [FIELD ...]], --group_by [FIELD [FIELD ...]] Group output by fields. This option is useful for aggregation output where summary statistics are grouped by one or more fields. --order_by [FIELD [FIELD ...]] Order output by specified fields in ascending order. -u, --unique Remove duplicated records while keeping the order of output. This option can be time- and RAM-consuming because it keeps all outputted records in RAM to identify duplicated records. You should pipe output to command 'uniq' if you only need to remove adjacent duplicated lines.  2. Details This command differs from vtools select only in that it excludes (rather than selects) from a variant table a subset of variants satisfying given condition(s), count, output or save the remaining variants.\nHowever, command vtools exclude is not simply a vtools select command with a reversed condtion. As we will show in the examples, command \u0026ldquo;`vtools select table cond\u0026rdquo; (e.g. sift_score \u0026gt; 0.95) and \u0026ldquo;vtools exclude table reverse-cond\u0026rdquo; (e.g. sift_score \u0026lt;= 0.95) might select different sets of variants. This happens when\n If field values for some variants are missing (NULL), they will not be selected by commands such as vtools select table \u0026quot;sift_score \u0026gt; 0.95\u0026quot; and vtools select table \u0026quot;sift_score \u0026lt;= 0.95\u0026quot;. Variants without a score and with score \u0026gt; 0.95 can be selected by command vtools exclude table \u0026quot;sift_score \u0026lt;= 0.95\u0026quot;. Alternatively, you can use command vtools select table \u0026quot;sift_score \u0026gt; 0.95 OR sift_score is NULL\u0026quot; to explicitly specify the NULL case.\n If there are multiple entries for a variant in the annotation database, these variants might match both conditions. This is, for example, the case for some variants in dbNSFP when these variants are included in different genes and have different damaging scores. These variants will only be selected by vtools select.\n   Examples: \nFor example,\n% vtools select ns 'sift_score \u0026gt; 0.95' -t ns_damaging Running: 0 0.0/s in 00:00:00 INFO: 10 variants selected.  selects 10 variants. If we remove non-synonymous variants with sift_score \u0026lt;= 0.95, we will get 9 variants.\n% vtools exclude ns 'sift_score \u0026lt;= 0.95' -t ns_excl_benign Running: 0 0.0/s in 00:00:00 INFO: 9 variants selected.  We track this difference using vtools compare\n% vtools compare ns_damaging ns_excl_benign --difference diff -v0  and output the information for this variant\n% vtools output diff variant_id chr pos ref alt sift_score genename --build hg18 1036 5 139908704 C A 1 ANKHD1-EIF4EBP3 1036 5 139908704 C A 0.942108 EIF4EBP3  if we use the complete dbNSFP annotation database we can show more fields\n% vtools output diff variant_id chr pos ref alt CCDSid sift_score genename Descriptive_gene_name --build hg18 #id chr pos ref alt CCDSid sift_score genename Descriptive_gene_name 1036 5 139908704 C A CCDS4224.1 1.0 ANKHD1-EIF4EBP3 ANKHD1-EIF4EBP3 readthrough 1036 5 139908704 C A CCDS4226.1 0.942108 EIF4EBP3 eukaryotic translation initiation factor 4E binding protein 3  It turns out that this variant has two entries in dbNSFP for different genes. In this case the variant matches both conditions \u0026ldquo;sift_score\u0026gt;0.95\u0026rdquo; and \u0026ldquo;sift_score\u0026lt;=0.95\u0026rdquo;. As a result this variant will be selected by vtools select \u0026quot;sift_score\u0026gt;0.95\u0026quot; but not vtools exclude \u0026quot;sift_score\u0026lt;=0.95\u0026quot;\n\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_report/meta_analysis/",
	"title": "meta_analysis",
	"tags": [],
	"description": "",
	"content": " Meta-analysis for Association Testing Results Introduction vtools_report meta_analysis implements meta-analysis methods detailed in Willer et al 2010[^C. J. Willer, Y. Li and G. R. Abecasis (2010). METAL: fast and efficient meta-analysis of genomewide association scans. Bioinformatics^]. Two statistics are available: the sample size based statistic and inverse variance based statistic. Input of this command are multiple text or compressed text files of association results delimited by tabs.\nDetails Command interface % vtools_report meta_analysis -h usage: vtools_report meta_analysis [-h] [--beta col] [--pval col] [--se col] [-n col] [--link col [col ...]] [-m method] [--to_db database] [-v {0,1,2}] file [file ...] positional arguments: file Input text files in the format of $vtools associate output (supports plain text, gz or bz2 compressed text files) optional arguments: -h, --help show this help message and exit --beta col column number of beta --pval col column number of p-value --se col column number of standard error -n col, --size col column number of sample size --link col [col ...] columns that links entries of two datasets -m method, --method method Method (choose from \u0026quot;ssb\u0026quot; for sample based method and \u0026quot;ivb\u0026quot; for inverse variance based method), default set to \u0026quot;ssb\u0026quot; --to_db database will write the results also to a sqlite3 database compatible with vtools associate result format -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information of vtools and vtools_report. Debug information are always recorded in project and vtools_report log files.  Example Input files are\n% zless study1.gz refGene_name2 sample_size_VT num_variants_VT total_mac_VT beta_x_VT pvalue_VT std_error_VT num_permutations_VT MAF_threshold_VT A1BG 159 2 24 0.0191151 0.891109 0.213265 1000 0.00628931 A1BG-AS1 309 2 43 -0.409899 0.563437 0.27416 1000 0.00161812 A1CF 327 6 10 0.274825 0.275724 0.18807 1000 0.00152905 A2M 330 6 21 -0.0123306 0.985015 0.153102 1000 0.00151515 A2ML1 331 8 19 -0.280548 0.25974 0.159701 1000 0.00151057 ...  study2.gz is in the same format. The effect size is the 5th column, p-value the 6th column and sample size 1st column. The two data-sets are matched by gene name, i.e., the first column. The meta analysis command is:\n% vtools_report meta_analysis study1.gz study2.gz --beta 5 --pval 6 --size 2 --link 1 \\ % --to_db study1and2 \u0026gt; study1and2.txt  Result are outputted to both text file and database.\n% less study1and2.txt refGene_name2 p_meta sample_size_meta beta_x_VT_1 pvalue_VT_1 sample_size_VT_1 beta_x_VT_2 pvalue_VT_2 sample_size_VT_2 RESP18 6.380E-01 238 0.570054 0.1998 119 -0.228113 0.537463 119 STX6 8.583E-01 633 0.010475 0.875125 302 -0.434853 0.691309 331 ARFGEF2 7.984E-01 645 0.161718 0.417582 314 -0.169275 0.251748 331 TSEN34 3.459E-01 104 0.604153 0.323676 52 0.461471 0.729271 52 ...  To load the meta analysis result to the project\n% vtools use study1and2.DB --linked_by name2 INFO: Using annotation DB study1and2 in project SSc. INFO: Combined association tests result database. Created on Thu, 14 Mar 2013 17:35:44 INFO: 7459 out of 23242 refGene.name2 are annotated through annotation database study1and2  [^#^]\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/variants/thousand/",
	"title": "thousandGenomes",
	"tags": [],
	"description": "",
	"content": " thousandGenomes The samples for the 1000 Genomes Project mostly are anonymous and have no associated medical or phenotype data. Variants in this annotation database are sometimes considered to be \u0026lsquo;neutral\u0026rsquo; and could be removed if the goal of a study is to look for variants with high penetrance that dispose to rare Mendelian diseases. This database contains all of the variants supplied by the 1000 Genomes Project. The original vcf file can be obtained from here:\nftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20110521/ALL.wgs.phase1_release_v3.20101123.snps_indels_sv.sites.vcf.gz\nAll of the annotation data supplied through the INFO fields in the VCF file can be used to annotate, filter or select project variants. A description of the fields available in the database are listed below.\n% vtools show annotation thousandGenomes -v2 Annotation database thousandGenomes (version hg19_v3_20101123) Description: 1000 Genomes VCF file analyzed in March 2012 from data generated from phase 1 of the project (available from: ftp://ftp.1000genomes .ebi.ac.uk/vol1/ftp/release/20110521/ALL.wgs.phase1_release_v3.20101123.snps _indels_sv.sites.vcf.gz). Database type: variant Number of records: 39,701,227 Distinct variants: 39,701,227 Reference genome hg19: chr, pos, ref, alt Field: chr Type: string Missing entries: 0 Unique Entries: 23 Field: pos Type: integer Missing entries: 0 Unique Entries: 35,755,441 Range: 56 - 249239465 Field: dbsnp_id Type: string Comment: DB SNP ID Missing entries: 0 Unique Entries: 39,628,006 Field: ref Type: string Comment: Reference allele (as on the + strand) Missing entries: 0 Unique Entries: 50,996 Field: alt Type: string Comment: Alternative allele (as on the + strand) Missing entries: 0 Unique Entries: 19,919 Field: LDAF_INFO Type: float Comment: MLE Allele Frequency Accounting for LD Missing entries: 0 Unique Entries: 10,001 Range: 0 - 1 Field: AVGPOST_INFO Type: float Comment: Average posterior probability from MaCH/Thunder Missing entries: 0 Unique Entries: 4,365 Range: 0.5242 - 1 Field: RSQ_INFO Type: float Comment: Genotype imputation quality from MaCH/Thunder Missing entries: 0 Unique Entries: 9,500 Range: 0 - 1 Field: ERATE_INFO Type: float Comment: Per-marker Mutation rate from MaCH/Thunder Missing entries: 0 Unique Entries: 1,395 Range: 0.0001 - 0.2051 Field: THETA_INFO Type: float Comment: Per-marker Transition rate from MaCH/Thunder Missing entries: 0 Unique Entries: 828 Range: 0 - 0.1493 Field: CIEND_INFO Type: string Comment: Confidence interval around END for imprecise variants Missing entries: 39,692,293 (100.0% of 39,701,227 records) Unique Entries: 1,097 Field: CIPOS_INFO Type: string Comment: Confidence interval around POS for imprecise variants Missing entries: 39,692,293 (100.0% of 39,701,227 records) Unique Entries: 984 Field: END_INFO Type: integer Comment: End position of the variant described in this record Missing entries: 39,692,293 (100.0% of 39,701,227 records) Unique Entries: 1,097 Range: -10,145 - 0,0 Field: HOMLEN_INFO Type: integer Comment: Length of base pair identical micro-homology at event breakpoints Missing entries: 39,692,371 (100.0% of 39,701,227 records) Unique Entries: 162 Range: 0 - 415 Field: HOMSEQ_INFO Type: string Comment: Sequence of base pair identical micro-homology at event breakpoints Missing entries: 39,694,177 (100.0% of 39,701,227 records) Unique Entries: 2,465 Field: SVLEN_INFO Type: integer Comment: Difference in length between REF and ALT alleles Missing entries: 39,692,293 (100.0% of 39,701,227 records) Unique Entries: 5,540 Range: -964078 - 190 Field: SVTYPE_INFO Type: string Comment: Type of structural variant Missing entries: 39,692,293 (100.0% of 39,701,227 records) Unique Entries: 1 Field: AC_INFO Type: integer Comment: Alternate allele count Missing entries: 0 Unique Entries: 2,185 Range: 0 - 2184 Field: AN_INFO Type: integer Comment: Total allele count Missing entries: 0 Unique Entries: 2 Range: 1659 - 2184 Field: AA_INFO Type: string Comment: Ancestral Allele, ftp://ftp.1000genomes.ebi.ac.uk/vol1 /ftp/pilot_data/technical/reference/ancestral_alignmen ts/README Missing entries: 8,934 (0.0% of 39,701,227 records) Unique Entries: 37,047 Field: AF_INFO Type: float Comment: Global allele frequency based on AC/AN Missing entries: 0 Unique Entries: 10,001 Range: 0 - 1 Field: AMR_AF_INFO Type: float Comment: Allele frequency for samples from AMR based on AC/AN Missing entries: 19,038,919 (48.0% of 39,701,227 records) Unique Entries: 102 Range: 0.0028 - 1 Field: ASN_AF_INFO Type: float Comment: Allele frequency for samples from ASN based on AC/AN Missing entries: 24,655,050 (62.1% of 39,701,227 records) Unique Entries: 104 Range: 0.0017 - 1 Field: AFR_AF_INFO Type: float Comment: Allele frequency for samples from AFR based on AC/AN Missing entries: 12,995,707 (32.7% of 39,701,227 records) Unique Entries: 103 Range: 0.002 - 1 Field: EUR_AF_INFO Type: float Comment: Allele frequency for samples from EUR based on AC/AN Missing entries: 22,081,461 (55.6% of 39,701,227 records) Unique Entries: 105 Range: 0.0013 - 1 Field: VT_INFO Type: string Comment: Variant type Missing entries: 0 Unique Entries: 3 Field: SNPSOURCE_INFO Type: string Comment: indicates if a snp was called when analyzing the low coverage or exome alignment data Missing entries: 1,452,448 (3.7% of 39,701,227 records) Unique Entries: 3  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/format/formats/casava18snps/",
	"title": "CASAVA18Snps",
	"tags": [],
	"description": "",
	"content": " HomePage Sample data # ** CASAVA depth-filtered snp calls ** #$ CMDLINE /CASAVA-1.8.0a19/filterSmallVariants.pl --chrom=chr1 #$ SEQ_MAX_DEPTH chr1 142.345267150165 # #$ COLUMNS seq_name pos bcalls_used bcalls_filt ref Q(snp) max_gt Q(max_gt) max_gt|poly_site Q(max_gt|poly_site) A_used C_used G_used T_used chr1 10231 5 9 C 28 AC 28 AC 59 3 2 0 0 chr1 10255 14 29 A 1 AA 9 AT 25 12 0 0 2 chr1 10264 15 19 C 18 AC 18 AC 51 4 11 0 0 chr1 10291 2 16 C 1 CC 10 CT 21 0 1 0 1 chr1 10330 3 14 C 2 CC 5 AC 28 2 1 0 0 chr1 13273 9 0 G 58 CG 54 CG 57 0 6 3 0 chr1 14464 18 0 A 60 AT 60 AT 93 12 0 0 6 chr1 14673 19 0 G 63 CG 63 CG 96 0 8 11 0 chr1 14699 23 0 C 72 CG 72 CG 105 0 14 9 0 chr1 14907 13 0 A 118 AG 65 AG 65 4 0 9 0 chr1 14930 14 2 A 119 AG 68 AG 68 5 0 9 0 chr1 14933 14 2 G 78 AG 78 AG 110 6 0 8 0 chr1 14976 4 0 G 18 AG 18 AG 47 2 0 2 0 chr1 15211 2 0 T 37 GG 5 GG 5 0 0 2 0 chr1 15817 1 0 G 11 GT 3 GT 3 0 0 0 1 chr1 15820 1 0 G 11 GT 3 GT 3 0 0 0 1 chr1 16487 12 0 T 62 CT 62 CT 94 0 6 0 6 chr1 17538 64 0 C 88 AC 88 AC 121 18 46 0 0 chr1 17746 53 1 A 22 AG 22 AG 55 39 0 14 0 chr1 17765 47 1 G 26 AG 26 AG 59 13 0 34 0 chr1 20131 1 0 G 8 CG 2 CG 3 0 1 0 0 chr1 20144 1 0 G 9 AG 2 AG 3 1 0 0 0 chr1 20206 2 0 C 4 CT 4 CT 30 0 1 0 1 chr1 20245 3 0 G 4 AG 4 AG 34 1 0 2 0 chr1 20304 2 0 G 2 GG 5 CG 27 0 1 1 0  Example vtools import --format Illumina_SNP Illumina_SNP.txt --build hg18 INFO: Opening project f.proj INFO: Additional genotype fields: Q_max_gt INFO: Importing genotype from Illumina_SNP.txt (1/1) Illumina_SNP.txt: 30  The variants are\nvtools show table variant -l -1 INFO: Opening project f.proj variant_id, bin, chr, pos, ref, alt 1, 585, 1, 10231, C, A 2, 585, 1, 10264, C, A 3, 585, 1, 13273, G, C 4, 585, 1, 14464, A, T 5, 585, 1, 14673, G, C 6, 585, 1, 14699, C, G 7, 585, 1, 14907, A, G 8, 585, 1, 14930, A, G 9, 585, 1, 14933, G, A 10, 585, 1, 14976, G, A 11, 585, 1, 15817, G, T 12, 585, 1, 15820, G, T 13, 585, 1, 16487, T, C 14, 585, 1, 17538, C, A 15, 585, 1, 17746, A, G 16, 585, 1, 17765, G, A 17, 585, 1, 20131, G, C 18, 585, 1, 20144, G, A 19, 585, 1, 20206, C, T 20, 585, 1, 20245, G, A  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/create_your_test/",
	"title": "Create your test!",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/annotation/variants/ebi/",
	"title": "EBI",
	"tags": [],
	"description": "",
	"content": " 1000 Genomes (EBI) This database contains all of the variants supplied by the 1000 Genomes Project downloaded from the European Bioinformatics Institute (EBI) website. The original vcf file can be obtained from here:\nftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20110521/ALL.wgs.phase1_release_v3.20101123.snps_indels_sv.sites.vcf.gz\nThis represents version 3 of an integrated variant call set based on both low coverage and exome whole genome sequence data from the 1000 Genomes project. All of the annotation data supplied through the INFO fields in the VCF file can be used to annotate, filter or select project variants. A description of the fields available in the database are listed below.\nvtools show annotation thousandGenomesEBI -v2 Annotation database thousandGenomesEBI (version hg19_phase1_release_v3.20101123) Description: 1000 Genomes VCF file (available from: ftp://ftp.1000genomes.ebi.ac.uk /vol1/ftp/release/20110521/ALL.wgs.phase1_release_v3.20101123.snps _indels_sv.sites.vcf.gz). Database type: variant Number of records: 39,706,715 Number of distinct variants: 39,706,710 Reference genome hg19: ['chr', 'pos', 'ref', 'alt'] Field: chr Type: string Missing entries: 0 Unique Entries: 23 Field: pos Type: integer Missing entries: 0 Unique Entries: 35,759,802 Range: 56 - 249239465 Field: dbsnp_id Type: string Comment: DB SNP ID Missing entries: 0 Unique Entries: 37,979,186 Field: ref Type: string Comment: Reference allele (as on the + strand) Missing entries: 0 Unique Entries: 50,996 Field: alt Type: string Comment: Alternative allele (as on the + strand) Missing entries: 0 Unique Entries: 19,919 Field: LDAF_INFO Type: float Comment: MLE Allele Frequency Accounting for LD Missing entries: 0 Unique Entries: 10,001 Range: 0 - 1 Field: AVGPOST_INFO Type: float Comment: Average posterior probability from MaCH/Thunder Missing entries: 0 Unique Entries: 4,365 Range: 0.5242 - 1 Field: RSQ_INFO Type: float Comment: Genotype imputation quality from MaCH/Thunder Missing entries: 0 Unique Entries: 9,500 Range: 0 - 1 Field: ERATE_INFO Type: float Comment: Per-marker Mutation rate from MaCH/Thunder Missing entries: 0 Unique Entries: 1,395 Range: 0.0001 - 0.2051 Field: THETA_INFO Type: float Comment: Per-marker Transition rate from MaCH/Thunder Missing entries: 0 Unique Entries: 828 Range: 0 - 0.1493 Field: CIEND_INFO Type: string Comment: Confidence interval around END for imprecise variants Missing entries: 39,692,293 (100.0% of 39,706,715 records) Unique Entries: 1,152 Field: CIPOS_INFO Type: string Comment: Confidence interval around POS for imprecise variants Missing entries: 39,692,293 (100.0% of 39,706,715 records) Unique Entries: 1,026 Field: END_INFO Type: integer Comment: End position of the variant described in this record Missing entries: 39,692,293 (100.0% of 39,706,715 records) Unique Entries: 7,575 Range: 34838 - 0,0 Field: HOMLEN_INFO Type: integer Comment: Length of base pair identical micro-homology at event breakpoints Missing entries: 39,697,859 (100.0% of 39,706,715 records) Unique Entries: 162 Range: 0 - 415 Field: HOMSEQ_INFO Type: string Comment: Sequence of base pair identical micro-homology at event breakpoints Missing entries: 39,699,665 (100.0% of 39,706,715 records) Unique Entries: 2,465 Field: SVLEN_INFO Type: integer Comment: Difference in length between REF and ALT alleles Missing entries: 39,697,781 (100.0% of 39,706,715 records) Unique Entries: 5,540 Range: -964078 - 190 Field: SVTYPE_INFO Type: string Comment: Type of structural variant Missing entries: 39,692,293 (100.0% of 39,706,715 records) Unique Entries: 1 Field: AC_INFO Type: integer Comment: Alternate allele count Missing entries: 0 Unique Entries: 2,185 Range: 0 - 2184 Field: AN_INFO Type: integer Comment: Total allele count Missing entries: 0 Unique Entries: 1 Range: 2184 - 2184 Field: AA_INFO Type: string Comment: Ancestral Allele, ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pil ot_data/technical/reference/ancestral_alignments/READ ME Missing entries: 1,457,936 (3.7% of 39,706,715 records) Unique Entries: 11 Field: AF_INFO Type: float Comment: Global allele frequency based on AC/AN Missing entries: 0 Unique Entries: 10,001 Range: 0 - 1 Field: AMR_AF_INFO Type: float Comment: Allele frequency for samples from AMR based on AC/AN Missing entries: 19,042,603 (48.0% of 39,706,715 records) Unique Entries: 102 Range: 0.0028 - 1 Field: ASN_AF_INFO Type: float Comment: Allele frequency for samples from ASN based on AC/AN Missing entries: 24,658,006 (62.1% of 39,706,715 records) Unique Entries: 104 Range: 0.0017 - 1 Field: AFR_AF_INFO Type: float Comment: Allele frequency for samples from AFR based on AC/AN Missing entries: 12,998,330 (32.7% of 39,706,715 records) Unique Entries: 103 Range: 0.002 - 1 Field: EUR_AF_INFO Type: float Comment: Allele frequency for samples from EUR based on AC/AN Missing entries: 22,084,479 (55.6% of 39,706,715 records) Unique Entries: 105 Range: 0.0013 - 1 Field: VT_INFO Type: string Comment: Variant type Missing entries: 0 Unique Entries: 3 Field: SNPSOURCE_INFO Type: string Comment: indicates if a snp was called when analyzing the low coverage or exome alignment data Missing entries: 1,457,936 (3.7% of 39,706,715 records) Unique Entries: 3  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/form/",
	"title": "Format",
	"tags": [],
	"description": "",
	"content": " Import a list of variants in an unsupported format 1. Data Your collaborator send you a list of variants of interest and you would like to annotate these variants with properties like SIFT and PolyPhen2 scores. However, the list of variants were dumped from an excel file and were saved in a format that cannot be directly imported by variant tools.\nhead -20 myVars.csv ADARB2,chr10,1224091,-/C ADARB2,chr10,1224097,-/A ADARB2,chr10,1225078,-/TACTC ADARB2,chr10,1226607,-/CCCTCTG ADARB2,chr10,1227210,-/T ADARB2,chr10,1231436,-/AAAAC ADARB2,chr10,1234557,-/T ADARB2,chr10,1240467,-/ATCT ADARB2,chr10,1245155,-/CC ADARB2,chr10,1245562,CAGGTGGG/- ADARB2,chr10,1248053,-/T ADARB2,chr10,1251205,TTTTAGGGCCACC/- ADARB2,chr10,1255256,CCCACCATGCCATCA/- ADARB2,chr10,1255475,TCGCCCACACCCATGCCA/- ADARB2,chr10,1257255,-/ATCT ADARB2,chr10,1259938,-/CTG ADARB2,chr10,1260318,CCTGGACCT/- ADARB2,chr10,1262873,G/- ADARB2,chr10,1265793,TGATGA/- ADARB2,chr10,1267343,T/-  2. Use shell commands to process data The standard format that variant tools support is a text file that is\n tab delimited has columns chromosome, position, reference allele and alternative allele no \u0026ldquo;chr\u0026rdquo; before chromosome name use - for missing allele for insertions  A recent version of csv format can handle the first and third problem but still cannot get reference and alternative alleles from the last column.\nOur data does not follow this format in that\n is comma delimited first column is gene name chromosome names are prefixed with chr reference and alternative alleles are in one column separated by /  If you are familiar with shell commands, you can convert the files using the following commands\n# remove first column cut -d, -f2,3,4 myVars.csv \u0026gt; f1 # change , to tab (use Ctrl-V, tab to enter tab) sed 's/,/ /g' f1 \u0026gt; f2 # remove leading chr sed 's/chr//' f2 \u0026gt; f3 # split ref and alt alleles sed 's/\\// /g' f3 \u0026gt; output.lst  or connect the commands using Unix pipes:\ncut -d, -f2,3,4 myVars.csv | sed 's/,/ /g' | \\ sed 's/chr//' | sed 's/\\// /g' \u0026gt; output.lst  The resulting file could then be imported to variant tools using command\nvtools import output.lst --format basic  3. Use customized .fmt file With some effort, these text-processing tools could be used to manipulate input files so that they could be imported by variant tools. However, when there are a large number of such files (in the same format), it might be easier to describe this format so that variant tools can import the files directly. To do this, let us get hold of the format description file of the basic format:\nvtools show format basic cp cache/basic.fmt myformat.fmt  The first command downloads (and shows) the basic format from the variant tools website (vtools.houstonbioinformatics.org). It is saved in a cache directory so you can copy it to your project directory and rename it.\nThe file looks like this:\ncat cache/basic.fmt # Copyright (C) 2011 Bo Peng (bpeng@mdanderson.org) # Distributed under GPL. see \u0026lt;http://www.gnu.org/licenses/\u0026gt; # # Please refer to http://varianttools.sourceforge.net/Format/New for # a description of the format of this file. [format description] description=A basic variant input format with four columns: chr, pos, ref, alt. variant=chr,pos,ref,alt [chr] index=1 type=VARCHAR(20) adj=RemoveLeading('chr') comment=Chromosome [pos] index=2 type=INTEGER NOT NULL comment=1-based position [ref] index=3 type=VARCHAR(255) comment=Reference allele, '-' for insertion. [alt] index=4 type=VARCHAR(255) comment=Alternative allele, '-' for deletion.  You can find detailed description of this file here, but it is not too difficult to learn that\n variant=chr,pos,ref,alt defines four fields for chromosome, position, reference and alternative alleles.\n For each field, index specifies the index of the column, type specifies the type of field, comment gives a description of the field, and most importantly adj adjust the input to something variant tools can recognize. For example, RemoveLeading('chr') for the chr field remove leading chr from input if it exists.\n  To adapt this format file to handle our format, we need to\n Add delimiter=\u0026quot;,\u0026quot; in the format description section to indicate that our files are comma delimited.\n change the indexes of the four fields to 2, 3, 4, 4 because we will get the fields from these columns.\n  These changes will correctly import fields chr and pos, but not ref and alt, because they will both get values such as A/G from the fourth column. To separate A and G from such inputs, you will need to use a adj function. If you look through functions listed in here, you can find a function ExtractField that does exactly this. More specifically, ExtractField(1, sep=\u0026quot;/\u0026quot;) will split the input by separator /, and return the first item, and ExtractField(2, sep=\u0026quot;/\u0026quot;) will split the input and return the second item. So, to input ref and alt correctly, you can add lines\n ExtractField(1, sep=\u0026quot;/\u0026quot;) to field ref, and ExtractField(2, sep=\u0026quot;/\u0026quot;) to field alt.  The format file now looks like this:\ncat myformat.fmt # Copyright (C) 2011 Bo Peng (bpeng@mdanderson.org) # Distributed under GPL. see \u0026lt;http://www.gnu.org/licenses/\u0026gt; # # Please refer to http://varianttools.sourceforge.net/Format/New for # a description of the format of this file. [format description] description=A basic variant input format with four columns: chr, pos, ref, alt. variant=chr,pos,ref,alt delimiter=\u0026quot;,\u0026quot; [chr] index=2 type=VARCHAR(20) adj=RemoveLeading('chr') comment=Chromosome [pos] index=3 type=INTEGER NOT NULL comment=1-based position [ref] index=4 type=VARCHAR(255) adj=ExtractField(1, sep='/') comment=Reference allele, '-' for insertion. [alt] index=4 type=VARCHAR(255) adj=ExtractField(2, sep='/') comment=Alternative allele, '-' for deletion.  With this file, you can use\nvtools import myVars.lst --format myformat.fmt --build hg18  to import the data.\n4. Import gene name as well The input file has a column with gene names. We do not have to import this column because gene name could be retrieved and outputted using command\nvtools use refGene vtools output variant chr pos ref alt refGene.name2  However, because one variant can belong to several genes, importing this column can help us focus on the gene we are interested in. To import this column, we need to\n define a field genename with proper type add this field to variant_info so that it will be imported automatically as a variant info field  The modified format file should look like (with modified descriptions):\ncat myformat.fmt [format description] description=A format file that import genename, chr, pos, ref and alt from a comma delimited file variant=chr,pos,ref,alt variant_info=genename delimiter=\u0026quot;,\u0026quot; [genename] index=1 type=VARCHAR(255) comment=Gene name [chr] index=2 type=VARCHAR(20) adj=RemoveLeading('chr') comment=Chromosome [pos] index=3 type=INTEGER NOT NULL comment=1-based position [ref] index=4 type=VARCHAR(255) adj=ExtractField(1, sep='/') comment=Reference allele, '-' for insertion. [alt] index=4 type=VARCHAR(255) adj=ExtractField(2, sep='/') comment=Alternative allele, '-' for deletion.  The command to import data is the same\nvtools import myVars.lst --format myformat.fmt --build hg18  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_commands/compare/",
	"title": "compare",
	"tags": [],
	"description": "",
	"content": " Compare two or more variant tables 1. Usage % vtools compare -h usage: vtools compare [-h] [--union [TABLE [DESC ...]]] [--intersection [TABLE [DESC ...]]] [--difference [TABLE [DESC ...]]] [--expression EXPR [DESC ...]] [--mode {variant,site,genotype}] [--samples [SAMPLES [SAMPLES ...]]] [-v {0,1,2}] [tables [tables ...]] Get the difference, intersection and union of two or more variant tables, according to sites, variants, or genotypes of associated samples of these variants. Resulting variants can be counted or write to other variant tables. positional arguments: tables variant tables to compare. Wildcard characters * and ? can be used to specify multiple tables. A table name will be automatically repeated for the comparison of genotype of multiple samples if only one table is specified. optional arguments: -h, --help show this help message and exit --union [TABLE [DESC ...]] Print the number (default) or save variants with TYPE in the TYPE of any of the tables (T1 | T2 | T3 ...) to TABLE if a name is specified. An optional message can be added to describe the table. --intersection [TABLE [DESC ...]] Print the number (default) or save variants with TYPE in the TYPE of all the tables (T1 \u0026amp; T2 \u0026amp; T3 ...) to TABLE if a name is specified. An optional message can be added to describe the table. --difference [TABLE [DESC ...]] Print the number (default) or save variants with TYPE in the TYPE of the first, but not in the TYPE of others (T1 - T2 - T3...) to TABLE if a name is specified. An optional message can be added to describe the table. --expression EXPR [DESC ...] Evaluate a set expression with table names representing variants in these tables. Operators | (or), \u0026amp; (and), - (difference) and ^ (A or B but not both) are allowed. The results will be saved to table if the result is assigned to a name (e.g. --expression 'D=A-(B\u0026amp;C)'). The table names in the expression can be written as _1, _2 etc if tables are listed before the option, and be used to populate the list of tables if it was left unspecified. --mode {variant,site,genotype} Compare variants (chr, pos, ref, alt), site (chr, pos), or genotype (chr, pos, ref, alt, GT for a specified sample) of variants. The results are variants from all input tables that match specified condition. The default comparison TYPE compares variants in input variant tables. For the comparison of sites, the position of all variants are collected and compared, and variants (in all tables) with site in resulting set of sites are returned. For the comparison of genotypes, the genotypes of specified samples for all variants (see option --samples) are collected and compared, and variants with genotype in resulting set of genotypes are returned. The results of genotype comparisons are affected by runtime option treat_missing_as_wildtype because items with missing genotype (chr, pos, ref, alt, NULL) are excluded if treat_missing_as_wildtype is false (default), and are treated as (chr, pos, ref, alt, 0) otherwise. The default comparison type is variant, or genotype if option --samples is specified. --samples [SAMPLES [SAMPLES ...]] A list of sample names corresponding to the variant tables to compare. An error will be raised if a sample name matches no or multiple samples or if a sample does not have any genotype. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1).  2. Details Command vtools compare compares variants in two or more variant tables. In the basic form, this command identifies variants that appear in one table but not others (set difference), in one or the tables (set union), or in all tables (set intersection). The results can be counted or written to a variant table.\nThe items being compare in this case are variants (namely chr, pos, ref, and alt), which can be reduced to sites (chr and pos), or expanded to genotypes of specified samples (chr, pos, ref, alt, and GT of an associated sample). The results are variants (from all involved tables) that belong to the resulting sites or genotypes.\n2.1 Compare variants in variant tables  Examples: Load a sample project and create a few variant tables\n% vtools init compare % vtools import V1-3_hg19_combine.vcf --build hg19 % vtools use refGene_exon % vtools use dbSNP % vtools select variant 'dbSNP.chr IS NOT NULL' -t inDbSNP 'In dbSNP database' % vtools select variant 'refGene_exon.chr IS NOT NULL' -t exonic 'In exonic regions of ref seq genes' % vtools select variant 'refGene_exon.name2 == \u0026quot;AGRN\u0026quot;' -t G_AGRN 'In gene AGRM' % vtools select variant 'refGene_exon.name2 == \u0026quot;FAM41C\u0026quot;' -t G_FAM41C 'In gene FAM41C'  \nIn the default \u0026lsquo;variant\u0026rsquo; comparison type, command vtools compare compares variants in two or more tables and look for variants that in one, all, or none of the tables. It either counts and prints the number of matching variants or write the variants to a variant table. For example, if the master variant table has 4 variants, and when we compare variant tables T1 and T2,\n   variant tables     chr pos   1 31705   1 50195   1 50195   1 50589    The number of variants for each type of comparison would be\n% vtools compare T1 T2 INFO: Reading approximately 2 variants in T1... INFO: Reading approximately 3 variants in T2... INFO: Number of variants in A but not B, B but not A, A and B, and A or B 1 2 1 4  for variants B, C and D, A, and all four variants for the counts, if we name the four variants as variants A, B, C, and D.\n Examples: Compare two variant tables  The project has a few variant tables that can be listed by command vtools show tables\n% vtools show tables table #variants date message G_AGRN 11 May29 In gene AGRM G_FAM41C 2 May29 In gene FAM41C exonic 103 May29 In exonic regions of ref seq genes inDbSNP 1,303 May29 In dbSNP database variant 1,611 May29 Master variant table  Variants that are in dbSNP database is in table inDbSNP. If you would like to get a list of variants that are not in dbSNP, you can do\n% vtools compare variant inDbSNP --difference notInDbSNP 'variants that are not in dbSNP' INFO: Reading 1,611 variants in variant... INFO: Reading 1,303 variants in inDbSNP... Writing to notInDbSNP: 100% [=========================] 308 37.1K/s in 00:00:00 308  Or, you can check what variants in the AGRN table are exonic\n% vtools compare G_AGRN exonic --intersection AGRN_exonic 'Exonic variants in gene AGRN' INFO: Reading 11 variants in G_AGRN... INFO: Reading 103 variants in exonic... Writing to AGRN_exonic: 100% [==============================] 11 1.8K/s in 00:00:00 11  If you only need to check the number of exonic variants in gene AGRN, you can use the --intersection option without parameter,\n% vtools compare G_AGRN exonic --intersection INFO: Reading 11 variants in G_AGRN... INFO: Reading 103 variants in exonic... 11  You can also get the number of variants that are not exonic, and in both tables etc using similar options, but a shortcut to get all counts is\n% vtools compare G_AGRN exonic INFO: Reading approximately 11 variants in G_AGRN... INFO: Reading approximately 103 variants in exonic... INFO: Number of variants in A but not B, B but not A, A and B, and A or B 0 92 11 103  \nMore than two variant tables can be specified. Option --intersection and --union will select variants that belong to all or any of all tables, respectively. Option --difference will select variants that are in the first, but not in any of the rest of the tables (A - B - C - D ...).\n Examples: Comparing more than two tables\n% vtools compare exonic 'G_*' --difference other 'Exonic variants not in AGRN and FAM41C' INFO: Reading 103 variants in exonic... INFO: Reading 11 variants in G_AGRN... INFO: Reading 2 variants in G_FAM41C... Writing to other: 100% [===================================] 90 13.5K/s in 00:00:00 90  \nThis command allows the use of wildcard characters * and ? in the specification of table names, which can be handy if you have a large number of variant tables for, e.g. variants in a list of genes.\n Now, if you have more complex expressions that involve more than one types of set operations, you can use option --expression for it. For example\n% vtools compare --expression 'A-(B|C)'  print out the number of variants in table A, but not in B or C. The allowed operations are\n A | B: In table A or B (--union) A \u0026amp; B: In table A and B (--intersection) A - B: In table A but not in B (--difference) A ^ B: In table A or B but not in both ((A|B)-(A\u0026amp;B)).  If you need to save the result to a table, you can assign the expression to a table name,\n% vtools compare --expression 'D=A-(B|C)' 'variants in A but not in B or C'  If you have a table with non-alpha-numeric characters, you should quote it inside the expression using either single or double quotes, for example,\n% vtools compare --expression 'D=\u0026quot;@TP32\u0026quot;-( B | C)'  Note that these commands are simplified version of\n% vtools compare \u0026quot;@TP32\u0026quot; B C --expression 'D=\u0026quot;@TP32\u0026quot;-( B | C)'  and if you do list the tables before the option, you could use _1, _2 etc in place of table names,\n% vtools compare \u0026quot;@TP32\u0026quot; B C --expression 'D=_1 - ( _2 | _3)' --union all_variants  This syntax is recommended if you would like to perform multiple operations for the same set of tables (e.g. --expression and --union in the above example), or if you would like to compare variants by genotypes, in which case a sample should be specified for each table.\n Examples: Use set expression to compare multiple tables\nIf we would like to exclude variants that are not in DBSNP, but keep those in exonic regions, we can run\n% vtools compare --expression 'variant - inDBSNP | exonic' INFO: Comparing tables variant, inDBSNP, exonic INFO: Reading 1,611 variants in variant... INFO: Reading 1,303 variants in inDBSNP... INFO: Reading 103 variants in exonic... 405  This command is equivalent to\n% vtools compare inDBSNP exonic variant --expression '_3 - _1 | _2' INFO: Reading 1,303 variants in inDBSNP... INFO: Reading 103 variants in exonic... INFO: Reading 1,611 variants in variant... 405  Let us conclude this example with an expression that does not make much sense\n% vtools compare --expression 'variant - (inDBSNP \u0026amp; exonic ^ G_AGRN) | G_FAM41C' INFO: Comparing tables variant, inDBSNP, exonic, G_AGRN, G_FAM41C INFO: Reading 1,611 variants in variant... INFO: Reading 1,303 variants in inDBSNP... INFO: Reading 103 variants in exonic... INFO: Reading 11 variants in G_AGRN... INFO: Reading 2 variants in G_FAM41C... 1525  \n2.2 Compare genotypes of multiple samples If parameter --samples is specified, command vtools compare compares genotypes of specified samples. Although we usually compare all genotypes of samples using a command similar to (e.g. genotypes in SAMP1 and SAMP2 with variants in table variant)\n% vtools compare variant --samples SAMP1 SAMP2  you can compare a subset of genotypes using command\n% vtools compare exonic --samples SAMP1 SAMP2  or even different variants from each sample, as in\n% vtools compare var1 var2 --samples SAMP1 SAMP2  In these cases, genotypes that belong to specified variant table are selected and compared, and variants that belong to the resulting set of genotypes are returned.\nFor example, suppose the master variant table variant has the following 4 variants, and two samples both have 2 genotypes,\n| variant | genotypes | || | chr | pos | ref | alt | GT of SAMP1 | GT of SAMP2 | | 1 | 31705 | A | G | 2 | . | | 1 | 50195 | T | C | . | . | | 1 | 50195 | T | G | 1 | 1 | | 1 | 50589 | C | A | . | 1 |\nThe first command would yield results\n% vtools compare variant --samples SAMP1 SAMP2 INFO: Reading genotype of sample SAMP1 of approximately 1,611 variants in variant... INFO: Reading genotype of sample SAMP2 of approximately 1,611 variants in variant... INFO: Number of genotypes in A only, B only, in A and B, and in A or B INFO: 753 754 856 2363 INFO: Number of variants with genotypes in A only, B only, in A and B, and in A or B 753 754 856 1611  with variants A (for genotype A2), D (for genotype D1), C (for genotype C1), and A,C,D (for genotypes A2, C1, and D1) for the four counts, if we name the four variants A, B, C, and D.\nThe result of such comparisons, however, is affected by runtime option treat_missing_as_wildtype. If we run\n% vtools admin --set_runtime_option treat_missing_as_wildtype=1 INFO: Option treat_missing_as_wildtype is set to True  The output of command changes to\n% vtools compare variant --samples SAMP1 SAMP2 INFO: Reading genotype of sample SAMP1 of approximately 1,611 variants in variant... INFO: Reading genotype of sample SAMP2 of approximately 1,611 variants in variant... INFO: Number of genotypes in A only, B only, in A and B, and in A or B INFO: 755 755 856 2366 INFO: Number of variants with genotypes in A only, B only, in A and B, and in A or B 755 755 856 1611  with variants A and D (for genotypes A2 and D0), A and D (for genotypes A0 and D1), B and C (for genotypes B0 and C1), and A, B, C, D (for genotypes A0, A2, B0, C1, D0, and D1) for the four counts.\nAlthough it is a bit confusing to return variants for a comparison of genotypes, this command is very useful to compare genotypes of two or more samples.\n2.3 Count or output of genotypes shared by two or more samples  Examples: identify genotypes that are identical across samples\n% vtools show genotypes sample_name filename num_genotypes sample_genotype_fields SAMP1 V1-3_hg19_combine.vcf 1609 GT SAMP2 V1-3_hg19_combine.vcf 1610 GT SAMP3 V1-3_hg19_combine.vcf 1608 GT  The following command shows number of genotypes that are shared by all three samples,\n% vtools compare variant --intersection --samples SAMP1 SAMP2 SAMP3 INFO: Reading genotypes of sample SAMP1 of approximately 1,611 geno in variant... INFO: Reading genotypes of sample SAMP2 of approximately 1,611 geno in variant... INFO: Reading genotypes of sample SAMP3 of approximately 1,611 geno in variant... INFO: Genotypes in all samples: 432 432  Because each variant corresponds to one genotype in this case, the number of genotypes and variants are the same. As we can see, about half of genotypes of each sample are shared with other samples.\n\nIdentify genotypes that are unique to one sample There are two cases to consider here. The first one is that the mutation might exist in another sample, but with different genotype. This can be achieved using a straigforward genotype comparison:\n Examples: Identify genotypes are unique in one sample\n% vtools compare variant --difference S1 --samples SAMP1 SAMP2 SAMP3 INFO: Reading genotypes of sample SAMP1 of approximately 1,611 geno in variant... INFO: Reading genotypes of sample SAMP2 of approximately 1,611 geno in variant... INFO: Reading genotypes of sample SAMP3 of approximately 1,611 geno in variant... INFO: Genotypes in sample SAMP1 only: 442 Writing to S1: 100% [=====================================] 442 56.5K/s in 00:00:00 442  Let us have a look at the genotypes of the variants in table S1 in the samples\n% vtools export S1 --samples 1 --format csv | head -10 INFO: Genotypes of 3 samples are exported. INFO: Using 2 processes to handle 3 samples Selecting genotypes: 100% [===================================] 2 2.0/s in 00:00:01 Writing: 100% [============================================] 442 8.8K/s in 00:00:00 INFO: 442 lines are exported from variant table S1 1,15820,\u0026quot;G\u0026quot;,\u0026quot;T\u0026quot;,1,0,0 1,20235,\u0026quot;G\u0026quot;,\u0026quot;A\u0026quot;,2,0,0 1,39676,\u0026quot;C\u0026quot;,\u0026quot;T\u0026quot;,1,0,0 1,49298,\u0026quot;T\u0026quot;,\u0026quot;C\u0026quot;,1,0,2 1,49515,\u0026quot;G\u0026quot;,\u0026quot;A\u0026quot;,1,0,0 1,54716,\u0026quot;C\u0026quot;,\u0026quot;T\u0026quot;,1,0,0  As you can see, table S1 contains variants with genotypes in sample SAMP1 and are missing or with a different genotype in other samples.\n\nHowever, if you are interested in further divide the genotypes, namely to identify genotypes that only available in one sample (missing in others), or available in all samples (not missing in others), you will have to limit the search first.\n Examples: Identify genotypes only exist in one sample (missing in others) To obtain genotypes are are unique in one sample (and missing in others), you need to first identify genotypes that are not missing in other samples,\n% vtools select variant --samples \u0026quot;sample_name = 'SAMP1'\u0026quot; -t varSAMP1 % vtools select variant --samples \u0026quot;sample_name = 'SAMP2'\u0026quot; -t varSAMP2 % vtools select variant --samples \u0026quot;sample_name = 'SAMP3'\u0026quot; -t varSAMP3 % vtools show tables table #variants date message AGRN_exonic 11 May29 Exonic variants in gene AGRN G_AGRN 11 May29 In gene AGRM G_FAM41C 2 May29 In gene FAM41C S1 442 May29 exonic 103 May29 In exonic regions of ref seq genes inDbSNP 1,303 May29 In dbSNP database notInDbSNP 308 May29 variants that are not in dbSNP other 90 May29 Exonic variants not in AGRN and FAM41C varSAMP1 985 May29 varSAMP2 984 May29 varSAMP3 986 May29 variant 1,611 May29 Master variant table  We can then identify genotypes that only appear in SAMP1 using command\n% vtools compare varSAMP1 varSAMP2 varSAMP3 --difference SAMP1_only INFO: Reading 985 variants in varSAMP1... INFO: Reading 984 variants in varSAMP2... INFO: Reading 986 variants in varSAMP3... Writing to SAMP1_only: 100% [=============================] 263 37.5K/s in 00:00:00 263  The genotypes associated with SAMP1_only only appear in SAMP1,\n% vtools export SAMP1_only --samples 1 --format csv | head -10 INFO: Genotypes of 3 samples are exported. INFO: Using 2 processes to handle 3 samples Selecting genotypes: 100% [===================================] 2 2.0/s in 00:00:01 Writing: 100% [============================================] 263 8.0K/s in 00:00:00 INFO: 263 lines are exported from variant table SAMP1_only 1,15820,\u0026quot;G\u0026quot;,\u0026quot;T\u0026quot;,1,0,0 1,20235,\u0026quot;G\u0026quot;,\u0026quot;A\u0026quot;,2,0,0 1,39676,\u0026quot;C\u0026quot;,\u0026quot;T\u0026quot;,1,0,0 1,49515,\u0026quot;G\u0026quot;,\u0026quot;A\u0026quot;,1,0,0 1,54716,\u0026quot;C\u0026quot;,\u0026quot;T\u0026quot;,1,0,0 1,60726,\u0026quot;C\u0026quot;,\u0026quot;A\u0026quot;,1,0,0  Note that the following commands cannot be used in this case\n% vtools compare varSAMP1 varSAMP2 varSAMP3 --difference --samples SAMP1 SAMP2 SAMP3 INFO: Reading genotypes of sample SAMP1 of approximately 985 geno in varSAMP1... INFO: Reading genotypes of sample SAMP2 of approximately 984 geno in varSAMP2... INFO: Reading genotypes of sample SAMP3 of approximately 986 geno in varSAMP3... INFO: Genotypes in sample SAMP1 only: 321 321  because genotype difference cannot remove variants with different genotypes in different samples.\n\n Examples: Identify mutations that exist in all sample\nTo get a list of variants that are not-missing in all samples, we need to get the intersection of all variants\n% vtools compare varSAMP1 varSAMP2 varSAMP3 --intersection varNotMissing INFO: Reading 985 variants in varSAMP1... INFO: Reading 984 variants in varSAMP2... INFO: Reading 986 variants in varSAMP3... Writing to varNotMissing: 100% [==========================] 509 50.3K/s in 00:00:00 509  We can then find variants that with different genotypes in SAMP1:\n% vtools compare varNotMissing --samples SAMP1 SAMP2 SAMP3 --difference SAMP1_not_missing INFO: Reading genotypes of sample SAMP1 of approximately 509 geno in varNotMissing... INFO: Reading genotypes of sample SAMP2 of approximately 509 geno in varNotMissing... INFO: Reading genotypes of sample SAMP3 of approximately 509 geno in varNotMissing... INFO: Genotypes in sample SAMP1 only: 0 Writing to SAMP1_not_missing: 0 0.0/s in 00:00:00 0  Only 7 variants that are not missing and have unique genotype in SAMP1 exist:\n% vtools export SAMP1_not_missing --samples 1 --format csv 2\u0026gt; /dev/null  Here we redirect all progress bar etc from stderr to /dev/null to check only the output sent to standard output.\n\n2.4 Compare sites of variants (ignore multiple alternative alleles) | site | | tables | || | chr | pos | ref | alt | T1 | T2 | | 1 | 31705 | A | G | ✓ | ✓ | | 1 | 50195 | T | C | ✓ | | | 1 | 50195 | T | G | | ✓ | | 1 | 50589 | C | A | | ✓ |\nThe number of variants for each type of comparison would be\n% vtools compare T1 T2 --mode site INFO: Reading locations of approximately 2 variants in T1... INFO: Reading locations of approximately 3 variants in T2... INFO: Number of sites in A only, B only, in A and B, and in A or B INFO: 0 1 2 3 INFO: Number of variants in both tables with locations in A only, B only, in A and B, and in A or B 0 1 3 4  for 0 variant (no location is T1 only), variant D (location 50589), variants B, C and D (location 50195 and 50589), and all variants (for locations 31705, 50195, 50589). It is interesting to note that the site-intersection of two variant tables with 2 and 3 variants respectively produces a variant table of 3 variants.\nExample: identification of de novo mutations In a parent - offspring setting, we are often interested in locating variants of offspring that are not inherited from his or her parents (de novo mutations). Assuming that we have a project with three samples with names offspring, father and mother, we can first get variants from offspring and parents using commands such as\n% vtools select variant --samples \u0026quot;sample_name='offspring'\u0026quot; -t WGS3_1 % vtools select variant --samples \u0026quot;sample_name='father'\u0026quot; -t WGS3_2 % vtools select variant --samples \u0026quot;sample_name='mother'\u0026quot; -t WGS3_3  We can compare these three tables by genotype, variant, and site, each have different meanings.\nThe easiest one is to compare variants. The following command gets a list of 113,553 variants that are only available in offspring.\n% vtools compare WGS3_1 WGS3_2 WGS3_3 --difference by_variant INFO: Reading 4,343,418 variants in WGS3_1... INFO: Reading 4,367,814 variants in WGS3_2... INFO: Reading 4,455,890 variants in WGS3_3... Writing to by_variant: 100% [================================] 113,553 171.2K/s in 00:00:00 113553  We can compare by genotype, that is to say, we only exclude variants that have different genotypes from the offspring.\n% vtools compare WGS3_1 WGS3_2 WGS3_3 --difference by_genotype --samples offspring father mother INFO: Reading genotypes of sample WGS3_1 of approximately 4,343,418 geno in WGS3_1... INFO: Reading genotypes of sample WGS3_2 of approximately 4,367,814 geno in WGS3_2... INFO: Reading genotypes of sample WGS3_3 of approximately 4,455,890 geno in WGS3_3... INFO: Genotypes in sample WGS3_1 only: 808425 Writing to by_genotype: 100% [=======================================================] 808,425 174.9K/s in 00:00:04 808425  Or, we can exclude all variants that have any other variants at the same locations.\n% vtools compare WGS3_1 WGS3_2 WGS3_3 --difference by_site --mode site INFO: Reading locations of approximately 4,343,418 sites in WGS3_1... INFO: Unique sites in table WGS3_1: 4326495 INFO: Reading locations of approximately 4,367,814 sites in WGS3_2... INFO: Unique sites in table WGS3_2: 4348488 INFO: Reading locations of approximately 4,455,890 sites in WGS3_3... INFO: Unique sites in table WGS3_3: 4435967 INFO: Unique sites in table WGS3_1 only: 95373 Writing to by_site: 100% [============================================================] 95,653 169.2K/s in 00:00:00 95653  As we can see, excluding by genotype keeps the most of the variants. This should not be the method to use because offspring genotype can naturally be different from his or her parents (e.g. homozygote father + wildtype mother ==\u0026gt; heterzygote offspring). Let us see if this is the case:\n% vtools compare by_genotype by_variant by_site --difference by_genotype_only INFO: Reading 808,425 variants in by_genotype... INFO: Reading 113,553 variants in by_variant... INFO: Reading 95,653 variants in by_site... Writing to by_genotype_only: 100% [==================================================] 694,872 179.9K/s in 00:00:03 694872 % vtools output by_genotype_only \u0026quot;genotype('offspring')\u0026quot; \u0026quot;genotype('father')\u0026quot; \u0026quot;genotype('mother')\u0026quot; -l 10 2 1 . 2 1 1 2 1 . 1 . 2 1 2 . 1 2 . 1 2 . 1 . 2 1 2 . 2 1 .  We can see that the variants have offspring genotypes that are different from his or her parents. It is strange that we observe a few homozygotes when only one of the parents have heterozygotes of this genotype. This can be due to variant calling errors that should be validated from original sources (e.g. check bam files).\nSite-difference produces a list that is a strict subset of varant-difference, as confirmed by\n% vtools compare by_site by_variant INFO: Reading approximately 95,653 variants in by_site... INFO: Reading approximately 113,553 variants in by_variant... INFO: Number of variants in A but not B, B but not A, A and B, and A or B 0 17900 95653 113553  but what exactly are the differences? Let us check the genotypes at these variant-only variants:\n% vtools compare by_variant by_site --difference by_variant_only INFO: Reading 113,553 variants in by_variant... INFO: Reading 95,653 variants in by_site... Writing to by_site_only: 100% [=======================================================] 17,900 180.6K/s in 00:00:00 17900  We can only confirm that these variants do not have any genotype for father and mother.\n% vtools output by_variant_only \u0026quot;genotype('offspring')\u0026quot; \u0026quot;genotype('father')\u0026quot; \u0026quot;genotype('mother')\u0026quot; -l 10 1 . . 1 . . 1 . . -1 . . -1 . . 1 . . 1 . . 1 . . 2 . . -1 . .  Then, how can we find variants that share the same locations as these in table by_variant_only. This is a little bit tricky but we can achive it in two steps: The first step finds all variants that do not share location with the variants of interest, and the second step find the complement of them.\n% vtools compare variant by_variant_only --difference not_at_variant_site --mode site INFO: Reading locations of approximately 10,126,300 sites in variant... INFO: Unique sites in table variant: 8725216 INFO: Reading locations of approximately 17,900 sites in by_variant_only... INFO: Unique sites in table by_variant_only: 17728 INFO: Unique sites in table variant only: 8707488 Writing to not_at_variant_site: 100% [=============================================] 8,978,176 182.3K/s in 00:00:49 8978176 % compare variant not_at_variant_site --difference at_variant_site INFO: Reading 10,126,300 variants in variant... INFO: Reading 8,978,176 variants in not_at_variant_site... Writing to at_variant_site: 100% [====================================================] 61,905 172.0K/s in 00:00:00 61905  As we can see, there are 61905 variants that share the same sites with 17900 variants of interest. To confirm this,\n% vtools compare by_variant_only at_variant_site INFO: Reading approximately 17,900 variants in by_variant_only... INFO: Reading approximately 61,905 variants in at_variant_site... INFO: Number of variants in A but not B, B but not A, A and B, and A or B 0 44005 17900 61905 % vtools compare by_variant_only at_variant_site --mode site INFO: Reading locations of approximately 17,900 variants in by_variant_only... INFO: Reading locations of approximately 61,905 variants in at_variant_site... INFO: Number of sites in A only, B only, in A and B, and in A or B INFO: 0 0 17728 17728 INFO: Number of variants in both tables with locations in A only, B only, in A and B, and in A or B 0 0 61905 61905 % vtools output at_variant_site chr pos \u0026quot;genotype('offspring')\u0026quot; \u0026quot;genotype('father')\u0026quot; \\ \u0026quot;genotype('mother')\u0026quot; ref alt --order_by chr pos -l 20 1 54721 1 . . T - 1 54721 . . 1 TTTCT - 1 817121 1 . . - CTTTAAGATTCAACCTGAA 1 817121 . . 1 - TTACCTTTAAGATTCAACCTGAA 1 817121 . . 1 - CTTCAAGATTCAACCTGAATAAGTC 1 822005 1 . . T A 1 822005 . 1 1 T G 1 825767 1 . . - ACTCTGGAAGCTGAGGCAGGAGAATCACTTGAATCTGGGAGGTGGAGATTG 1 825767 . 1 . - TACTCTGGAAGCTGAGGCAGGAGAATCACTTGGACCCGAGAGGCAGAGATTG 1 825767 . . . - AACCCGGGAGGCAGAGATTG 1 825767 . . . - CCCAGCTACTCTGGAAGCTGAGGCAGGAGAATCACTTGGACCCGAGAGGCAGAGATTG 1 884042 1 . . - GGCTGCACCCTGGTCCCCCTGGTCCCTTTGGCCCTGCA 1 884042 . 1 . - CCCTGGTCCCCCTGGTCCCTTTGGCCCTGCA 1 884042 . . . - TGCACCCTGGTCCCCCTGGTCCCTTTGGCCCTGCA 1 884042 . . 1 - GCTGCACCCTGGTCCCCCTGGTCCCTTTGGCCCTGCA 1 884042 . . . - GTCCCCCTGGTCCCTTTGGCCCTGCA 1 884042 . . . - GGTCCCCCTGGTCCCTTTGGCCCTGCA 1 884042 . . . - CCTGGTCCCCCTGGTCCCTTTGGCCCTGCA 1 884042 . . . - GCACCCTGGTCCCCCTGGTCCCTTTGGCCCTGCA 1 884042 . . . - CACCCTGGTCCCCCTGGTCCCTTTGGCCCTGCA  It appears that most differences come from indels with different lengths. For example, both parents have mutants T-G at chr1:822005 and the offspring have mutation T-\u0026gt;A, and parents and offspring have different insertions at some other locations.\nIn summary, when we identify offspring-only variants, the command\n% vtools compare WGS3_1 WGS3_2 WGS3_3 --difference by_variant  identifies all variants (113,553 in this example) that are available only in offspring. These include the true de novo mutations (or genotype calling errors, 95,653 in this example) idenfified by\n% vtools compare WGS3_1 WGS3_2 WGS3_3 --difference by_site --mode site  and these with different variants but at the same sites (see the output of the last command). It is up to individual analysis pipeline to determine how to handle these de novo mutations.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_report/plot_fields/",
	"title": "plot_fields",
	"tags": [],
	"description": "",
	"content": " Plot fields from variant tables Usage % vtools_report plot_fields -h usage: vtools_report plot_fields [-h] [--variants TABLE] [--save_data FILENAME] [--save_script FILENAME] [--width px] [--height px] [--hist name] [--norm_curve] [--dot name] [--dot_size pt] [--discrete_color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd}] [--box name] [--stratify C [C ...]] [--outlier_size pt] [--color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd}] [-v {0,1,2}] fields [fields ...] positional arguments: fields A list of fields that will be outputted. optional arguments: -h, --help show this help message and exit --variants TABLE Limit value of fields to variant in specified variant table. Default to all variants. --save_data FILENAME Save data to file. --save_script FILENAME Save R script to file. --width px Width of plot. Default to 800. --height px Height of plot. Default to 600. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information of vtools and vtools_report. Debug information are always recorded in project and vtools_report log files. Draw histogram: --hist name File name of the outputted figure, which can have type PDF, EPS, or JPG. Multiple files might be produced if more than one figure is produced (e.g. MyFig_$FIELD1.pdf, MyFig_$FILED2.pdf if MyFig.pdf is specified) --norm_curve Add a normal distribution N(mean, stdev) density curve to the histogram. Draw dot plot. Allow up to 3 input fields: for single input field, the values will be plotted on y-axis with index being x-axis; for two input fields, the first field will be plotted on x-axis and the second field on y-axis; for three input fields, values of the third input field is represented by color of the dots.: --dot name File name of the outputted figure, which can have type PDF, EPS, or JPG. --dot_size pt Size of dots. Default is 2.0 --discrete_color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd} If specified, the third field of input will be treated as \u0026quot;factor\u0026quot; data. Draw box plot. Allow one or more input fields and produce box plot for all fields in one graph. With --stratify option, box plot will be generated for field in different strata, if there is only one input field, or for the first field in different strata of the second field, if there are two input fields.: --box name File name of the outputted figure, which can have type PDF, EPS, or JPG. --stratify C [C ...] Cutoff values to stratify data in the input field for box plot. When this option is on, only one input field is allowed. --outlier_size pt Size of outlier dots. Default is 2.0 --color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd} Color theme for boxes.  Example Histograms, dot plots and box plots can be generated for variant info fields. The command interface is similar to vtools_report plot_pheno_fields.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/format/formats/casava18indels/",
	"title": "CASAVA18Indels",
	"tags": [],
	"description": "",
	"content": " HomePage Sample data # ** CASAVA depth-filtered indel calls ** #$ CMDLINE /filterSmallVariants.pl --chrom=chr1 #$ SEQ_MAX_DEPTH chr1 143.988337798483 # #$ COLUMNS seq_name pos type ref_upstream ref/indel ref_downstream Q(indel) max_gtype Q(max_gtype) depth alt_reads indel_reads other_reads repeat_unit ref_repeat_count indel_repeat_count chr1 10147 1D CTAACCCTAA C/- CCCTAACCCT 70 het 70 6 2 3 1 C 4 3 chr1 10231 1D CTAACCCTAA C/- CCCTAACCCT 1203 het 284 53 7 30 17 C 4 3 chr1 10353 1I CCCTAACCCT -/A ACCCTAACCC 434 het 118 17 3 8 9 A 1 2 chr1 10390 1D CTAACCCTAA C/- CCCTAACCCC 765 het 399 39 9 19 12 C 4 3 chr1 10397 1D TAACCCCTAA C/- CCCTAACCCT 730 het 496 38 11 20 9 C 4 3 chr1 10440 1D CTAACCCTAA C/- CCCTAACCCT 774 het 302 31 7 21 3 C 4 3 chr1 28327 1D AAGCCTGTAG T/- TGCTCATCTG 3 het 3 2 1 1 0 T 2 1 chr1 54711 1I AAACCTTGTA -/T TTTTTCTTTC 37 het 37 21 8 2 12 T 5 6 chr1 62240 2D AGACACACAT AC/-- ACACACACAC 100 het 100 22 16 4 2 AC 8 7 chr1 83830 8D AGAAAGAAAG AGAAAGAA/-------- AGAAAGAAAG 273 het 161 13 3 6 4 AGAA 11 9 chr1 108546 BP_RIGHT N/A ------/CTATCA AAAAAAAAAA 28 het 28 13 9 2 2 N/A 0 0 chr1 123089 2D TGTGGACATG TA/-- TATATATATA 142 het 142 13 9 4 0 TA 6 5 chr1 128590 1D CTTCAAGTTC A/- CCCCCTTTTT 220 het 220 13 4 5 8 A 1 0 chr1 129011 3D GGGATGTAGA ATG/--- ATAAGGCTCT 258 het 258 12 5 6 1 ATG 1 0 chr1 136743 1I GGTGAGGCAA -/C GGGCTCACAC 76 het 76 80 66 6 12 C 0 1 chr1 136889 1D TGTGAGGCAA G/- GGGCTCGGGC 205 het 205 41 29 8 8 G 4 3 chr1 237577 1I AAAGGGGGTT -/C ATTATCTAGG 60 het 60 51 45 4 2 C 0 1 chr1 247917 3D ACCCAACCTC AGG/--- AGTTCAGGGC 69 hom 5 2 0 2 0 AGG 1 0 chr1 255910 2I TGTGTGTGTA --/TG TGTGTGTGTG 257 het 28 7 1 5 1 TG 10 11 chr1 531809 2D CACACTTATG CA/-- CACATTCACA 327 het 327 25 17 8 1 CA 3 2 chr1 532239 2D TGTTCACATT CA/-- CACTCATACA 325 het 325 64 53 10 2 CA 2 1 chr1 532259 3D CACAGCCCAA AAT/--- AATATACACA 303 het 303 61 43 9 10 AAT 2 1 chr1 537252 2D AGCCACATGT GG/-- GACAGGGCAG 6 hom 2 1 0 1 0 G 3 1 chr1 537494 5I CAGCGTCCAT -----/GCCCA GCCGGCCTCC 23 het 3 2 0 1 1 GCCCA 0 1 chr1 537641 50D ATCCCCCTCT CCATCCCCCTCTCCATCTCCCTCTCCTTTCTCCTCTCTAGCCCCCTCTCC/-------------------------------------------------- TTTCTCCTCT 66 het 66 22 18 3 10 CCATCCCCCTCTCCATCTCCCTCTCCTTTCTCCTCTCTAGCCCCCTCTCC 1 0  Example vtools import --format Illumina_INDEL Illumina_INDEL.txt --build hg18 INFO: Opening project f.proj INFO: Additional genotype fields: Q_indel INFO: Importing genotype from Illumina_INDEL.txt (1/1) Illumina_INDEL.txt: 30 INFO: 25 new variants from 25 records are imported, with 0 SNVs, 7 insertions, 18 deletions, and 0 complex variants. vtools show table variant -l -1 INFO: Opening project f.proj variant_id, bin, chr, pos, ref, alt 1, 585, 1, 10147, C, - 2, 585, 1, 10231, C, - 3, 585, 1, 10353, -, A 4, 585, 1, 10390, C, - 5, 585, 1, 10397, C, - 6, 585, 1, 10440, C, - 7, 585, 1, 28327, T, - 8, 585, 1, 54711, -, T 9, 585, 1, 62240, AC, - 10, 585, 1, 83830, AGAAAGAA, - 11, 585, 1, 108546, -, CTATCA 12, 585, 1, 123089, TA, - 13, 585, 1, 128590, A, - 14, 585, 1, 129011, ATG, - 15, 586, 1, 136743, -, C 16, 586, 1, 136889, G, - 17, 586, 1, 237577, -, C 18, 586, 1, 247917, AGG, - 19, 586, 1, 255910, -, TG 20, 589, 1, 531809, CA, - 21, 589, 1, 532239, CA, - 22, 589, 1, 532259, AAT, - 23, 589, 1, 537252, GG, - 24, 589, 1, 537494, -, GCCCA 25, 589, 1, 537641, CCATCCCCCTCTCCATCTCCCTCTCCTTTCTCCTCTCTAGCCCCCTCTCC, -  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/sample/",
	"title": "Sample",
	"tags": [],
	"description": "",
	"content": " Handling sample genotypes that imported from multiple files When vtools import imports a file, it creates one or more samples associated with this file. This works well if all genotypes belong to a sample are contained in one file, but not so if the genotypes are scattered in multiple files (e.g. chromosome by chromosome). This tutorial demonstrates how to use vtools admin command to handle sample genotypes that are imported from multiple files.\n1. Data 1.1 Create project and import data We import genotypes for two samples, with names MG1000 and MG1004. SNV and Indels are imported from different files but are imported with the same sample names.\nvtools init proj vtools import snv/MG1000-240.snp.txt.vcf --build hg18 --sample_name MG1000 vtools import snv/MG1004-200.snp.txt.vcf --sample_name MG1004 vtools import indel/MG1000-240.pileup.indel --format pileup_indel --sample_name MG1000 vtools import indel/MG1004-200.pileup.indel --format pileup_indel --sample_name MG1004  variant tools treats each line in the sample table as a separate sample, even if some of them share the same sample names.\n when we list the samples in this project, we can see four samples:\nvtools show samples sample_name filename MG1000 snv/MG1000-240.snp.txt.vcf MG1000 indel/MG1000-240.pileup.indel MG1004 snv/MG1004-200.snp.txt.vcf MG1004 indel/MG1004-200.pileup.indel  If we try to, for example, count the number of variants in each sample, we can use the vtools phenotype command:\nvtools phenotype --from_stat 'het=#(het)' 'hom=#(hom)' 'GT=#(GT)' Calculating phenotype: 100% [==========================================\u0026gt;] 4 0.4/s in 00:00:09 INFO: 12 values of 3 phenotypes (3 new, 0 existing) of 4 samples are updated.  The statistics (phenotypes) are available in the sample table\nvtools show samples sample_name filename het hom GT MG1000 snv/MG1000-240.snp.txt.vcf 2384712 1319373 3708513 MG1000 indel/MG1000-240.pileup.indel 623571 224378 847949 MG1004 snv/MG1004-200.snp.txt.vcf 2372093 1328117 3704532 MG1004 indel/MG1004-200.pileup.indel 605539 231405 836944  which can also be displayed using command vtools phenotype --output if you are only interested in a subset of phenotypes:\nvtools phenotype --output sample_name hom het GT sample_name filename het hom GT MG1000 1319373 2384712 3708513 MG1004 1328117 2372093 3704532 MG1000 224378 623571 847949 MG1004 231405 605539 836944  2 Merge samples The problem is that genotypes imported from snv and indel folders belong to the same physical samples. Although it is useful to know the number of SNVs and Indels separately, genotypes belongs to the same physical sample should better be treated together because\n handling of phenotype: Phenotypes such as blood pressure, sex, and weight are defined for physical samples. Although command vtools phenotype allows you to import phenotype by sample name and will automatically replicate phenotypes to all samples with the same sample name, it is confusing to have several \u0026ldquo;\u0026ldquo;samples\u0026rdquo;\u0026rdquo; with the same phenotypes.\n association analysis: Association analysis are based on samples and sometimes use sample size for its analysis. Spreading genotypes that belong to the same physical sample into several samples will lead to erroneous results.\n export variants: variants are exported by samples. SNVs and indels will be exported as different samples in this example.\n  2.1 Prepare to merge Because samples are merged by their names, it is important to double check the names of samples before you merge samples. Because samples are imported with correct names in this tutorial, we do not have to rename samples. Otherwise, you might have to rename samples using command vtools admin --rename_samples. For example, assuming that we did not use any of the --sample_name option during import, we would get a sample table as follows:\nsample_name filename het hom GT SAMPLE snv/MG1000-240.snp.txt.vcf 2384712 1319373 3708513 None indel/MG1000-240.pileup.indel 623571 224378 847949 SAMPLE snv/MG1004-200.snp.txt.vcf 2372093 1328117 3704532 None indel/MG1004-200.pileup.indel 605539 231405 836944  Samples imported from vcf files have a dummy sample name obtained from the header of the vcf files, others have None because the pileup.indel format does not have a header. If you merge samples, SNVs and Indels would be merged together as samples SAMPLE and None, which is definitely not we want.\nvtools admin --merge_samples are used to merge genotypes of the same physical samples. If samples share genotypes for the same variants, this command will fail with an error message.\n To correct this problem, we can run\nvtools admin --rename_samples 'filename like \u0026quot;%MG1000%\u0026quot;' MG1000 vtools admin --rename_samples 'filename like \u0026quot;%MG1004%\u0026quot;' MG1004  2.2 Merge samples After we make sure that samples to be merged share the same sample names, we can merge samples using command vtools admin --merge_samples:\nvtools admin --merge_samples INFO: 4 samples that share identical names are merged to 2 samples Merging MG1004: 100% [=====================================================\u0026gt;] 5 2.2/s in 00:00:02 Merging MG1000: 100% [=====================================================\u0026gt;] 5 2.1/s in 00:00:02  The new sample table looks like:\nvtools show samples sample_name filename het hom GT MG1000 snv/MG1000-240.snp.txt.vcf,indel/MG1000-240.pileup.indel 2384712 1319373 3708513 MG1004 snv/MG1004-200.snp.txt.vcf,indel/MG1004-200.pileup.indel 2372093 1328117 3704532  2.3 Update phenotype Merging samples will merge genotypes from original samples. Source filenames will also be updated. Phenotypes, if any, are copied from one of the original samples. The number of homozygotes, heterozygotes, and genotypes are therefore wrong in the above sample table and we need to update them by running vtools phenotype --from_stat again.\nvtools phenotype --from_stat 'het=#(het)' 'hom=#(hom)' 'GT=#(GT)' Calculating phenotype: 100% [=========================================\u0026gt;] 2 0.5/s in 00:00:04 INFO: 6 values of 3 phenotypes (0 new, 3 existing) of 2 samples are updated.  The statistics (phenotypes) are now\nvtools show samples sample_name filename het hom GT MG1000 snv/MG1000-240.snp.txt.vcf,indel/MG1000-240.pileup.indel 3008283 1543751 4556462 MG1004 snv/MG1004-200.snp.txt.vcf,indel/MG1004-200.pileup.indel 2977632 1559522 4541476  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/applications/association/view_association_result/",
	"title": "View association result",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_commands/associate/",
	"title": "associate",
	"tags": [],
	"description": "",
	"content": " Identify genotype - phenotype association 1. Usage % vtools associate -h usage: vtools associate [-h] [--covariates [COVARIATES [COVARIATES ...]]] [--var_info [VAR_INFO [VAR_INFO ...]]] [--geno_info [GENO_INFO [GENO_INFO ...]]] [-m METHODS [METHODS ...]] [-g [GROUP_BY [GROUP_BY ...]]] [-s [COND [COND ...]]] [--genotypes [COND [COND ...]]] [--discard_samples [EXPR [EXPR ...]]] [--discard_variants [EXPR [EXPR ...]]] [--to_db annoDB] [-f] [-j N] [-v {0,1,2}] variants phenotypes Call one or more statistical association tests and return test results as fields to variants tested. optional arguments: -h, --help show this help message and exit -j N, --jobs N Number of processes to carry out association tests. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1). Genotype, phenotype, and covariates: variants Table of variants to be tested. phenotypes A list of phenotypes that will be passed to the association statistics calculator. Currently only a single phenotype is allowed. --covariates [COVARIATES [COVARIATES ...]] Optional phenotypes that will be passed to statistical tests as covariates. Values of these phenotypes should be integer or float. --var_info [VAR_INFO [VAR_INFO ...]] Optional variant information fields (e.g. minor allele frequency from 1000 genomes project) that will be passed to statistical tests. The fields could be any annotation fields of with integer or float values, including those from used annotation databases (use \u0026quot;vtools show fields\u0026quot; to see a list of usable fields). --geno_info [GENO_INFO [GENO_INFO ...]] Optional genotype fields (e.g. quality score of genotype calls, cf. \u0026quot;vtools show genotypes\u0026quot;) that will be passed to statistical tests. Note that the fields should exist for all samples that are tested. Association tests: -m METHODS [METHODS ...], --methods METHODS [METHODS ...] Method of one or more association tests. Parameters for each method should be specified together as a quoted long argument (e.g. --methods \u0026quot;m --alternative 2\u0026quot; \u0026quot;m1 --permute 1000\u0026quot;), although the common method parameters can be specified separately, as long as they do not conflict with command arguments. (e.g. --methods m1 m2 -p 1000 is equivalent to --methods \u0026quot;m1 -p 1000\u0026quot; \u0026quot;m2 -p 1000\u0026quot;.). You can use command 'vtools show tests' for a list of association tests, and 'vtools show test TST' for details about a test. Customized association tests can be specified as mod_name.test_name where mod_name should be a Python module (system wide or in the current directory), and test_name should be a subclass of NullTest. -g [GROUP_BY [GROUP_BY ...]], --group_by [GROUP_BY [GROUP_BY ...]] Group variants by fields. If specified, variants will be separated into groups and are tested one by one. Select and filter samples and genotypes: -s [COND [COND ...]], --samples [COND [COND ...]] Limiting variants from samples that match conditions that use columns shown in command 'vtools show sample' (e.g. 'aff=1', 'filename like \u0026quot;MG%\u0026quot;'). Each line of the sample table (vtools show samples) is considered as samples. If genotype of a physical sample is scattered into multiple samples (e.g. imported chromosome by chromosome), they should be merged using command vtools admin. --genotypes [COND [COND ...]] Limiting genotypes to those matching conditions that use columns shown in command 'vtools show genotypes' (e.g. 'GQ\u0026gt;15'). Genotypes failing such conditions will be regarded as missing genotypes. --discard_samples [EXPR [EXPR ...]] Discard samples that match specified conditions within each test group (defined by parameter --group_by). Currently only expressions in the form of \u0026quot;%(NA)\u0026gt;p\u0026quot; is providedted to remove samples that have more 100*p percent of missing values. --discard_variants [EXPR [EXPR ...]] Discard variant sites based on specified conditions within each test group. Currently only expressions in the form of '%(NA)\u0026gt;p' is provided to remove variant sites that have more than 100*p percent of missing genotypes. Note that this filter will be applied after \u0026quot;--discard_samples\u0026quot; is applied, if the latter also is specified. Output of test statistics: --to_db annoDB Name of a database to which results from association tests will be written. Groups with existing results in the database will be ignored unless parameter --force is used. -f, --force Analyze all groups including those that have recorded results in the result database.  2. Details Please check the VAT homepage for details.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_report/plot_geno_fields/",
	"title": "plot_geno_fields",
	"tags": [],
	"description": "",
	"content": " Plot genotype and/or genotype information fields Usage % vtools_report plot_geno_fields -h usage: vtools_report plot_geno_fields [-h] [--variants TABLE] [--samples [SAMPLES [SAMPLES ...]]] [--genotypes [GENOTYPES [GENOTYPES ...]]] [--save_data FILENAME] [--save_script FILENAME] [--width px] [--height px] [--hist name] [--norm_curve] [--dot name] [--dot_size pt] [--discrete_color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd}] [--box name] [--stratify C [C ...]] [--outlier_size pt] [--color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd}] [-v {0,1,2}] fields [fields ...] positional arguments: fields A list of genotype fields that will be outputted. optional arguments: -h, --help show this help message and exit --variants TABLE Limit value of fields to variant in specified variant table. Default to all variants. --samples [SAMPLES [SAMPLES ...]] Conditions based on which samples are selected. Default to all samples. --genotypes [GENOTYPES [GENOTYPES ...]] Conditions based on which genotypes are selected. Default to all variants. --save_data FILENAME Save data to file. --save_script FILENAME Save R script to file. --width px Width of plot. Default to 800. --height px Height of plot. Default to 600. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information of vtools and vtools_report. Debug information are always recorded in project and vtools_report log files. Draw histogram: --hist name File name of the outputted figure, which can have type PDF, EPS, or JPG. Multiple files might be produced if more than one figure is produced (e.g. MyFig_$FIELD1.pdf, MyFig_$FILED2.pdf if MyFig.pdf is specified) --norm_curve Add a normal distribution N(mean, stdev) density curve to the histogram. Draw dot plot. Allow up to 3 input fields: for single input field, the values will be plotted on y-axis with index being x-axis; for two input fields, the first field will be plotted on x-axis and the second field on y-axis; for three input fields, values of the third input field is represented by color of the dots.: --dot name File name of the outputted figure, which can have type PDF, EPS, or JPG. --dot_size pt Size of dots. Default is 2.0 --discrete_color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd} If specified, the third field of input will be treated as \u0026quot;factor\u0026quot; data. Draw box plot. Allow one or more input fields and produce box plot for all fields in one graph. With --stratify option, box plot will be generated for field in different strata, if there is only one input field, or for the first field in different strata of the second field, if there are two input fields.: --box name File name of the outputted figure, which can have type PDF, EPS, or JPG. --stratify C [C ...] Cutoff values to stratify data in the input field for box plot. When this option is on, only one input field is allowed. --outlier_size pt Size of outlier dots. Default is 2.0 --color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd} Color theme for boxes.  Example Histograms, dot plots and box plots can be generated for variant info fields. The command interface is similar to vtools_report plot_pheno_fields.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/mouthgenome/",
	"title": "Non-human genomes",
	"tags": [],
	"description": "",
	"content": " Working with mouse and other non-human reference genomes Variant Tools supports build hg18 and hg19 of the human reference genome natively. If your data uses a different reference genome, you will need to provide your own fasta files, which can usually be downloaded from resources such as Illumina iGenomes. The reference genome needs to be converted to a binary format (crr) before it can be used, and need to be stored under the project directory, or under $local_resource/reference (usually ~/.variant_tools/reference). This tutorial shows you how to use the mm10 mouse genome for variant tools.\n1. Getting the reference genome and create a .crr file. The first step is to build a .crr file from fasta files of the reference genome using command vtools admin --fasta2crr. This command accepts either local fasta files or URLs to one or more fasta files. For example, you can use the following command to create a .crr file for build mm10 of the mouse reference genome.\n% vtools admin --fasta2crr \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr1.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr2.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr3.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr4.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr5.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr6.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr7.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr8.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr9.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr10.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr11.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr12.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr13.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr14.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr15.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr16.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr17.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr18.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr19.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chrX.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chrY.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chrM.fa.gz \\ mm10.crr  After you have successfully created this file, you can put it in the project directory, or under $local_resource/reference so that it can be shared by multiple projects. After this step is done, you can specify the reference genome to parameter --build of commands such as vtools init and vtools import.\n2. Annotation databases Annotation databases for non-human reference genomes are currently scarce so you will most likely need to build your own annotation databases. Fortunately, most of the time you only need to modify the corresponding annotation database of the human genome. For example, you can create a ref seq annotation database by changing the header of refGene-hg19_xxx.ann from\n[linked fields] hg19=chr, txStart, txEnd [data sources] anno_type=range description=Known human protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq). version=hg19_20130904 source_url=ftp://hgdownload.cse.ucsc.edu/goldenPath/hg19/database/refGene.txt.gz direct_url=annoDB/refGene-hg19_20130904.DB.gz f3ae8c8baf11b1e32344ee3c7b64edb6 source_type=txt  to\n[linked fields] mm10=chr, txStart, txEnd [data sources] anno_type=range description=Known mouse protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq). version=mm10_20141201 source_url=ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/database/refGene.txt.gz direct_url=annoDB/refGene-mm10_20141201.DB.gz source_type=txt  Note that the ref seq annotation database for mm10 refGene-mm10_20141201 is already available from the variant tools repository.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_commands/output/",
	"title": "output",
	"tags": [],
	"description": "",
	"content": " Output variants in a variant table 1. Usage % vtools output -h usage: vtools output [-h] [--header [HEADER [HEADER ...]]] [-d DELIMITER] [--na NA] [-l N] [--build BUILD] [-g [FIELD [FIELD ...]]] [--all] [--order_by FIELD [FIELD ...]] [-v {0,1,2}] table fields [fields ...] Output variants, variant info fields, annotation fields and expressions that involve these fields in a tab or comma separated format. positional arguments: table variants to output. fields A list of fields that will be outputted. SQL- compatible expressions or functions such as \u0026quot;pos-1\u0026quot;, \u0026quot;count(1)\u0026quot; or \u0026quot;sum(num)\u0026quot; are also allowed. optional arguments: -h, --help show this help message and exit -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1). Output options: --header [HEADER [HEADER ...]] A complete header or a list of names that will be joined by a delimiter (parameter --delimiter). If a special name - is specified, the header will be read from the standard input, which is the preferred way to specify large multi-line headers (e.g. cat myheader | vtools export --header -). If this parameter is given without parameter, a default header will be derived from field names. -d DELIMITER, --delimiter DELIMITER Delimiter use to separate columns of output. The default output uses multiple spaces to align columns of output. Use '-d,' for csv output, or -d'\\t' for tab-delimited output. --na NA Output string for missing value -l N, --limit N Limit output to the first N records. --build BUILD Output reference genome. If set to alternative build, chr and pos in the fields will be replaced by alt_chr and alt_pos -g [FIELD [FIELD ...]], --group_by [FIELD [FIELD ...]] Group output by fields. This option is useful for aggregation output where summary statistics are grouped by one or more fields. --all Variant tools by default output only one of the records if a variant matches multiple records in an annotation database. This option tells variant tools to output all matching records. --order_by FIELD [FIELD ...] Order output by specified fields in ascending order, or descending order if field name is followed by DESC (e.g. --order_by 'num DESC')  2. Details Command vtools output outputs properties of variant in a specified variant table. The properties include fields from annotation databases and variant tables (e.g. sample frequency), basically fields outputted from command vtools show fields, and SQL-supported functions and expressions.\n2.1 Basic usage of the command The basic usage of vtools output is to output variant info fields of selected variants. You can use option --limit to limit the number of records, --delimiter to specify delimiter between output fields (default to tab).\n Examples: Load data and produce basic output Let us load a small project from online\n% vtools init output % vtools import CEU_hg19.vcf --var_info AA AC AN DP --geno_info DP --build hg19  This project has a single variant table and 8 variant info fields. To view variants with the fields, we can\n% vtools output variant chr pos ref alt aa ac an dp -l 10 1 10533 G C . 6 120 423 1 51479 T A . 29 120 188 1 51928 G A . 5 120 192 1 54586 T C C 2 120 166 1 54676 C T T 2 120 131 1 54708 G C g 7 120 135 1 55299 C T c 20 120 166 1 62203 T C C 18 120 159 1 63671 G A G 18 120 243 1 86028 T C . 11 120 182  The first parameter is name of a variant table, which does not have to be the master variant table variant. For example, you can create a variant table using variants with T as ancestral allele,\n% vtools select variant 'aa=\u0026quot;T\u0026quot;' -t 'aa=T' Running: 0 0.0/s in 00:00:00 INFO: 22 variants selected.  and view the content of this variant table as follows:\n% vtools output 'aa=T' chr pos ref alt aa ac an dp -l 10 1 54676 C T T 2 120 131 22 51158111 T C T 1 120 298 22 51158301 T C T 7 120 169 22 51162850 C T T 41 120 367 22 51164115 C T T 52 120 357 22 51164287 T C T 37 120 331 22 51172460 T C T 3 120 274 22 51174939 C T T 4 120 317 22 51176164 T C T 3 120 380 22 51186228 C T T 51 120 253  You can use comma to separate values using option -d,\n% vtools output variant chr pos ref alt aa ac an dp -l 10 -d, 1,10533,G,C,.,6,120,423 1,51479,T,A,.,29,120,188 1,51928,G,A,.,5,120,192 1,54586,T,C,C,2,120,166 1,54676,C,T,T,2,120,131 1,54708,G,C,g,7,120,135 1,55299,C,T,c,20,120,166 1,62203,T,C,C,18,120,159 1,63671,G,A,G,18,120,243 1,86028,T,C,.,11,120,182  or option -d'\\t' to produce tab-delimited output:\n% vtools output variant chr pos ref alt aa ac an dp -l 10 -d'\\t' 1 10533 G C . 6 120 423 1 51479 T A . 29 120 188 1 51928 G A . 5 120 192 1 54586 T C C 2 120 166 1 54676 C T T 2 120 131 1 54708 G C g 7 120 135 1 55299 C T c 20 120 166 1 62203 T C C 18 120 159 1 63671 G A G 18 120 243 1 86028 T C . 11 120 182  \nYou can also specify a header to the output. There are three ways to specify headers:\n Use option --header without argument to output a default header Use option --header V1 V2 ... to output specified headers Use option --header - to read header from standard input.   Examples: Specify a header to the output The easiest way to add a header is to use parameter --header and let variant tools generate a default header from field names:\n% vtools output variant chr pos ref alt aa ac --header -l 10 chr pos ref alt aa ac 1 10533 G C . 6 1 51479 T A . 29 1 51928 G A . 5 1 54586 T C C 2 1 54676 C T T 2 1 54708 G C g 7 1 55299 C T c 20 1 62203 T C C 18 1 63671 G A G 18 1 86028 T C . 11  If you are unhappy about the default header, you can specify one manually\n% vtools output variant chr pos ref alt aa ac --header chr pos ref alt 'ancestral allele' 'ancestral count' -l 10 -d, chr,pos,ref,alt,ancestral allele,ancestral count 1,10533,G,C,.,6 1,51479,T,A,.,29 1,51928,G,A,.,5 1,54586,T,C,C,2 1,54676,C,T,T,2 1,54708,G,C,g,7 1,55299,C,T,c,20 1,62203,T,C,C,18 1,63671,G,A,G,18 1,86028,T,C,.,11  If you have a longer header, or a header that is saved in a file, you can send the header to vtools output through its standard input\n% echo chr pos ref alt 'ancestral allele' 'ancestral count' | \\ vtools output variant chr pos ref alt aa ac --header - -l 10 chr pos ref alt ancestral allele ancestral count 1 10533 G C . 6 1 51479 T A . 29 1 51928 G A . 5 1 54586 T C C 2 1 54676 C T T 2 1 54708 G C g 7 1 55299 C T c 20 1 62203 T C C 18 1 63671 G A G 18 1 86028 T C . 11  \nYou can sort the output by one or more fields using option --order_by. variant tools by default oder fields in ascending order. You can order by descending order by adding DESC to field name.\n Examples: Order output by one or more field names You can oder the output using option --order_by, for example\n% vtools output variant chr pos ref alt aa ac --order_by ac alt -l 10 1 526727 G A . 1 1 726440 G A . 1 1 773106 G A g 1 1 809700 G A - 1 22 51158111 T C T 1 22 51176004 G C G 1 1 793947 A G N 1 1 776876 C T c 1 22 51197087 C T C 1 1 88316 G A . 2  You can order in descending oder by specifying DESC after field name, for example\n% vtools output variant chr pos ref alt aa ac --order_by 'ac DESC' 'aa' -l 10 1 814790 C T c 7,2 1 814790 C G c 7,2 1 799463 T C N 120 1 780027 G T t 120 1 792480 C T t 120 1 812751 T C N 119 1 804540 T C t 119 1 723891 G C . 114 22 51173542 T C C 113 22 51185848 G A A 110  \nIf your project has a primary and a secondary reference genomes, you can output variants in both coordinates.\n Examples: Output variants in alternative coordinates Our sample project uses the hg18 reference genome. We can add an alternative reference genome by mapping all variants from hg18 to hg19 coordinates:\n% vtools liftover hg38 INFO: Downloading liftOver chain file from UCSC INFO: Exporting variants in BED format Exporting variants: 100% [================================] 288 69.0K/s in 00:00:00 INFO: Running UCSC liftOver tool Updating table variant: 100% [============================] 288 537.9/s in 00:00:00  You can output variants in the primary reference genome,\n% vtools output variant chr pos ref alt aa ac --header --order_by ac --build hg19 -l 10 chr pos ref alt aa ac 1 526727 G A . 1 1 726440 G A . 1 1 773106 G A g 1 1 776876 C T c 1 1 793947 A G N 1 1 809700 G A - 1 22 51158111 T C T 1 22 51176004 G C G 1 22 51197087 C T C 1 1 54586 T C C 2  or the alternative reference genome using option --build\n% vtools output variant chr pos ref alt aa ac --header --order_by ac --build hg38 -l 10 chr pos ref alt aa ac 1 591347 G A . 1 1 791060 G A . 1 1 837726 G A g 1 1 841496 C T c 1 1 858567 A G N 1 1 874320 G A - 1 22 50719683 T C T 1 22 50737576 G C G 1 22 50758659 C T C 1 1 54586 T C C 2  \n2.2 Output fields from annotation databases (option --all) You can output fields from one or more annotation databases in the same way as variant info fields. To output annotation fields of variants, you simply need to\n Link annotation databases to the project using command vtools use Use command vtools show annotation ANNODB or vtools show fields to check name and meaning of available fields Output annotation fields along with variant info fields. Name of annotation database can be ignored if there is no ambiguity.   Examples: Output fields of annotation fields Let us use annotation databases refGene and dbSNP,\n% vtools use refGene INFO: Choosing version refGene-hg38_20170201 from 5 available databases. INFO: Downloading annotation database annoDB/refGene-hg38_20170201.ann INFO: Using annotation DB refGene as refGene in project output. INFO: Known human protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq). % vtools use dbSNP INFO: Choosing version dbSNP-hg38_143 from 10 available databases. INFO: Downloading annotation database annoDB/dbSNP-hg38_143.ann INFO: Using annotation DB dbSNP as dbSNP in project output. INFO: dbSNP version 143, created using vcf file downloaded from NCBI  because this project uses both hg18 and hg19, it can make use of the latest version of refGene and dbSNP databases that use hg19.\nThese two databases bring in a large number of annotation fields, as listed by command\n% vtools show fields variant.chr (char) Chromosome name (VARCHAR) variant.pos (int) Position (INT, 1-based) variant.ref (char) Reference allele (VARCHAR, - for missing allele of an insertion) variant.alt (char) Alternative allele (VARCHAR, - for missing allele of an deletion) variant.AA (char) variant.AC (int) variant.AN (int) variant.DP (int) variant.alt_chr (char) variant.alt_pos (int) aa=T.chr (char) Chromosome name (VARCHAR) refGene.name (char) Gene name refGene.chr (char) refGene.strand (char) which DNA strand contains the observed alleles refGene.txStart (int) Transcription start position (1-based) refGene.txEnd (int) Transcription end position refGene.cdsStart (int) Coding region start (1-based) refGene.cdsEnd (int) Coding region end refGene.exonCount (int) Number of exons refGene.exonStarts (char) Starting point of exons (adjusted to 1-based positions) refGene.exonEnds (char) Ending point of exons refGene.score (int) Score refGene.name2 (char) Alternative name refGene.cdsStartStat (char) cds start stat, can be 'non', 'unk', 'incompl', and 'cmp1' refGene.cdsEndStat (char) cds end stat, can be 'non', 'unk', 'incompl', and 'cmp1' refGene.exonFrames (char) Exon frame {0,1,2}, or -1 if no frame for exon dbSNP.chr (char) dbSNP.pos (int) dbSNP.name (char) DB SNP ID (rsname) dbSNP.ref (char) Reference allele (as on the + strand) dbSNP.alt (char) Alternative allele (as on the + strand) dbSNP.FILTER (char) Inconsistent Genotype Submission For At Least One Sample dbSNP.RS (int) dbSNP ID (i.e. rs number) dbSNP.RSPOS (int) Chr position reported in dbSNP dbSNP.RV (int) RS orientation is reversed dbSNP.VP (char) Variation Property. Documentation is at ftp://ftp.ncbi.nlm.nih.gov/snp/specs/dbSNP_BitField_latest.pdf dbSNP.GENEINFO (char) Pairs each of gene symbol:gene id. The gene symbol and id are delimited by a colon (:) and each pair is delimited by a vertical bar (|) dbSNP.dbSNPBuildID (int) First dbSNP Build for RS dbSNP.SAO (int) Variant Allele Origin: 0 - unspecified, 1 - Germline, 2 - Somatic, 3 - Both dbSNP.SSR (int) Variant Suspect Reason Codes (may be more than one value added together) 0 - unspecified, 1 - Paralog, 2 - byEST, 4 - oldAlign, 8 - Para_EST, 16 - 1kg_failed, 1024 - other dbSNP.WGT (int) Weight, 00 - unmapped, 1 - weight 1, 2 - weight 2, 3 - weight 3 or more dbSNP.VC (char) Variation Class dbSNP.PM_flag (int) Variant is Precious(Clinical,Pubmed Cited) dbSNP.TPA_flag (int) Provisional Third Party Annotation(TPA) (currently rs from PHARMGKB who will give phenotype data) dbSNP.PMC_flag (int) Links exist to PubMed Central article dbSNP.S3D_flag (int) Has 3D structure - SNP3D table dbSNP.SLO_flag (int) Has SubmitterLinkOut - From SNP-\u0026gt;SubSNP-\u0026gt;Batch.link_out dbSNP.NSF_flag (int) Has non-synonymous frameshift A coding region variation where one allele in the set changes all downstream amino acids. FxnClass = 44 dbSNP.NSM_flag (int) Has non-synonymous missense A coding region variation where one allele in the set changes protein peptide. FxnClass = 42 dbSNP.NSN_flag (int) Has non-synonymous nonsense A coding region variation where one allele in the set changes to STOP codon (TER). FxnClass = 41 dbSNP.REF_flag_flag (int) Has reference A coding region variation where one allele in the set is identical to the reference sequence. FxnCode = 8 dbSNP.SYN_flag (int) Has synonymous A coding region variation where one allele in the set does not change the encoded amino acid. FxnCode = 3 dbSNP.U3_flag (int) In 3' UTR Location is in an untranslated region (UTR). FxnCode = 53 dbSNP.U5_flag (int) In 5' UTR Location is in an untranslated region (UTR). FxnCode = 55 dbSNP.ASS_flag (int) In acceptor splice site FxnCode = 73 dbSNP.DSS_flag (int) In donor splice-site FxnCode = 75 dbSNP.INT_flag (int) In Intron FxnCode = 6 dbSNP.R3_flag (int) In 3' gene region FxnCode = 13 dbSNP.R5_flag (int) In 5' gene region FxnCode = 15 dbSNP.OTH_flag (int) Has other variant with exactly the same set of mapped positions on NCBI refernce assembly. dbSNP.CFL_flag (int) Has Assembly conflict. This is for weight 1 and 2 variant that maps to different chromosomes on different assemblies. dbSNP.ASP_flag (int) Is Assembly specific. This is set if the variant only maps to one assembly dbSNP.MUT_flag (int) Is mutation (journal citation, explicit fact): a low frequency variation that is cited in journal and other reputable sources dbSNP.VLD_flag (int) Is Validated. This bit is set if the variant has 2+ minor allele count based on frequency or genotype data. dbSNP.G5A_flag (int) \u0026gt;5% minor allele frequency in each and all populations dbSNP.G5_flag (int) \u0026gt;5% minor allele frequency in 1+ populations dbSNP.HD_flag (int) Marker is on high density genotyping kit (50K density or greater). The variant may have phenotype associations present in dbGaP. dbSNP.GNO_flag (int) Genotypes available. The variant has individual genotype (in SubInd table). dbSNP.KGValidated_flag (int) 1000 Genome validated dbSNP.KGPhase1_flag (int) 1000 Genome phase 1 (incl. June Interim phase 1) dbSNP.KGPilot123_flag (int) 1000 Genome discovery all pilots 2010(1,2,3) dbSNP.KGPROD_flag (int) Has 1000 Genome submission dbSNP.OTHERKG_flag (int) non-1000 Genome submission dbSNP.PH3_flag (int) HAP_MAP Phase 3 genotyped: filtered, non-redundant dbSNP.CDA_flag (int) Variation is interrogated in a clinical diagnostic assay dbSNP.LSD_flag (int) Submitted from a locus-specific database dbSNP.MTP_flag (int) Microattribution/third-party annotation(TPA:GWAS,PAGE) dbSNP.OM_flag (int) Has OMIM/OMIA dbSNP.NOC_flag (int) Contig allele not present in variant allele list. The reference sequence allele at the mapped position is not present in the variant allele list, adjusted for orientation. dbSNP.WTD_flag (int) Is Withdrawn by submitter If one member ss is withdrawn by submitter, then this bit is set. If all member ss' are withdrawn, then the rs is deleted to SNPHistory dbSNP.NOV_flag (int) Rs cluster has non-overlapping allele sets. True when rs set has more than 2 alleles from different submissions and these sets share no alleles in common. dbSNP.CAF (char) An ordered, comma delimited list of allele frequencies based on 1000Genomes, starting with the reference allele followed by alternate alleles as ordered in the ALT column. Where a 1000Genomes alternate allele is not in the dbSNPs alternate allele set, the allele is added to the ALT column. The minor allele is the second largest value in the list, and was previuosly reported in VCF as the GMAF. This is the GMAF reported on the RefSNP and EntrezSNP pages and VariationReporter dbSNP.COMMON (int) RS is a common SNP. A common SNP is one that has at least one 1000Genomes population with a minor allele of frequency \u0026gt;= 1% and for which 2 or more founders contribute to that minor allele frequency.  You can output annotation fields as follows:\n% vtools output 'aa=T' chr pos ref alt dbSNP.name refGene.name refGene.name2 -l 10 1 1105366 T C rs111751804 NM_001130045 TTLL10 1 1110240 T A rs116321663 NM_001130045 TTLL10 1 6447088 T C rs11800462 NM_003790 TNFRSF25 1 6447275 T C rs3170675 NM_003790 TNFRSF25 1 11633148 T G rs9614 NM_012168 FBXO2 1 20897488 C T rs522496 NM_001122819 KIF17 1 20903629 T C rs2296225 NM_001122819 KIF17 1 35998535 T C rs7537203 NM_022111 CLSPN 1 36002845 T G rs115614983 NM_022111 CLSPN 1 40510176 T C rs2076697 NM_005857 ZMPSTE24  \nThis looks simple but the problem is more complicated than what is shown here, because a variant can match multiple records in annotation databases. For example, mutation T-\u0026gt;C at position 1105366 on chr1 belongs to reference sequences NM_153254 and NM_001130045 of the reference sequence database. Because vtools output by default only displays a random record of multiple records, its output can miss important information. To address this problem, an option --all is provided to output all annotation records. This option has its own problem though. For example, if you do not output the differentiating field that lead to multiple records, you can see a bunch of duplicated records.\n Examples: Use option \u0026ndash;all to list all annotation records Using option --all, command vtools output can display multiple records for a variant:\n% vtools output 'aa=T' chr pos ref alt dbSNP.name refGene.name refGene.name2 --all -l 10 1 54676 C T rs2462492 . . 22 51158111 T C rs73174428 NM_033517 SHANK3 22 51158301 T C rs117910162 NM_033517 SHANK3 22 51162850 C T rs5770822 NM_033517 SHANK3 22 51164115 C T rs5770996 NM_033517 SHANK3 22 51164287 T C rs6009957 NM_033517 SHANK3 22 51172460 T C rs5770824 . . 22 51174939 C T rs73174435 NR_134637 LOC105373100 22 51176164 T C rs76593947 NR_134637 LOC105373100 22 51186228 C T rs3865766 . .  A consequence of this is that duplicated records can be displayed if the field that lead to multiple records is not outputted:\n% vtools output 'aa=T' chr pos ref alt dbSNP.name refGene.name2 --all -l 10 1 54676 C T rs2462492 . 22 51158111 T C rs73174428 SHANK3 22 51158301 T C rs117910162 SHANK3 22 51162850 C T rs5770822 SHANK3 22 51164115 C T rs5770996 SHANK3 22 51164287 T C rs6009957 SHANK3 22 51172460 T C rs5770824 . 22 51174939 C T rs73174435 LOC105373100 22 51176164 T C rs76593947 LOC105373100 22 51186228 C T rs3865766 .  This is why the output of command vtools output --all is usually piped to command uniq,\n% vtools output 'aa=T' chr pos ref alt dbSNP.name refGene.name2 --all -l 10 | uniq  although uniq cannot suppress all duplicated records in all cases because it only removes adjacent duplicated records.\n\n2.3 Output expressions of fields In addition to values of variant info and annotation fields, command vtools output can be used to output SQL-acceptable expressions that involves multiple fields. For example,\n Because variant tools uses 1-based coordinates, you might want to output pos-1 instead of pos to generate output with 0-based indexes, You can output allele frequency by dividing number of alternative alleles by total number of alleles,  In addition to basic arithmetic operations, variant tools accept additional mathematical and string extension functions for SQL queries using the loadable extensions mechanism from HERE, including mathematical functions acos, asin, atan, atn2, atan2, acosh, asinh, atanh, difference, degrees, radians, cos, sin, tan, cot, cosh, sinh, tanh, coth, exp, log, log10, power, sign, sqrt, square, ceil, floor, pi, and string operations replicate, charindex, leftstr, rightstr, ltrim, rtrim, trim, replace, reverse, proper, padl, padr, padc, strfilter.\n Examples: Output expressionf of fields This example demonstrates the use of SQL expressions in command vtools output. Note that the sqlite string concatenation operator is ||.\n% vtools output \u0026quot;aa=T\u0026quot; chr 'pos-1' 'refGene.name2 || \u0026quot;.\u0026quot; || refGene.name' 'log(DP)' --header -l 10 chr pos_1 refGene_name2_refGene_name log_DP_ 1 54675 . 4.875197323201151 22 51158110 SHANK3.NM_033517 5.697093486505405 22 51158300 SHANK3.NM_033517 5.1298987149230735 22 51162849 SHANK3.NM_033517 5.905361848054571 22 51164114 SHANK3.NM_033517 5.877735781779639 22 51164286 SHANK3.NM_033517 5.802118375377063 22 51172459 . 5.6131281063880705 22 51174938 LOC105373100.NR_134637 5.75890177387728 22 51176163 LOC105373100.NR_134637 5.940171252720432 22 51186227 . 5.53338948872752  As you can see, the default header that variant tools generates replaces all non-alphanumeric characters by underscores, and you should most likely specify your own headers in these cases.\n\n2.4 Output summary statistics of fields using SQL aggregating functions (option --group_by) In addition to functions that operate on values of the same field, you can use SQL aggregating functions to output summary statistics of fields. For example, you can use function count(*) to count the number of records, sum(DP) to get the sum of depth for all variants. More usefully, these operations can be applied to groups of variants defined by option --group_by.\nCommand vtools output accepts the following aggregating functions:\n All sqlite3 functions listed HERE are supported. The most useful ones are count, sum, avg, min and max. Additional aggregation functions such as stdev, variance, mode, median, lower_quartile, upper_quartile defined HERE.   Examples: Output summary statistics of fields The following command calculate the average depth for all variants:\n% vtools output variant 'avg(DP)' 271.875  You can also output average of depth, grouped by variants that belong to genes,\n% vtools output variant refGene.name2 'count(*)' 'avg(DP)' --group_by refGene.name2 -l 10 . 161 281.1366459627329 ACR 5 240.6 FAM41C 19 294.7894736842105 FAM87B 8 214.875 LINC00115 1 122.0 LINC01128 24 242.29166666666666 LOC100288069 4 236.75 LOC105373100 6 332.6666666666667 RABL2B 22 219.5 RPL23AP82 20 293.1  Here count(*) is used to count the number of variants in each gene, and NA is a special group for variants that do not belong to any gene, which can be confirmed by command\n% vtools select variant 'refGene.chr is NULL' --output 'avg(DP)' 281.1366459627329  Option --all should not be used in these commands because this option will lead to multiple entries for some variants, and biase the results. For example, the output of the following command differs from the previous one:\n% vtools output variant refGene.name2 'count(*)' 'avg(DP)' --group_by refGene.name2 --all -l 10 . 161 281.1366459627329 ACR 5 240.6 FAM41C 19 294.7894736842105 FAM87B 8 214.875 LINC00115 1 122.0 LINC01128 128 243.03125 LOC100288069 4 236.75 LOC105373100 6 332.6666666666667 RABL2B 484 219.5 RPL23AP82 44 256.22727272727275  \nUsing option --all along with aggregating function will most likely lead to erroneous results because the aggregating function will be applied to a dataset with duplicated entries, unless you intentionally would like to count, for example, number of duplicated entries for each variant.\n "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_report/plot_pheno_fields/",
	"title": "plot_pheno_fields",
	"tags": [],
	"description": "",
	"content": " Plot Sample phenotype fields Usage % vtools_report plot_pheno_fields -h usage: vtools_report plot_pheno_fields [-h] [--samples [SAMPLES [SAMPLES ...]]] [--save_data FILENAME] [--save_script FILENAME] [--width px] [--height px] [--hist name] [--norm_curve] [--dot name] [--dot_size pt] [--discrete_color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd}] [--box name] [--stratify C [C ...]] [--outlier_size pt] [--color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd}] [-v {0,1,2}] fields [fields ...] positional arguments: fields A list of fields that will be outputted. optional arguments: -h, --help show this help message and exit --samples [SAMPLES [SAMPLES ...]] Conditions based on which samples are selected. Default to all samples. --save_data FILENAME Save data to file. --save_script FILENAME Save R script to file. --width px Width of plot. Default to 800. --height px Height of plot. Default to 600. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information of vtools and vtools_report. Debug information are always recorded in project and vtools_report log files. Draw histogram: --hist name File name of the outputted figure, which can have type PDF, EPS, or JPG. Multiple files might be produced if more than one figure is produced (e.g. MyFig_$FIELD1.pdf, MyFig_$FILED2.pdf if MyFig.pdf is specified) --norm_curve Add a normal distribution N(mean, stdev) density curve to the histogram. Draw dot plot. Allow up to 3 input fields: for single input field, the values will be plotted on y-axis with index being x-axis; for two input fields, the first field will be plotted on x-axis and the second field on y-axis; for three input fields, values of the third input field is represented by color of the dots.: --dot name File name of the outputted figure, which can have type PDF, EPS, or JPG. --dot_size pt Size of dots. Default is 2.0 --discrete_color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd} If specified, the third field of input will be treated as \u0026quot;factor\u0026quot; data. Draw box plot. Allow one or more input fields and produce box plot for all fields in one graph. With --stratify option, box plot will be generated for field in different strata, if there is only one input field, or for the first field in different strata of the second field, if there are two input fields.: --box name File name of the outputted figure, which can have type PDF, EPS, or JPG. --stratify C [C ...] Cutoff values to stratify data in the input field for box plot. When this option is on, only one input field is allowed. --outlier_size pt Size of outlier dots. Default is 2.0 --color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd} Color theme for boxes.  File type of graph (pdf, png, eps, etc) are determined by output file name extension. Common graphic options\n --save_data and --save_script: save data and script to files. If you want to customize the graph, you can save the data and script, make changes, and run Rscript --slave saved_code.R \u0026lt; saved_data.txt --width and --height: controls the size of the graph generated --color and --discrete_color: choose customized coloring theme for box plot and dot plot  Example The snapshot vt_plots containing phenotype information of ~1000 samples is used to demonstrate various graphs that can be generated.\n% vtools init plot % vtools admin --load_snapshot vt_plots  Histogram vtools_report plot_pheno_fields BMI logBMI BMI_qnormalized --hist hist.pdf --norm_curve  Attach:histogram.png\nBox plot Plot single field, stratified by given thresholds:\nvtools_report plot_pheno_fields BMI --box box.pdf --stratify 21 23 25 27 29  Attach:boxplot1.png\nPlot single field, stratified by another field with given thresholds:\nvtools_report plot_pheno_fields BMI gender --box box.pdf --stratify 2  In this example, BMI values are stratified by samples gender information. Gender is 1 (\u0026ldquo;Below 2.0\u0026rdquo;) for males, and 2 (\u0026ldquo;2.0 or more\u0026rdquo;) for females.\nAttach:boxplot2.png\nPlot multiple fields on the same graph:\nvtools_report plot_pheno_fields MDS1 MDS2 --box box.pdf --color Accent  Attach:boxplot3.png\nDot plot Dot plot for single field\nvtools_report plot_pheno_fields BMI --dot dot.pdf  Attach:dotplot1.png\nDot plot for two fields\nvtools_report plot_pheno_fields BMI logBMI --dot dot.pdf  Attach:dotplot2.png\nColored dot plot for three fields, with the third field being a continuous variable\nvtools_report plot_pheno_fields MDS1 MDS2 BMI --dot dot.pdf  Attach:dotplot3.png\nColored dot plot for three fields, with the third field being a discrete variable\nvtools_report plot_pheno_fields MDS1 MDS2 Population --dot dot.pdf --discrete_color Accent  Attach:dotplot4.png\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/annotation/",
	"title": "Annotation",
	"tags": [],
	"description": "",
	"content": " Annotating variants using multiple annotation databases, a tutorial 1. Getting annotation databases This tutorial demonstrates how to use various databases to annotate variants in a variant tools project. These databases will be automatically downloaded and saved in directory ~/.variant_tools when they are used in a project. The amount of time required to download these databases depends on the speed of your internet connection, server load, and size of the databases. If you do no want to wait for the downloads and if you have enough disk space, you can download all variant tools resources into your local resource directory using the following commands:\n% wget --mirror http://vtools.houstonbioinformatics.org % rm -rf ~/.variant_tools # remove existing directory if exists % mv vtools.houstonbioinformatics.org ~/.variant_tools  The amount of data to download is 29G as of October 2012, and is expected to grow over time. The --mirror option allows command wget to get all files recursively, skipping files that exist locally.\n2. Download a snapshot project with some variants Let us create a project and download a snapshot project called vt_quickStartGuide.\n% vtools init anno INFO: variant tools 2.0.0 : Copyright (c) 2011 - 2012 Bo Peng INFO: San Lucas FA, Wang G, Scheet P, Peng B (2012) Bioinformatics 28(3):421-422 INFO: Please visit http://varianttools.sourceforge.net for more information. INFO: Creating a new project anno % vtools admin --load_snapshot vt_quickStartGuide Downloading snapshot vt_quickStartGuide.tar.gz from online INFO: Snapshot vt_quickStartGuide has been loaded  This project has variants from CEU and JPT populations of the 1000 genomes pilot study. As we can see from the following commands, it has 4,858 variants from two samples:\n% vtools show samples sample_name filename CEU CEU.exon...3.sites.vcf.gz JPT JPT.exon...3.sites.vcf.gz % vtools show tables table #variants date message variant 4,858  3. Annotating variants 3.1 Listing available annotation databases These are available annotation databases (as of October 2012) that can be downloaded and used automatically to annotate variants within a variant tools project. You can use the following command to list currently available databases.\n% vtools show annotations CancerGeneCensus-20111215 CancerGeneCensus ccdsGene-hg19_20110909 ccdsGene-hg19_20111206 ccdsGene ccdsGene_exon-hg19_20110909 ccdsGene_exon-hg19_20111206 ccdsGene_exon dbNSFP-hg18_hg19_1.1_2 dbNSFP dbNSFP_light-hg18_hg19_1.0_0 dbNSFP_light dbSNP-hg18_129 dbSNP-hg18_130 dbSNP-hg19_131 dbSNP-hg19_132 dbSNP evs-hg19_20111107 evs evs_5400 keggPathway-20110823 keggPathway knownGene-hg18_20110909 knownGene-hg19_20110909 knownGene knownGene_exon-hg18_20110909 knownGene_exon-hg19_20110909 knownGene_exon phastCons-hg19_20110909 phastCons refGene-hg18_20110909 refGene-hg19_20110909 refGene refGene_exon-hg18_20110909 refGene_exon-hg19_20110909 refGene_exon thousandGenomes-hg19_20110909 thousandGenomes  3.2 How do I add an annotation database to my project? To add a gene-based annotation source such as ccdsGene to your project, the following command will accomplish this. If you haven\u0026rsquo;t already downloaded this annotation database with this or another project, vtools will automatically download the database and associate ccdsGene annotations to your project.\n% vtools use ccdsGene  3.3 What genes do my variants belong to? There are several annotation sources that could be used to annotate your variants to gene transcripts. Some examples include refGene, knownGene and ccdsGene. To get more details of these databases use vtools show annotation ccdsGene -v2 (or a similar command with refGene or knownGene) as described previously. This command downloads the ccdsGene data source allowing variants to be annotated to transcripts.\n3.4 What about the exon? Gene-based annotation sources such as ccdsGene, refGene and knownGene have corresponding annotation sources that are exon-based: ccdsGene_exon, refGene_exon and knownGene_exon respectively (provided indirectly through the UCSC Genome Browser database). These exon-based annotation sources contain exon start and end coordinates that are used in lieu of gene start and end coordinates for linking the annotations to your variants.\n% vtools use ccdsGene_exon  3.5 What pathways do my variants belong to? This command downloads the keggPathway annotation source allowing variants to be annotated to KEGG pathways indirectly through transcript annotations (provided by the ccdsGene annotation source).\n% vtools use keggPathway --linked_by ccdsGene.name INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/keggPathway.ann INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/keggPathway-20110823.DB.gz : Unsupported scheme. --18:54:24-- http://vtools.houstonbioinformatics.org/annoDB/keggPathway-20110823.DB.gz =\u0026gt; `./keggPathway-20110823.DB.gz' Resolving vtools.houstonbioinformatics.org... 70.39.145.13 Connecting to vtools.houstonbioinformatics.org[70.39.145.13]:80... connected. HTTP request sent, awaiting response... 200 OK Length: 350,847 [application/x-gzip] 100%[=============================================================================\u0026gt;] 350,847 330.94K/s 18:54:26 (329.78 KB/s) - `./keggPathway-20110823.DB.gz' saved [350847/350847] FINISHED --18:54:26-- Downloaded: 350,847 bytes in 1 files INFO: Using annotation DB keggPathway in project quickstart. INFO: kegg pathway for CCDS genes  Now lets filter all of our variants to include only those involved in metabolic pathways. This command uses the pathway annotation source that we just downloaded to find all variants that are on transcripts of proteins known to be involved in metabolic pathways. These variants are then stored in a table called metabolic.\n% vtools select variant 'kgDesc=\u0026quot;Metabolic pathways\u0026quot;' -t metabolic Running: 2,788 2.1K/s in 00:00:01 INFO: 109 variants selected.  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_commands/export/",
	"title": "export",
	"tags": [],
	"description": "",
	"content": " Export variants and samples to external files 1. Usage % vtools export -h usage: vtools export [-h] [-o [OUTPUT]] [-s [COND [COND ...]]] [--format FORMAT] [--build BUILD] [--header [HEADER [HEADER ...]]] [-j JOBS] [-v {0,1,2}] table Export variants and genotypes in text, vcf and other formats. positional arguments: table A variant table whose variants will be exported. If parameter --samples is specified, only variants belong to one or more of the samples will be exported. optional arguments: -h, --help show this help message and exit -o [OUTPUT], --output [OUTPUT] Name of output file. Output will be written to the standard output if this parameter is left unspecified. -s [COND [COND ...]], --samples [COND [COND ...]] Samples that will be exported, specified by conditions such as 'aff=1' and 'filename like \u0026quot;MG%\u0026quot;'. Multiple samples could be exported to a file if the output format allows. No sample will be outputted if this parameter is ignored. --format FORMAT Format of the exported file. It can be one of the variant tools supported file types such as VCF (cf. 'vtools show formats') or a local format specification file (with extension .fmt). Some formats accept additional parameters (cf. 'vtools show format FMT') and allows you to export additional or alternative fields. --build BUILD Build version of the reference genome (e.g. hg18) of the exported data. It can only be one of the primary (default) of alternative (if exists) reference genome of the project. --header [HEADER [HEADER ...]] A complete header or a list of names that will be joined by a delimiter specified by the file format to form a header. If a special name - is specified, the header will be read from the standard input, which is the preferred way to specify large multi-line headers (e.g. cat myheader | vtools export --header -). Strings in the form of %(VAR)s will be interpolated to values of variable VAR, which can be \u0026quot;sample_names\u0026quot; for list of sample names, \u0026quot;datetime\u0026quot; for current date and time, and \u0026quot;command\u0026quot; for the command used to create output. -j JOBS, --jobs JOBS Number of processes to export data. Multiple threads will be automatically used if there are a large number of samples. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1).  2. Details vtools export and vtools output perform similar functions but with different emphasis. vtools output output variants and variant info fields (and their summary statistics) in a tabular format, but it does not output genotype or genotype info fields. In comparison, vtools export exports variant, variant info fields, genotype and genotype info in pre-specified formats.\n2.1 Supported file formats Command vtools show formats lists all formats that are supported by variant tools but some file formats can only be used to import or update variants. To check whether or not you can export data in a particular format, you can run command vtools show format FMT and check if it defines one or more Columns.\n Check details of file formats\n% vtools show format ANNOVAR Format: ANNOVAR Description: Input format of ANNOVAR. No genotype is defined. Columns: 1 chromosome 2 position (1-based) 3 end position 4 reference allele 5 alternative allele 6 optional column variant: chr Chromosome pos 1-based position ref Reference allele, '-' for insertion. alt Alternative allele, '-' for deletion. Format parameters: comment_string Output one or more fields to the optional comment column of this format. (default: )  Note the Columns section in the above configuration file. Columns in this section will be the output columns as a result of output. vtools export does not (yet) support as many formats as vtools import does, for example\n% vtools show format pileup_indel Format: pileup_indel Description: Input format for samtools pileup indel caller. This format imports chr, pos, ref, alt and genotype. Columns: None defined, cannot export to this format variant: chr Chromosome name pos Start position of the indel event. ref reference allele, '-' for insertion alt alternative allele, '-' for deletion Genotype: GT type of indel (homozygote or heterozygote) Other fields (usable through parameters): type String summarizing the indel type, one of Dn (deletion of length n) and In (insertion of length n) Format parameters: geno (default: GT)  You see that the Columns section is not defined. \n2.2 Export variants and variant info fields The motivation of this export format is to prepare input files for annotating variants using ANNOVAR\n Examples: Export in ANNOVAR format\n% vtools init test % vtools import CEU_hg38.vcf --var_info AA AC AN DP --geno_info DP --build hg38 % vtools export variant -o ANNOVAR.input --format ANNOVAR % head ANNOVAR.input 1 10533 10533 G C 1 51479 51479 T A 1 51928 51928 G A 1 54586 54586 T C 1 54676 54676 C T 1 54708 54708 G C 1 55299 55299 C T 1 62203 62203 T C 1 63671 63671 G A 1 86028 86028 T C  This optional comment field comes from the available fields in the variant table to be outputted. They should have been created using vtools import or vtools update\n% vtools export variant -o ANNOVAR.input --format ANNOVAR --comment_string DP % head ANNOVAR.input 1 10533 10533 G C 423 1 51479 51479 T A 188 1 51928 51928 G A 192 1 54586 54586 T C 166 1 54676 54676 C T 131 1 54708 54708 G C 135 1 55299 55299 C T 166 1 62203 62203 T C 159 1 63671 63671 G A 243 1 86028 86028 T C 182  \n2.3 Output in PLINK TPED format Please refer to the TPED format page.\n2.4 Export in vcf format VCF is a flexible format that can store almost arbitrary information for variant, variant info, genotype and genotype info fields. All these information needs to be specified through command line options of the vcf format. To learn what options are available, you can use command\n% vtools show format vcf  Section Other fields lists the fields that can be imported (if they exist in the input file), and section Format parameters lists the parameters that can be specified from command line.\nExport variants in VCF format The basic command to export variants in vcf format is vtools export TABLE --format vcf. In this case, the variants are exported in vcf format, without header and with default (missing) name, INFO, and FILTER fields. --format vcf can be ignored if a .vcf file is specified in option --output.\n Examples: export variants in vcf format Let us first get some data,\n% vtools init test % vtools import CEU_hg38.vcf --var_info AA AC AN DP --geno_info DP --build hg38  When we export variants in vcf format,\n% vtools export variant -o my.vcf INFO: Using 2 processes to handle 0 samples Selecting genotypes: 100% [===================================] 5 4.9/s in 00:00:01 my.vcf: 100% [============================================] 292 15.6K/s in 00:00:00 INFO: 290 lines are exported from variant table variant  The outputted file looks like\n% head my.vcf 1 10533 . G C . PASS . 1 51479 . T A . PASS . 1 51928 . G A . PASS . 1 54586 . T C . PASS . 1 54676 . C T . PASS . 1 54708 . G C . PASS . 1 55299 . C T . PASS . 1 62203 . T C . PASS . 1 63671 . G A . PASS . 1 86028 . T C . PASS .  \nIndel variants are outputted in VCF format. That is to say, instead of using - to represent missing alleles, indels such as - =\u0026gt; A are outputted with padding alleles (e.g. G =\u0026gt; GA if the reference allele before the variant is G). The positions of the variants are automatically adjusted.\n Examples: export indel variants in vcf format\n% vtools init test -f % vtools admin --load_snapshot vt_testData % vtools import indels.vcf --build hg19 INFO: Importing variants from indels.vcf (1/1) indels.vcf: 100% [==============================================] 184 21.5K/s in 00:00:00 INFO: 137 new variants (1 SNVs, 77 insertions, 58 deletions, 7 complex variants) from 184 lines are imported. Importing genotypes: 0 0.0/s in 00:00:00 Copying samples: 0 0.0/s in 00:00:00  When we export variants in vcf format,\n% vtools export variant -o my_indel.vcf Writing: 100% [=================================================] 137 22.5K/s in 00:00:00 INFO: 129 lines are exported from variant table variant  The outputted file looks like\n% head my_indel.vcf 1 10433 . A AC . PASS . 1 10439 . AC A . PASS . 1 54787 . TC T . PASS . 1 54789 . C CT . PASS . 1 63735 . CCTA C . PASS . 1 63738 . ACT CTA . PASS . 1 81962 . T TAA . PASS . 1 82133 . CA C . PASS . 1 82133 . C CAAAAAAAAAAAAAA . PASS . 1 83118 . CA C . PASS .  The difference is clear if you compare the output with what outputted from command vtools output:\n% vtools output variant chr pos ref alt -l 10 1 10434 - C 1 10440 C - 1 54788 C - 1 54790 - T 1 63736 CTA - 1 63738 ACT CTA 1 81963 - AA 1 82134 A - 1 82134 - AAAAAAAAAAAAAA 1 83119 A -  \nYou can export one or more variant info fields using parameter --var_info, depending on how the field is defined in vcf.fmt, the field will be outputted as a flag (show field name if its value if True), a name value pair (show name=val), or a value. Outputting values of a field is usually not recommended unless the values already conform to vcf standard.\nYou can specify fields that are not defined in vcf.fmt. However, because variant tools does not know how to output it (as value or flag etc), it will output its value directly without a field name. Such fields do not conform to the vcf format standard. To output fields that are not defined in vcf.fmt, it is recommended that you add the field to a local copy of vcf.fmt and use the modified format file to export data.\n  Examples: export variant info fields\n% vtools init test -f % vtools import CEU_hg38.vcf --var_info AA AC AN DP --geno_info DP --build hg38 % vtools export variant --var_info AA -o my.vcf % head my.vcf 1 10533 . G C . PASS AA=. 1 51479 . T A . PASS AA=. 1 51928 . G A . PASS AA=. 1 54586 . T C . PASS AA=C 1 54676 . C T . PASS AA=T 1 54708 . G C . PASS AA=g 1 55299 . C T . PASS AA=c 1 62203 . T C . PASS AA=C 1 63671 . G A . PASS AA=G 1 86028 . T C . PASS AA=.  Anyway, if you have imported the whole INFO column of the input file, you can export it as it is for each variant\n% vtools init test -f % vtools import CEU_hg38.vcf --var_info AA info --geno_info DP --build hg38 % vtools output variant chr pos ref alt info -l 5 1 10533 G C AA=.;AC=6;AN=120;DP=423 1 51479 T A AA=.;AC=29;AN=120;DP=188 1 51928 G A AA=.;AC=5;AN=120;DP=192 1 54586 T C AA=C;AC=2;AN=120;DP=166 1 54676 C T AA=T;AC=2;AN=120;DP=131 % vtools export variant --var_info info -o my.vcf % head my.vcf 1 10533 . G C . PASS AA=.;AC=6;AN=120;DP=423 1 51479 . T A . PASS AA=.;AC=29;AN=120;DP=188 1 51928 . G A . PASS AA=.;AC=5;AN=120;DP=192 1 54586 . T C . PASS AA=C;AC=2;AN=120;DP=166 1 54676 . C T . PASS AA=T;AC=2;AN=120;DP=131 1 54708 . G C . PASS AA=g;AC=7;AN=120;DP=135 1 55299 . C T . PASS AA=c;AC=20;AN=120;DP=166;HM2 1 62203 . T C . PASS AA=C;AC=18;AN=120;DP=159 1 63671 . G A . PASS AA=G;AC=18;AN=120;DP=243 1 86028 . T C . PASS AA=.;AC=11;AN=120;DP=182  \nIf you compare the outputted vcf file with the original vcf file, you can notice a few differences. More specifically,\n variant tools removes duplicate variants from input file when it imports data. If your data has multiple lines for a variant (e.g. the same variant with multiple rsnames), you will only be able to export one of them. variant tools split variants from an input file if there are multiple alternative alleles. It exports variants one by one so such variants will not be combined into records that define multiple variants. Variant tools does not import phase information of genotypes and it always output variants in the format of A/B.   Specify a header The --header option can be used to add a header to outputs. Although it is possible to specify a minimal header using option --header CHROM POS ID REF ALT QUAL FILTER INFO FORMAT, it is useful to create a header file and send it to vtools export command through standard input (option --header -). The latter is preferred because vcf files usually has long headers.\n Examples: export in vcf format with header\n% vtools init test -f % vtools import indels.vcf --build hg19 % vtools export variant --header CHROM POS ID REF ALT QUAL FILTER INFO FORMAT -o my_indel.vcf % head -5 my_indel.vcf CHROM POS ID REF ALT QUAL FILTER INFO FORMAT 1 10433 . A AC . PASS . 1 10439 . AC A . PASS . 1 54788 . CC C . PASS . 1 54789 . C CT . PASS .  You can add '%(sample_names)s' to the header to add a list of sample names to the header if you are exporting sample genotypes (see examples below).\nAlternatively you can create a text file with a tab delimited and use --header -. For example, we can use the header of an existing vcf file, and export variants with command\n% head -200 indels.vcf | grep '#' | vtools export variant --format ~/vtools/format/vcf --header - \u0026gt; my_indels.vcf INFO: Reading header from standard input Writing: 100% [=====================================================================] 137 13.8K/s in 00:00:00 INFO: 129 lines are exported from variant table variant  \nOutput genotype Genotypes of selected samples can be outputted if you use use parameter --samples to specify samples to output. --samples 1 will output genotypes of all samples.\n Examples: export genotypes of selected samples\n% vtools init test -f % vtools import CEU_hg38.vcf --geno_info DP --var_info AA --build hg38 % vtools export variant --samples 'sample_name like \u0026quot;NA128%\u0026quot;' --format_string \u0026quot;GT\u0026quot; -o my.vcf INFO: Genotypes of 8 samples are exported. Writing: 100% [==============================================] 288 10.6K/s in 00:00:00 INFO: 286 lines are exported from variant table variant with 1 failed records % head -10 my.vcf 1 10533 . G C . PASS . GT 0/0 0/0 0/0 0/1 0/0 0/0 0/1 0/1 1 51479 . T A . PASS . GT 0/0 0/0 0/1 0/1 0/0 0/0 0/0 0/0 1 51928 . G A . PASS . GT 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 1 54586 . T C . PASS . GT 0/1 0/0 0/0 0/0 0/0 0/0 0/0 0/0 1 54676 . C T . PASS . GT 0/1 0/0 0/0 0/0 0/0 0/0 0/0 0/0 1 54708 . G C . PASS . GT 0/1 0/0 0/0 0/0 0/0 0/0 0/0 0/0 1 55299 . C T . PASS . GT 0/0 0/0 0/1 0/0 1/1 0/0 0/0 0/0 1 62203 . T C . PASS . GT 0/1 0/0 0/0 0/0 0/0 0/0 0/0 0/1 1 63671 . G A . PASS . GT 0/1 0/1 0/0 0/0 0/0 0/0 0/0 0/0 1 86028 . T C . PASS . GT 0/0 0/0 1/1 0/0 0/1 0/0 0/0 0/0  \nYou could export one or more genotype info fields using option --geno_info (Hint: use command vtools show genotypes to show available genotype fields). However, because the format string cannot be automatically determined, you will have to specify the FORMAT string manually using option --format_string,\n Examples: export genotype info fields\n% vtools export variant --samples 'sample_name like \u0026quot;NA128%\u0026quot;'\\ --geno_info DP_geno --format_string 'GT:DP' -o my.vcf INFO: Genotypes of 8 samples are exported. INFO: Using 2 processes to handle 8 samples Selecting genotypes: 100% [===================================] 5 4.9/s in 00:00:01 my.vcf: 100% [=============================================] 292 5.1K/s in 00:00:00 INFO: 288 lines are exported from variant table variant with 2 failed records % head -10 my.vcf 1 10533 . G C . PASS . GT:DP 0/0:7.0 0/0:0.0 0/0:6.0 0/1:5.0 0/0:4.0 0/0:5.0 0/1:5.0 0/1:9.0 1 51479 . T A . PASS . GT:DP 0/0:1.0 0/0:1.0 0/1:9.0 0/1:2.0 0/0:3.0 0/0:5.0 0/0:2.0 0/0:3.0 1 51928 . G A . PASS . GT:DP 0/0:6.0 0/0:1.0 0/0:5.0 0/0:6.0 0/0:0.0 0/0:6.0 0/0:0.0 0/0:2.0 1 54586 . T C . PASS . GT:DP 0/1:3.0 0/0:0.0 0/0:6.0 0/0:0.0 0/0:3.0 0/0:1.0 0/0:1.0 0/0:0.0 1 54676 . C T . PASS . GT:DP 0/1:2.0 0/0:0.0 0/0:4.0 0/0:1.0 0/0:2.0 0/0:3.0 0/0:1.0 0/0:0.0 1 54708 . G C . PASS . GT:DP 0/1:2.0 0/0:0.0 0/0:2.0 0/0:1.0 0/0:3.0 0/0:2.0 0/0:1.0 0/0:0.0 1 55299 . C T . PASS . GT:DP 0/0:4.0 0/0:0.0 0/1:7.0 0/0:5.0 1/1:3.0 0/0:0.0 0/0:4.0 0/0:1.0 1 62203 . T C . PASS . GT:DP 0/1:3.0 0/0:1.0 0/0:6.0 0/0:0.0 0/0:2.0 0/0:2.0 0/0:2.0 0/1:3.0 1 63671 . G A . PASS . GT:DP 0/1:3.0 0/1:1.0 0/0:3.0 0/0:0.0 0/0:3.0 0/0:0.0 0/0:1.0 0/0:0.0 1 86028 . T C . PASS . GT:DP 0/0:7.0 0/0:0.0 1/1:6.0 0/0:2.0 0/1:2.0 0/0:6.0 0/0:5.0 0/0:0.0  \nExport ID, QUAL, and FILTER columns You can specify arbitrary fields (or constant values) to the ID (name), QUAL, and FILTER columns of the vcf output, using parameters --id, --qual and --filter. The ID column is supposed to list rsnames of variants, you can specify a field in your project (e.g. if you import the id field from the original vcf file), or dbSNP.name.\n Examples: export id, qual and filter columns Suppose we have imported everything from the original vcf file,\n% vtools init test -f % vtools admin --load_snapshot vt_testData % vtools import CEU_hg38.vcf --var_info id qual filter info AA --build hg38  we can export them for selected variants,\n% vtools select variant 'AA=\u0026quot;T\u0026quot;' -t 'AA=T' % vtools export 'AA=T' --id id --qual qual --var_info info --filter filter -o my.vcf % head my.vcf 1 54676 rs2462492 C T . PASS AA=T;AC=2;AN=120;DP=131 22 50719683 . T C . PASS AA=T;AC=1;AN=120;DP=298 22 50719873 . T C . PASS AA=T;AC=7;AN=120;DP=169 22 50724422 rs5770822 C T . PASS AA=T;AC=41;AN=120;DP=367 22 50725687 rs5770996 C T . PASS AA=T;AC=52;AN=120;DP=357 22 50725859 rs6009957 T C . PASS AA=T;AC=37;AN=120;DP=331 22 50734032 rs5770824 T C . PASS AA=T;AC=3;AN=120;DP=274 22 50736511 . C T . PASS AA=T;AC=4;AN=120;DP=317 22 50737736 . T C . PASS AA=T;AC=3;AN=120;DP=380 22 50747800 rs3865766 C T . PASS AA=T;AC=51;AN=120;DP=253;HM3  Actually, because we are using columns such as qual from a VCF file, we can export these columns using a vcf track. The input CEU.vcf.gz file must be indexed though:\n% vtools export 'AA=T' --id id --qual 'track(\u0026quot;CEU_hg38.vcf\u0026quot;, \u0026quot;qual\u0026quot;)' --var_info 'track(\u0026quot;CEU_hg38.vcf\u0026quot;, \u0026quot;info\u0026quot;)' \\ --filter 'track(\u0026quot;CEU_hg38.vcf\u0026quot;, \u0026quot;filter\u0026quot;)' -o my.vcf % head my.vcf 1 54676 rs2462492 C T . PASS AA=T;AC=2;AN=120;DP=131 22 50719683 . T C . PASS AA=T;AC=1;AN=120;DP=298 22 50719873 . T C . PASS AA=T;AC=7;AN=120;DP=169 22 50724422 rs5770822 C T . PASS AA=T;AC=41;AN=120;DP=367 22 50725687 rs5770996 C T . PASS AA=T;AC=52;AN=120;DP=357 22 50725859 rs6009957 T C . PASS AA=T;AC=37;AN=120;DP=331 22 50734032 rs5770824 T C . PASS AA=T;AC=3;AN=120;DP=274 22 50736511 . C T . PASS AA=T;AC=4;AN=120;DP=317 22 50737736 . T C . PASS AA=T;AC=3;AN=120;DP=380 22 50747800 rs3865766 C T . PASS AA=T;AC=51;AN=120;DP=253;HM3  Optionally, you can use rsnames in the dbSNP database\n% vtools use dbSNP % vtools export 'AA=T' --id dbSNP.name --qual qual --var_info info --filter dbSNP.filter -o my.vcf % head my.vcf 1 54676 rs2462492 C T . . AA=T;AC=2;AN=120;DP=131 22 50719683 rs73174428 T C . . AA=T;AC=1;AN=120;DP=298 22 50719873 rs117910162 T C . . AA=T;AC=7;AN=120;DP=169 22 50724422 rs5770822 C T . . AA=T;AC=41;AN=120;DP=367 22 50725687 rs5770996 C T . . AA=T;AC=52;AN=120;DP=357 22 50725859 rs6009957 T C . . AA=T;AC=37;AN=120;DP=331 22 50734032 rs5770824 T C . . AA=T;AC=3;AN=120;DP=274 22 50736511 rs73174435 C T . . AA=T;AC=4;AN=120;DP=317 22 50737736 rs76593947 T C . . AA=T;AC=3;AN=120;DP=380 22 50747800 rs3865766 C T . . AA=T;AC=51;AN=120;DP=253;HM3  \n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_report/plot_association/",
	"title": "plot_association",
	"tags": [],
	"description": "",
	"content": " Graphic Summary of Association Analysis Introduction vtools_report plot_association generates QQ plot and Manhattan plot of p-values from output of vtools associate command. The graphics are powered by the R package ggplot2. Fonts, color, page layout etc can be specified from the command interface, generating high quality and customized graphs.\nInput data format vtools associate command typically generates two types of output: output of gene based association tests and single variant analysis.\nGene-based test input #refGene_name2 sample_size_SBurdenTest statistic_SBurdenTest pvalue_SBurdenTest AAGAB 1246 14 0.709392 ABHD2 1246 1 0.423756 ACAN 1246 107 0.0235792 ACSBG1 1246 23 0.887873 ACTC1 1246 0 1 ADAL 1246 2 1 ADAMTS17 1246 19 0.875558 ADAM10 1246 0 0.0766778 AGBL1 1246 120 0.119562 ...  Single variant test input #chr pos sample_size_SNV beta_x_SNV pvalue_SNV 1 802398 120 0.164128 0.205794 1 861292 316 -0.0339594 0.556444 1 865580 252 0.448666 0.271728 1 866422 316 -0.106212 0.734266 1 865584 268 0.0681559 0.267732 1 865625 303 -0.54794 0.837163 1 866517 311 0.154219 0.17982 1 865662 303 -0.571153 0.881119 1 871129 315 0.0691795 0.476523  Note that\n The program will read the header and only handle the columns prefixed by pvalue_ and suffixed by some non-empty character string which will be used as legend names Multiple columns of p-values are allowed (see examples below)  Sample output graphs QQ Plot samples Attach:qqplots.zip\nManhattan Plot samples Attach:manhattanplots.zip\nDetails Command interface % vtools_report plot_association -h usage: vtools_report plot_association [-h] [-v {0,1,2}] {qq,manhattan,manhattan_plain} ... positional arguments: {qq,manhattan,manhattan_plain} qq QQ plot via ggplot2 manhattan Manhattan plot via ggplot2 manhattan_plain Manhattan plot implementation not using ggplot2 optional arguments: -h, --help show this help message and exit -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information of vtools and vtools_report. Debug information are always recorded in project and vtools_report log files. % vtools_report plot_association qq -h usage: vtools_report plot_association qq [-h] [--shape INTEGER] [--fixed_shape] [--no_slope] [-t TITLE] [--color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd}] [--width_height INCHES INCHES] [-s] [-o FILE] [-b] [-l POSITION [POSITION ...]] [--label_top INTEGER] [--label_these NAME [NAME ...]] [-f SIZE] optional arguments: -h, --help show this help message and exit --shape INTEGER Choose a shape theme (integer 1 to 16) for dots on QQ plot. Default set to 1. --fixed_shape Use the same dot-shape theme for all plots --no_slope Do not plot the diagonal line graph properties: -t TITLE, --title TITLE Title of plot. --color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd} Choose a color theme from the list above to apply to the plot. (via the 'RColorBrewer' package: cran.r-project.org/web/packages/RColorBrewer) --width_height INCHES INCHES The width and height of the graphics region in inches -s, --same_page Plot multiple groups of p-values on the same graph -o FILE, --output FILE Specify output graph filename. Output is in pdf format. It can be converted to jpg format via the 'convert' command in Linux (e.g., convert -density 180 p.pdf p.jpg) variants/genes highlighting: -b, --bonferroni Plot the horizontal line at 0.05/N on Y-axis (significance level after Bonferroni correction) -l POSITION [POSITION ...], --hlines POSITION [POSITION ...] Additional horizontal line(s) to be drawn on the Y-axis. --label_top INTEGER Specify how many top hits (smallest p-values by rank) you want to highlight with their identifiers in text. --label_these NAME [NAME ...] Specify the names of variants (chr:pos, e.g., 1:87463) or genes (genename, e.g., IKBKB) you want to highlight with their identifiers in text. -f SIZE, --font_size SIZE Font size of text labels. Default set to '2.5'. % vtools_report plot_association manhattan -h usage: vtools_report plot_association manhattan [-h] [--chrom CHROMOSOME [CHROMOSOME ...]] [--chrom_prefix PREFIX] [--gene_map FILE] [-t TITLE] [--color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd}] [--width_height INCHES INCHES] [-s] [-o FILE] [-b] [-l POSITION [POSITION ...]] [--label_top INTEGER] [--label_these NAME [NAME ...]] [-f SIZE] optional arguments: -h, --help show this help message and exit --chrom CHROMOSOME [CHROMOSOME ...] Specify the particular chromosome(s) to display. Can be one or multiple in this list: \u0026quot;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y Un ?:?\u0026quot;. Slicing syntax \u0026quot;?:?\u0026quot; is supported. For example \u0026quot;1:22\u0026quot; is equivalent to displaying all autosomes; \u0026quot;1:Y\u0026quot; is equivalent to displaying all mapped chromosomes. Default set to all including unmapped chromosomes. --chrom_prefix PREFIX Prefix chromosome ID with a string. Default is set to \u0026quot;chr\u0026quot; (X-axis will be displayed as \u0026quot;chr1\u0026quot;, \u0026quot;chr2\u0026quot;, etc). Use \u0026quot;None\u0026quot; for no prefix. --gene_map FILE If the plot units are genes and the program fails to map certain genes to chromosomes, you can fix it by providing a text file of genomic coordinate information of these genes. Each gene in the file is a line of 3 columns specifying \u0026quot;GENENAME CHROM MIDPOINT_POSITION\u0026quot;, e.g., \u0026quot;IKBKB 8 42128820\u0026quot;. graph properties: -t TITLE, --title TITLE Title of plot. --color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd} Choose a color theme from the list above to apply to the plot. (via the 'RColorBrewer' package: cran.r-project.org/web/packages/RColorBrewer) --width_height INCHES INCHES The width and height of the graphics region in inches -s, --same_page Plot multiple groups of p-values on the same graph -o FILE, --output FILE Specify output graph filename. Output is in pdf format. It can be converted to jpg format via the 'convert' command in Linux (e.g., convert -density 180 p.pdf p.jpg) variants/genes highlighting: -b, --bonferroni Plot the horizontal line at 0.05/N on Y-axis (significance level after Bonferroni correction) -l POSITION [POSITION ...], --hlines POSITION [POSITION ...] Additional horizontal line(s) to be drawn on the Y-axis. --label_top INTEGER Specify how many top hits (smallest p-values by rank) you want to highlight with their identifiers in text. --label_these NAME [NAME ...] Specify the names of variants (chr:pos, e.g., 1:87463) or genes (genename, e.g., IKBKB) you want to highlight with their identifiers in text. -f SIZE, --font_size SIZE Font size of text labels. Default set to '2.5'. % vtools_report plot_association manhattan_plain -h usage: vtools_report plot_association manhattan_plain [-h] [--chrom CHROMOSOME [CHROMOSOME ...]] [--chrom_prefix PREFIX] [--gene_map FILE] [-t TITLE] [--color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd}] [--width_height INCHES INCHES] [-s] [-o FILE] [-b] [-l POSITION [POSITION ...]] [--label_top INTEGER] [--label_these NAME [NAME ...]] [-f SIZE] optional arguments: -h, --help show this help message and exit --chrom CHROMOSOME [CHROMOSOME ...] Specify the particular chromosome(s) to display. Can be one or multiple in this list: \u0026quot;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y Un ?:?\u0026quot;. Slicing syntax \u0026quot;?:?\u0026quot; is supported. For example \u0026quot;1:22\u0026quot; is equivalent to displaying all autosomes; \u0026quot;1:Y\u0026quot; is equivalent to displaying all mapped chromosomes. Default set to all including unmapped chromosomes. --chrom_prefix PREFIX Prefix chromosome ID with a string. Default is set to \u0026quot;chr\u0026quot; (X-axis will be displayed as \u0026quot;chr1\u0026quot;, \u0026quot;chr2\u0026quot;, etc). Use \u0026quot;None\u0026quot; for no prefix. --gene_map FILE If the plot units are genes and the program fails to map certain genes to chromosomes, you can fix it by providing a text file of genomic coordinate information of these genes. Each gene in the file is a line of 3 columns specifying \u0026quot;GENENAME CHROM MIDPOINT_POSITION\u0026quot;, e.g., \u0026quot;IKBKB 8 42128820\u0026quot;. graph properties: -t TITLE, --title TITLE Title of plot. --color {Dark2,grayscale,default,BrBG,PiYG,PRGn,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral,Accent,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Blues,BuGn,BuPu,GnBu,Greens,Greys,Oranges,OrRd,PuBu,PuBuGn,PuRd,Purples,RdPu,Reds,YlGn,YlGnBu,YlOrBr,YlOrRd} Choose a color theme from the list above to apply to the plot. (via the 'RColorBrewer' package: cran.r-project.org/web/packages/RColorBrewer) --width_height INCHES INCHES The width and height of the graphics region in inches -s, --same_page Plot multiple groups of p-values on the same graph -o FILE, --output FILE Specify output graph filename. Output is in pdf format. It can be converted to jpg format via the 'convert' command in Linux (e.g., convert -density 180 p.pdf p.jpg) variants/genes highlighting: -b, --bonferroni Plot the horizontal line at 0.05/N on Y-axis (significance level after Bonferroni correction) -l POSITION [POSITION ...], --hlines POSITION [POSITION ...] Additional horizontal line(s) to be drawn on the Y-axis. --label_top INTEGER Specify how many top hits (smallest p-values by rank) you want to highlight with their identifiers in text. --label_these NAME [NAME ...] Specify the names of variants (chr:pos, e.g., 1:87463) or genes (genename, e.g., IKBKB) you want to highlight with their identifiers in text. -f SIZE, --font_size SIZE Font size of text labels. Default set to '2.5'.  QQ Plot Examples Gene base tests zcat genetest.result.gz | vtools_report plot_association qq -o genes_qq1 zcat genetest.result.gz | vtools_report plot_association qq -s --color Dark2 -b -o genes_qq\\ 2 zcat genetest.result.gz | vtools_report plot_association qq -t \u0026quot;Demo QQ plot\u0026quot; -b -o genes_q\\ q3 zcat genetest.result.gz | vtools_report plot_association qq -t \u0026quot;Demo otherwise shaped QQ pl\\ ot\u0026quot; -s -b --shape 12 -o genes_qq4  Single variant tests zcat varianttest.result.gz | vtools_report plot_association qq -o variants_qq1 zcat varianttest.result.gz | vtools_report plot_association qq -s --color Dark2 -b -o varia\\ nts_qq2 zcat varianttest.result.gz | vtools_report plot_association qq -t \u0026quot;Demo QQ plot\u0026quot; -b -o vari\\ ants_qq3 zcat varianttest.result.gz | vtools_report plot_association qq -t \u0026quot;Demo otherwise shaped QQ\\ plot\u0026quot; -s -b --shape 12 -o variants_qq4  Manhattan Plot Examples Gene base tests zcat genetest.result.gz | vtools_report plot_association manhattan -t \u0026quot;Demo Manhattan plot\u0026quot;\\ --color Dark2 --s -b -o genes_man1 zcat genetest.result.gz | vtools_report plot_association manhattan -t \u0026quot;Demo Manhattan plot\u0026quot;\\ --chrom 1:22 --chrom_prefix None --same_page -o genes_man2 zcat genetest.result.gz | vtools_report plot_association manhattan_plain -t \u0026quot;Demo Manhattan\\ plain plot\u0026quot; --color Dark2 --s -b -o genes_man3 zcat genetest.result.gz | vtools_report plot_association manhattan_plain -t \u0026quot;Demo Manhattan\\ plain plot\u0026quot; --chrom 1:22 --chrom_prefix None --same_page -o genes_man4  Single variant tests zcat varianttest.result.gz | vtools_report plot_association manhattan -t \u0026quot;Demo Manhattan pl\\ ot\u0026quot; --color Dark2 --s -b -o variants_man1 zcat varianttest.result.gz | vtools_report plot_association manhattan -t \u0026quot;Demo Manhattan pl\\ ot\u0026quot; --chrom 1:22 --chrom_prefix None --same_page -o variants_man2 zcat varianttest.result.gz | vtools_report plot_association manhattan_plain -t \u0026quot;Demo Manhat\\ tan plain plot\u0026quot; --color Dark2 --s -b -o variants_man3 zcat varianttest.result.gz | vtools_report plot_association manhattan_plain -t \u0026quot;Demo Manhat\\ tan plain plot\u0026quot; --chrom 1:22 --chrom_prefix None --same_page -o variants_man4  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/association/",
	"title": "Quality control",
	"tags": [],
	"description": "",
	"content": " Demonstration of Quality Control and Association Analysis 1. Getting Started This section describes the data-set, required software and computational environment for the exome association analysis to be demonstrated in this tutorial.\n1.1 Data Source We use the exome data from the 1000 genomes project. The entire data-set can be found at the NCBI ftp site. This release (version 3.0, April 30th, 2012) contains phased genotype calls on 1092 samples in VCF format, with 38.2M SNVs, 3.9M Short Indels and 14K Large Deletions. Data from different sources are pooled together. Targets for exome sequencing can be found at the 1000 genomes ftp site.\nWe created a snapshot dataset for this demonstration with the original exome data plus simulated genotype quality scores and phenotype values. The dataset is 2.1GB and can be automatically downloaded and loaded for use with the following commands:\nvtools init qc vtools admin --load_snapshot vt_qc   Details about this snapshot data \nGenotypes Exome variant sites with higher coverage are extracted from the original VCF files, resulting the g1000exomesnv.vcf.gz (411MB) input exome data file.\n#!bin/bash chrs='1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X' data\\_dir=\u0026quot;/home/guest/Data1000g\u0026quot; zcat$data\\_dir/ALL.chr1.phase1\\_release\\_v3.20101123.snps\\_indels\\_svs.genotypes.vcf.gz | head -500 |grep -P \u0026quot;^#\u0026quot; | bgzip -c \u0026gt; g1000exomesnv.header.vcf.gz for chr in $chrs do echo $chr zcat $data_dir/ALL.chr$chr.phase1_release_v3.20101123.snps_indels_svs.genotypes.vcf.gz | grep -v -P \u0026quot;^#\u0026quot; | grep -P \u0026quot;SNPSOURCE=EXOME\u0026quot; | grep -P \u0026quot;VT=SNP\u0026quot; | bgzip -c \u0026gt; g1000exomesnv_chr$chr.vcf.gz done fn=\\`for i in $chr; do echo g1000exomesnv_chr$i.vcf.gz; done\\` zcat g1000exomesnv.header.vcf.gz $fn | bgzip -c \u0026gt; g1000exomesnv.vcf.gz  Genotype attributes The VCF file from 1000 genomes project has two genotype attributes, Genotype dosage from MaCH/Thunder and Genotype Likelihoods. To demonstrate the data QC procedures we need to have additional attributes such as Genotype Depth (GD) and Genotype Quality (GQ). We randomly simulate GD and GQ scores and append them to each genotype call, which is neither based on genotype dosage nor on genotype likelihoods. These scores will be used in QC for demonstration purposes.\nPhenotypes Two simulated phenotypes BMI and smoking combined with the original PED file will be used as phenotype data for this demonstration.\n\n1.2 Software Quality control and association analysis will be performed with variant association tools (vtools update, vtools select and vtools associate) with simple annotations from variant association tools. A few other software are occasionally needed for certain tasks along the pipeline.\nOther software\nANNOVAR We will use the ANNOVAR program to determine which variants should be analyzed in association tests based on their functionality (nonsynonymous, splicing sites, etc).\nKING We will use KING program for phenotype level quality control, i.e., to infer kinship and population structure. PLINK program is needed to convert output to KING compatible format.\nR with ggplot2 vtools report requires R with ggplot2 in order to produce QQ plot and Manhattan plot. To install it in R:\ninstall.packages(\u0026quot;ggplot2\u0026quot;)  \nComputer Environment Demonstrative analysis for this tutorial are not computationally intensive and can be efficiently carried out in a reasonably powered computer. We have applied similar analysis on ~6,500 whole exome sequencing samples with a total of ~2 million variants and experienced satisfactory performance on a regular Debian GNU/Linux based workstation.\n Read the workstation configurations \nCPU  product: AMD FX\u0026trade;-8150 Eight-Core Processor vendor: Advanced Micro Devices [AMD] size: 3600MHz capacity: 3600MHz width: 64 bits clock: 200MHz  RAM (4X4=16GB)  description: DIMM Synchronous 1066 MHz (0.9 ns) size: 4GiB (each, 16GB total) width: 64 bits clock: 1066MHz (0.9ns)  Cache  description: L1 cache size: 384KiB capacity: 384KiB clock: 1GHz (1.0ns) description: L2 cache size: 8MiB capacity: 8MiB clock: 1GHz (1.0ns) description: L3 cache size: 8MiB capacity: 8MiB clock: 1GHz (1.0ns)  Motherboard  product: Crosshair V Formula vendor: ASUSTeK COMPUTER INC.  Harddrive (2X2TB)  product: ST32000641AS vendor: Seagate version: CC13 serial: 9WM6ZQJG size: 1863GiB  \n2. Initializing a Project for convenience and portability of commands, we set bash variables:\nscript_dir=\u0026quot;./cache\u0026quot; data_dir=\u0026quot;./data\u0026quot;  2.1 Preparing input format configuration file A \u0026ldquo;data format configuration file\u0026rdquo; *.fmt is required to build a project. This mechanism allows importing variants/samples from a number of arbitrary input format. It is always good practice to review and adapt a template fmt file for a specific data-set. We provide a few FMT templates, among which a vcf format template is available. A modified version of the template vcf.fmt results in g1000vcf.fmt. We created this file by extracting the meta information of the source vcf file and make changes accordingly on the fmt template. You should find this file in your project directory if you have loaded our snapshot vt_qc. Using this snapshot, you do not need to import any data for this tutorial. However you can modify and use the configuration files for your other projects.\ng1000vcf.fmt is configured such that it will not import variant INFO fields (we will create separated annotation database for it) and genotype likelihood GL field (we will not use it in the analysis)\n Optimize the performance If you have a large volume of data to import, it is important to set \u0026ldquo;runtime optimization\u0026rdquo; parameters to speed up the process. Please read this documentation for details.\nImport from multiple sources If your dataset is stored in multiple VCF file, please read this documentation for properly importing such dataset.\n2.2 Creating Annotations Annotations of variants can be incorporated to the project via\n building/using annotation databases (vtools use)  or,\n adding annotation fields to variant database (vtools update).  We will demonstrate both approaches.\nAnnotations from the source VCF file Two files are required to create annotation database: the source data and the .ann configuration file. A number of ANN templates are provided. To create customized annotation configuration please refer to the online documentation.\nThe snapshot we provided has intentionally left out information in the INFO field of the VCF file, which you will find in the file variants.tsv.gz in this snapshot, as well as the g1000.ann file to build annotation database from the INFO field of VCF file.\nvtools use $script_dir/g1000.ann --file $data_dir/g1000exomesnv.vcf.gz -j8 INFO: Importing annotation data from variants.tsv.gz variants.tsv.gz: 100% [================] 142,403 7.8K/s in 00:00:18 INFO: 291088 records are handled, 0 ignored. INFO: Using annotation DB g1000 in project g1000. INFO: 1000genome VCF file  Available annotation fields can be viewed by either\nvtools show annotation g1000  or\nvtools show fields   which will show all the variant fields in current project.\nvariant.variant_id variant.bin variant.chr variant.pos variant.ref variant.alt g1000.chr Chromosome g1000.pos 1-based position g1000.dbsnp_id variant id (rs number or other IDs) g1000.ref Reference allele, '-' for insertion. g1000.alt Alternative allele, '-' for deletion. g1000.qual phred-scaled quality score for the assertion made in ALT. High QUAL scores indicate high confidence calls. g1000.filter PASS if this position has passed all filters, i.e. a call is made at this position. Otherwise, if the site has not passed all filters, a semicolon-separated list of codes for filters that fail. g1000.LDAF MLE Allele Frequency Accounting for LD g1000.AVGPOST Average posterior probability from MaCH/Thunder g1000.RSQ Genotype imputation quality from MaCH/Thunder g1000.ERATE Per-marker Mutation rate from MaCH/Thunder g1000.THETA Per-marker Transition rate from MaCH/Thunder g1000.CIEND Confidence interval around END for imprecise variants g1000.CIPOS Confidence interval around POS for imprecise variants g1000.END End position of the variant described in this record g1000.HOMLEN Length of base pair identical micro-homology at event breakpoints g1000.HOMSEQ Sequence of base pair identical micro-homology at event breakpoints g1000.SVLEN Difference in length between REF and ALT alleles g1000.SVTYPE Type of structural variant g1000.AN Total Allele Count g1000.AC Alternate Allele Count g1000.AA Ancestral Allele, ftp://ftp.1000genomes.ebi.ac.uk/ vol1/ftp/pilot_data/technical/reference/a ncestral_alignments/README g1000.AF Global Allele Frequency based on AC/AN g1000.AMR_AF Allele Frequency for samples from AMR based on AC/AN g1000.ASN_AF Allele Frequency for samples from ASN based on AC/AN g1000.AFR_AF Allele Frequency for samples from AFR based on AC/AN g1000.EUR_AF Allele Frequency for samples from EUR based on AC/AN g1000.VT indicates what type of variant the line represents (eg: INDEL, SNP) g1000.SNPSOURCE indicates if a snp was called when analysing the low coverage or exome alignment data (eg: EXOME, LOWCOV)  \nANNOVAR Annotations We want to annotate variants with ANNOVAR for variants functionality so that we can focus on functional variants in rare variants association analysis. Although all variants in this dataset should be found in the large collection of readily available annotation databases in variant annotation tools, we want to demonstrate here the use of customized text based annotation sources. For readily usable annotation please refer to documentation of variant annotation tools.\nFirstly we output the variants for ANNOVAR to annotate:\nvtools output variant chr pos pos ref alt \u0026gt; $data_dir/exomesnv.txt /path/to/annotate_variation.pl $data_dir/exomesnv.txt $data_dir/humandb/ -buildver hg19 NOTICE: The --geneanno operation is set to ON by default NOTICE: Reading gene annotation from humandb/hg19_refGene.txt ... Done with 40272 transcripts (including 6670 without coding sequence annotation) for 23416 unique genes NOTICE: Reading FASTA sequences from /home/min/HD1s/humandb/hg19_refGeneMrna.fa ... Done with 29603 sequences NOTICE: Finished gene-based annotation on 291088 genetic variants in exomesnv.txt NOTICE: Output files were written to exomesnv.txt.variant_function, exomesnv.txt.exonic_variant_function  We use refGene hg19 database in ANNOVAR, although there are other options (see ANNOVAR website for details).\n Then we import the annotated result into the project database, using two of our template format configurations:\nvtools update variant --format ANNOVAR_exonic_variant_function \\ --from_file $data_dir/exomesnv.txt.exonic_variant_function \\ --var_info mut_type function genename vtools update variant --format ANNOVAR_variant_function \\ --from_file $data_dir/exomesnv.txt.variant_function \\ --var_info region_type region_name INFO: Using primary reference genome hg19 of the project. Getting existing variants: 100% [========================] 291,088 385.1K/s in 00:00:00 INFO: Updating variants from cache/exomesnv.txt.exonic_variant_function (1/1) exomesnv.txt.exonic_variant_function: 100% [========================] 184,931 3.5K/s in 00:00:53 INFO: Fields mut_type, function, genename of 184,931 variants are updated INFO: Using primary reference genome hg19 of the project. Getting existing variants: 100% [==============================] 291,088 395.1K/s in 00:00:00 INFO: Updating variants from cache/exomesnv.txt.variant_function (1/1) exomesnv.txt.variant_function: 100% [============================] 291,088 5.8K/s in 00:00:50 INFO: Fields region_type, region_name of 291,088 variants are updated  vtools show format ANNOVAR_exonic_variant_function and vtools show format ANNOVAR_variant_function will display details of these configuration formats\n vtools show format ANNOVAR_exonic_variant_function Format: ANNOVAR_exonic_variant_function Description: Output from ANNOVAR, generated from command \u0026quot;path/to/annovar/annotate_variation.pl annovar.txt path/to/annovar/humandb/\u0026quot;. This format imports chr, pos, ref, alt and ANNOVAR annotations. For details please refer to http://www.openbioinformatics.org/annovar/annovar_gene.html Columns: None defined, cannot export to this format variant: chr Chromosome pos 1-based position, hg18 ref Reference allele, '-' for insertion. alt Alternative allele, '-' for deletion. Variant info: mut_type the functional consequences of the variant. Other fields (usable through parameters): genename Gene name (for the first exon if the variant is in more than one exons, but usually the names for all exons are the same). function the gene name, the transcript identifier and the sequence change in the corresponding transcript Format parameters: var_info Fields to be outputted, can be one or both of mut_type and function. (default: mut_type) vtools show format ANNOVAR_variant_function Format: ANNOVAR_variant_function Description: Output from ANNOVAR for files of type \u0026quot;*.variant_function\u0026quot;, generated from command \u0026quot;path/to/annovar/annotate_variation.pl annovar.txt path/to/annovar/humandb/\u0026quot;. This format imports chr, pos, ref, alt and ANNOVAR annotations. For details please refer to http://www.openbioinformatics.org/annovar/annovar_gene.html Columns: None defined, cannot export to this format variant: chr Chromosome pos 1-based position, hg18 ref Reference allele, '-' for insertion. alt Alternative allele, '-' for deletion. Variant info: region_type The genomic region type (i.e., intergenic, ncRNA_intronic, etc) where this variant lies. Other fields (usable through parameters): region_name Genomic region name that corresponds to the region_type. If the variant lies in an intergenic region, this field will specify the closest known regions upstream and downstream of this variant. Format parameters: var_info Fields to be outputted, can be one or both of region_type and region_name. (default: region_type)  A few additional fields regarding variant functionality are added to the variant table. They will be useful for selecting, filtering and grouping variants for association analysis.\nvtools show table variant -l3 variant_id, bin, chr, pos, ref, alt, region_type, region_name 1, 585, 1, 69536, C, T, exonic, OR4F5 2, 591, 1, 861275, C, T, intronic, SAMD11 3, 591, 1, 861315, G, A, UTR5, SAMD11 (291085 records omitted, use parameter --limit to display more or all records)  3. Basic Quality Control \u0026amp; Data Preprocessing Quality control is a crucial yet tedious step in association analysis. To facilitate this step, we provide a variety of summary statistic along with a number of sample/variant selection and filtering operations for quality control purpose. In this section we will demonstrate some basic quality control procedures. Please refer to our data exploration tutorial for advanced summary statistics and QC measures.\n3.1 Variant \u0026amp; Genotype Level QC vtools select and vtools exclude commands implement variant level data selection and filtering. Variants can be subsetted on the basis of criteria defined by variant properties (variant information, annotations, summary statistics, etc) displayed by vtools show fields. We could either focus on subsets of variants of interest or remove non-informative subsets of variants after variants are subsetted.\nLow quality variants filter We have made the FILTER column from the original vcf file available as annotation field g1000.filter. It can be used directly to remove low quality variants from the database. We select variants of good quality into a separate table, and use this table (instead of using table variant) for next steps of analysis.\nvtools select variant \u0026quot;g1000.filter='PASS'\u0026quot; -t variant_pass  An alternative approach would be applying vtools remove so that variants of low quality are removed from the variant table. Note that the remove command is irreversible.\nvtools exclude variant \u0026quot;g1000.filter='PASS'\u0026quot; -t variant_to_rm vtools remove variants variant_to_rm  Low quality genotypes filter Information on genotype calls (displayed in FORMAT column for each variant in VCF files) can be used for quality control of individual genotypes. To list available genotype information fields,\nvtools show genotypes -l 4 sample_name filename num_genotypes sample_genotype_fields HG00096 simulatedQc1000g.tar.gz 291088 GT,DS,GD,GQ HG00097 simulatedQc1000g.tar.gz 291088 GT,DS,GD,GQ HG00099 simulatedQc1000g.tar.gz 291088 GT,DS,GD,GQ HG00100 simulatedQc1000g.tar.gz 291088 GT,DS,GD,GQ (1088 records omitted, use parameter --limit to display more or all records)  The GT and DS genotype fields are genotypes and genotype dosage from MaCH/Thunder. Both of them are from the original 1000 genomes project data. GQ and GD are simulated genotype quality and genotype depth of coverage. Genotype level filtering can be performed by removing genotype calls of given quality measure, which will irreversibly remove genotypes of low coverage and quality:\nvtools remove genotypes \u0026quot;GD\u0026lt;10 or GQ\u0026lt;20\u0026quot;  In many cases, however, we do not want to remove genotypes at the early stage of analysis, since we may later decide to change the QC criteria. It is possible to always calculate various statistics conditioning on genotypes defined by expressions such as GD\u0026gt;10 and GQ\u0026gt;20, for example: vtools update variant --from_stat ... --genotypes \u0026lt;em\u0026gt;GD\u0026gt;10 and GQ\u0026gt;20\u0026lt;/em\u0026gt; In this way we obtain statistic over genotype calls excluding the low quality genotypes. This approach is more flexible and allows evaluation of the same statistic conditional on different criteria.\n QC statistics conditioned on genotype information We will demonstrate here the calculation of summary statistics conditioning on genotype information. We set up a genotype condition expression from genotype information fields GD and GQ. The calculation of various statistic will skip genotypes failing to satisfy this expression, as you can see by comparing the counts of total genotypes and minor allele counts after executing the following commands.\nStatistic without genotype condition constraints:\nvtools update variant --from_stat 'total=#(GT)' 'num=#(alt)' \\ 'het=#(het)' 'hom=#(hom)' 'other=#(other)' \\ 'wildtype=#(wtGT)' 'mutants=#(mutGT)' 'missing=#(missing)' Counting variants: 100% [===================] 1,092 1.5/s in 00:12:08 INFO: Adding field num INFO: Adding field hom INFO: Adding field het INFO: Adding field other INFO: Adding field total Updating variant: 100% [=================] 291,088 79.2K/s in 00:00:03 INFO: 291087 records are updated  Statistic with genotype condition constraints:\nvtools update variant --from_stat 'total_GD10GQ20=#(GT)' 'num_GD10GQ20=#(alt)' \\ 'het_GD10GQ20=#(het)' 'hom_GD10GQ20=#(hom)' 'other_GD10GQ20=#(other)' \\ 'wildtype_GD10GQ20=#(wtGT)' 'mutants_GD10GQ20=#(mutGT)' 'missing_GD10GQ20=#(missing)\\ '\\ --genotypes \u0026quot;GD\u0026gt;10 and GQ\u0026gt;20\u0026quot; Counting variants: 100% [================] 1,092 15.2/s in 00:01:11 INFO: Adding field num_GD10GQ20 INFO: Adding field hom_GD10GQ20 INFO: Adding field het_GD10GQ20 INFO: Adding field other_GD10GQ20 INFO: Adding field total_GD10GQ20 Updating variant: 100% [======================] 290,999 79.1K/s in 00:00:03 Updating missing variants in variant: 100% [=======================] 89 60.6K/s in 00:00:00  Compare the statistic from original data vs. statistic conditional on genotype info scores:\nvtools output variant chr pos ref alt total total_GD10GQ20 num num_GD10GQ20 missing missing\\ _GD10GQ20 -l4 --header chr pos ref alt total total_GD10GQ20 num num_GD10GQ20 missing missing_GD10GQ20 1 69536 C T 1092 1088 0 0 0 4 1 861275 C T 1092 1091 1 1 0 1 1 861315 G A 1092 1091 2 2 0 1 1 865488 A G 1092 1092 1 1 0 0  Looking at the first variant \u0026ldquo;1:69536\u0026rdquo; we see the original total count is 1092 genotype calls; after conditioning on GD\u0026gt;10 and GQ\u0026gt;20, 4 genotype calls are skipped, resulting in 1088 counts. If all genotype calls in a variant site fail the genotype quality constraint, the total count will be zero. These variants are:\nvtools select variant \u0026quot;total_GD10GQ20 == 0\u0026quot; -o chr pos ref alt 1 10719967 C T 1 11199698 T C 1 11210331 C T 1 40432550 C T 1 44057597 C T 1 44063508 C T 1 203452763 G A 1 212506861 C T 1 212506964 G A 1 212530649 G A ...  A more informative use of the statistic would be for example a ratio of the two total fields:\nvtools update variant --set \u0026quot;missing_ratio = missing_GD10GQ20/(total * 1.0)\u0026quot; chr pos ref alt missing_ratio 1 69536 C T 0.003663003663 1 861275 C T 0.000915750915751 1 861315 G A 0.000915750915751 1 865488 A G 0.0 1 865545 G A 0.0 ...  This calculates the proportion of genotypes having low quality scores per variant. Such variant level statistics can be useful in creating customized variant level quality control criteria.\nThe statistics calculated above are for demonstration only and will not be used in our next analysis steps. We will not pursue any QC related summary statistic calculations for now, since groups of samples have to be defined before statistics of subset of samples can be calculated (e.g., population specific minor allele frequency). In the next section we will demonstrate manipulation of sample information.\n3.2 Processing Phenotype / Sample Level Information We discuss in this section the organization and use of sample phenotype information. This snapshot provides a phenotype file that we can load phenotype data from:\nvtools phenotype --from_file $data_dir/g1000_simulated_phenotypes.txt INFO: Adding field Family_ID INFO: Adding field Paternal_ID INFO: Adding field Maternal_ID INFO: Adding field Gender INFO: Adding field Population INFO: Adding field BMI INFO: Adding field smoking INFO: 7 field (7 new, 0 existing) phenotypes of 1092 samples are updated.  To view the phenotypes available,\nvtools show samples -l10 sample_name filename Family_ID Paternal_ID Maternal_ID Gender Population BMI smoking HG00096 simulatedQc1000g.vcf.gz HG00096 0 0 1 GBR 23.04 0 HG00097 simulatedQc1000g.vcf.gz HG00097 0 0 2 GBR 37.09 0 HG00099 simulatedQc1000g.vcf.gz HG00099 0 0 2 GBR 28.87 0 HG00100 simulatedQc1000g.vcf.gz HG00100 0 0 2 GBR 24.12 1 HG00101 simulatedQc1000g.vcf.gz HG00101 0 0 1 GBR 27.72 0  To view specific phenotypes,\nvtools phenotype --output sample_name Population BMI smoking HG00096 GBR 23.04 0 HG00097 GBR 37.09 0 HG00099 GBR 28.87 0 HG00100 GBR 24.12 1 HG00101 GBR 27.72 0 HG00102 GBR 27.41 0  Creating sample information columns based on sample genotypes Individual level genotype summary can be generated and appended to the sample information table. For example we want to calculate the number of alternative alleles per individual:\nvtools phenotype --from_stat \u0026quot;allele_counts=#(alt)\u0026quot; -j8 Calculating phenotype: 100% [==================] 1,092 90.9/s in 00:00:12 INFO: 1092 values of 1 phenotypes (1 new, 0 existing) of 1092 samples are updated.  Similar to variant level genotype summary, genotype information condition can be applied, for example:\nvtools phenotype --from_stat \u0026quot;allele_counts_GD10GQ20=#(alt)\u0026quot; --genotypes 'GD\u0026gt;10 and GQ\u0026gt;20' \\ -j8  Two additional sample information fields allele_counts and allele_counts_ds are added to the database.\nvtools phenotype --output sample_name allele_counts allele_counts_GD10GQ20 -l 3 --header sample_name allele_counts allele_counts_GD10GQ20 HG00096 1232 1182 HG00097 1317 1263 HG00099 1431 1363  Sample information thus created can be useful in individual genotype level quality control. For example, we may want to remove sample having too many low quality or missing genotype calls from the analysis (vtools remove samples). Advanced use of phenotype --from_stat command include calculating sample level \u0026lsquo;transition-transversion ratio\u0026rsquo;, or \u0026lsquo;synonymous-nonsynonymous SNV ratio\u0026rdquo;, see this [tutorial].\n Creating phenotypes based on existing sample information vtools phenotype --set accepts arithmetic operations on existing columns, producing new useful sample information, or phenotypes. For example,\nvtools phenotype --set \u0026quot;ds_proportion=allele_counts_ds / (allele_counts * 1.0)\u0026quot;  Or, to create a new phenotype BMI_bin on the basis of existing phenotypes (note the use of --samples condition):\nvtools phenotype --set \u0026quot;BMI_bin=1\u0026quot; --samples \u0026quot;BMI\u0026gt;25\u0026quot; vtools phenotype --set \u0026quot;BMI_bin=0\u0026quot; --samples \u0026quot;BMI\u0026lt;=25\u0026quot; INFO: 590 values of 1 phenotypes (1 new, 0 existing) of 590 samples are updated. INFO: 502 values of 1 phenotypes (0 new, 1 existing) of 502 samples are updated.  In later sections we will demonstrate the association analysis using both the quantitative trait BMI and the binary trait BMI_bin.\nUpdating sample information for association testing There are 14 different population groups in our data-set\nvtools phenotype --output Population | sort -u | wc -l # 14  also there are a few related individuals\nvtools phenotype --output sample_name Paternal_ID Maternal_ID \\ --samples \u0026quot;Maternal_ID != 0 or Paternal_ID != 0\u0026quot; HG00155 0 HG00144 NA07048 NA07034 NA07055 NA10847 NA12146 NA12239 NA10851 NA12056 NA12057 NA19129 NA19128 NA19127 NA19434 0 NA19432 NA19444 0 NA19432 NA19469 0 NA19470 NA19675 NA19679 NA19678 NA19685 NA19661 NA19660  We choose to group and analyze some unrelated European populations (CEU, BGR and TSI) in association tests. Firstly we define a new phenotype Unrelated_Europeans:\nvtools phenotype --set \u0026quot;Unrelated_Europeans='yes'\u0026quot; \\ --samples \u0026quot;Population in ('CEU', 'GBR', 'TSI') and Maternal_ID == 0 and Paternal_ID \\ == 0\u0026quot; vtools phenotype --set \u0026quot;Unrelated_Europeans='no'\u0026quot; \\ --samples \u0026quot;Population not in ('CEU', 'GBR', 'TSI') or Maternal_ID != 0 or Paternal_I\\ D != 0\u0026quot; INFO: Adding field Unrelated_Europeans INFO: 268 values of 1 phenotypes (1 new, 0 existing) of 268 samples are updated. INFO: 824 values of 1 phenotypes (0 new, 1 existing) of 824 samples are updated.  There are 268 samples having a yes tag for being unrelated Europeans. Within these European samples, there are population substructures which we would want to control for by incorporating principle components (PC) from MDS analysis as covariates. We calculated the PC for the 268 samples using the KING program, and import the output into the database:\nvtools phenotype --from_file $data_dir/European_PC.txt INFO: Adding field PC1 INFO: Adding field PC2 INFO: 3 field (2 new, 1 existing) phenotypes of 268 samples are updated.  Population structure determination and selection of unrelated samples is very important in exome association analysis. Even though the 1000 genomes data comes with self-reported kinship and population information, it is still necessary to conduct population structure and kinship analysis. One can use the same technique as has been applied in GWAS studies.\n 3.3 Variant and Sample Selection for Association Analysis Alternative allele frequency calculations We calculate AF within the 268 European samples, by first calculate total genotypes and number of alternative alleles, then calculate AF from them.\nvtools update variant --from_stat 'total_ie=#(GT)' 'num_ie=#(alt)' 'het_ie=#(het)' \\ 'hom_ie=#(hom)' 'other_ie=#(other)' --samples \u0026quot;Unrelated_Europeans='yes'\u0026quot; \\\\ --genotypes \u0026quot;GD\u0026gt;10 and GQ\u0026gt;20\u0026quot; vtools update variant --set 'af_ie=num_ie/(total_ie * 2.0)'  Notice that\n As was previously discussed, genotype conditions --genotypes can be applied with specified criteria. Several other fields num_ie, het_ie, hom_ie, other_ie are calculated and will be used in HWE analysis.  Allele frequency thus calculated af=num/(total * 2.0) will be wrong for variants on X chromosome if males present in samples. Correct allele frequency can be calculated using more involved vtools update command, which we will not demonstrate here.\n A new allele frequency field is added to the database. We can look at variants having non-trivial af_ie field and compare it with the allele frequency estimate based on the entire data-set\nvtools select variant \u0026quot;af_ie\u0026gt;0\u0026quot; -o chr pos ref alt g1000.AF af_ie -l5 1 874551 G A 0.0005 0.0018656716417910447 1 874706 A G 0.0005 0.0018656716417910447 1 878709 C T 0.0014 0.0018656716417910447 1 878712 C T 0.0015 0.0018656716417910447 1 878744 G C 0.0057 0.0018656716417910447  Note that all the 5 variants displayed above are singletons ({$MAF=\\frac{1}{268\\times2}$}). We can explore the variants distribution in the 268 samples using select commands\n variant counts by type\n arr=(\\`vtools select variant -c -v0\\`) arr+=(\\`vtools select variant \u0026quot;af\\_ie\u0026gt;0\u0026quot; -c -v0\\`) for i in 1 2 3 do arr+=(\\`vtools select variant \u0026quot;num\\_ie=$i\u0026quot; -c -v0\\`) done echo ${arr[1]} \u0026quot;out of a total of\u0026quot; ${arr[0]} \u0026quot;variants are selected in our sample, among which\u0026quot; ${arr[2]} \u0026quot;are singletons,\u0026quot; ${arr[3]} \u0026quot;are doubletons and\u0026quot; ${arr[4]} \u0026quot;are tripletons\u0026quot;.  \nThe output says: 60896 out of a total of 291088 variants are selected in our sample, among which 49813 are singletons, 5663 are doubletons and 1546 are tripletons.\nHWE filter Exact Test of Hardy-Weinberg Equilibrium is implemented as in Wigginton et al (2005)[^J WIGGINTON, D CUTLER and G ABECASIS (2005) A Note on Exact Tests of Hardy-Weinberg Equilibrium. The American Journal of Human Genetics doi:10.1086/429864. http://linkinghub.elsevier.com/retrieve/pii/S0002929707607356^] to detect and filter out variants deviating from HWE.\nvtools update variant --set \u0026quot;hwe=HWE_exact(num_ie, het_ie, hom_ie, other_ie)\u0026quot;  An hwe field is created with p-values from the HWE test. We want to filter out variant sites with {$HWE\u0026lt;5\\times10^{-8}$}, which is 1132 variants. It turns out most of these variants have MAF greater than 0.01.\nvtools select variant 'hwe\u0026lt;5e-8' -c  Creating common and rare variant subsets Unlike traditional GWAS analysis, exome association analysis will study both common variants (variants having relatively high minor allele frequency) and rare variants (variants having relatively low minor allele frequency). Statistical methods for analyzing common and rare variants are different. It is thus necessary to subset variants based on minor allele frequency. We define common variants as having MAF greater than 1%, and rare variants MAF smaller than 1%.\nvtools select variant \u0026quot;af_ie\u0026gt;=0.01 and af_ie\u0026lt;=0.99 and hwe\u0026gt;=5e-8\u0026quot; \\ -t common_var \u0026quot;common variants for the 268 unrelated European samples, hwe \\ and quality pass\u0026quot; vtools select variant \u0026quot;((af_ie\u0026lt;0.01 and af_ie\u0026gt;0.0) or (af_ie\u0026gt;0.99 and af_ie\u0026lt;1.0)) and hwe\u0026gt;=\\ 5e-8\u0026quot; \\ -t rare_var \u0026quot;rare variants for the 268 unrelated European samples, hwe and \\ quality pass\u0026quot; vtools show tables table #variants date message variant 291,088 common_var 1,711 Jul10 common variants for the 268 unrelated European samples, hwe and quality pass rare_var 58,053 Jul10 rare variants for the 268 unrelated European samples, hwe and quality pass  The 1% cutoff for rare/common variants is arbitrary. For this small demonstration data-set (60k variants, 268 individuals) using 1% cut off we have 58062 rare variants and 2825 common variants. Alternatively, for single variant association tests (common variants analysis) one could analyze all variants except for singletons and doubletons regardless of their MAF classification; for aggregated variants analysis (rare variants analysis) one may want to use other MAF cutoffs depending on the available sample size, and particularly, for variable thresholds or RareCover methods, the cutoff should be higher (say, 5%).\n Selecting functional rare variants Rare variants analysis typically focus only on variants that effect protein function. We have already annotated the variants with ANNOVAR. The annotation fields can be used to select functional rare variants for association studies.\nvtools select rare_var \u0026quot;mut_type like 'nonsynonymous%'\u0026quot; \\ -t rare_nonsyn \u0026quot;nonsynonymous variants selected from table rare_var\u0026quot; vtools select rare_var \u0026quot;mut_type like 'nonsynonymous%' OR mut_type like 'stoploss%' OR mut_\\ type like 'stopgain%' OR mut_type like 'splicing%'\u0026quot; \\ -t rare_fvar \u0026quot;nonsynonymous, stoploss, stopgain and splicing variants selec\\ ted from table rare_var\u0026quot; vtools show tables rare_nonsyn 23,207 Jul10 nonsynonymous variants selected from table rare_var rare_fvar 23,757 Jul10 nonsynonymous, stoploss, stopgain and splicing variants selected from table rare_var  Summary We originally have a total of 291,088 variants. After\n Restricting the variants to only 268 selected samples Filtering for low variants/genotypes quality Filtering for HWE Sub-setting into common/rare variants Filtering rare variants by functionality  we end up having 1,711 common variants and 23,757 rare variants for association analysis.\n3.4 Additional QC for Missing Data Although there is no missing genotype calls in our test data (or, missing genotype calls have already being imputed), in practice it is not always the case. In addition to missing calls, low quality genotypes will be regarded missing in effect. As has already been discussed, we can use --genotypes conditions to skip low quality genotypes. The overall missingness of data per variant can be evaluated on both variant level and individual level.\nVariant level missingness vtools update variant --from_stat \u0026quot;mnum=#(missing)\u0026quot; --genotypes CONDITION vtools update variant --set \u0026quot;missing_ratio = mnum/(N * 1.0)\u0026quot;  where N is the total sample size.\nIndividual level missingness vtools phenotype --from_stat \u0026quot;num=#(missing)\u0026quot; --genotypes CONDITION vtools phenotype --set \u0026quot;missing_ratio = mnum/(M * 1.0)\u0026quot;  where M is the total number of variant sites.\nGroup specific filtering of missing data for rare variant association analysis After the variant/sample information field missing_ratio is calculated, an overall variant/sample level filtering can be performed. However we do not recommend the overall filtering for rare variant association analysis. In practice the distribution of missing genotype calls are not uniform. Some samples may not have data on a particular genetic region while other samples have (due to different exome capture arrays). To fully exploit the data we will filter variants and samples for missing data specific to each small genomic unit while carrying out association tests, as will be introduced in the next section of this tutorial.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_commands/remove/",
	"title": "remove",
	"tags": [],
	"description": "",
	"content": " Remove project, variant table, fields and others 1. Usage % vtools remove -h usage: vtools remove [-h] [-v STD[LOG]] {project,tables,samples,fields,geno_fields,annotations,variants,genotypes,phenotypes} [items [items ...]] Remove from the current project various items such as variants genotypes, and annotation fields. positional arguments: {project,tables,samples,fields,geno_fields,annotations,variants,genotypes,phenotypes} Type of items to be removed. items Items to be removed, which should be, for 'project' the name of project to be removed (optional), for 'tables' names of one or more variant tables, for 'samples' patterns using which matching samples are removed, for 'fields' name of fields to be removed, for 'geno_fields' name of genotype fields to be removed (cf. 'vtools show genotypes'), for 'annotations' names of annotation databases, for 'variants' variant tables whose variants will be removed from all variant tables and genotypes, for 'genotypes' conditions using which matching genotypes are removed, and for 'phenotypes' columns in the output of 'vtools show samples'. Note that removal of samples will only remove sample name, filename (if all related samples are removed), and related genotypes, but not variants themselves; removal of annotation databases will stop using these databases in the project, but will not delete them from disk. optional arguments: -h, --help show this help message and exit -v STD[LOG], --verbosity STD[LOG] Output error and warning (0), info (1) and debug (2) information to standard output (default to 1), and to a logfile (default to 2).  Fields from annotation databases cannot be removed.\n Removing samples will only remove information for specified samples from existing variants. Variants themselves will not be removed.\n Removing annotation databases only remove the database from the project (stop using it), not from the disk.\n Removing an annotation database might make other databases unusable if they are linked through one of the fields in the removed database.\n 2. Details 2.1 Remove variant table To remove a variant table,\n% vtools remove tables CEU % vtools show tables  This command accept the use of wildcard characters ? and * so it is possible to easily remove a large number of tables. For example, the following command removes all temporary tables that were created when tables with the same names were created:\n% vtools remove tables '*_Dec*'  The parameter should be quoted to avoid early interpretation of wildcard characters from the command line.\nWildcard characters should be used with caution.\n 2.2 Remove variant info fields To remove a field,\n% vtools remove field CEU_ctrls_freq CEU_ctrls_het % vtools show fields  2.3 Remove genotype info fields from genotype tables % vtools remove geno_fields DP_geno % vtools show genotypes  2.4 Remove project The following command will remove an existing project.\n% vtools remove project  2.5 Remove samples Show existing samples\n% vtools show samples filename sample_name aff sex BMI SAMP1.vcf SAMP1 1 M 22.78 SAMP2.vcf SAMP1 2 F 24.43 var_format.vcf SRR028913.aln.sorted.bam None None None  Remove one sample with an affection status of 1\n% vtools remove samples 'aff = 1' -v2 INFO: Removing sample SAMP1 from file SAMP1.vcf  Show samples again\n% show samples INFO: Opening project sample.proj filename sample_name aff sex BMI SAMP2.vcf SAMP1 2 F 24.43 var_format.vcf SRR028913.aln.sorted.bam None None None  2.6 Remove annotation databases A project uses three databases, dbNSFP, keggPathway, and dbSNP131,\n% vtools show Project name: RA Primary reference genome: hg18 Secondary reference genome: hg19 Database engine: sqlite3 Variant tables: variant, NS, NS_damaging, NS_sp_damaging, NS_pp, NS1_Aug16_012302, NS1, NS2 Annotation databases: dbNSFP (1.1_0), keggPathway, dbSNP131 (0)  You can remove dbNSFP from the project using command\n% vtools remove annotations dbNSFP INFO: Removing annotation database dbNSFP from the project  dbNSFP is no longer available, so keggPathway cannot be be loaded either, because it is linked by dbNSFP.genename.\n% vtools show WARNING: Failed to locate field genename WARNING: Cannot open annotation database keggPathway Project name: RA Primary reference genome: hg18 Secondary reference genome: hg19 Database engine: sqlite3 Variant tables: variant, NS, NS_damaging, NS_sp_damaging, NS_pp, NS1_Aug16_012302, NS1, NS2 Annotation databases: dbSNP131 (0)  2.7 Remove variants from specified variant tables For example, we can remove all variants having low quality by:\n% vtools select variant \u0026quot;DP\u0026lt;10\u0026quot; -t lowDP % vtools remove variants lowDP  If you would like to remove all but variants in a specified table, you will have to create a table with all variants to be removed using command vtools compare.\n% vtools compare variant to_be_kept --difference to_be_removed  before you remove the table to_be_removed\n% vtools remove variants to_be_removed  Removing a large number of variants will be slow. In this case, it is usually much more efficient to create a subproject using the variants to be kept. (vtools init name --parent /path/to/parent --variants to_be_kept)\n 2.8 Remove genotypes For example, we can remove all variants having low quality by:\n% vtools remove genotypes \u0026quot;DP_geno\u0026lt;10\u0026quot;  2.9 Remove phenotype from sample table % vtools remove phenotypes BMI  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/testing/",
	"title": "Association",
	"tags": [],
	"description": "",
	"content": " Association Analysis 1. Statistical Tests for Genotype/phenotype Associations 1.1 The VAT association command We will introduce the basic usage of this command without diving into each association test. For a complete demonstration of all the tests please refer to the documentation for VAT (on the sidebar of this webpage).\n1.2 Getting started The general interface of vtools associate is as follows\n% vtools associate -h usage: vtools associate [-h] [--covariates [COVARIATES [COVARIATES ...]]] [--var_info [VAR_INFO [VAR_INFO ...]]] [--geno_info [GENO_INFO [GENO_INFO ...]]] [-m METHODS [METHODS ...]] [-g [GROUP_BY [GROUP_BY ...]]] [-s [COND [COND ...]]] [--genotypes [COND [COND ...]]] [--discard_samples [EXPR [EXPR ...]]] [--discard_variants [EXPR [EXPR ...]]] [--to_db annoDB] [-f] [-j N] [-v {0,1,2}] variants phenotypes Call one or more statistical association tests and return test results as fields to variants tested. optional arguments: -h, --help show this help message and exit -j N, --jobs N Number of processes to carry out association tests. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1). Genotype, phenotype, and covariates: variants Table of variants to be tested. phenotypes A list of phenotypes that will be passed to the association statistics calculator. Currently only a single phenotype is allowed. --covariates [COVARIATES [COVARIATES ...]] Optional phenotypes that will be passed to statistical tests as covariates. Values of these phenotypes should be integer or float. --var_info [VAR_INFO [VAR_INFO ...]] Optional variant information fields (e.g. minor allele frequency from 1000 genomes project) that will be passed to statistical tests. The fields could be any annotation fields of with integer or float values, including those from used annotation databases (use \u0026quot;vtools show fields\u0026quot; to see a list of usable fields). --geno_info [GENO_INFO [GENO_INFO ...]] Optional genotype fields (e.g. quality score of genotype calls, cf. \u0026quot;vtools show genotypes\u0026quot;) that will be passed to statistical tests. Note that the fields should exist for all samples that are tested. Association tests: -m METHODS [METHODS ...], --methods METHODS [METHODS ...] Method of one or more association tests. Parameters for each method should be specified together as a quoted long argument (e.g. --method \u0026quot;m --alternative 2\u0026quot; \u0026quot;m1 --permute 1000\u0026quot;), although the common method parameters can be specified separately, as long as they do not conflict with command arguments. (e.g. --method m1 m2 -p 1000 is equivalent to --method \u0026quot;m1 -p 1000\u0026quot; \u0026quot;m2 -p 1000\u0026quot;.). You can use command 'vtools show tests' for a list of association tests, and 'vtools show test TST' for details about a test. Customized association tests can be specified as mod_name.test_name where mod_name should be a Python module (system wide or in the current directory), and test_name should be a subclass of NullTest. -g [GROUP_BY [GROUP_BY ...]], --group_by [GROUP_BY [GROUP_BY ...]] Group variants by fields. If specified, variants will be separated into groups and are tested one by one. Select and filter samples and genotypes: -s [COND [COND ...]], --samples [COND [COND ...]] Limiting variants from samples that match conditions that use columns shown in command 'vtools show sample' (e.g. 'aff=1', 'filename like \u0026quot;MG%\u0026quot;'). Each line of the sample table (vtools show samples) is considered as samples. If genotype of a physical sample is scattered into multiple samples (e.g. imported chromosome by chromosome), they should be merged using command vtools admin. --genotypes [COND [COND ...]] Limiting genotypes to those matching conditions that use columns shown in command 'vtools show genotypes' (e.g. 'GQ\u0026gt;15'). Genotypes failing such conditions will be regarded as missing genotypes. --discard_samples [EXPR [EXPR ...]] Discard samples that match specified conditions within each test group (defined by parameter --group_by). Currently only expressions in the form of \u0026quot;%(NA)\u0026gt;p\u0026quot; is providedted to remove samples that have more 100*p percent of missing values. --discard_variants [EXPR [EXPR ...]] Discard variant sites based on specified conditions within each test group. Currently only expressions in the form of '%(NA)\u0026gt;p' is provided to remove variant sites that have more than 100*p percent of missing genotypes. Note that this filter will be applied after \u0026quot;--discard_samples\u0026quot; is applied, if the latter also is specified. Output of test statistics: --to_db annoDB Name of a database to which results from association tests will be written. Groups with existing results in the database will be ignored unless parameter --force is used. -f, --force Analyze all groups including those that have recorded results in the result database.  Each association test method (-m/--method) has its own commandline interface. To show all available association tests,\n% vtools show tests BurdenBt Burden test for disease traits, Morris \u0026amp; Zeggini 2009 BurdenQt Burden test for quantitative traits, Morris \u0026amp; Zeggini 2009 CFisher Fisher's exact test on collapsed variant loci, Li \u0026amp; Leal 2008 ....  To show usage of a particular test,\n% vtools show test CFisher Name: CFisher Description: Fisher's exact test on collapsed variant loci, Li \u0026amp; Leal 2008 usage: vtools associate --method CFisher [-h] [--name NAME] [-q1 MAFUPPER] [-q2 MAFLOWER] [--alternative TAILED] [--midp] [--moi {additive,dominant,recessive}] Collapsing test for case-control data (CMC test, Li \u0026amp; Leal 2008). Different from the original publication which jointly test for common/rare variants using Hotelling's t^2 method, this version of CMC will binaries rare variants (default frequency set to 0.01) within a group defined by \u0026quot;--group_by\u0026quot; and calculate p-value via Fisher's exact test. A \u0026quot;mid-p\u0026quot; option is available for one-sided test to obtain a less conservative p-value estimate. optional arguments: -h, --help show this help message and exit --name NAME Name of the test that will be appended to names of output fields, usually used to differentiate output of different tests, or the same test with different parameters. Default set to \u0026quot;CFisher\u0026quot; -q1 MAFUPPER, --mafupper MAFUPPER Minor allele frequency upper limit. All variants having sample MAF\u0026lt;=m1 will be included in analysis. Default set to 0.01 -q2 MAFLOWER, --maflower MAFLOWER Minor allele frequency lower limit. All variants having sample MAF\u0026gt;m2 will be included in analysis. Default set to 0.0 --alternative TAILED Alternative hypothesis is one-sided (\u0026quot;1\u0026quot;) or two-sided (\u0026quot;2\u0026quot;). Default set to 1 --midp This option, if evoked, will use mid-p value correction for one-sided Fisher's exact test. --moi {additive,dominant,recessive} Mode of inheritance. Will code genotypes as 0/1/2/NA for additive mode, 0/1/NA for dominant or recessive model. Default set to additive  A basic association test requires the following input:\n variants to be analyzed (see vtools show tables) a variant table previously created for a subset of variants phenotype to be analyzed (see vtools show samples -l1) phenotype covariates to be incorporated (--covariates) samples to be analyzed (--samples) genotype quality conditions, if low quality genotypes are not previously purged from database (--genotypes) missing data filters (--discard_samples and --discard_variants) association analysis method association testing group unit (--group_by. Will perform single variant analysis if unspecified.) output database filename (--to_db) number of CPU processors to be used for parallel computing  Missing values are not allowed in phenotype/covariates data. Samples having missing values in phenotype or any covariates will be removed and you will receive a warning message. If you want to retain samples having missing values in covariates we suggest you manually fill them with specified values (vtools phenotype --set ... --samples ...). For quantitative traits the value can be the sample mean, and for qualitative traits be the most likely category.\n In this tutorial we demonstrate basic association analysis of a disease phenotype and a quantitative phenotype (simulated traits status and bmi). We choose to include covariate phenotypes gender and age when we demonstrate the multivariate analysis.\nAssociation analysis for common variants For single variant analysis with disease trait:\n% vtools associate common status \\ --covariates gender age \\ --discard_variants \u0026quot;%(NA)\u0026gt;0.1\u0026quot; \\ --method \u0026quot;LogitRegBurden --name SNV --alternative 2\u0026quot; \\ --to_db SNV \\ -j8 \u0026gt; SNV.txt  {$p$} values calculated by this command are based on Wald statistic of logistic regression analysis. To evaluate p-values empirically,\n% vtools associate common status \\ --covariates gender age \\ --discard_variants \u0026quot;%(NA)\u0026gt;0.1\u0026quot; \\ --method \u0026quot;LogitRegBurden --name SNV_permute --alternative 2 -p 100000000 --\\ adaptive 5e-5\u0026quot; \\ --to_db SNV \\ -j8 \u0026gt; SNV_permute.txt  we use a maximum of 100 million permutations per test, with an adaptive criteria {$p=5 \\times 10^{-5}$}. It takes about 15 seconds to complete the analysis on 1711 groups analytically and about 15 minutes on the same data using permutation based p-value evaluations.\nBy setting --name (inside the --method option) to a different name SNV_permute it is possible to insert new results from permutation tests to the same database SNV.DB while keeping the results from the previous non-permutation based analysis intact.\n Association analysis for rare variants Instead of analyzing them individually, rare variants are usually grouped into association units and are analyzed by groups. For exome analysis association units are genes. The --group_by/-g option can be used to create flexible grouping themes for rare variant analysis from variant fields or annotation databases. For example the name2 field in the refGene database can be used to classify variants into genes for analysis:\n% vtools associate rare status \\ --covariates gender age \\ --discard_samples \u0026quot;%(NA)\u0026gt;0.1\u0026quot; \\ --discard_variants \u0026quot;%(NA)\u0026gt;0.1\u0026quot; \\ --method \u0026quot;BurdenBt --name BurdenTest --alternative 2\u0026quot; \\ --group_by name2 \\ --to_db BurdenTest \\ -j8 \u0026gt; BurdenTest.txt  Permutation based analysis and other association methods (vtools show tests for disease traits and quantitative traits) are available but will not be demonstrated here.\nResuming previously terminated analysis Exome-wide association scan typically consists of thousands of tests for gene-based analysis, and up to a million tests for single variant analysis. In many cases an association command may be interrupted before all tests are completed (e.g., commands terminated due to running out of reserved CPU time on clusters, etc). If you have used --to_db option in the previous command, then resuming the analysis is simple: just re-run the exact command that was interrupted. The program will skip the records that exist in the result database and only carry out the ones that are missing. If you want to start all over, you may apply a --force option to the association command so that the existing result database will be overwritten, regardless of the data it already contains.\nSetting a timeout for permutation based association analysis Although with the \u0026quot;adaptive permutation\u0026quot; approach most permutation tests in an exome-wide a\\ ssociation scan would terminate early after a few thousand permutations, for scans involvin\\ g up to a million association tests you are likely to see some tests running for hours, rep\\ orting very small p-values in the end. These tests will temporarily hold up the computation\\ resource (they have to be finished first before the rest of tests get started). We provide\\ an option to set a time limit per test, in addition to using the adaptive permutation. Thi\\ s option is useful particularly when your computation resource is tight, or if you use a cl\\ uster that offers limited walltime, or if your sample size is small and result in extreme v\\ alues of test statistic. To set the association timeout to 1 hour (3600s): % vtools admin --set_runtime_option association_timeout=3600 % vtools show  After association scan is complete you can track and redo these timed out tests with larger or no timeout value,\n% vtools select variant \u0026quot;test_pvalue \u0026lt; 0\u0026quot; --table TO_REDO % vtools admin --reset_runtime_option association_timeout  and re-run the association command with --force option so that the updated results will be written to the database previously generated with the --to_db option.\nReset temporary data folder for association analysis We implemented a mechanism to optimally organize and access the genotype data for association testing. Temporary association databases will be generated on the fly and removed after the analysis is complete. By default these databases will be placed in the operating system\u0026rsquo;s temp path (usually /tmp or /var/tmp on Unix-like system). We may need to specify a temporary folder for association testing that 1) has large disk space and 2) locates on a different physical harddrive than the original project database bundle. Using a small disk for the temporary data may cause program crash (in which case you will receive an error message complaining about disk space) or degraded performance (in which case you will receive a warning message). To reset the temp folder, use\n% vtools admin --set_runtime_option temp_dir=/path/to/an/empty/directory  Other runtime options for association analysis Two other runtime options associate_num_of_readers and treat_missing_as_wildtype for association testing are available but will not be discussed here. Please use the following command to see the usage of these runtime options:\n% vtools show runtime_options  1.3 Viewing and Interpreting Association Results View association analysis results (This feature is under development)\nvtools_report commands plot_qq and plot_manhattan to present the association analysis results in QQ plot or Manhattan plot:\nusage: aviewer [-h] [--version] {qq,manhattan,manhattan_plain} ... Association Viewer, generating QQ / Manhattan plots of p-values from association analysis. Input data should be in the format of the output from 'vtools associate' command and be piped to the program as stdin. positional arguments: {qq,manhattan,manhattan_plain} qq QQ plot via ggplot2 manhattan Manhattan plot via ggplot2 manhattan_plain Manhattan plot implementation not using ggplot2 optional arguments: -h, --help show this help message and exit --version show program's version number and exit  This program generates graphs for {$p$} values, allowing for\n multiple association results plotted on the same / different pages various color, shape and legend themes to choose from text labels for siginificant p-values on the graph text labels for specified variants/genes on the graph marks for significance levels (Bonforroni correction or user specified value)  2. Online Dataset Examples You can use our snapshot for association vt_ExomeAssociation to test out the VAT association features. This is a non-trivial dataset of ~30k variants and ~3k samples with simulated phenotypes\n% vtools init test % vtools show snapshots % vtools admin --load_snapshot vt_ExomeAssociation  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_commands/execute/",
	"title": "execute",
	"tags": [],
	"description": "",
	"content": " Execute variant tools pipelines 1. Usage % vtools execute -h usage: vtools execute [-h] [-i [INPUT_FILE [INPUT_FILE ...]]] [-o [OUTPUT_FILE [OUTPUT_FILE ...]]] [-j JOBS] [-d DELIMITER] [-v {0,1,2}] PIPELINE/QUERY [PIPELINE/QUERY ...] Execute a pipeline that uses external commands to process input files, usually to align raw reads to a reference genome and call variants from aligned reads. The pipelines are controlled by pipeline description files. This command can also be used to execute arbitrary SQL query against the project database. Additional parameters will be passed to pipelines as pipeline parameters. positional arguments: PIPELINE/QUERY Name of a pipeline configuration file with optional names of pipelines to be executed if the configuration file defines more than one pipelines. The configuration file can be identified by path to a .pipeline file (with or without extension), or one of the online pipelines listed by command \u0026quot;vtools show pipelines\u0026quot;. If no input and output files are specified (options --input and --output), values of this option is treated as a SQL query that will be executed against the project database, with project genotype database attached as \u0026quot;genotype\u0026quot; and annotation databases attached by their names. optional arguments: -h, --help show this help message and exit -i [INPUT_FILE [INPUT_FILE ...]], --input [INPUT_FILE [INPUT_FILE ...]] Input files to the pipeline, which will be passed to the pipelines as pipeline variable ${CMD_INPUT}. -o [OUTPUT_FILE [OUTPUT_FILE ...]], --output [OUTPUT_FILE [OUTPUT_FILE ...]] Names of output files of the pipeline, which will be passed to the pipelines as ${CMD_OUTPUT}. -j JOBS, --jobs JOBS Maximum number of concurrent jobs to execute. -d DELIMITER, --delimiter DELIMITER Delimiter used to output results of a SQL query. -v {0,1,2}, --verbosity {0,1,2} Output error and warning (0), info (1) and debug (2) information to standard output (default to 1).  2. Details 2.1 Execute variant tools pipelines This command executes a pipeline that calls external commands to perform various operations. The general command line is\n% vtools execute pipeline_file [pipeline_name] [--input input_files] [--output output_files] [--options]  Here only the pipeline_file is required, which is a local or online pipeline file that defines one or more pipelines. pipeline_name can be ignored if only one pipeline is defined in this file. To get a list of available pipelines, you should run\n% vtools show pipelines  You can then use command\n% vtools show pipeline pipeline_file  to get details of the pipelines defined in this file.\nEach pipeline accepts different --input, --output and optional parameters so please refer to the documentation for details of each pipeline.\n2.2 Execute SQL query This command executes arbitrary SQL query and displays output to standard output or a file.\nSuccessful use of this command requires clear understanding of the structure of tables, which can be changed without notice from version to version.\n Display name of samples\n% vtools execute select sample_name from sample -v2 DEBUG: Loading annotation database testNSFP DEBUG: Executing SQL statement: \u0026quot;select sample_name from sample\u0026quot; NA06985 NA06986 NA06994 NA07000 ... ...  The following query needs to be quoted because of the existence of *\n% vtools execute 'SELECT * FROM sample' -v2 DEBUG: Opening project esp.proj DEBUG: Loading annotation database refGene_exon DEBUG: Loading annotation database ../annoDB/dbSNP-hg19_132 DEBUG: Analyze statement: \u0026quot;SELECT * FROM SAMPLE\u0026quot; DEBUG: 0 0 0 SCAN TABLE SAMPLE (~1000000 rows) 1 1 NA06985 2 1 NA06986 3 1 NA06994 4 1 NA07000 5 1 NA07037 6 1 NA07051 7 1 NA07346 8 1 NA07347 ... ...  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/subprojects/",
	"title": "Subprojects",
	"tags": [],
	"description": "",
	"content": " Use of subprojects to manage large project \u0026ndash; a tutorial 1. Data This tutorial uses the same data (whole genome-sequencing data for 44 cases, with SNV and indel data in separate files, and 200 exome controls) as this tutorial, but demonstrates the uses of subproject to import and analyze data. Performance data is collected on a Mac Workstation with 2x2.26G Quad-Core Xeon processor with 8G RAM, using variant tools v1.0rc2.\n2. Create subprojects for groups of data Importing indel data in a project named indel. Because we would like to use hg19 as the primary reference genome, we first import data in hg18, and run the liftover tool to add alternative coordinates in hg19. The --flip option flips the primary and alternative reference genomes and make hg19 the primary.\nIt takes 3hr 30min to import 44 vcf files.\nmkdir SNV cd SNV vtools init SNV vtools import ../../data/hg18/*.vcf --build hg18 vtools liftover hg19 --flip  We use another project for indel data:\nIt takes 1hr 30min to import 44 indel files\ncd .. mkdir indel cd indel vtools init indel vtools import ../../data/indel/*.indel --format pileup_indel --build hg18 vtools liftover hg19 --flip  Import control data and add hg18 as alternative reference genome.\nIt takes 15min to import 200 exome vcf files\ncd .. mkdir ctrl cd ctrl vtools init ctrl vtools import ../../data/Ctrl/*.vcf --build hg19 vtools liftover hg18  3. Create a master project from subprojects We can then merge the subprojects into one large project:\nIt takes 37min to merge 18M variants from three projects, peak memory usages is 5.3G\ncd .. mkdir main cd main vtools init main --children ../indel ../SNV ../ctrl  4. Creating a subproject for each sample If you have a large number of samples, and plenty of CPU and disk space to spare, it can be a good idea to \u0026lsquo;pre-process\u0026rsquo; your samples by creating subprojects for groups of samples, because merging subprojects are generally faster than importing raw data.\nFor example, perhaps on a cluster system, you can do, for each $sample_name,\nmkdir ${sample_name}_hg18 cd ${sample_name}_hg18 vtools init $sample_name vtools import ../data/hg18/$sample_name.vcf --build hg18  Then, for 44 samples, we can merge it using commands\nThis command takes 40min to complete.\nmkdir SNV cd SNV vtools init SNV --children ../*_hg18  We can not merge this project to the main project because its primary reference genome is hg18, because we need to lift over our data from hg18 to hg19, and make hg19 the primary reference genome, we have to run\nvtools liftover hg19 --flip  5. Create a subproject with part of the variants If for a project that you are only interested in variants on chromosome 5, you can create a subproject from the main project with variants only on chromosome 5. To do that, you will need to first create a variant table with these variants:\nthis takes 13s\nvtools select variant 'chr=\u0026quot;5\u0026quot;' -t chr5  Then, you can create another project using main as the parent project:\nThis command takes 9 min to execute.\ncd .. mkdir chr5 cd chr5 vtools init chr5 --parent ../main --variants chr5  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/vtools_commands/admin/",
	"title": "admin",
	"tags": [],
	"description": "",
	"content": " Miscellaneous administrative procedures 1. Usage % vtools admin -h usage: vtools admin [-h] [--update_resource [TYPE]] [--mirror_repository dest] [--merge_samples] [--rename_samples COND [COND ...]] [--rename_table NAME NEW_NAME] [--describe_table TABLE NEW_DESCRIPTION] [--validate_build] [--validate_sex] [--save_snapshot NAME MESSAGE] [--extra_files [FILE [FILE ...]]] [--load_snapshot NAME] [--set_runtime_option OPTION [OPTION ...]] [--reset_runtime_option OPT] [--fasta2crr FASTA [FASTA ...]] [-v {0,1,2,3}] Optimize or modify projects. Currently supports merging and rename of samples optional arguments: -h, --help show this help message and exit -v {0,1,2,3}, --verbosity {0,1,2,3} Output error and warning (0), info (1), debug (2) and trace (3) information to standard output (default to 1). Download or update resources: --update_resource [TYPE] Download resources of specified type, which can be 'current' (latest version of all resources), 'all' (all resources including obsolete databases), 'existing' (only update resources that exist locally), 'hg18' or 'hg19' (all resources for reference genome hg18 or hg19), 'annotation' (all current annotation databases), 'format' (all formats), and 'snapshot' (all online snapshots). Identical resources that are available locally (under ~/.variant_tools or runtime option $local_resource) are ignored. Note that option 'all' will download all versions of annotation databases which can be slow and take a lot of disk spaces. --mirror_repository dest Mirror the main variant tools repository to a local directory. This command will check files under dest, download all missing or outdated files. Existing files that do not belong to the repository will not be removed. Merge samples: --merge_samples Merge samples with the same sample names by combining genotypes belonging to these samples. Phenotypes related to individual samples will be merged. Rename samples: --rename_samples COND [COND ...] This argument takes a condition by which samples are selected, followed by either a new sample name (assign a new name to selected samples) or an OLDNAME NEWNAME pair of patterns for which the first instance of OLDNAME in sample names will be replaced by NEWNAME. Rename/describe tables: --rename_table NAME NEW_NAME Change table NAME to a NEW_NAME. --describe_table TABLE NEW_DESCRIPTION Update description for TABLE with a NEW_DESCRIPTION. Validate reference genome: --validate_build Validate the build of project's reference genome by checking if the reference alleles of variants agree with the reference genome sequence. A reference genome will be automatically downloaded if it does not exist in the local resource directory. Validate reported sex: --validate_sex Validate the sex of samples by checking the genotypes of samples on sex chromosomes (excluding pseudo- autosomal regions). Sex of samples are determined by a phenotype named sex or gender with values 1/2, M/F or Male/Female. Inconsistency will be reported if, for example, a female sample has genotypes on chromosome Y. Save and load snapshots: --save_snapshot NAME MESSAGE Create a snapshot of the current project with NAME, which could be re-loaded using command 'vtools admin --load_snapshot'. A filename with extension .tar, .tgz or .tar.gz can be used to save the snapshot to a specific directory with compression but such snapshots are not listed by command 'vtools show snapshots'. --extra_files [FILE [FILE ...]] Additional files that will be saved along with the project and genotype databases. This could include customized format files, project-specific annotations, and results. Files outside of the current project directory are not allowed due to security considerations. --load_snapshot NAME Revert the current project to specified snapshot. All changes since the that snapshot will be lost. The NAME should be one of the project snapshots or online snapshots listed by command 'vtools show snapshots', or name of a local snapshot file (with extension .tar, .tgz or .tar.gz). Set values for some various internal options.: --set_runtime_option OPTION [OPTION ...] Set value to internal options such as the batch size for database options. The default values of these options were chosen to fit most usage patterns but tweaking them might provide better performance under certain circumstances. Please use command \u0026quot;vtools show runtime_options\u0026quot; to list all currently supported runtime options. --reset_runtime_option OPT Reset value to a runtime option to its default value. Misc utilities: --fasta2crr FASTA [FASTA ...] Convert fasta files to a crr file (a binary format for faster access) that can be used by variant tools. This is only needed if you are working with a reference genome that is not supported by variant tools. This parameter accepts a list of fastq files (URLs and .gz format are acceptable) followed by the name of the .crr file. The .crr file should be put under the project directory or the local resource directory (under directory reference) to be usable by variant tools.  2. Details The vtools admin command performs various adminstrative functions for a variant tools project.\n2.1 Download or update local resources (--update_resource) Resources, such as annotation databases, format specification, and reference genomes are downloaded automatically when they are used. However, if you prefer having all resources downloaded before using variant tools (so that you do not have to wait each time when a source is needed), you can use option --update_resource to download them in batch. The resources will be saved to your home directory under ~/.variant_tools unless you change this location using runtime option @local_resource.\nThis command by default download all current resources (e.g. most recent versions of annotation databases for latest version of reference genome). You can however using option hg18 to download resources for another reference genome, or option existing to update only resources that exists locally.\n Examples: Download resources The following command checks files under the local resource directory, ignored 112 existing files and downloaded a new version of EVS annotation database.\n% vtools init temp # needed if there is no project in the current directory % vtools admin --update_resource Scanning 112 local files: 100% [========================] 18,537,133,615 407.1M/s in 00:00:45 INFO: 2 files need to be downloaded or updated 1/2 annoDB/evs-6500.DB.gz: 100% [==========================] 109,502,699.0 1.4M/s in 00:01:17 2/2 annoDB/evs-6500.ann: 100% [=================================] 7,984.0 40.2K/s in 00:00:00  \n2.2 Rename samples (--rename_samples) Although samples in variant tools can be identified by items other than sample names (e.g. filename such as filename = \u0026quot;V1.vcf\u0026quot;), or any of the phenotypes such as aff=1), sample name is the important identifier for samples and are used ubiquitously for reports. Sample names are assigned during vtools import, using either names specified in input files, or names specified by parameter --sample_names. If a sample name is missing or mis-specified, you can use the vtools admin --rename_samples to rename samples.\nGiven a condition (COND) that selects one or more samples, this command accepts two types of inputs:\n% vtools admin --rename_samples COND name  and\n% vtools admin --rename_samples COND name1 name2  In the first option, all selected samples are renamed to name. In the second option, the first instance of name1 in sample names will be replaced by name2. The former is similar to linux command move src dest and the latter is similar to command rename pat1 pat2 files.\n Examples: Rename samples Let us first get some data and a few samples\n% vtools init admin -f % vtools admin --load_snapshot vt_testData % vtools import V*_hg38.vcf --build hg38  There are four samples\n% vtools show samples sample_name filename SAMP1 V1_hg38.vcf SAMP2 V2_hg38.vcf SAMP3 V3_hg38.vcf  The first three samples share the same name, which can lead to erroneous results during analysis (e.g. vtools associate will treat them as genotypes from the same sample). We can rename them using commands\n% vtools admin --rename_samples 'filename=\u0026quot;V1_hg38.vcf\u0026quot;' V1 % vtools admin --rename_samples 'filename=\u0026quot;V2_hg38.vcf\u0026quot;' V2 % vtools admin --rename_samples 'filename=\u0026quot;V3_hg38.vcf\u0026quot;' V3 INFO: 1 samples with names SAMP1 are renamed to V1 INFO: 1 samples with names SAMP1 are renamed to V2 INFO: 1 samples with names SAMP1 are renamed to V3  The samples now have different names:\n% vtools show samples sample_name filename V1 V1_hg38.vcf V2 V2_hg38.vcf V3 V3_hg38.vcf  If you would like to change names of multiple samples according to a pattern, you can use the second form of the command. For example, the following command changes samples V1, V2, and V3 to SAMP1, SAMP2, and SAMP3:\n% vtools admin --rename_samples 1 V SAMP INFO: Rename 1 sample with name V1 to SAMP1 INFO: Rename 1 sample with name V2 to SAMP2 INFO: Rename 1 sample with name V3 to SAMP3 % vtools show samples sample_name filename SAMP1 V1_hg38.vcf SAMP2 V2_hg38.vcf SAMP3 V3_hg38.vcf  The command might look strange to you, but the first 1 is a condition to select all samples (true), the second and third parameter changes the first incidence of V to SAMP for all matched sample names.\n\nIf you would like to prefix sample names by a string (e.g. V1 -\u0026gt; SAMP_V1), you can use commands such as vtools admin --rename_samples 1 '' SAMP_, because an empty string matches an empty string before the fist character of the sample name.\n2.3 (This function is only supported when STOREMODE is set to sqlite.) Merge samples by sample\u0026rsquo;s name (--merge_samples) Command vtools admin --merge_samples merges samples with the same names to a single sample. This command is used when genotypes of a sample are stored in several files (e.g. chromosome by chromosome, or seprate files for SNPs and Indels resulting from the Illumina pipeline) and are imported as separate samples. These samples should be merged together because otherwise number of samples in the variant tools project will not match number of physical samples, and lead to erronous results during analysis. Because this command merge samples by names, samples to be merged should be renamed to have the same names if needed.\n Examples: Merge samples with same names All our samples have different names now so we have to rename one of them in order to merge it with another sample,\n% vtools init admin -f % vtools admin --load_snapshot vt_testData % vtools import V1.vcf --build hg18 % vtools import V2.vcf % vtools import V3.vcf % vtools import CASAVA18_SNP.txt --format CASAVA18_snps % vtools admin --rename_samples 'sample_name = \u0026quot;max_gt\u0026quot;' SAMP3 INFO: 1 samples with names max_gt are renamed to SAMP3  Now we have four samples with the last two sharing the same name\n% vtools show genotypes sample_name filename num_genotypes sample_genotype_fields SAMP1 V1.vcf 989 GT SAMP2 V2.vcf 990 GT SAMP3 V3.vcf 988 GT SAMP3 CASAVA18_SNP.txt 21 GT,Q_max_gt  We can then merge the last two samples,\n% vtools admin --merge_samples INFO: 2 samples that share identical names will be merged to 1 samples Merging samples: 100% [=========================================] 2 235.8/s in 00:00:00  The genotypes are\n% vtools show genotypes sample_name filename num_genotypes sample_genotype_fields SAMP1 V1.vcf 989 GT SAMP2 V2.vcf 990 GT SAMP3 CASAVA18_SNP.txt,V3.vcf 1009 GT,Q_max_gt  Note the change of filename field of the last sample. In addition, the orignal SAMP3 sample does not have genotype info field Q_max_gt. The new SAMP3 has this field but the 988 genotypes from the orignal sample have NULL values for this field. \nSamples to be merged should not share any genotype (variant) because it is otherwise difficult to determine what genotypes to use for the merged sample.\n Examples: Fail to merge samples with shared genotypes If we rename sample SAMP2 to SAMP1,\n% vtools admin --rename_samples 1 SAMP2 SAMP1 INFO: Rename 1 sample with name SAMP2 to SAMP1  and try to merge SAMP2 to SAMP1, we will get an error message because SAMP1 and SAMP2 share many of the variants.\n% vtools admin --merge_samples INFO: 2 samples that share identical names will be merged to 1 samples Merging samples: 100% [=========================================] 2 197.5/s in 00:00:00 ERROR: Failed to merge samples with name SAMP1 because there are 1979 genotypes for 1341 unique variants.  Note that we use vtools admin --rename_samples 1 SAMP2 SAMP1 to rename sample using the second option of the vtools admin --rename_samples command. It is easier to use than vtools admin --rename_samples 'sample_name = \u0026quot;SAMP2\u0026quot;' SAMP1, but has the risk of renaming other tables containing SAMP2 (e.g. SAMP21) and should be used with caution. \n2.4 Rename and modify descriptions of variant tables (--rename_table and --describe_table) A lot of variant tables can be generated during the analysis and it can be difficult to remember what types of variants are stored in each table. variant tools allows you to use arbitrary characters in table names and describe tables with messages when they are created, rename tables and modify their descriptions after they are created. The latter two operations are performed using commands vtools admin --rename-table OLDNAME NEWNAME and vtools admin --describe_table NAME NEW_DESCRIPTION. The usages of these two commands are straightforward.\n Examples: Change name and comment of variant tables Let us get a sample project and create a few variant tables\nvtools init testProj vtools import V*_hg38.vcf --build hg38 vtools select variant -t 'all variant' vtools select variant --samples 'filename = \u0026quot;V1_hg38.vcf\u0026quot;' -t fromV1 'variants from v1'  The project has three tables,\n% vtools show tables table #variants date message all variant 2,051 May29 fromV1 1,269 May29 variants from v1 variant 2,051 May29 Master variant table  You can rename the all variant to all_variant\n% vtools admin --rename_table 'all variant' all_variant INFO: Table all variant is renamed to all_variant  and give it a short description,\n% vtools admin --describe_table 'all_variant' 'A replicate of the master variant table' INFO: Description of table all_variant is updated  The table now has a new name and a description, but its creation date and command are not changed.\n% vtools show table all_variant Name: all_variant Description: A replicate of the master variant table Creation date: May29 Command: select variant -t \u0026quot;all variant\u0026quot; Fields: variant_id, chr Number of variants: 2051  \n2.5 Validate build of project\u0026rsquo;s reference genome (--validate_build) Sometimes when you get a bunch of data, look everywhere in the folder and emails, and cannot find any information regarding the reference genome used to call the variants. In this case, you can import your data using the most likely build of reference genome (hg19), and use command vtools admin --validate_build to check if you have made the correct assumption.\n Examples: Validate the reference genome used in a project Let us create a project and get some test data\n% vtools init test % vtools admin --load_snapshot vt_testData Downloading snapshot vt_testData.tar.gz from online INFO: Snapshot vt_testData has been loaded  We would like to import data from V1.vcf, V2.vcf, and V3.vcf but do not know the correct reference genome to use, so we use hg19\n% vtools import V*.vcf --build hg19 INFO: Importing variants from V1.vcf (1/3) V1.vcf: 100% [======================================] 1,000 19.3K/s in 00:00:00 INFO: 989 new variants (989 SNVs) from 1,000 lines are imported. INFO: Importing variants from V2.vcf (2/3) V2.vcf: 100% [======================================] 1,000 27.6K/s in 00:00:00 INFO: 352 new variants (352 SNVs) from 995 lines are imported. INFO: Importing variants from V3.vcf (3/3) V3.vcf: 100% [======================================] 1,000 27.8K/s in 00:00:00 INFO: 270 new variants (270 SNVs) from 1,000 lines are imported. Importing genotypes: 100% [==========================] 2,995 1.5K/s in 00:00:02 Copying genotype: 100% [=================================] 3 8.1K/s in 00:00:00 INFO: 1,611 new variants (1,611 SNVs) from 2,995 lines (3 samples) are imported.  Let us see if these 1,611 variants have the correct reference alleles at the specified locations of the reference genome,\n% vtools admin --validate_build Validate reference alleles: 100% [=============] 1,611/1,238 14.8K/s in 00:00:00 INFO: 1611 non-insertion variants are checked. 1238 mismatch variants found.  As you can see, most of the variants do not have correct reference genomes. Now if we import the data using hg18, the validation process completes successfully and we are confident that we are using the correct reference genome this time.\n% vtools init test -f % vtools import V*.vcf --build hg18 % vtools admin --validate_build Validate reference alleles: 100% [==================] 1,611 60.1K/s in 00:00:00 INFO: 1611 non-insertion variants are checked. 0 mismatch variants found.  \n2.6 Validate sex of samples (--validate_sex) If your data contain genotypes on sex chromosomes and have sex information, you can use command vtools admin --validate_sex to check if the reported sex information match sample genotypes. To use this command, your project should have a phenotype with name sex or gender that contains sex of samples (coded in 1/2, M/F, or Male/Female, missing values are not allowed). This command goes through all samples, and identify inconsistencies by\n For males, check if there are homozygote alternative alleles on non-pseudo-autosomal regions of chromosome X, For females, check if there are any genotype on chromosome Y.  Variant calling pipelines are unlikely to call variants on sex chromosomes correctly if the variants are called blindly (without knowing chromosome name and sex of samples), so it is common that your data appear to have genotypes that are inconsistent with the sex of samples.\n 2.7 Save and load snapshots of a project (--save_snapshot and --load_snapshot) You can save snapshots of the current project and revert to them later. This allows you to recover a project when it is damaged by incorrect operations or system failure, and more importantly, allows you to explore different processing pipelines with saved baseline stages. A snapshot is also a good way to carry a project around.\nThere are several types of snapshots:\n Online snapshots that can be downloaded automatically using command vtools admin --load_snapshot. The names of these snapshots starts with vt_. Project-specific snapshots that are saved in the project\u0026rsquo;s cache directory. These snapshots are saved and loaded by snapshot name and are listed by command vtools show snapshots. Local snapshots that are saved in arbitrarily specified directory, with extension .tar or .tar.gz (compressed). These snapshots are not listed by command vtools show snapshots.  You should in general use project-specific snapshots, unless you plan to carry the snapshots around. In that case you should use the compressed snapshots although it can take some time to compress a large project.\nAll changes to the current project will be lost if you revert to a previous snapshot.\n  Examples: Save snapshots of a project  By default, a snapshot can be created with a name, and saved without compression in the cache directory of the current project:\n% vtools admin --save_snapshot stage1 \u0026quot;after importing date\u0026quot; INFO: Snapshot stage1 has been saved  A message is required to describe each snapshot so that you can know later on what this snapshot is about:\n% vtools show snapshots stage1 after importing date (122.0KB, created: Jul15 14:35:14) vt_qc snapshot for QC tutorial, exome data of 1000 genomes project with simulated GD and GQ scores (2.0GB, online snapshot) vt_ExomeAssociation Data with ~26k variants from chr1 and 2, ~3k samples, 3 phenotypes, ready for association testing. (446.0MB, online snapshot) vt_quickStartGuide A simple project with variants from the CEU and JPT pilot data of the 1000 genome project (148.0KB, online snapshot) vt_illuminaTestData Test data with 1M paired reads (49.0MB, online snapshot) vt_simple A simple project with variants imported from three vcf files (41.0KB, online snapshot) vt_testData An empty project with some test datasets (63.0KB, online snapshot)  If for some reason you would like to revert to a particular snapshot, you can do\n% vtools admin --load_snapshot stage1 INFO: Snapshot stage1 has been loaded  If the disk that holds your project does not have enough free diskspace to hold these snapshots, you can save snapshots to another disk using filenames with extension .tar, .tgz, or .tar.gz. In the latter two cases, the snapshot will be compressed.\n% vtools admin --save_snapshot stage1.tgz \u0026quot;after importing phenotypes\u0026quot; INFO: Snapshot stage1.tgz has been saved  This snapshot will not be displayed by command vtools show snapshots because it is managed by the current project\n% vtools show snapshots -l 2 stage1 after importing date (122.0KB, created: Jul15 14:35:14) vt_qc snapshot for QC tutorial, exome data of 1000 genomes project with simulated GD and GQ scores (2.0GB, online snapshot)  but it can be viewed using command vtools show snapshot\n% vtools show snapshot stage1.tgz Name: stage1.tgz Source: local Size: 40273 (40.0KB) Creation date: Jul15 14:36:37 Description: after importing phenotypes  You can revert to this snapshot using command\n% vtools admin --load_snapshot stage1.tgz INFO: Snapshot stage1.tgz has been loaded  A snapshot only contains the project, and the genotype database. It does not save log file, annotation databases, and various output and results (e.g. database created by command vtools associate. You should use --extra_files option to include other files in a snapshot.\n% vtools admin --save_snapshot stage1.tgz 'a snapshot with extra files' \\ --extra_files test.log cache/*  Directories cannot be directly added to snapshots, since recursively adding files under a directory may lead to unwanted behaviors (e.g., when symbolic links are involved). However you may use wildcard names (cache/*) to include files in a directory.\n\n2.8 Set and reset runtime options (--set_runtime_option and --reset_runtime_option) Setting runtime options, for example,\n% vtools admin --set_runtime_option 'logfile_verbosity=0'  can stop the project from writing debug information to a file.\nA list of runtime options and their descriptions could be obtained by\n% vtools show runtime_options associate_num_of_readers None (default) Use specified number of processes to read genotype data for association tests. The default value is the minimum of value of option --jobs and 8. Note that a large number of reading processes might lead to degraded performance or errors due to disk access limits. association_timeout None (default) Cancel associate test and return special values when a test lasts more than specified time (in seconds). The default value of this option is None, which stands for no time limit. check_update True (default) Automatically check update of variant tools and resources. import_num_of_readers 2 (default) variant tools by default uses two processes to read from input files during multi-process importing (--jobs \u0026gt; 0). You can want to set it to zero if a single process provides better performance or reduces disk traffic. local_resource ~/.variant_tools (default) A directory to store variant tools related resources such as reference genomes and annotation database. Files under this directory is usually downloaded automatically upon use, but can also be synchronized directly from http://vtools.houstonbioinformatics.org/. logfile_verbosity 2 (default) Verbosity level of the log file, can be 0 for warning and error only, 1 for general information, or 2 for general and debug information. search_path .;http://vtools.houstonbioinformatics.org/ (default) A ;-separated list of directories and URLs that are used to locate annotation database (.ann, .DB), file format (.fmt) and other files. Reset this option allows alternative local or online storage of such files. variant tools will append trailing directories such as annoDB for certain types of data so only root directories should be listed in this search path. sqlite_pragma (default) pragmas for sqlite database that can be used to optimize the performance of database operations. temp_dir None (default) Use the specified temporary directory to store temporary files to improve performance (use separate disks for project and temp files), or avoid problems due to insufficient disk space. treat_missing_as_wildtype False (default) Treat missing values as wildtype alleles for association tests. This option is used when samples are called individuals or in batch so genotypes for some samples are ignored and treated as missing if they consist of all wildtype alleles. This option should be used with caution because it convert real missing genotypes and genotypes removed due to, for example low quality score, to wildtype genotypes. verbosity 1 (default) Default verbosity level (to the standard output) of the project. This option can be set during vtools init where the verbosity level set by option --verbosity will be set as the project default.  In particular,\n temp_dir: Project temporary directory. By default a random temporary directory will be created each time when a project is opened. If  the partition that hosts the temporary directory is not large enough, the partition is slow, or if you would like to move the temporary directory to a separate physical disk to improve I/O performance,   you can set a different location for this directory. Note that this directory will be removed after the project is closed.\n sqlite_pragma: Sqlite pragma can have a significant impact on the performance of sqlite database operations. Variant tools strives to provide optimal pragma to achieve good performance (for example, synchronous=OFF to disable disk write check), but you can define your own set of pragmas that fit your environment. For example, if your system has plenty of RAM, you can use\n% vtools admin \u0026ndash;set_runtime_option \u0026lsquo;sqlite_pragma=synchronous=OFF,journal_mode=MEMORY\u0026rsquo;\n  to use in-memory journal.\nThe MEMORY journaling mode saves disk I/O but at the expense of database safety and integrity. If the application using SQLite crashes in the middle of a transaction when the MEMORY journaling mode is set, then the database file will very likely go corrupt [][1]. You can enable it for data import operations such as vtools import and vtools update --from_file and set it to default (journal_mode=DELETE) afterwards.\n The pragmas are usually applied to all databases (e.g. project, genotype and annotation databases) but you can limit the pragma to certain databases if you prefix it with database name (e.g. _geno.snchronous=OFF). This, however, needs an understanding of the databases involved in a command, and is generally not recommended. Please read about supported pragma statements here.\n treat_missing_as_wildtype: If your sample variants are called sample by sample or in batch, some variants might exists for certain samples but not for others, because they have all wildtype alleles for some samples and are not recorded. For example, if you are analyzing your samples with affected individuals, and use the 1000 genomes data as controls, novel variants in your data might not have corresponding genotypes in the 1000 genomes data, leading to complete missing genotypes for controls. The variants will likely to be discarded due to excessive missing data and will not be selected.  In this case, it is advised that you set runtime option treat_missing_as_wildtype to 1 before association analysis so that all missing and not-imported gentoypes are considered as wildtype alleles. This is dangerous because it might introduce a large number of non-existing (wildtype) alleles, and effectively change all NA genotypes to wildtype alleles from your input data. The results from such analysis should therefore be compared with results with this optoin turned off, and be examined closely for validity. If you would like to reset a runtime option, simply run\n% vtools admin --reset_runtime_option sqlite_pragma  to reset an option to its default values.\n2.9 Convert fasta files of non-human reference genomes to .crr files Variant tools supports human reference genomes natively. It can also work with other reference genomes in .crr format, which is a binary format that allows efficient random access to the reference genome. If you have a reference genome in fasta format, you will need to convert it to .crr format using command vtools admin --fasta2crr.\n Examples: Create a .crr file for a mouse genome\n% vtools admin --fasta2crr \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr1.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr2.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr3.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr4.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr5.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr6.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr7.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr8.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr9.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr10.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr11.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr12.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr13.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr14.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr15.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr16.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr17.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr18.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chr19.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chrX.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chrY.fa.gz \\ ftp://hgdownload.cse.ucsc.edu/goldenPath/mm10/chromosomes/chrM.fa.gz \\ mm10.crr  \n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/tutorials/tutorialacm/",
	"title": "ACM-BCB tutorial",
	"tags": [],
	"description": "",
	"content": " Tutorial (ACM-BCB2014): Integrated analysis of next-gen sequencing data using variant tools This tutorial explains the concepts of variant tools and demonstrates, through examples, how to use variant tools to import, select, and annotate genetic variants. You will need to have variant tools installed (Linux or Mac OSX) to follow this tutorial. Please also download sample data from here .\n1. Getting help (--help, `vtools show) Getting details of commands\n$ vtools -h $ vtools init -h  The [variant tools website][2] has detailed explanation and examples for all commands, utilities and pipelines.\n Getting details of file formats, fields, pipelines, association tests, file tracks, runtime options, annotation databases, snapshots, pipelines and simulation models.\nGetting a list of all supported file formats:\n$ vtools show formats -v0 CASAVA18_snps CASAVA18_indels plink rsname ANNOVAR_output ANNOVAR pileup_indel ANNOVAR_exonic_variant_function ANNOVAR_variant_function twoalleles map polyphen2 basic vcf CGA csv tped  and details of a particular format:\n$ vtools show format basic A basic variant import/export format that import variants with four tab- delimited columns (chr, pos, ref, alt), and export variants, optional variant info fields and genotypes. Columns: 1 chromosome 2 variant position, set --pos_adj to -1 to export variants in 0-based positions. 3 reference allele 4 alternative allele 5 Output variant info fields as one column 6 genotype in numeric style Formatters are provided for fields: gt variant: chr Chromosome pos 1-based position, set --pos_adj to 1 if input position is 0 based. ref Reference allele, '-' for insertion. alt Alternative allele, '-' for deletion. Format parameters: chr_col Column index for the chromosome field (default: 1) pos_col Column index for the position field (default: 2) ref_col Column index for the reference field (default: 3) alt_col Column index for the alternative field (default: 4) pos_adj Set to 1 to import variants with 0-based positions, or to -1 to export variants in 0-based positions. (default: 0) fields Fields to output, simple arithmetics are allowed (e.g. pos+1) but aggregation functions are not supported. (default: )  2. Create a project (init) Create an empty project\n$ vtools init tutorial INFO: variant tools 2.4.0 : Copyright (c) 2011 - 2014 Bo Peng INFO: San Lucas FA, Wang G, Scheet P, Peng B (2012) Bioinformatics 28(3):421-422 INFO: Please visit http://varianttools.sourceforge.net for more information. INFO: Creating a new project tutorial  You cannot create a project in a folder with another project\n$ vtools init tutorial ERROR: A project can only be created in a directory without another project.  but you can use option --force to override this\n$ vtools init tutorial -f INFO: variant tools 2.4.0 : Copyright (c) 2011 - 2014 Bo Peng INFO: San Lucas FA, Wang G, Scheet P, Peng B (2012) Bioinformatics 28(3):421-422 INFO: Please visit http://varianttools.sourceforge.net for more information. INFO: Creating a new project tutorial  3. Load data (`vtools import) Let us have a look at the data\n$ gzcat CEU.vcf.gz | head -10 ##fileformat=VCFv4.0 ##INFO=\u0026lt;ID=DP,Number=1,Type=Integer,Description=\u0026quot;Total Depth\u0026quot;\u0026gt; ##INFO=\u0026lt;ID=HM2,Number=0,Type=Flag,Description=\u0026quot;HapMap2 membership\u0026quot;\u0026gt; ##INFO=\u0026lt;ID=HM3,Number=0,Type=Flag,Description=\u0026quot;HapMap3 membership\u0026quot;\u0026gt; ##INFO=\u0026lt;ID=AA,Number=1,Type=String,Description=\u0026quot;Ancestral Allele, ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/technical/reference/ancestral_alignments/README\u0026quot;\u0026gt; ##reference=human_b36_both.fasta ##FORMAT=\u0026lt;ID=GT,Number=1,Type=String,Description=\u0026quot;Genotype\u0026quot;\u0026gt; ##FORMAT=\u0026lt;ID=DP,Number=1,Type=Integer,Description=\u0026quot;Read Depth\u0026quot;\u0026gt; ##FORMAT=\u0026lt;ID=CB,Number=1,Type=String,Description=\u0026quot;Called by S(Sanger), M(UMich), B(BI)\u0026quot;\u0026gt; ##rsIDs=dbSNP b129 mapped to NCBI 36.3, August 10, 2009 bpeng1@BCBMC02MG1WJF6T:~/temp$ gzcat CEU.vcf.gz | head -14 ##fileformat=VCFv4.0 ##INFO=\u0026lt;ID=DP,Number=1,Type=Integer,Description=\u0026quot;Total Depth\u0026quot;\u0026gt; ##INFO=\u0026lt;ID=HM2,Number=0,Type=Flag,Description=\u0026quot;HapMap2 membership\u0026quot;\u0026gt; ##INFO=\u0026lt;ID=HM3,Number=0,Type=Flag,Description=\u0026quot;HapMap3 membership\u0026quot;\u0026gt; ##INFO=\u0026lt;ID=AA,Number=1,Type=String,Description=\u0026quot;Ancestral Allele, ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/technical/reference/ancestral_alignments/README\u0026quot;\u0026gt; ##reference=human_b36_both.fasta ##FORMAT=\u0026lt;ID=GT,Number=1,Type=String,Description=\u0026quot;Genotype\u0026quot;\u0026gt; ##FORMAT=\u0026lt;ID=DP,Number=1,Type=Integer,Description=\u0026quot;Read Depth\u0026quot;\u0026gt; ##FORMAT=\u0026lt;ID=CB,Number=1,Type=String,Description=\u0026quot;Called by S(Sanger), M(UMich), B(BI)\u0026quot;\u0026gt; ##rsIDs=dbSNP b129 mapped to NCBI 36.3, August 10, 2009 ##INFO=\u0026lt;ID=AC,Number=.,Type=Integer,Description=\u0026quot;Allele count in genotypes\u0026quot;\u0026gt; ##INFO=\u0026lt;ID=AN,Number=1,Type=Integer,Description=\u0026quot;Total number of alleles in called genotypes\u0026quot;\u0026gt; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT NA06985 NA06986 NA06994 NA07000 NA07037 NA07051 NA07346 NA07347 NA07357 NA10847 NA10851 NA11829 NA11830 NA11831 NA11832 NA11840 NA11881 NA11894 NA11918 NA11919 NA11920 NA11931 NA11992 NA11993 NA11994 NA11995 NA12003 NA12004 NA12005 NA12006 NA12043 NA12044 NA12045 NA12144 NA12154 NA12155 NA12156 NA12234 NA12249 NA12287 NA12414 NA12489 NA12716 NA12717 NA12749 NA12750 NA12751 NA12760 NA12761 NA12762 NA12763 NA12776 NA12812 NA12813 NA12814 NA12815 NA12828 NA12872 NA12873 NA12874 1 533 . G C . PASS AA=.;AC=6;AN=120;DP=423 GT:DP:CB 0|0:6:SMB 0|0:14:SMB 0|0:4:SMB 0|0:3:SMB 0|0:7:SMB 0|0:4:SMB 1|0:6:MB 0|0:3:SMB 0|0:13:SMB 0|0:1:SMB 0|0:14:SMB 0|0:10:SMB 0|0:6:SB 0|0:2:SMB 0|0:6:SMB 0|0:4:SMB 0|0:2:SMB 0|0:15:SMB 0|0:2:SMB 0|0:1:SMB 0|0:26:SMB 0|0:6:SMB 0|1:14:MB 0|0:5:SMB 0|0:3:SMB 0|0:20:SMB 0|0:3:SMB 0|0:2:SMB 0|0:4:SMB 0|0:12:SMB 0|0:1:SMB 0|0:7:SMB 0|0:2:SMB 0|0:25:SMB 0|0:9:SMB 0|1:1:MB 0|0:9:SMB 0|0:1:SMB 0|0:6:SMB 0|0:12:SMB 0|0:7:SMB 0|0:18:SMB 0|0:2:SMB 0|0:2:SM 0|0:38:SMB 0|0:3:SM 0|0:3:SMB 0|0:5:SMB 0|0:5:SMB 0|0:3:SMB 0|0:0:MB 0|0:5:SMB 0|0:7:SMB 0|0:0:SMB 0|0:6:SMB 1|0:5:SMB 0|0:4:MB 0|0:5:SMB 1|0:5:MB 0|1:9:SMB  If the compressed .vcf file is indexed (with .tbi file), you can use vtools to show its information\n$ vtools show track CEU.vcf.gz Version VCF v4.0 Number of fields: 69 Header: (excluding INFO and FORMAT lines) ##reference=human_b36_both.fasta ##rsIDs=dbSNP b129 mapped to NCBI 36.3, August 10, 2009 Available fields (with type VARCHAR if unspecified or all=1): 0 (INTEGER) 1 if matched chr (1, chrom) chromosome pos (2, INTEGER) position (1-based) name (3) name of variant ref (4) reference allele alt (5) alternative alleles qual (6) qual filter (7) filter info (8, default) variant info fields info.DP (INTEGER) Total Depth info.HM2 (INTEGER, flag) HapMap2 membership info.HM3 (INTEGER, flag) HapMap3 membership info.AA Ancestral Allele, ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/technical/reference/ancestral_alignments/README info.AC (INTEGER) Allele count in genotypes info.AN (INTEGER) Total number of alleles in called genotypes format (9) genotype format NA06985 (10) genotype for sample NA06985 NA06985.GT Genotype for sample NA06985 NA06985.DP (INTEGER) Read Depth for sample NA06985 NA06985.CB Called by S(Sanger), M(UMich), B(BI) for sample NA06985 ...  Looking for\n reference genome used fields that can be imported  Import data with one variant information field AA,\n$ vtools import CEU.vcf.gz --var_info AA --build hg18 INFO: Importing variants from CEU.vcf.gz (1/1) CEU.vcf.gz: 100% [=================================================] 300 16.8K/s in 00:00:00 INFO: 288 new variants (288 SNVs) from 300 lines are imported. Importing genotypes: 100% [======================================] 18,000 9.0K/s in 00:00:02 Copying samples: 100% [==============================================] 79 78.9/s in 00:00:01  Show the status of the project\n$ vtools show Project name: tutorial Created on: Fri Sep 19 06:09:40 2014 Primary reference genome: hg18 Secondary reference genome: Runtime options: verbosity=1 Variant tables: variant Annotation databases:  available variant tables\n$ vtools show tables table #variants date message variant 288 Sep19 Master variant table  details of a variant table\n$ vtools show table variant Name: variant Description: Master variant table Creation date: Sep19 Command: Fields: variant_id, bin, chr, pos, ref, alt, AA Number of variants: 288  all genotypes\n$ vtools show genotypes -l 10 sample_name filename num_genotypes sample_genotype_fields NA06985 CEU.vcf.gz 287 GT NA06986 CEU.vcf.gz 287 GT NA06994 CEU.vcf.gz 287 GT NA07000 CEU.vcf.gz 287 GT NA07037 CEU.vcf.gz 287 GT NA07051 CEU.vcf.gz 287 GT NA07346 CEU.vcf.gz 288 GT NA07347 CEU.vcf.gz 287 GT NA07357 CEU.vcf.gz 287 GT NA10847 CEU.vcf.gz 287 GT  Information fields for each variant\n$ vtools show fields variant.chr (char) Chromosome name (VARCHAR) variant.pos (int) Position (INT, 1-based) variant.ref (char) Reference allele (VARCHAR, - for missing allele of an insertion) variant.alt (char) Alternative allele (VARCHAR, - for missing allele of an deletion) variant.AA (char)  Output variants in a specified variant table with specified info fields\n$ vtools output variant chr pos ref alt AA -l 10 1 533 G C . 1 41342 T A . 1 41791 G A . 1 44449 T C C 1 44539 C T T 1 44571 G C g 1 45162 C T c 1 52066 T C C 1 53534 G A G 1 75891 T C .  4. Sample statistics (`vtools update) Command update adds more variant info fields to the project.\n4.1 import additional information from the source files $ vtools update variant --from_file CEU.vcf.gz --var_info DP INFO: Using primary reference genome hg18 of the project. Getting existing variants: 100% [================================================] 288 197.1K/s in 00:00:00 INFO: Updating variants from CEU.vcf.gz (1/1) CEU.vcf.gz: 100% [=================================================================] 300 9.4K/s in 00:00:00 INFO: Field DP of 288 variants are updated  A new field DP is added,\n$ vtools show fields variant.chr (char) Chromosome name (VARCHAR) variant.pos (int) Position (INT, 1-based) variant.ref (char) Reference allele (VARCHAR, - for missing allele of an insertion) variant.alt (char) Alternative allele (VARCHAR, - for missing allele of an deletion) variant.AA (char) variant.DP (int) $ vtools output variant chr pos ref alt AA DP -l 10 1 533 G C . 423 1 41342 T A . 188 1 41791 G A . 192 1 44449 T C C 166 1 44539 C T T 131 1 44571 G C g 135 1 45162 C T c 166 1 52066 T C C 159 1 53534 G A G 243 1 75891 T C . 182  4.2 Add sample statistics as variant info fields Count the number of alternative alleles (not genotypes), homozygotes, heterozygotes, and calculate minior allele frequency for each variant\n$ vtools update variant --from_stat 'num=#(alt)' 'hom=#(hom)' 'het=#(het)' 'maf=maf()' Counting variants: 100% [==================================] 60 1.1K/s in 00:00:00 INFO: Adding variant info field num with type INT INFO: Adding variant info field hom with type INT INFO: Adding variant info field het with type INT INFO: Adding variant info field maf with type FLOAT Updating variant: 100% [=================================] 288 65.0K/s in 00:00:00 INFO: 288 records are updated $ vtools output variant chr pos ref alt num hom het maf -l 10 1 533 G C 6 0 6 0.05 1 41342 T A 29 3 23 0.241666666667 1 41791 G A 5 0 5 0.0416666666667 1 44449 T C 2 0 2 0.0166666666667 1 44539 C T 2 0 2 0.0166666666667 1 44571 G C 7 0 7 0.0583333333333 1 45162 C T 20 4 12 0.166666666667 1 52066 T C 18 1 16 0.15 1 53534 G A 18 0 18 0.15  We can also calculate sample statistics for a subset of samples (e.g. in cases and controls)\n$ vtools show samples -l 10 sample_name filename NA06985 CEU.vcf.gz NA06986 CEU.vcf.gz NA06994 CEU.vcf.gz NA07000 CEU.vcf.gz NA07037 CEU.vcf.gz NA07051 CEU.vcf.gz NA07346 CEU.vcf.gz NA07347 CEU.vcf.gz NA07357 CEU.vcf.gz NA10847 CEU.vcf.gz (50 records omitted) $ vtools update variant --from_stat 'num12=#(alt)' 'hom12=#(hom)' 'het12=#(het)' \\ 'maf12=maf()' --samples \u0026quot;sample_name like 'NA12%'\u0026quot; INFO: 34 samples are selected Counting variants: 100% [==================================] 34 1.9K/s in 00:00:00 INFO: Adding variant info field num12 with type INT INFO: Adding variant info field hom12 with type INT INFO: Adding variant info field het12 with type INT INFO: Adding variant info field maf12 with type FLOAT Updating variant: 100% [=================================] 288 45.9K/s in 00:00:00 INFO: 288 records are updated $ vtools output variant chr pos num maf num12 maf12 -l 10 1 533 6 0.05 4 0.0588235294118 1 41342 29 0.241666666667 16 0.235294117647 1 41791 5 0.0416666666667 2 0.0294117647059 1 44449 2 0.0166666666667 2 0.0294117647059 1 44539 2 0.0166666666667 2 0.0294117647059 1 44571 7 0.0583333333333 7 0.102941176471 1 45162 20 0.166666666667 11 0.161764705882 1 52066 18 0.15 14 0.205882352941 1 53534 18 0.15 8 0.117647058824 1 75891 11 0.0916666666667 9 0.132352941176 $ vtools show fields variant.chr (char) Chromosome name (VARCHAR) variant.pos (int) Position (INT, 1-based) variant.ref (char) Reference allele (VARCHAR, - for missing allele of an insertion) variant.alt (char) Alternative allele (VARCHAR, - for missing allele of an deletion) variant.AA (char) variant.DP (int) variant.num (int) Created from stat \u0026quot;#(alt)\u0026quot; with type INT on Sep19 variant.hom (int) Created from stat \u0026quot;#(hom)\u0026quot; with type INT on Sep19 variant.het (int) Created from stat \u0026quot;#(het)\u0026quot; with type INT on Sep19 variant.maf (float) Created from stat \u0026quot;maf()\u0026quot; with type FLOAT on Sep19 variant.num12 (int) Created from stat \u0026quot;#(alt)\u0026quot; for samples [\u0026quot;sample_name like 'NA12%'\u0026quot;]with type INT on Sep19 variant.hom12 (int) Created from stat \u0026quot;#(hom)\u0026quot; for samples [\u0026quot;sample_name like 'NA12%'\u0026quot;]with type INT on Sep19 variant.het12 (int) Created from stat \u0026quot;#(het)\u0026quot; for samples [\u0026quot;sample_name like 'NA12%'\u0026quot;]with type INT on Sep19 variant.maf12 (float) Created from stat \u0026quot;maf()\u0026quot; for samples [\u0026quot;sample_name like 'NA12%'\u0026quot;]with type FLOAT on Sep19  5. Phenotypes (`vtools phenotype) $ vtools show phenotypes -l 10 sample_name NA06985 NA06986 NA06994 NA07000 NA07037 NA07051 NA07346 NA07347 NA07357 NA10847 (50 records omitted) $ head -5 phenotype.txt sample_name aff sex BMI NA06985 2 F 19.64 NA06986 1 M None NA06994 1 F 19.49 NA07000 2 F 21.52 $ vtools phenotype --from_file phenotype.txt INFO: Adding phenotype aff of type INT INFO: Adding phenotype sex of type VARCHAR(1) INFO: Adding phenotype BMI of type FLOAT WARNING: Value \u0026quot;None\u0026quot; is treated as missing in phenotype BMI WARNING: 1 missing values are identified for phenotype BMI $ vtools show phenotypes -l 10 sample_name aff sex BMI NA06985 2 F 19.64 NA06986 1 M . NA06994 1 F 19.49 NA07000 2 F 21.52 NA07037 2 F 23.05 NA07051 1 F 21.01 NA07346 1 F 18.93 NA07347 2 M 19.2 NA07357 2 M 20.61 NA10847 2 M 14.6 (50 records omitted)  Phenotypes can be used to select samples.\n $ vtools show samples -l 10 sample_name filename aff sex BMI NA06985 CEU.vcf.gz 2 F 19.64 NA06986 CEU.vcf.gz 1 M . NA06994 CEU.vcf.gz 1 F 19.49 NA07000 CEU.vcf.gz 2 F 21.52 NA07037 CEU.vcf.gz 2 F 23.05 NA07051 CEU.vcf.gz 1 F 21.01 NA07346 CEU.vcf.gz 1 F 18.93 NA07347 CEU.vcf.gz 2 M 19.2 NA07357 CEU.vcf.gz 2 M 20.61 NA10847 CEU.vcf.gz 2 M 14.6 (50 records omitted) $ vtools update variant --from_stat 'nCase=#(alt)' --samples 'aff=2' INFO: 35 samples are selected Counting variants: 100% [=============================] 35 1.4K/s in 00:00:00 INFO: Adding variant info field nCase with type INT Updating variant: 100% [============================] 288 72.3K/s in 00:00:00 INFO: 288 records are updated $ vtools update variant --from_stat 'nCtrl=#(alt)' --samples 'aff=1' INFO: 25 samples are selected Counting variants: 100% [=============================] 25 2.0K/s in 00:00:00 INFO: Adding variant info field nCtrl with type INT Updating variant: 100% [============================] 288 78.5K/s in 00:00:00 INFO: 288 records are updated  6. Variant Selection (`vtools select) The master variant table variant contains all variants in the project, we can select subsets of variants from this table and create multiple variant tables.\n$ vtools show fields variant.chr (char) Chromosome name (VARCHAR) variant.pos (int) Position (INT, 1-based) variant.ref (char) Reference allele (VARCHAR, - for missing allele of an insertion) variant.alt (char) Alternative allele (VARCHAR, - for missing allele of an deletion) variant.AA (char) variant.DP (int) variant.num (int) Created from stat \u0026quot;#(alt)\u0026quot; with type INT on Sep19 variant.hom (int) Created from stat \u0026quot;#(hom)\u0026quot; with type INT on Sep19 variant.het (int) Created from stat \u0026quot;#(het)\u0026quot; with type INT on Sep19 variant.maf (float) Created from stat \u0026quot;maf()\u0026quot; with type FLOAT on Sep19 variant.num12 (int) Created from stat \u0026quot;#(alt)\u0026quot; for samples [\u0026quot;sample_name like 'NA12%'\u0026quot;]with type INT on Sep19 variant.hom12 (int) Created from stat \u0026quot;#(hom)\u0026quot; for samples [\u0026quot;sample_name like 'NA12%'\u0026quot;]with type INT on Sep19 variant.het12 (int) Created from stat \u0026quot;#(het)\u0026quot; for samples [\u0026quot;sample_name like 'NA12%'\u0026quot;]with type INT on Sep19 variant.maf12 (float) Created from stat \u0026quot;maf()\u0026quot; for samples [\u0026quot;sample_name like 'NA12%'\u0026quot;]with type FLOAT on Sep19 variant.nCase (int) Created from stat \u0026quot;#(alt)\u0026quot; for samples ['aff=2']with type INT on Sep19 variant.nCtrl (int) Created from stat \u0026quot;#(alt)\u0026quot; for samples ['aff=1']with type INT on Sep19  Select variant and output to another table (option --to_table)\n$ vtools select variant 'maf \u0026gt; 0.1' -t common 'Variants with MAF \u0026gt; 0.1' Running: 0 0.0/s in 00:00:00 INFO: 89 variants selected. $ vtools show tables table #variants date message common 89 Sep19 Variants with MAF \u0026gt; 0.1 variant 288 Sep19 Master variant table $ vtools output common chr pos ref alt AA maf -l 10 1 41342 T A . 0.241666666667 1 45162 C T c 0.166666666667 1 52066 T C C 0.15 1 53534 G A G 0.15 1 98173 T C . 0.483333333333 1 225792 G A . 0.116666666667 1 742429 G A g 0.141666666667 1 742584 A G a 0.141666666667 1 743268 C A a 0.116666666667 1 743288 T C t 0.308333333333  Count the number of variants\n$ vtools select common 'hom \u0026gt; 2' --count Counting variants: 0 0.0/s in 00:00:00 45  or output them,\n$ vtools select common 'hom \u0026gt; 2' -o chr pos hom het maf -l 10 1 41342 3 23 0.241666666667 1 45162 4 12 0.166666666667 1 98173 10 38 0.483333333333 1 742429 43 17 0.141666666667 1 742584 43 17 0.141666666667 1 743268 46 14 0.116666666667 1 743288 29 25 0.308333333333 1 743712 5 25 0.291666666667 1 744197 44 16 0.133333333333 1 744366 43 17 0.141666666667  You can also select variants from specified samples\n$ vtools select common --samples \u0026quot;sample_name = 'NA12776'\u0026quot; -t common_in_12776 INFO: 1 samples are selected by condition: sample_name = 'NA12776' Running: 0 0.0/s in 00:00:00 INFO: 88 variants selected.  7. Annotation databases (`vtools use) $ vtools show annotations -v0 -l 10 CancerGeneCensus-20130711 CancerGeneCensus CosmicCodingMuts-v67_20131024 CosmicCodingMuts CosmicMutantExport-v67_241013 CosmicMutantExport CosmicNonCodingVariants-v67_241013 CosmicNonCodingVariants DGV-hg18_20130723 DGV-hg19_20130723 (77 records omitted)  7.1 Genes $ vtools use refGene INFO: Downloading annotation database from annoDB/refGene.ann ERROR: Annotation database cannot be used because it is based on a reference genome that is different from the one used by the project. Please use a version of annotation databse for the project (vtools show annotations), or liftover the existing project (vtoos liftover) to make it compatible with the annotation database. $ vtools liftover hg19 INFO: Downloading liftOver chain file from UCSC INFO: Exporting variants in BED format Exporting variants: 100% [==================================] 288 137.0K/s in 00:00:00 INFO: Running UCSC liftOver tool Updating table variant: 100% [================================] 288 1.6K/s in 00:00:00  Coordinates in hg18\n$ vtools output variant chr pos ref alt -l 10 1 533 G C 1 41342 T A 1 41791 G A 1 44449 T C 1 44539 C T 1 44571 G C 1 45162 C T 1 52066 T C 1 53534 G A 1 75891 T C  Coordinates in hg19\n$ vtools output variant chr pos ref alt -l 10 --build hg19 1 10533 G C 1 51479 T A 1 51928 G A 1 54586 T C 1 54676 C T 1 54708 G C 1 55299 C T 1 62203 T C 1 63671 G A 1 86028 T C $ vtools use refGene INFO: Downloading annotation database from annoDB/refGene.ann INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/refGene-hg19_20130904.DB.gz INFO: Using annotation DB refGene as refGene in project tutorial. INFO: Known human protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq). $ vtools show annotation refGene Annotation database refGene (version hg19_20130904) Description: Known human protein-coding and non-protein-coding genes taken from the NCBI RNA reference sequences collection (RefSeq). Database type: range Reference genome hg19: chr, txStart, txEnd name (char) Gene name chr (char) strand (char) which DNA strand contains the observed alleles txStart (int) Transcription start position (1-based) txEnd (int) Transcription end position cdsStart (int) Coding region start (1-based) cdsEnd (int) Coding region end exonCount (int) Number of exons exonStarts (char) Starting point of exons (adjusted to 1-based positions) exonEnds (char) Ending point of exons score (int) Score name2 (char) Alternative name cdsStartStat (char) cds start stat, can be 'non', 'unk', 'incompl', and 'cmp1' cdsEndStat (char) cds end stat, can be 'non', 'unk', 'incompl', and 'cmp1' $ vtools show fields variant.chr (char) Chromosome name (VARCHAR) variant.pos (int) Position (INT, 1-based) variant.ref (char) Reference allele (VARCHAR, - for missing allele of an insertion) variant.alt (char) Alternative allele (VARCHAR, - for missing allele of an deletion) variant.AA (char) variant.DP (int) variant.num (int) Created from stat \u0026quot;#(alt)\u0026quot; with type INT on Sep19 variant.hom (int) Created from stat \u0026quot;#(hom)\u0026quot; with type INT on Sep19 variant.het (int) Created from stat \u0026quot;#(het)\u0026quot; with type INT on Sep19 variant.maf (float) Created from stat \u0026quot;maf()\u0026quot; with type FLOAT on Sep19 variant.num12 (int) Created from stat \u0026quot;#(alt)\u0026quot; for samples [\u0026quot;sample_name like 'NA12%'\u0026quot;]with type INT on Sep19 variant.hom12 (int) Created from stat \u0026quot;#(hom)\u0026quot; for samples [\u0026quot;sample_name like 'NA12%'\u0026quot;]with type INT on Sep19 variant.het12 (int) Created from stat \u0026quot;#(het)\u0026quot; for samples [\u0026quot;sample_name like 'NA12%'\u0026quot;]with type INT on Sep19 variant.maf12 (float) Created from stat \u0026quot;maf()\u0026quot; for samples [\u0026quot;sample_name like 'NA12%'\u0026quot;]with type FLOAT on Sep19 variant.nCase (int) Created from stat \u0026quot;#(alt)\u0026quot; for samples ['aff=2']with type INT on Sep19 variant.nCtrl (int) Created from stat \u0026quot;#(alt)\u0026quot; for samples ['aff=1']with type INT on Sep19 variant.alt_chr (char) variant.alt_pos (int) refGene.name (char) Gene name refGene.chr (char) refGene.strand (char) which DNA strand contains the observed alleles refGene.txStart (int) Transcription start position (1-based) refGene.txEnd (int) Transcription end position refGene.cdsStart (int) Coding region start (1-based) refGene.cdsEnd (int) Coding region end refGene.exonCount (int) Number of exons refGene.exonStarts (char) Starting point of exons (adjusted to 1-based positions) refGene.exonEnds (char) Ending point of exons refGene.score (int) Score refGene.name2 (char) Alternative name refGene.cdsStartStat (char) cds start stat, can be 'non', 'unk', 'incompl', and 'cmp1' refGene.cdsEndStat (char) cds end stat, can be 'non', 'unk', 'incompl', and 'cmp1' $ vtools output variant chr pos refGene.name refGene.name2 -l10 1 533 . . 1 41342 . . 1 41791 . . 1 44449 . . 1 44539 . . 1 44571 . . 1 45162 . . 1 52066 . . 1 53534 . . 1 75891 . . $ vtools select variant 'refGene.chr IS NOT NULL' -t in_gene Running: 4 902.7/s in 00:00:00 INFO: 121 variants selected. $ vtools output in_gene chr pos refGene.name refGene.name2 -l10 1 695745 NR_033908 LOC100288069 1 697749 NR_033908 LOC100288069 1 703777 NR_033908 LOC100288069 1 703882 NR_033908 LOC100288069 1 743268 NR_103536 FAM87B 1 743288 NR_103536 FAM87B 1 743404 NR_103536 FAM87B 1 743712 NR_103536 FAM87B 1 744074 NR_103536 FAM87B 1 744197 NR_103536 FAM87B  7.2 dbSNP, dbNSFP, 1000 genomes $ vtools use dbSNP INFO: Downloading annotation database from annoDB/dbSNP.ann INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/dbSNP-hg19_138.DB.gz INFO: Using annotation DB dbSNP as dbSNP in project tutorial. INFO: dbSNP version 138, created using vcf file downloaded from NCBI $ vtools select common 'dbSNP.chr IS NOT NULL' -t in_dbSNP Running: 0 0.0/s in 00:00:00 INFO: 83 variants selected. $ vtools output in_dbSNP chr pos ref alt dbSNP.name -l 10 1 41342 T A rs116400033 1 45162 C T rs10399749 1 52066 T C rs28402963 1 53534 G A rs116440577 1 98173 T C rs74747225 1 225792 G A rs200488504 1 742429 G A rs3094315 1 742584 A G rs3131972 1 743268 C A rs61770173 1 743288 T C rs3131970  Select damaging variants\n$ vtools use dbNSFP INFO: Downloading annotation database from annoDB/dbNSFP.ann INFO: Downloading annotation database from http://vtools.houstonbioinformatics.org/annoDB/dbNSFP-hg18_hg19_2_4.DB.gz INFO: Decompressing /Users/bpeng1/.variant_tools/annoDB/dbNSFP-hg18_hg19_2_4.DB.gz INFO: Using annotation DB dbNSFP as dbNSFP in project tutorial. INFO: dbNSFP version 2.4, maintained by Xiaoming Liu from UTSPH. Please cite \u0026quot;Liu X, Jian X, and Boerwinkle E. 2011. dbNSFP: a lightweight database of human non-synonymous SNPs and their functional predictions. Human Mutation. 32:894-899\u0026quot; and \u0026quot;Liu X, Jian X, and Boerwinkle E. 2013. dbNSFP v2.0: A Database of Human Nonsynonymous SNVs and Their Functional Predictions and Annotations. Human Mutation. 34:E2393-E2402.\u0026quot; if you find this database useful.  Unfortunately, this dataset does not have any nonsynonymous variants recorded in dbNSFP\n$ vtools select variant 'dbNSFP.chr is not NULL' -c Counting variants: 0 0.0/s in 00:00:00 0  8. Slightly more advanced features 8.1 Function ref_genome $ vtools output common chr pos ref 'ref_sequence(chr, pos)' -l 10 1 41342 T T 1 45162 C C 1 52066 T T 1 53534 G G 1 98173 T T 1 225792 G G 1 742429 G G 1 742584 A A 1 743268 C C 1 743288 T T $ vtools output common chr pos ref 'ref_sequence(chr, pos-5, pos+5)' -l 10 1 41342 T TGTATTTTATG 1 45162 C CTATGCGACCT 1 52066 T TATTATATTTT 1 53534 G TCGTCGGCTCA 1 98173 T TTCCATAAGAA 1 225792 G TTTTCGTGTGC 1 742429 G GAAACGTTTGA 1 742584 A GGAAAAGGGAA 1 743268 C GATGGCGGGAA 1 743288 T CTCTGTGGGCC  8.2 Function genotype and samples You can check the genotype of variants in a particular sample\n$ vtools output common chr pos ref alt \u0026quot;genotype('NA07037')\u0026quot; -l 10 1 41342 T A 0 1 45162 C T 2 1 52066 T C 0 1 53534 G A 1 1 98173 T C 1 1 225792 G A 0 1 742429 G A 2 1 742584 A G 2 1 743268 C A 2 1 743288 T C 2  or in all samples\n$ vtools output common chr pos \u0026quot;genotype()\u0026quot; -l 2 1 41342 0,1,1,0,0,1,0,1,1,0,0,0,1,0,0,1,0,0,1,0,1,0,1,1,2,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,2,1,1,1,0,0,0,1,1,2,0,1,0,0,1,1,0,0,0,0 1 45162 0,0,0,1,2,1,0,0,0,0,0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,2,0,1,0,0,0,0,0,1,0,1,0,1,2,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,2,0,0,0  Function samples outputs name of samples that harbor the variants\n$ vtools output common \u0026quot;samples('geno_filter=GT!=0')\u0026quot; -l 2 NA06986,NA06994,NA07051,NA07347,NA07357,NA11830,NA11840,NA11918,NA11920,NA11992,NA11993,NA11994,NA12005,NA12044,NA12154,NA12234,NA12414,NA12489,NA12716,NA12717,NA12760,NA12761,NA12762,NA12776,NA12814,NA12815 NA07000,NA07037,NA07051,NA11829,NA11840,NA11894,NA11995,NA12004,NA12144,NA12155,NA12234,NA12249,NA12761,NA12763,NA12814,NA12828  8.3 Function track A track is an external file that contains information about variants, which can be in format vcf, bam and BigWig and BigBed.\n$ vtools output common chr pos ref alt \u0026quot;track('CEU.vcf.gz')\u0026quot; -l 10 1 41342 T A AA=.;AC=29;AN=120;DP=188 1 45162 C T AA=c;AC=20;AN=120;DP=166;HM2 1 52066 T C AA=C;AC=18;AN=120;DP=159 1 53534 G A AA=G;AC=18;AN=120;DP=243 1 98173 T C AA=.;AC=58;AN=120;DP=184 1 225792 G A AA=.;AC=14;AN=120;DP=464 1 742429 G A AA=g;AC=103;AN=120;DP=314;HM2 1 742584 A G AA=a;AC=103;AN=120;DP=366;HM3 1 743268 C A AA=a;AC=106;AN=120;DP=64 1 743288 T C AA=t;AC=83;AN=120;DP=69  The track function is particularly useful for checking reads that cover a variant in BAM files.\n 8.4 Pipeline ANNOVA $ vtools show pipeline ANNOVAR Pipeline to call ANNOVAR and import results as variant info fields. Available pipelines: geneanno Pipeline \u0026quot;geneanno\u0026quot;: This pipeline exports variants in specified variant table (parameter --var_table, default to variant), executes ANNOVAR's gene-based annotation (annotate_variantion.pl --geneanno), and imports specified fields from output of the command. Four fields (two for all variants and two for exonic variants) will be imported unless you disable some of them using parameters --variant_info and --exonic_info. No input or output file is required for this pipeline, but a snapshot could be specified, in which case the snapshot will be loaded (and overwrite the present project). geneanno_0: Load specified snapshot if a snapshot is specified. Otherwise use the existing project. geneanno_10: Check the existence of ANNOVAR's annotate_variation.pl command. geneanno_11: Determine the humandb path of ANNOVAR geneanno_14: Download gene database for specified --dbtype if they are unavailable geneanno_20: Export variants in ANNOVAR format geneanno_30: Execute ANNOVAR annotate_variation.pl --geneanno geneanno_40: Importing results from ANNOVAR output .variant_function if --variant_info is specified geneanno_50: Importing results from ANNOVAR output .exonic_variant_function if --exonic_info is specified Pipeline parameters: var_table Variant table for the variants to be analyzed. (default: variant) annovar_path Path to a directory that contains annotate_variation.pl, if the script is not in the default $PATH. dbtype --dbtype parameter that will be passed to annotate_variation.pl --dbtype. The default value if refGene, but you can also use knownGene, ensGene. (default: refGene) variant_info Fields to import from the first two columns of .variant_function output of ANNOVAR. (default: region_type, region_name) exonic_info Fields to import from the .exonic_variant_function output of ANNOVAR. It has to be zero, one or more of mut_type and function. (default: mut_type, function)  Using ANNOVAR to annotate variants\n$ vtools execute ANNOVAR --annovar_path ~/bin/annovar/ INFO: Executing ANNOVAR.geneanno_0: Load specified snapshot if a snapshot is specified. Otherwise use the existing project. INFO: Executing ANNOVAR.geneanno_10: Check the existence of ANNOVAR's annotate_variation.pl command. INFO: Command /Users/bpeng1/bin/annovar//annotate_variation.pl is located. INFO: Executing ANNOVAR.geneanno_11: Determine the humandb path of ANNOVAR INFO: Running which /Users/bpeng1/bin/annovar//annotate_variation.pl \u0026gt; cache/annovar.path INFO: Executing ANNOVAR.geneanno_14: Download gene database for specified --dbtype if they are unavailable INFO: Running /Users/bpeng1/bin/annovar//annotate_variation.pl --buildver hg18 -downdb refGene /Users/bpeng1/bin/annovar//humandb INFO: Executing ANNOVAR.geneanno_20: Export variants in ANNOVAR format INFO: Running vtools export variant --format ANNOVAR --output cache/annovar_input INFO: Executing ANNOVAR.geneanno_30: Execute ANNOVAR annotate_variation.pl --geneanno INFO: Running /Users/bpeng1/bin/annovar//annotate_variation.pl --geneanno --dbtype refGene --buildver hg18 cache/annovar_input /Users/bpeng1/bin/annovar//humandb INFO: Executing ANNOVAR.geneanno_40: Importing results from ANNOVAR output .variant_function if --variant_info is specified INFO: Using primary reference genome hg18 of the project. Getting existing variants: 100% [==================================] 288 206.3K/s in 00:00:00 INFO: Updating variants from cache/annovar_input.variant_function (1/1) annovar_input.variant_function: 100% [==============================] 288 20.8K/s in 00:00:00 INFO: Fields region_type, region_name of 288 variants are updated INFO: Running vtools update variant --from_file cache/annovar_input.variant_function --format ANNOVAR_variant_function --var_info region_type, region_name INFO: Executing ANNOVAR.geneanno_50: Importing results from ANNOVAR output .exonic_variant_function if --exonic_info is specified INFO: Using primary reference genome hg18 of the project. Getting existing variants: 100% [==================================] 288 160.6K/s in 00:00:00 INFO: Updating variants from cache/annovar_input.exonic_variant_function (1/1) annovar_input.exonic_variant_function: 0 0.0/s in 00:00:00 INFO: Fields mut_type, function of 0 variants are updated INFO: Running vtools update variant --from_file cache/annovar_input.exonic_variant_function --format ANNOVAR_exonic_variant_function --var_info mut_type, function  8.5 Snapshots Save a snapshot of the project\n$ vtools admin --save_snapshot ACM-BCB2014-tutorial.tgz 'Tutorial section for AVM BCB meeting' ACM-BCB2014-tutorial.tgz: 100% [================================] 358,722 13.6M/s in 00:00:00 INFO: Snapshot ACM-BCB2014-tutorial.tgz has been saved  You can load it using command\n$ vtools admin --load_snapshot ACM-BCB2014-tutorial.tgz Extracting ACM-BCB2014-tutorial.tgz: 0.0% [\u0026gt; ] in 00:00:00 Extracting ACM-BCB2014-tutorial.tgz: 100% [=======================] 74,928 4.5M/s in 00:00:00 INFO: Snapshot ACM-BCB2014-tutorial.tgz has been loaded  It is strongly recommended that you save copies of your project (snapshots) during the analysis of real-world projects.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/documentation/customization/format/formats/functor/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " HomePage Import/Export adjustment functors The following are all the adjustment functions that are provided by variant tools. The export functors are of course only used for exporting variants using .fmt files, and are not used in .ann files.\nAdjust input  IncreaseBy(inc=1), converting 5 -\u0026gt; 6  Increase input integer value by inc. This is usually used to adjust 0-based position to 1-based position that is used by variant tools.\n MapValue(map)\u0026rdquo;\u0026lsquo;, converting A/A -\u0026gt; 2  Map value to another. This function is used to map input value to another one, for example, MapValue({'het': '1', 'hom': '2'}) maps value \u0026lsquo;het\u0026rsquo; to \u0026lsquo;1\u0026rsquo; and \u0026lsquo;hom\u0026rsquo; to \u0026lsquo;2\u0026rsquo;. The mapped values should be strings or None. The item itself will be returned if it cannot be mapped.\n Nullify(val)\u0026rdquo;\u0026lsquo;, converting NA -\u0026gt; None  Treat value as NULL\u0026rdquo;\u0026lsquo;. This is usually used to adjust input NA values to NULL in the database. Multiple NULL values are allowed (e.g. Nullify(['NA', '.'])).\n DiscardRecord(val, keepMatched=False), discard records with (or without) val at specified field  Discard the whole record if the file has val, or is one of val if val is a list at the specified column, or if val is evaluated to be True if val is a lambda function. If keepMatched is true, non-matching records will be discarded. For example, DiscardRecord(lambda x: x.startswith('NC_')) will discard all records with passed value starts with NC_.\n RemoveLeading(val), converting chr10 -\u0026gt; 10  Remove leading characters val. This is usually used to remove leading chr from inputs with chromosomes such as chr1, chr2, because variant tools only stores 1, 2, etc.\nEncode genotype Variant tools ignores phase of genotype and stores 1 for heterozygote (alt/ref), 2 for homozygote (alt/alt), and -1 for both variants (ref/alt1, ref/alt2) for genotype alt1/alt2.\n EncodeGenotype(default=None), converting 1/1 -\u0026gt; 2  Convert genotype formats such as 0/1, 0|1 etc in vcf format to mutation type.\n VcfGenotype(default=None), converting A/A;50 -\u0026gt; 2  Extract genotype as the first item of a field and return mutation type. This is a shortcut to ExtractField(1, ';'), EncodeGenotype(default=None). For a .vcf file with multiple genotype columns, the index should be specified as index=10:.\n VcfGenoFromFormat(default=None), converting GT;DP, A/A;50 -\u0026gt; 2  Extract genotype field according to format specification and return mutation type. This is a shortcut to FieldFromFormat('GT', ';'), EncodeGenotype(default=None). There should be two inputting columns, the first for FORMAT, the second for value. Fields defined by this functor is used to extract genotype from a .vcf file that does not put genotype as the first field.\nThis field requires two input columns, the first one for format, and the second one for genotype field. For a typical .vcf file with multiple samples, this field should have index=9,10: in order to get format string from column 9, and values from columns 10, 11, \u0026hellip;.\nExtract values from a field  ExtractFlag(name, sep=';'), converting SD:SF1:NS=1 -\u0026gt; 1  Split the value by sep, return 1 if it contains name and `` otherwise.\n ExtractField(index, sep=';', default=None), converting 10;20:30 -\u0026gt; 20  Split the value by sep and return the index-th field (1-based). Return default if there are less than index fields. For example, ExtractField(2, ':') extracts 20 from 10:20:30.\n ExtractValue(name, sep=';', default=None), converting AS;MAF=0.4;dbSNP -\u0026gt; 0.4  Split the value by sep, return the rest of an item if it starts with name. For example, functor ExtractValue('MAF=') extracts 0.4 from AS;MAF=0.4;dbSNP.\n FieldFromFormat(name, sep=';', default=None), converting GT;DP, A/A;50 -\u0026gt; 50  Get the format from the first column and extract the corresponding field from the second column. This is used to extract genotype info according to FORMAT column of a vcf file. There should be two input columns, the first for FORMAT, the second for value.\nThis field requires two input columns, the first one for format, and the second one for genotype field. For a typical .vcf file with multiple samples, this field should have index=9,10: in order to get format from column 9, and values from columns 10, 11, \u0026hellip;.\nProduce multiple records  SplitField(sep=','), converting 0.4,0.6 -\u0026gt; (0.4, 0.6)  This functor split value at a column to a tuple of multiple items, which will lead to multiple records if there are more than one items.\n CheckSplit(sep=','), converting A-\u0026gt;A, A,T-\u0026gt;(A, T)  This functor returns a tuple if there are multiple fields (the same as SplitField), and the item itself if it contains only one field (different from SplitField). This functor is used when you would like to copy an value to multiple records if there is a single item, and spread the items to multiple records if there are more than one item.\nRetrieve information from annotation database.  FieldFromDB(dbfile, res_field, cond_fields, default=None), obtaining reference allele from chromosome and position.  This functor accepts an annotation database, and returns value of a field by querying the database with inputted values. For example FieldFromDB(\u0026quot;dbSNP.DB\u0026quot;, \u0026quot;refNCBI\u0026quot;, \u0026quot;chr,start\u0026quot;) with index=1,2 will feed the functor with chromosome and start position from columns 1 and 2 of the input file. The querier will run a query similar to SELECT refNCBI FROM dbSNP WHERE chr=? AND start=? for each input value of chromosome and position, and use the result as the value of this field. A default value will be returned if no record is found, which will most likely invalidate the whole record (because of no reference allele in this case).\nConnecting multiple functors and lambda functions  func1, func2, converting AS=2/3;BD=5 to 3  When multiple functors (or lambda functions) are provided, the output of the first functor will be sent to the second, and so on. If a tuple is returned by one of the functors, the following functors will be applied to items in the tuple one by one. For example, SplitField(','), IncreaseBy(1) will convert 2,3,4 to (2, 3, 4), and then (3, 4, 5). Output values of other types (including list) are passed directly to the next functor/function, although there is no guarantee that the latter functor/function can handle such an input value.\nAdjust output  JoinFields(sep=','), converting field1 field2 -\u0026gt; field1,field2  This functor joins multiple items in different fields into one field. The items are separated by specified delimiter.\n IfMulti(ifFunc=None, elseFunc=None)\n ValueOfNull(val), converting NULL-\u0026gt;val\n  Treat NULL values as specified value. This is usually used to adjust output NULL values to some symbols that the file format conventionally use. For example ValueOfNull('PASS') is applied to output filters for qualified variants, and ValueOfNull('.') for missing genotypes.\n Constant(val=CONSTANT_VAL), converting field_val-\u0026gt;CONSTANT_VAL  Set a constant value to a field.\n SequentialCollector([..extractors..])  Define an extractor that calls a list of extractors. The string extracted from the first extractor will be passed to the second, and so on.\n CSVFormatter()  Format any input as a field in a csv file. It will quote strings with \u0026quot;, , or newline. In the first case, it will also replace all instances of \u0026quot; to \u0026quot;\u0026quot;.\n InfoFormatter(name, ignore='')  Output value val in the format of name=val. Nothing will be outputted if item matches ignore.\n FlagFormatter(name)  Output name if value is True, and '' otherwise.\n GenoFormatter(style='genotype', **kwargs)  This formatter determines how genotypes are outputted.\n style='genotype': Output actual genotype. This style accepts paramters sep and null to specify how to join two genotypes, and what to use for null genotype for indels. For example, if ref=A, alt=T, sep=',' (default is tab), this formatter returns A,A, A,T, T,T, and T,- for homozygous reference alleles, heterozygote, homozygous alternative alleles, and one of double alternative alleles, respectively. Missing data are represented by \u0026lsquo;.\u0026rsquo;.\n style='numeric': Output number of alternative alleles. This style accepts parameter base=0 and outputs `,1,2(ifbase=0for homozygous reference alleles, heterozygote, homozygous alternative alleles. Genotypes with two different alternative alleles are also outputted as 2. Missing data are represented by 'NA`\u0026lsquo;.\n style='vcf': output genotype in vcf format. For example 0/0 for homozygous reference alleles, 1/1 for homozygous alternative alleles, and 1/2 for two different alternative alleles. Missing data are represented by \u0026lsquo;.\u0026rsquo;.\n style='plink': The same as style genotype but treat half-missing genotype (./A) as missing, and ignore all multi-allele variants. Missing data are represented by \u0026lsquo;``\u0026lsquo;.\n  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/_footer/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "copyright = \u0026copy; Bo Peng, Ph.D. / MD AndersonCancer Center All rights reserved\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " Home of Variant Tools   A presentation about variant tools (Oct, 3rd, 2013)  Variant tools is a software tool for the manipulation, annotation, selection, simulation, and analysis of variants in the context of next-gen sequencing analysis. Unlike some other tools used for Next-Gen sequencing analysis, variant tools is project based and provides a whole set of tools to manipulate and analyze genetic variants. Please refer to what you can do with variant tools for a list of features provided by variant tools.\nNews  May 10, 2016: We have released a docker container for variant tools called `mdabioinfo/varianttools`, which allows users to test variant tools without installing it. Jan 20th, 2016: Release of variant tools 2.7.0, with significantly improved variant pipeline tools and support for arbitrary reference genome. Jan 15th, 2015: Release of variant tools 2.6.1, which fixes some issues with Python 3. Dec 20th, 2014: Release of variant tools 2.6.0. This version cleans up the pipeline code to assist users to write customized pipelines and actions. Nov 10th, 2014: Release of variant tools 2.5.1, which is a maintenance release that address a bug with 2.5.0 on the use of user-specified temp_dir. Manhattan and QQ plot engine is also updated to work with ggplot2 version 1.0.0 (backward compatibility is dropped). Oct 15th, 2014: Release of variant tools 2.5.0 with new variant tools repository. The variant tools repository used by variant tools 2.4.0 and earlier has been discontinued. Please upgrade to variant tools 2.5.0 to access the new repository.  Aug 15th, 2014: Release of variant tools 2.4.0. Feb 27th, 2014: Release of variant tools 2.3.0. Jan 16th, 2014: Release of variant tools 2.2.0. Nov 6th, 2013: Release of variant tools 2.1.0, which adds a few useful features such as functions genotype() and samples() SQL function, and the --as option to command vtools use. Oct 9, 2013: Release of variant tools 2.0.1, which is a maintenance release of version 2.0.0. Aug 27, 2013: Release of variant tools 2.0. This is a major release of variant tools with many new features. Please check ChangeLog for details.  More\u0026hellip;\n May 16, 2013: Release of variant tools 1.0.6, which contains a lot of small features and bug fixes. Mar 20, 2013: Release of variant tools 1.0.5. This release adds commands vtools admin --update_resource and vtools_report sequences, and allows the use of arbitrary characters for names of variant tables. Feb 20, 2013: Release of variant tools 1.0.4. This release comes with numerous bug fixed and new minor features. Please check the ChangeLog for details. Oct 21, Nov 10, Nov 26, and Nov 29. 2012: Release of variant tools 1.0.3a, b, c and d to address various small issues. Sep 25, 2012: Release of variant tools version 1.0.3, with new features and improvements in vtools associate, vtools update, vtools phenotype and vtools_report commands. Jul 9th, 2012: Release of variant tools version 1.0.3rc1. Other than a few bug fixes and major performance improvements, this release introduces new commands vtools associate and vtools admin, with more than 20 association tests implemented under a unified association test framework. Jan 24th, 2012: Release of variant tools version 1.0.2. This release fixes a major bug that causes duplicate output in commands vtools output and vtools export when range-based annotation databases are used. All users are recommended to upgrade. Jan 2nd, 2012: Release of variant tools version 1.0.1. This version contains a few new features and bug fixes, and more importantly, dramatic performance improvement for many commands. Please refer to ChangeLog for details about this release. Dec 30th, 2011: the gwasCatalog annotation source is available for download. See examples of how to use gwasCatalog to find published GWA hits that are near your variants. Dec 15th, 2011: Two new annotation sources are available: Cancer Gene Census from the Cancer Genome Project, and the 5400 exomes EVS annotation database from the NHLBI Exome Sequencing Project. Dec 4th, 2011: An application note that describes variant tools has been published online in Bioinformatics. Nov 13, 2011: Release of variant tools version 1.0. Jan 24th, 2012: Release of variant tools version 1.0.2. This release fixes a major bug that causes duplicate output in commands vtools output and vtools export when range-based annotation databases are used. All users are recommended to upgrade. Jan 2nd, 2012: Release of variant tools version 1.0.1. This version contains a few new features and bug fixes, and more importantly, dramatic performance improvement for many commands. Please refer to ChangeLog? for details about this release. Dec 30th, 2011: the gwasCatalog annotation source is available for download. See examples of how to use gwasCatalog to find published GWA hits that are near your variants. Dec 15th, 2011: Two new annotation sources are available: Cancer Gene Census from the Cancer Genome Project, and the 5400 exomes EVS annotation database from the NHLBI Exome Sequencing Project. Dec 4th, 2011: An application note that describes variant tools has been published online in Bioinformatics. Nov 13, 2011: Release of variant tools version 1.0. Nov 7, 2011: A new annotation source called EVS (Exome Variant Server) is available consisting of exome sequencing variants from the NHLBI Exome Sequencing Project (ESP). This data was retrieved from the project\u0026rsquo;s EVS server and contains population-specific allele frequencies (currently for European Americans and African Americans) and various functional annotations for predicted variants in approximately 2500 exomes. Nov 2, 2011: Release of release candidate version 1.0rc3. This version adds option --jobs to a number of vtools commands and allow them to execute in multiple threads or processes. User interface is further cleaned for the final 1.0 release. As a result, support for the MySQL backend is temporarily disabled. Oct 16, 2011: Release of release candidate version 1.0rc2. This version has a new option --children for command vtools init, which allows the creation of a project by merging multiple subprojects. Oct 7, 2011: Release of release candidate version 1.0rc1. This version has a new vtools export command that can export in ANNOVAR and VCF formats. Sep 27, 2011: Release of the second beta. This version contains full Python 3 support and a much more powerful vtools import command. Sep 10, 2011: Release of 1.0 beta. July 15, 2011: Initial public release.   The integrative design of variant tools If you have used other sequencing or association analysis tools such as bedtools and pseq, you will be surprised that variant tools usually does not give you a nice report with a list of variants or genes with some useful information after performing an analysis. Instead, all the information, including results of analysis, are saved in the project in a consistent manner. An extra step is needed to output the information you need. In other words, the management and presentation of information regarding variants are two different processes, and you typically add more and more information to your project during analysis of your data. The end result is that you have immediate access to a large amount of information for the variants you are interested in, which can in turn help you perform more in-depth analysis. Using a fabricated and unusually long command,\n% vtools output # 2 myvariants # 1 chr pos ref alt # 3 hom_case hom_ctrl # 4 dbNSFP.SIFT_score dbSNP.name refGene.name2 # 5 asso1.p_value asso2.p_value # 6 \u0026quot;ref_sequence(chr, pos - 5, pos + 5)\u0026quot; # 7 \u0026quot;track('LP056A.BAM')\u0026quot; # 8 \u0026quot;genotype('WGS1')\u0026quot; # 9 \u0026quot;samples()\u0026quot;   myvariants contains a list of variants, which is a subset of the master variant table (all the variant of your project) and is typically created using command vtools select. Command vtools output output information for all variants in myvariant, which include chr, pos, ref, alt constitute a variant, namely location and type of a mutation. hom_case and hom_ctrl are number of homozygous genotypes of this variant in cases and controls. These are called variant info fields and are added to the project using command vtools update --from_stat dbNSFP.SIFT_score, dbSNP.name and refGene.name2 are annotation information from different annotation databases. Annotation databases are not part of the project. They are connected to the project using command vtools use. asso1.p_value and asso2.p_value are results of two different association analysis. These are annotation databases created by command vtools associate. ref_sequence is a function provided by variant tools to retrieve the reference sequence around the variant. Here 5 basepair of the up and downstream of each variant is returned. track is a function to extract information from external files. In this example, the depth of coverage at the location of the variant in the specified bam file is returned. genotype is another function to get the genotype of this variant in sample WGS1, for example, 1 for heterozygote and 2 for homozygote. Function samples() lists the samples that contain the variant.  As you can see, individual commands such as vtools use and vtools update do not produce any output, but adds information to the project that can be displayed along with others. Then, it is important to remember that all such information can be used to select, prioritize, and analyze your variants. Another fabricated command would look like\n% vtools select # 1 myvariants # 2 \u0026quot;refGene.name2='BRCA1'\u0026quot; # 3 'dbNSFP.SIFT_score \u0026gt; 0.95' 'hom_case \u0026gt; 15' 'hom_ctrl = 0' # 4 'asso1.p_value \u0026lt; 0.05 OR asso2.p_value \u0026lt; 0.05' # 5 --to_table significant # 6   Command vtools select selects variants according to their properties It starts from table myvariants, which was itself selected using some other crieteria, The variants must be in gene BRCA1 and must have \u0026gt; 0.95 SIFT scores (probably damagin) it should appear in at least 15 of the cases as homozygote, and not available (as homozygote) in any of the controls and it should be significant in one of the association tests, the selected variant are written to another table names significant.  In summary, variant tools is NOT designed to be a black-box tool that analyzes your data and generates a nice-looking report with a list of candidate variants or genes. It is a platform under which you can analyze your data using several methods, compare and analyze results, re-compare and re-analyze, and again using different methods or annotation sources, based on the information abtained from your previous analyses.** The unique advantage of variant tools is that you generally do not need to write a bunch of scripts to connect input output of different tools and parse and compare results in different formats, and you have easy access to a huge amount of information that help you select, prioritize and analyze your variants, all from your command line. However, because of the uniqueness of this design, please read through the Concepts section of this website before using variant tools.\n\nThings you can do with variant tools    Catagory Tasks     Variant calling Call variants from raw reads in FASTQ or BAM (convert to FASTQ first) formats using the GATK best practice pipeline.   Import variants Import variants and genotypes in VCF format, with options to import specified variant and genotype info fields.    Import all info and genotype fields, including customized fields from VCF files.    Import SNP and Indel variants from the Illumina CASAVA pipeline before version 1.8 (text files), and variants called from the Complete Genomics pipeline.    Pipeline to import variants from the recent versions of the Illumina CASAVA pipeline (in VCF format) that provides variant calls from two probabilistic models.    Import variants in text or CSV files.    Import variants from files in Plink format.    Import variants from a list of rsnames (dbSNP IDs), or just chromsome and positions, variant information are retrieved from the dbSNP database.    Import data in arbitrary format by defining customized format-description file.   Reference genome Native support for build hg18 and hg19 of the human genome, and other genomes such as the mouse genome. Reference genomes of the human genomes are downloaded automatically when they are used.    Variants in different reference genomes can be imported and analyzed together, through automatic mapping between primary and alternative reference genomes.    Supports the use of annotations in a different reference genome by mapping genomic coordinates across reference genomes.    Easily retrieve reference sequences around variant sites through function ref_sequence. This allows you to check if variants are in, for example, mononucleotide or short-tandem repeat sequences.    Validate the build of reference genome if you are uncertain about the reference genome used in the data.   Variant annotation Standardize annotations from different sources so that you do not have to worry about inconsistencies between the use of chromosome names (with/without leading chr), genomic positions (0- or 1-based) and other nomenclatures.    Annotations are automatically downloaded from online repository, or build from source if needed. Annotation databases are automatically updated although you can use a prior version, or use different versions of the same annotation database at the same time.    Detailed descriptions of available annotation databases are readily available from command vtools show annotation.    Supports CCDS, Entrez, Known Gene, and ref seq definitions of genes, which allow you to identify variants in genes, exon regions, or upstream/downstream of these genes.    Standardize gene names through the use of HUGO Gene Nomenclature Committee approved gene names.    Identify variants in Catalogue of Somatic Mutations in Cancer or within Database of Genomic Variants.    Identify variants in all versions of dbSNP databases, Exome Sequencing project, the thousand genomes project, and the HapMap project.    Annotate variants with SIFT, PolyPhen, MutationTaster and many other prediction scores from dbNSFP.    Check for variants that are in the GWAS Catalog database, or variants that are within certain range of GWAS hits.    Identify variants in highly conserved regions through the phastCons database, or variants in genomic duplication regions.    Pipelines to automatically annotate variants using ANNOVAR and snpEff.    Allow the creation of annotation databases from your own data in vcf format.    Convert variants in a variant tools project to an annotation database to be used by another project, or convert an annotation database to a project for detailed analysis.    Users can define and create their own annotation databases through [Annotation/New/customized annotation description files].   External Annotation Retrieve calls, reads, quality, and coverage information from BAM files, filtered by quality score, strand, type, or flags, and use such information to select variants. This provides a command line alternative to IGV to check raw reads for called variants.    Retreive variant info and genotype information from local or online tabix indexed vcf.gz files, this allows you, for example, to obtain variant info from vcf files on the 1000 genomes website.    Retrive annotation from bigWig or bigBed files, from the ENCODE project.   Samples and Phenotypes Import and keep track of samples using filename and sample names.    Rename samples and merge genotypes from multiple input files.    Arbitrary sample information such as sex, BMI, and ethnicity can be saved as phenotype and used for sample selection or association analysis.    Calculation of number of genotypes, alternative alleles, homozygotes, heterzygotes and other types of genotypes in all or subset of samples.    Calculate minimal, maximum, average values of genotype info (e.g. quality score) across all or selected samples for each variant.   Variant Selection Use sample statistics to select, for example, homozygous variants with acceptable quality that appear only in cases.    Select variants based on their membership in annotation databases such as dbSNP and thousand genomes project.    Select variants from multiple conditions that involves multiple variant and annotation info fields (e.g. SIFT score).    Variants selected by different criteria are kept in multiple variant tables, with meta information.    Compare variant tables and examine differences between two or more variant tables.    Identify De Novo mutations from family based samples, identify variants that share the same sites with an existing set of variants.    Pipelines to identify de novo or recessive mutations that might cause the phenotype of an affected offspring in a family of unaffected parents.   Output variants Output a large number of variant info and annotation fields across different annotation databases altogether.    Output expressions of variant info and annotation fields, including vtools-specific SQL functions.    Output reference sequence around variant site, genotypes of one or more samples, and samples that harbor the variants.    Output summary statistics (e.g. count, average) of variants and variant info fields, grouped by specified fields.   Export variants Export variants in vcf format, with variant and annotation info, and genotypes.    Export variants in other formats such as ANNOVAR and Plink to be analyzed by these programs.    Export variants with variant info and annotation fields in csv format.   Association analysis Use more than 20 association analysis methods to associate variants and genes with qualitative or quantitative traits.    Execute multiple association tests across the genome using multiple processes.    Results of association analyses are saved as annotation databases and are used to annotate individual variants, regardless of groups used to analyze data.    Draw manhantan and other figures from association test results.    Perform meta analysis from association test results.   Reports Print reference sequences for particular regions, or gene, exome etc.    Calculate discordance rate between samples.    Calculate average depth of coverage, number of SNPs and Indels for all or selected samples.    Calculate transition transversion ratio for all or selected variants.    Scatter, box plot, histgram plots for variant info fields, genotype info fields, and phenotypes.   Data Management A project can be saved, transferred and loaded easily as snapshots. A number of online snapshots are provided for learning purposes.    Remove genotypes based on different criteria (e.g. quality score), or remove variants in a variant table.    Merge data from several sub projects (e.g. adding data from different batches).    Split project into sub projects to focus on particular sets of variants or samples.    A resource management system to download and update resources on demand, or in batch.    Please refer to a list of tutorials to get started.\nCitation for variant tools Please cite\nF. Anthony San Lucas, Gao Wang, Paul Scheet, and Bo Peng (2012) Integrated annotation and analysis of genetic variants from next-generation sequencing studies with variant tools, Bioinformatics 28 (3): 421-422.\nfor Variant Tools and\nGao Wang, Bo Peng and Suzanne M. Leal (2014) Variant Association Tools for Quality Control and Analysis of Large-Scale Sequence and Genotyping Array Data, The American Journal of Human Genetics 94 (5): 770–83.\nfor Variant Association Tools, and\nBo Peng (2014) Reproducible Simulations of Realistic Samples for Next-Generation Sequencing Studies Using Variant Simulation Tools, Genetic Epidemiology.\nfor Variant Simulation Tools if you find variant tools helpful and use it in your publication. Thank you.\n"
},
{
	"uri": "https://vatlab.github.io/vat-docs/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vatlab.github.io/vat-docs/under-development/faq/",
	"title": "FAQ",
	"tags": [],
	"description": "",
	"content": " Import data Some of my samples occur in multiple vcf files but their genotype calls may be different. How can I identify them after they are imported? Because a file might contain genotype for multiple samples (.vcf), and genotype for a sample can be spread into several files (your case), a sample in variant tools is uniquely identified by filename and sample_name in the output of \u0026ldquo;vtools show sample\u0026rdquo;. However\n Samples usually come with pre-specified names (the header line of vcf or other text files). But you may customize sample names by option --sample_name in vtools import for different data sources when you import data. The customized names will overwrite the original names. Then your sample can be identified by option --samples 'sample_name = \u0026quot;name\u0026quot;' in vtools select command.\n If there are too many to customize, you could still identify your sample by filename + sample_name (e.g. --samples 'filename like \u0026quot;FILE_1%\u0026quot;' 'sample_name = \u0026quot;NA07000\u0026quot;').\n You can also add a column of customized sample names to the sample table using command vtools phenotype. You can then refer to the samples using the new names. For example you append an additional column sampleID to the sample table, where you customize sample names from different sources, then use --samples 'sampleID=\u0026quot;name\u0026quot;' to identify samples.\n  My filtering commands are running slowly With SQLite and MySQL, you can \u0026ldquo;analyze\u0026rdquo; tables or create indexes on table columns to help speed up queries. Creating indexes though does increase the size of the database and can slow down import speeds. Indexes based on genomic positions are automatically created by vtools.\nCan I rename sample\u0026rsquo;s name Is there a way to merge a sample from the different sources How to update the sample information, inclusing geno, and phenotype information What kind formats can be imported using vtools What kind of formats of the results can be outputed using vtools Can I use the different versions of human genome assembled How to create sub-project Can I exclude some specific samples How to remove the tables I created how to create connection between my samples and the annotation database Can I use more than 1 annotation databases vtools execute 'analyze variant'\nvtools execute 'create index my_index on variant(some_field)'\nFor more help see:\n http://www.sqlite.org/lang_analyze.html http://www.sqlite.org/lang_createindex.html  "
},
{
	"uri": "https://vatlab.github.io/vat-docs/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]